{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2319a5",
   "metadata": {},
   "source": [
    "This notebook will implement changing lora settings and separate dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1959ca-a3c9-46d8-8519-064c38f52007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:48:44.051741Z",
     "iopub.status.busy": "2024-04-05T12:48:44.050047Z",
     "iopub.status.idle": "2024-04-05T12:52:49.260801Z",
     "shell.execute_reply": "2024-04-05T12:52:49.259100Z",
     "shell.execute_reply.started": "2024-04-05T12:48:44.051657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torch==2.1.1 torchaudio torchvision tqdm==4.66.1 accelerate==0.24.1 biopython==1.81 numpy==1.26.2 pandas==2.1.3 \\\n",
    "# transformers==4.35.2 datasets==2.15.0 scikit-learn==1.3.2 umap-learn==0.5.5 sentencepiece==0.1.99 seaborn==0.13.0 scipy==1.11.4 \\\n",
    "# matplotlib==3.8.2 evaluate==0.4.1 deepspeed==0.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060d0bba-32ad-4dc9-b1b8-d1124da1336c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a377270-2995-4da1-a673-5369769a6279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:52:49.264011Z",
     "iopub.status.busy": "2024-04-05T12:52:49.263502Z",
     "iopub.status.idle": "2024-04-05T12:53:29.491461Z",
     "shell.execute_reply": "2024-04-05T12:53:29.490156Z",
     "shell.execute_reply.started": "2024-04-05T12:52:49.263956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "# from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "# from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from transformers import EsmModel, EsmConfig, EsmTokenizer\n",
    "\n",
    "\n",
    "# Initializing a ESM facebook/esm-1b style configuration >>> configuration = EsmConfig()\n",
    "\n",
    "# Initializing a model from the configuration >>> model = ESMModel(configuration)\n",
    "\n",
    "# Accessing the model configuration >>> configuration = model.config\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install umap-learn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0148ff8f-80eb-4bbd-aac7-fe1f371da27a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.508233Z",
     "iopub.status.busy": "2024-04-05T12:53:29.507801Z",
     "iopub.status.idle": "2024-04-05T12:53:29.536614Z",
     "shell.execute_reply": "2024-04-05T12:53:29.514877Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.508197Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.1.1+cu121\n",
      "Cuda version:  12.1\n",
      "Numpy version:  1.26.4\n",
      "Pandas version:  2.2.2\n",
      "Transformers version:  4.35.2\n",
      "Datasets version:  2.19.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96bd9396-a81c-4d87-a722-0d2020627dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.538488Z",
     "iopub.status.busy": "2024-04-05T12:53:29.538089Z",
     "iopub.status.idle": "2024-04-05T12:53:29.768968Z",
     "shell.execute_reply": "2024-04-05T12:53:29.767620Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.538452Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|P24928|RPB1_HUMAN%1775%1791</td>\n",
       "      <td>NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%58%74</td>\n",
       "      <td>SGMGGITAVTVNQSLLSPLVLEVDPNIQAVRTQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q14832|GRM3_HUMAN%829%845</td>\n",
       "      <td>QPQKNVVTHRLHLNRFSVSGTGTTYSQSSASTY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P01106|MYC_HUMAN%46%62</td>\n",
       "      <td>SEDIWKKFELLPTPPLSPSRRSGLCSPSYVAVT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2792%2808</td>\n",
       "      <td>TREGDSMALYNRTRRISQTSQVSVDAAHGYSPR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0  sp|P24928|RPB1_HUMAN%1775%1791  NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS      1\n",
       "1      sp|P05787|K2C8_HUMAN%58%74  SGMGGITAVTVNQSLLSPLVLEVDPNIQAVRTQ      1\n",
       "2    sp|Q14832|GRM3_HUMAN%829%845  QPQKNVVTHRLHLNRFSVSGTGTTYSQSSASTY      1\n",
       "3       sp|P01106|MYC_HUMAN%46%62  SEDIWKKFELLPTPPLSPSRRSGLCSPSYVAVT      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2792%2808  TREGDSMALYNRTRRISQTSQVSVDAAHGYSPR      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/train_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/train_Pos_Neg_Y.fasta'\n",
    "\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b784f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to get the middle character\n",
    "# def get_middle_char(sequence):\n",
    "#     chars = list(sequence)\n",
    "#     middle_index = len(chars) // 2\n",
    "#     return chars[middle_index]\n",
    "\n",
    "# # Apply the function to get the middle characters\n",
    "# df['middle_char'] = df['sequence'].apply(get_middle_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a68724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to count 'S', 'T', 'Y' in a sequence\n",
    "# def count_chars(sequence, char):\n",
    "#     return sequence.count(char)\n",
    "\n",
    "# # Count the occurrences of 'S', 'T', and 'Y' in the sequences\n",
    "# df['count_S'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'S'))\n",
    "# df['count_T'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'T'))\n",
    "# df['count_Y'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'Y'))\n",
    "\n",
    "# # Sum the counts to get the total occurrences in the DataFrame\n",
    "# total_S = df['count_S'].sum()\n",
    "# total_T = df['count_T'].sum()\n",
    "# total_Y = df['count_Y'].sum()\n",
    "\n",
    "# print(f\"Total number of 'S': {total_S}\")\n",
    "# print(f\"Total number of 'T': {total_T}\")\n",
    "# print(f\"Total number of 'Y': {total_Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9c28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group by label and sum the counts\n",
    "# grouped_counts = df.groupby('label')[['count_S', 'count_T', 'count_Y']].sum().reset_index()\n",
    "\n",
    "# # Display the grouped counts\n",
    "# print(grouped_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c189b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate the DataFrame by middle character\n",
    "# df_S = df[df['middle_char'] == 'S']\n",
    "# df_T = df[df['middle_char'] == 'T']\n",
    "# df_Y = df[df['middle_char'] == 'Y']\n",
    "\n",
    "# # Separate each subset by label\n",
    "# df_S_0 = df_S[df_S['label'] == 0]\n",
    "# df_S_1 = df_S[df_S['label'] == 1]\n",
    "# df_T_0 = df_T[df_T['label'] == 0]\n",
    "# df_T_1 = df_T[df_T['label'] == 1]\n",
    "# df_Y_0 = df_Y[df_Y['label'] == 0]\n",
    "# df_Y_1 = df_Y[df_Y['label'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "333000b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "# # Desired number of samples per group\n",
    "# n_samples_S = 500\n",
    "# n_sampple_T = 300\n",
    "# n_sampple_Y = 200\n",
    "# # Perform stratified sampling\n",
    "# df_S_0_resampled = resample(df_S_0, replace=False, n_samples=n_samples_S, random_state=42)\n",
    "# df_S_1_resampled = resample(df_S_1, replace=False, n_samples=n_samples_S, random_state=42)\n",
    "# df_T_0_resampled = resample(df_T_0, replace=True, n_samples=n_sampple_T, random_state=42)\n",
    "# df_T_1_resampled = resample(df_T_1, replace=True, n_samples=n_sampple_T, random_state=42)\n",
    "# df_Y_0_resampled = resample(df_Y_0, replace=True, n_samples=n_sampple_Y, random_state=42)\n",
    "# df_Y_1_resampled = resample(df_Y_1, replace=True, n_samples=n_sampple_Y, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31710914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine the resampled subsets\n",
    "# balanced_df = pd.concat([\n",
    "#     df_S_0_resampled, df_S_1_resampled,\n",
    "#     df_T_0_resampled, df_T_1_resampled,\n",
    "#     df_Y_0_resampled, df_Y_1_resampled\n",
    "# ])\n",
    "\n",
    "# # Shuffle the combined DataFrame\n",
    "# balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# print(\"Balanced DataFrame:\")\n",
    "# print(balanced_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46617eaa-de6d-4d12-82cb-08ec66b4f56a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.771322Z",
     "iopub.status.busy": "2024-04-05T12:53:29.770859Z",
     "iopub.status.idle": "2024-04-05T12:53:29.786558Z",
     "shell.execute_reply": "2024-04-05T12:53:29.785263Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.771275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the dataset into training and validation sets\n",
    "# my_train, my_valid = train_test_split(\n",
    "#     balanced_df, \n",
    "#     test_size=0.2, \n",
    "#     random_state=42, \n",
    "#     stratify=balanced_df[['label', 'middle_char']]\n",
    "# )\n",
    "\n",
    "# my_train=my_train[[\"sequence\", \"label\"]]\n",
    "# my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# # Print the first 5 rows of the training set\n",
    "# print(\"Training Set:\")\n",
    "# print(my_train.shape)\n",
    "\n",
    "# # Print the first 5 rows of the validation set\n",
    "# print(\"\\nValidation Set:\")\n",
    "# print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76760f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "(1584, 2)\n",
      "\n",
      "Validation Set:\n",
      "(396, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "my_train, my_valid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "my_train=my_train[[\"sequence\", \"label\"]]\n",
    "my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the training set\n",
    "print(\"Training Set:\")\n",
    "print(my_train.shape)\n",
    "\n",
    "# Print the first 5 rows of the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a424877b-787c-44fe-bf87-33346ffd3be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.789138Z",
     "iopub.status.busy": "2024-04-05T12:53:29.788675Z",
     "iopub.status.idle": "2024-04-05T12:53:29.816779Z",
     "shell.execute_reply": "2024-04-05T12:53:29.815341Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.789094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifies an existing transformer and introduce the LoRA layers\n",
    "\n",
    "class LoRAConfig:\n",
    "    def __init__(self, lora_rank=8, lora_init_scale=0.01, lora_scaling_rank=2):\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_init_scale = lora_init_scale\n",
    "        self.lora_modules = \".*SelfAttention|.*EncDecAttention\"\n",
    "        self.lora_layers = \"q|k|v|o\"\n",
    "        self.trainable_param_names = \".*layer_norm.*|.*lora_[ab].*\"\n",
    "        self.lora_scaling_rank = lora_scaling_rank\n",
    "        # lora_modules and lora_layers are specified with regular expressions\n",
    "        # see https://www.w3schools.com/python/python_regex.asp for reference\n",
    "        \n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, scaling_rank, init_scale):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.rank = rank\n",
    "        self.scaling_rank = scaling_rank\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        if self.rank > 0:\n",
    "            self.lora_a = nn.Parameter(torch.randn(rank, linear_layer.in_features) * init_scale)\n",
    "            if init_scale < 0:\n",
    "                self.lora_b = nn.Parameter(torch.randn(linear_layer.out_features, rank) * init_scale)\n",
    "            else:\n",
    "                self.lora_b = nn.Parameter(torch.zeros(linear_layer.out_features, rank))\n",
    "        if self.scaling_rank:\n",
    "            self.multi_lora_a = nn.Parameter(\n",
    "                torch.ones(self.scaling_rank, linear_layer.in_features)\n",
    "                + torch.randn(self.scaling_rank, linear_layer.in_features) * init_scale\n",
    "            )\n",
    "            if init_scale < 0:\n",
    "                self.multi_lora_b = nn.Parameter(\n",
    "                    torch.ones(linear_layer.out_features, self.scaling_rank)\n",
    "                    + torch.randn(linear_layer.out_features, self.scaling_rank) * init_scale\n",
    "                )\n",
    "            else:\n",
    "                self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, self.scaling_rank))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.scaling_rank == 1 and self.rank == 0:\n",
    "            # parsimonious implementation for ia3 and lora scaling\n",
    "            if self.multi_lora_a.requires_grad:\n",
    "                hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n",
    "            else:\n",
    "                hidden = F.linear(input, self.weight, self.bias)\n",
    "            if self.multi_lora_b.requires_grad:\n",
    "                hidden = hidden * self.multi_lora_b.flatten()\n",
    "            return hidden\n",
    "        else:\n",
    "            # general implementation for lora (adding and scaling)\n",
    "            weight = self.weight\n",
    "            if self.scaling_rank:\n",
    "                weight = weight * torch.matmul(self.multi_lora_b, self.multi_lora_a) / self.scaling_rank\n",
    "            if self.rank:\n",
    "                weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n",
    "            return F.linear(input, weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, rank={}, scaling_rank={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.rank, self.scaling_rank\n",
    "        )\n",
    "\n",
    "\n",
    "def modify_with_lora(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.lora_modules, m_name):\n",
    "            for c_name, layer in dict(module.named_children()).items():\n",
    "                if re.fullmatch(config.lora_layers, c_name):\n",
    "                    assert isinstance(\n",
    "                        layer, nn.Linear\n",
    "                    ), f\"LoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        c_name,\n",
    "                        LoRALinear(layer, config.lora_rank, config.lora_scaling_rank, config.lora_init_scale),\n",
    "                    )\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e79b323-4677-4723-a5fd-a60dc13a3b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.819433Z",
     "iopub.status.busy": "2024-04-05T12:53:29.818965Z",
     "iopub.status.idle": "2024-04-05T12:53:29.845976Z",
     "shell.execute_reply": "2024-04-05T12:53:29.844438Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.819335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.7, num_labels=2):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class ESMClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, class_config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "   \n",
    "        # Trainable emphasis factor\n",
    "        self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        seq_length = hidden_states.size(1)\n",
    "        middle_idx = seq_length // 2\n",
    "        middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "        # Apply trainable emphasis factor\n",
    "        emphasized_middle_embedding = middle_embedding * self.emphasis_factor\n",
    "\n",
    "        # Combine with the average embedding\n",
    "        average_embedding = torch.mean(hidden_states, dim=1)\n",
    "        combined_embedding = emphasized_middle_embedding + average_embedding\n",
    "\n",
    "        x = self.dropout(combined_embedding)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.out_proj(x)\n",
    "        return logits\n",
    "    \n",
    "from transformers import PreTrainedModel, EsmModel, EsmConfig\n",
    "\n",
    "class ESMForSequenceClassification(PreTrainedModel):\n",
    "    config_class = EsmConfig\n",
    "\n",
    "    def __init__(self, config: EsmConfig, class_config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.esm_model = EsmModel(config)\n",
    "        self.classifier = ESMClassificationHead(config, class_config)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.esm_model(input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        logits = self.classifier(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "            elif self.num_labels > 1 and labels.dtype in (torch.long, torch.int):\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71394626-6f8b-4ca5-80f3-c697e4320bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.848217Z",
     "iopub.status.busy": "2024-04-05T12:53:29.847782Z",
     "iopub.status.idle": "2024-04-05T12:53:29.859841Z",
     "shell.execute_reply": "2024-04-05T12:53:29.858398Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.848182Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "def ESM_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "    model_checkpoint = \"facebook/esm2_t36_3B_UR50D\"\n",
    "\n",
    "    # Load PT5 and tokenizer\n",
    "    tokenizer = EsmTokenizer.from_pretrained(model_checkpoint, cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "    model = EsmModel.from_pretrained(model_checkpoint, cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "    # model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "    # tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", do_lower_case=False, force_download=True) \n",
    "    \n",
    "    # Create new Classifier model with PT5 dimensions\n",
    "    class_config=ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "    class_model = ESMForSequenceClassification(model.config, class_config)\n",
    "    \n",
    "    # # Set encoder and embedding weights to checkpoint weights\n",
    "    # class_model.shared=model.shared\n",
    "    # class_model.encoder=model.encoder    \n",
    "    \n",
    "    # # Delete the checkpoint model\n",
    "    class_model.esm_model = model\n",
    "    model=class_model\n",
    "    del class_model\n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ESM_LoRA_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "    # Add model modification lora\n",
    "    config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "    # Add LoRA layers\n",
    "    model = modify_with_lora(model, config)\n",
    "    \n",
    "    # Freeze Embeddings and Encoder (except LoRA)\n",
    "    for (param_name, param) in model.named_parameters():\n",
    "                param.requires_grad = False\n",
    "    for (param_name, param) in model.classifier.named_parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # for (param_name, param) in model.named_parameters():\n",
    "    #         if re.fullmatch(config.trainable_param_names, param_name):\n",
    "    #             param.requires_grad = True\n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ESM_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4d56b2-c9ca-460d-b977-a1e4ae1e9568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.864172Z",
     "iopub.status.busy": "2024-04-05T12:53:29.863760Z",
     "iopub.status.idle": "2024-04-05T12:53:29.873119Z",
     "shell.execute_reply": "2024-04-05T12:53:29.871609Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.864135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4550fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    \"\"\"Custom early stopping callback that can monitor loss or accuracy.\"\"\"\n",
    "    \n",
    "    def __init__(self, metric_name='eval_loss', early_stopping_patience=3, minimize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric_name (str): Metric to monitor, default 'eval_loss'.\n",
    "            early_stopping_patience (int): Number of checks with no improvement after which training will be stopped.\n",
    "            minimize (bool): Set to True if the metric should be minimized, False if it should be maximized.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_counter = 0\n",
    "        self.minimize = minimize\n",
    "        self.best_metric = float('inf') if minimize else float('-inf')\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        current_metric = kwargs['metrics'][self.metric_name]\n",
    "        \n",
    "        if (self.minimize and current_metric < self.best_metric) or (not self.minimize and current_metric > self.best_metric):\n",
    "            self.best_metric = current_metric\n",
    "            self.early_stopping_counter = 0\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "        \n",
    "        if self.early_stopping_counter >= self.early_stopping_patience:\n",
    "            control.should_training_stop = True\n",
    "            print(f'Stopping early! No improvement in {self.metric_name} for {self.early_stopping_patience} evaluation steps.')\n",
    "\n",
    "\n",
    "class MultiObjectiveEarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        # Extract current validation loss and accuracy\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "\n",
    "        # Check if current loss and accuracy improved significantly\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            # Update best scores and reset wait time\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            # If no improvement, increment the wait counter\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                # If wait exceeds the patience, stop training\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "class MultiObjectiveEarlyStoppingAndSaveCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001, output_dir='./model_output', filename='finetuned_model'):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "        self.output_dir = output_dir\n",
    "        self.filename = filename\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "        model = kwargs['model']\n",
    "\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "            # Save the model as the best so far\n",
    "            self.save_finetuned_parameters(model, os.path.join(self.output_dir, self.filename))\n",
    "            print(f\"Saved improved model to {self.output_dir}/{self.filename}\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "    def save_finetuned_parameters(self, model, filepath):\n",
    "        # Create a dictionary to hold the non-frozen parameters\n",
    "        non_frozen_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "        # Save only the finetuned parameters \n",
    "        torch.save(non_frozen_params, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb8bb11-79b0-4936-9099-f9f8ef97e105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.875565Z",
     "iopub.status.busy": "2024-04-05T12:53:29.875038Z",
     "iopub.status.idle": "2024-04-05T12:53:30.214710Z",
     "shell.execute_reply": "2024-04-05T12:53:30.213349Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.875495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "# Set random seeds for reproducibility of your trainings run\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, min_dist=0.01):\n",
    "    umap_model = umap.UMAP(n_components=n_components)\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    data = {\"UMAP1\": embeddings[:, 0], \"UMAP2\": embeddings[:, 1], \"Label\": labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9)\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_new.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "# Main training fuction\n",
    "def train_per_protein(\n",
    "        train_dataset,         #training data\n",
    "        valid_dataset,         #validation data      \n",
    "        weight_decay,\n",
    "        warmup_pct,\n",
    "        num_labels= 2,    #1 for regression, >1 for classification\n",
    "    \n",
    "        # effective training batch size is batch * accum\n",
    "        # we recommend an effective batch size of 8 \n",
    "        batch= 4,         #for training\n",
    "        accum= 2,         #gradient accumulation\n",
    "    \n",
    "        val_batch = 16,   #batch size for evaluation\n",
    "        epochs=1,       #training epochs\n",
    "        lr= 3e-4,         #recommended learning rate\n",
    "        seed= 42,         #random seed\n",
    "        deepspeed=False,  #if gpu is large enough disable deepspeed for training speedup\n",
    "        gpu= 1,\n",
    "        dropout=0.5, #dropout rate\n",
    "         #L2 weight regularization\n",
    "        lora_rank=4,      #lora rank\n",
    "        lora_init_scale=0.01, #lora scaling rank\n",
    "        lora_scaling_rank=1,       #lora a\n",
    "        ):         #gpu selection (1 for first gpu)\n",
    "\n",
    "    # Set gpu device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # load model\n",
    "    model, tokenizer = ESM_classification_model(num_labels=num_labels, dropout=dropout, lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    # model_checkpoint = \"facebook/esm2_t36_3B_UR50D\"\n",
    "    # tokenizer = EsmTokenizer.from_pretrained(model_checkpoint, cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "    # model = EsmModel.from_pretrained(model_checkpoint, cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    total_steps = epochs * len(train_dataset) // batch\n",
    "    warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "    # Define TrainingArguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir='./results',              # where to save the model\n",
    "        evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "        logging_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        learning_rate=lr,                    # initial learning rate\n",
    "        per_device_train_batch_size=batch,   # batch size per device\n",
    "        gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "        num_train_epochs=epochs,             # number of epochs to train\n",
    "        weight_decay=weight_decay,           # L2 weight regularization\n",
    "        warmup_steps=warmup_steps,           # 10% of total steps\n",
    "        load_best_model_at_end=False,         # load the best model at the end of training\n",
    "        seed=seed,                           # random seed\n",
    "        push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "        logging_dir='./logs',\n",
    "    )\n",
    "    # metric_for_best_model='eval_loss|accuracy'\n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        # Check if predictions have the expected shape\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "        # Now, compute the metric (e.g., accuracy)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        # Return the metric(s) as a dictionary\n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    # For minimizing loss\n",
    "    early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "    # For maximizing accuracy\n",
    "    early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "            early_stopping_patience=3,\n",
    "            min_delta=0.001,\n",
    "            output_dir='./model_output',\n",
    "            filename='finetuned_model_all_esm2.pth'\n",
    "        )],\n",
    "    )    \n",
    "\n",
    "    def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "        embeddings = []\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "    \n",
    "        # Iterate over the sequences in batches\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            # Extract a batch of sequences\n",
    "            batch = sequences[i:i + batch_size]\n",
    "    \n",
    "            # Tokenize the batch using the specified tokenizer and convert to PyTorch tensors\n",
    "            inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                # Forward pass through the model to obtain outputs\n",
    "                outputs = model(**inputs)\n",
    "    \n",
    "            # Extract hidden states from the second-to-last layer (penultimate layer)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "    \n",
    "            # Take the embeddings from the second-to-last layer\n",
    "            embeddings_from_layer = hidden_states[:, 0, :]\n",
    "    \n",
    "            # Extend the list with the generated embeddings\n",
    "            embeddings.extend(embeddings_from_layer)\n",
    "    \n",
    "            print(f\"Batch {i // batch_size + 1}, Second-to-Last Layer Embeddings Shape: {embeddings_from_layer.shape}\")\n",
    "    \n",
    "        return np.array(embeddings)\n",
    "\n",
    "        \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    # Get the best model\n",
    "    # model = trainer.model\n",
    "    # Ensure the best model is loaded\n",
    "    best_model_path = os.path.join('./model_output', 'finetuned_model_all_esm2.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        state_dict = torch.load(best_model_path)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "    # Evaluate the best model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(eval_results)\n",
    "    \n",
    "    # Print the current learning rate\n",
    "    # current_lr = trainer.optimizer.param_groups[0]['lr']\n",
    "    # print(f\"Current learning rate: {current_lr}\")\n",
    "    \n",
    "    # valid_sequences = list(valid_dataset['sequence'])\n",
    "    # valid_embeddings = get_embeddings(model, tokenizer, valid_sequences)\n",
    "\n",
    "    # # Apply UMAP for dimensionality reduction\n",
    "    # umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "    # # Plot UMAP embeddings\n",
    "    # labels = list(valid_dataset['label'])\n",
    "    # plot_umap(umap_embeddings, labels)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b300952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Dataset creation\n",
    "def create_dataset(tokenizer,seqs,labels):\n",
    "    tokenized = tokenizer(seqs, max_length=1024, padding=True, truncation=True)\n",
    "    dataset = Dataset.from_dict(tokenized)\n",
    "    dataset = dataset.add_column(\"labels\", labels)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Initialize the tokenizer\n",
    "model_checkpoint = \"facebook/esm2_t36_3B_UR50D\"\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_checkpoint, cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", do_lower_case=False, force_download=True) \n",
    "\n",
    "train_df = my_train\n",
    "valid_df = my_valid\n",
    "\n",
    "# Preprocess inputs\n",
    "# Replace uncommon AAs with \"X\"\n",
    "train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "# Add spaces between each amino acid for PT5 to correctly use them\n",
    "train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "# Create Datasets\n",
    "train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']))\n",
    "valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f20a2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm all_dephos_withLORA_datasetloader.sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcbe5f",
   "metadata": {},
   "source": [
    "lr 0.0003459380673689418\n",
    "batch 4\n",
    "accum 4\n",
    "dropout_rate 0.6303139405233136\n",
    "weight_decay 7.145415686725527e-05\n",
    "warmup_pct 0.12121786012551566\n",
    "lora_rank 20\n",
    "lora_init_scale 0.004413381171295235\n",
    "lora_scaling_rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a57f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddfce510-da2b-4b95-9491-49f9ae8efb06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T13:08:03.246094Z",
     "iopub.status.busy": "2024-04-05T13:08:03.244479Z",
     "iopub.status.idle": "2024-04-05T14:04:37.162324Z",
     "shell.execute_reply": "2024-04-05T14:04:37.160516Z",
     "shell.execute_reply.started": "2024-04-05T13:08:03.246029Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [01:18<00:00, 39.18s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [00:07<00:00,  4.00s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1188' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1188/1980 11:02 < 07:22, 1.79 it/s, Epoch 12/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.706800</td>\n",
       "      <td>0.642258</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.648500</td>\n",
       "      <td>0.584324</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.601200</td>\n",
       "      <td>0.550624</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.567000</td>\n",
       "      <td>0.545805</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.553400</td>\n",
       "      <td>0.528095</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.562000</td>\n",
       "      <td>0.539324</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.562800</td>\n",
       "      <td>0.544778</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.550300</td>\n",
       "      <td>0.523778</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.535300</td>\n",
       "      <td>0.531071</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.524700</td>\n",
       "      <td>0.548785</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.546800</td>\n",
       "      <td>0.574609</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.555900</td>\n",
       "      <td>0.542341</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 12.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 12.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5310714244842529, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.6859, 'eval_samples_per_second': 45.591, 'eval_steps_per_second': 5.756, 'epoch': 12.0}\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model, history = train_per_protein(train_set, valid_set, num_labels=2, batch=4, accum=4, epochs=20, seed=42, lr=0.0003459380673689418, dropout=0.6303139405233136, weight_decay=7.145415686725527e-05, warmup_pct=0.12121786012551566, lora_rank=20, lora_init_scale=0.004413381171295235, lora_scaling_rank=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ebf90f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 17:26:58,506] A new study created in RDB with name: all_dephos_withLORA_esm2_10epochs\n",
      "Downloading shards: 100%|████████████████████████████████████████████████████████████| 2/2 [17:41<00:00, 530.59s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.12s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 10:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.689405</td>\n",
       "      <td>0.520202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.788500</td>\n",
       "      <td>0.675592</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.761900</td>\n",
       "      <td>0.659121</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.733200</td>\n",
       "      <td>0.645654</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.737900</td>\n",
       "      <td>0.634749</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.627298</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.716100</td>\n",
       "      <td>0.622683</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.705200</td>\n",
       "      <td>0.619486</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.716700</td>\n",
       "      <td>0.617758</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.617190</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 17:56:50,700] Trial 0 finished with values: [0.6177577972412109, 0.7121212121212122] and parameters: {'lr': 1.2096477090251053e-05, 'batch': 2, 'accum': 2, 'dropout_rate': 0.8862958691740843, 'weight_decay': 1.220828584650883e-05, 'warmup_pct': 0.1391730308918508, 'lora_rank': 20, 'lora_init_scale': 0.052007681690013734, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6177577972412109, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.7018, 'eval_samples_per_second': 45.508, 'eval_steps_per_second': 5.746, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7789, 'learning_rate': 4.346828428075696e-06, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6894054412841797, 'eval_accuracy': 0.5202020202020202, 'eval_runtime': 8.6165, 'eval_samples_per_second': 45.958, 'eval_steps_per_second': 5.803, 'epoch': 1.0, 'step': 396}, {'loss': 0.7885, 'learning_rate': 8.693656856151392e-06, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.675592303276062, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 8.6559, 'eval_samples_per_second': 45.749, 'eval_steps_per_second': 5.776, 'epoch': 2.0, 'step': 792}, {'loss': 0.7619, 'learning_rate': 1.1732482328263093e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6591209769248962, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 8.6644, 'eval_samples_per_second': 45.704, 'eval_steps_per_second': 5.771, 'epoch': 3.0, 'step': 1188}, {'loss': 0.7332, 'learning_rate': 1.0056413424225508e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6456542611122131, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 8.666, 'eval_samples_per_second': 45.696, 'eval_steps_per_second': 5.77, 'epoch': 4.0, 'step': 1584}, {'loss': 0.7379, 'learning_rate': 8.380344520187922e-06, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6347485780715942, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 8.6668, 'eval_samples_per_second': 45.692, 'eval_steps_per_second': 5.769, 'epoch': 5.0, 'step': 1980}, {'loss': 0.7372, 'learning_rate': 6.704275616150339e-06, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.6272984743118286, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.6749, 'eval_samples_per_second': 45.649, 'eval_steps_per_second': 5.764, 'epoch': 6.0, 'step': 2376}, {'loss': 0.7161, 'learning_rate': 5.028206712112754e-06, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.6226833462715149, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 8.6775, 'eval_samples_per_second': 45.635, 'eval_steps_per_second': 5.762, 'epoch': 7.0, 'step': 2772}, {'loss': 0.7052, 'learning_rate': 3.3521378080751695e-06, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.6194855570793152, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 8.6829, 'eval_samples_per_second': 45.607, 'eval_steps_per_second': 5.758, 'epoch': 8.0, 'step': 3168}, {'loss': 0.7167, 'learning_rate': 1.6760689040375848e-06, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.6177577972412109, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.6748, 'eval_samples_per_second': 45.649, 'eval_steps_per_second': 5.764, 'epoch': 9.0, 'step': 3564}, {'loss': 0.7175, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.6171899437904358, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 8.69, 'eval_samples_per_second': 45.57, 'eval_steps_per_second': 5.754, 'epoch': 10.0, 'step': 3960}, {'train_runtime': 652.8765, 'train_samples_per_second': 24.262, 'train_steps_per_second': 6.065, 'total_flos': 9465195637497600.0, 'train_loss': 0.7393106171579072, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.6177577972412109, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.7018, 'eval_samples_per_second': 45.508, 'eval_steps_per_second': 5.746, 'epoch': 10.0, 'step': 3960}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [01:07<00:00, 33.54s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.67s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 10:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>0.681951</td>\n",
       "      <td>0.570707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.677700</td>\n",
       "      <td>0.656033</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.657100</td>\n",
       "      <td>0.628518</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.628100</td>\n",
       "      <td>0.603374</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.608800</td>\n",
       "      <td>0.578182</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.584400</td>\n",
       "      <td>0.562656</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.563700</td>\n",
       "      <td>0.552735</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.557300</td>\n",
       "      <td>0.547726</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.546600</td>\n",
       "      <td>0.546117</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.542300</td>\n",
       "      <td>0.544772</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 18:09:59,573] Trial 1 finished with values: [0.544771671295166, 0.7348484848484849] and parameters: {'lr': 1.0270200625557769e-05, 'batch': 2, 'accum': 2, 'dropout_rate': 0.413615614490198, 'weight_decay': 4.0930776655257883e-05, 'warmup_pct': 0.2608180667667771, 'lora_rank': 20, 'lora_init_scale': 0.027063844464573716, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.544771671295166, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.6933, 'eval_samples_per_second': 45.552, 'eval_steps_per_second': 5.752, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.6985, 'learning_rate': 1.9694912579762113e-06, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6819512248039246, 'eval_accuracy': 0.5707070707070707, 'eval_runtime': 8.6364, 'eval_samples_per_second': 45.853, 'eval_steps_per_second': 5.789, 'epoch': 1.0, 'step': 396}, {'loss': 0.6777, 'learning_rate': 3.938982515952423e-06, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6560328602790833, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 8.6839, 'eval_samples_per_second': 45.602, 'eval_steps_per_second': 5.758, 'epoch': 2.0, 'step': 792}, {'loss': 0.6571, 'learning_rate': 5.908473773928634e-06, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6285179257392883, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 8.6796, 'eval_samples_per_second': 45.624, 'eval_steps_per_second': 5.761, 'epoch': 3.0, 'step': 1188}, {'loss': 0.6281, 'learning_rate': 7.877965031904845e-06, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6033744812011719, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 8.6677, 'eval_samples_per_second': 45.687, 'eval_steps_per_second': 5.769, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6088, 'learning_rate': 9.847456289881058e-06, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5781817436218262, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.6803, 'eval_samples_per_second': 45.621, 'eval_steps_per_second': 5.76, 'epoch': 5.0, 'step': 1980}, {'loss': 0.5844, 'learning_rate': 8.584695404160162e-06, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.5626562237739563, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.6802, 'eval_samples_per_second': 45.621, 'eval_steps_per_second': 5.76, 'epoch': 6.0, 'step': 2376}, {'loss': 0.5637, 'learning_rate': 6.438521553120121e-06, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.5527352690696716, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.6757, 'eval_samples_per_second': 45.645, 'eval_steps_per_second': 5.763, 'epoch': 7.0, 'step': 2772}, {'loss': 0.5573, 'learning_rate': 4.292347702080081e-06, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.5477255582809448, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.6768, 'eval_samples_per_second': 45.639, 'eval_steps_per_second': 5.763, 'epoch': 8.0, 'step': 3168}, {'loss': 0.5466, 'learning_rate': 2.1461738510400405e-06, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.5461174845695496, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.6745, 'eval_samples_per_second': 45.651, 'eval_steps_per_second': 5.764, 'epoch': 9.0, 'step': 3564}, {'loss': 0.5423, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.544771671295166, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.6763, 'eval_samples_per_second': 45.642, 'eval_steps_per_second': 5.763, 'epoch': 10.0, 'step': 3960}, {'train_runtime': 648.0735, 'train_samples_per_second': 24.442, 'train_steps_per_second': 6.11, 'total_flos': 9465195637497600.0, 'train_loss': 0.6064531499689275, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.544771671295166, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.6933, 'eval_samples_per_second': 45.552, 'eval_steps_per_second': 5.752, 'epoch': 10.0, 'step': 3960}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [01:01<00:00, 30.66s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.64s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 10:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.783600</td>\n",
       "      <td>0.690641</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.806800</td>\n",
       "      <td>0.680116</td>\n",
       "      <td>0.648990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.769100</td>\n",
       "      <td>0.667798</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>0.652949</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.749500</td>\n",
       "      <td>0.637399</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>0.623301</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.728500</td>\n",
       "      <td>0.612817</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.701300</td>\n",
       "      <td>0.603795</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.701300</td>\n",
       "      <td>0.594605</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.585179</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 18:22:47,587] Trial 2 finished with values: [0.5851788520812988, 0.7171717171717171] and parameters: {'lr': 0.00011898566699055648, 'batch': 2, 'accum': 8, 'dropout_rate': 0.8954826788437121, 'weight_decay': 0.00019241738449361328, 'warmup_pct': 0.23029762276671048, 'lora_rank': 4, 'lora_init_scale': 0.0707825015876256, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5851788520812988, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.7076, 'eval_samples_per_second': 45.477, 'eval_steps_per_second': 5.742, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7836, 'learning_rate': 6.461646205192042e-06, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6906406283378601, 'eval_accuracy': 0.5227272727272727, 'eval_runtime': 8.6295, 'eval_samples_per_second': 45.889, 'eval_steps_per_second': 5.794, 'epoch': 1.0, 'step': 99}, {'loss': 0.8068, 'learning_rate': 1.2923292410384083e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6801159977912903, 'eval_accuracy': 0.648989898989899, 'eval_runtime': 8.6747, 'eval_samples_per_second': 45.65, 'eval_steps_per_second': 5.764, 'epoch': 2.0, 'step': 198}, {'loss': 0.7691, 'learning_rate': 1.9384938615576124e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6677982807159424, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 8.6885, 'eval_samples_per_second': 45.578, 'eval_steps_per_second': 5.755, 'epoch': 3.0, 'step': 297}, {'loss': 0.744, 'learning_rate': 2.5846584820768167e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6529488563537598, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 8.6768, 'eval_samples_per_second': 45.639, 'eval_steps_per_second': 5.762, 'epoch': 4.0, 'step': 396}, {'loss': 0.7495, 'learning_rate': 3.2308231025960206e-05, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6373993158340454, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 8.6791, 'eval_samples_per_second': 45.627, 'eval_steps_per_second': 5.761, 'epoch': 5.0, 'step': 495}, {'loss': 0.734, 'learning_rate': 3.876987723115225e-05, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.6233014464378357, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 8.6862, 'eval_samples_per_second': 45.59, 'eval_steps_per_second': 5.756, 'epoch': 6.0, 'step': 594}, {'loss': 0.7285, 'learning_rate': 4.523152343634429e-05, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.6128171682357788, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.7039, 'eval_samples_per_second': 45.497, 'eval_steps_per_second': 5.745, 'epoch': 7.0, 'step': 693}, {'loss': 0.7013, 'learning_rate': 5.1693169641536334e-05, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.6037947535514832, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 8.6912, 'eval_samples_per_second': 45.563, 'eval_steps_per_second': 5.753, 'epoch': 8.0, 'step': 792}, {'loss': 0.7013, 'learning_rate': 5.815481584672837e-05, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.5946054458618164, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 8.6911, 'eval_samples_per_second': 45.564, 'eval_steps_per_second': 5.753, 'epoch': 9.0, 'step': 891}, {'loss': 0.6896, 'learning_rate': 6.461646205192041e-05, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5851788520812988, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.6904, 'eval_samples_per_second': 45.567, 'eval_steps_per_second': 5.753, 'epoch': 10.0, 'step': 990}, {'train_runtime': 634.3719, 'train_samples_per_second': 24.97, 'train_steps_per_second': 1.561, 'total_flos': 9465195637497600.0, 'train_loss': 0.7407679548167219, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5851788520812988, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.7076, 'eval_samples_per_second': 45.477, 'eval_steps_per_second': 5.742, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [01:02<00:00, 31.49s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.13s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='594' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [594/990 04:25 < 02:57, 2.23 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.713700</td>\n",
       "      <td>0.635564</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.651800</td>\n",
       "      <td>0.585238</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.636500</td>\n",
       "      <td>0.543815</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.557882</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.605100</td>\n",
       "      <td>0.563470</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.604100</td>\n",
       "      <td>0.548514</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 18:29:31,030] Trial 3 finished with values: [0.5438153147697449, 0.75] and parameters: {'lr': 0.0004081619465276262, 'batch': 8, 'accum': 2, 'dropout_rate': 0.7463317480416926, 'weight_decay': 4.9658112332606444e-05, 'warmup_pct': 0.2651769888445791, 'lora_rank': 28, 'lora_init_scale': 0.009364760913461176, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5438153147697449, 'eval_accuracy': 0.75, 'eval_runtime': 8.6719, 'eval_samples_per_second': 45.665, 'eval_steps_per_second': 5.766, 'epoch': 6.0}\n",
      "History:  [{'loss': 0.7137, 'learning_rate': 7.696768134520952e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6355636715888977, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 8.6175, 'eval_samples_per_second': 45.953, 'eval_steps_per_second': 5.802, 'epoch': 1.0, 'step': 99}, {'loss': 0.6518, 'learning_rate': 0.00015393536269041905, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5852380990982056, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 8.6698, 'eval_samples_per_second': 45.676, 'eval_steps_per_second': 5.767, 'epoch': 2.0, 'step': 198}, {'loss': 0.6365, 'learning_rate': 0.00023090304403562855, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5438153147697449, 'eval_accuracy': 0.75, 'eval_runtime': 8.7477, 'eval_samples_per_second': 45.269, 'eval_steps_per_second': 5.716, 'epoch': 3.0, 'step': 297}, {'loss': 0.615, 'learning_rate': 0.0003078707253808381, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5578821301460266, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.6954, 'eval_samples_per_second': 45.541, 'eval_steps_per_second': 5.75, 'epoch': 4.0, 'step': 396}, {'loss': 0.6051, 'learning_rate': 0.00038483840672604757, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.563469648361206, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 8.6807, 'eval_samples_per_second': 45.618, 'eval_steps_per_second': 5.76, 'epoch': 5.0, 'step': 495}, {'loss': 0.6041, 'learning_rate': 0.00034759598026868813, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.548514187335968, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 8.6737, 'eval_samples_per_second': 45.655, 'eval_steps_per_second': 5.765, 'epoch': 6.0, 'step': 594}, {'train_runtime': 266.3569, 'train_samples_per_second': 59.469, 'train_steps_per_second': 3.717, 'total_flos': 5679117382498560.0, 'train_loss': 0.6377191896791812, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5438153147697449, 'eval_accuracy': 0.75, 'eval_runtime': 8.6719, 'eval_samples_per_second': 45.665, 'eval_steps_per_second': 5.766, 'epoch': 6.0, 'step': 594}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:54<00:00, 27.34s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:09<00:00, 34.88s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 07:18, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.714400</td>\n",
       "      <td>0.652686</td>\n",
       "      <td>0.664141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.628100</td>\n",
       "      <td>0.578825</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.557100</td>\n",
       "      <td>0.537681</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.539300</td>\n",
       "      <td>0.524937</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.511400</td>\n",
       "      <td>0.524301</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>0.523429</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 18:40:00,259] Trial 4 finished with values: [0.5234290361404419, 0.7449494949494949] and parameters: {'lr': 0.00017928695155936908, 'batch': 8, 'accum': 4, 'dropout_rate': 0.6476080215943276, 'weight_decay': 6.181385782136418e-05, 'warmup_pct': 0.09463956710801381, 'lora_rank': 20, 'lora_init_scale': 0.0005059760844739306, 'lora_scaling_rank': 8}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5234290361404419, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.6683, 'eval_samples_per_second': 45.684, 'eval_steps_per_second': 5.768, 'epoch': 9.9}\n",
      "History:  [{'loss': 0.7144, 'learning_rate': 4.697893383106462e-05, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.6526862382888794, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 8.634, 'eval_samples_per_second': 45.865, 'eval_steps_per_second': 5.791, 'epoch': 0.99, 'step': 49}, {'loss': 0.647, 'learning_rate': 9.491662141378363e-05, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.59687340259552, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 8.6883, 'eval_samples_per_second': 45.578, 'eval_steps_per_second': 5.755, 'epoch': 2.0, 'step': 99}, {'loss': 0.6281, 'learning_rate': 0.00014189555524484826, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.5788245797157288, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 8.7324, 'eval_samples_per_second': 45.348, 'eval_steps_per_second': 5.726, 'epoch': 2.99, 'step': 148}, {'loss': 0.5722, 'learning_rate': 0.00017277818434104214, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5678238272666931, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 8.7046, 'eval_samples_per_second': 45.493, 'eval_steps_per_second': 5.744, 'epoch': 4.0, 'step': 198}, {'loss': 0.5571, 'learning_rate': 0.00014378458491394946, 'epoch': 4.99, 'step': 247}, {'eval_loss': 0.537680983543396, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.6706, 'eval_samples_per_second': 45.671, 'eval_steps_per_second': 5.767, 'epoch': 4.99, 'step': 247}, {'loss': 0.5334, 'learning_rate': 0.00011419927937609978, 'epoch': 6.0, 'step': 297}, {'eval_loss': 0.5269480347633362, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.6672, 'eval_samples_per_second': 45.69, 'eval_steps_per_second': 5.769, 'epoch': 6.0, 'step': 297}, {'loss': 0.5393, 'learning_rate': 8.520567994900709e-05, 'epoch': 6.99, 'step': 346}, {'eval_loss': 0.5249372124671936, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.6708, 'eval_samples_per_second': 45.671, 'eval_steps_per_second': 5.766, 'epoch': 6.99, 'step': 346}, {'loss': 0.51, 'learning_rate': 5.56203744111574e-05, 'epoch': 8.0, 'step': 396}, {'eval_loss': 0.5276600122451782, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.6743, 'eval_samples_per_second': 45.652, 'eval_steps_per_second': 5.764, 'epoch': 8.0, 'step': 396}, {'loss': 0.5114, 'learning_rate': 2.6626774984064714e-05, 'epoch': 8.99, 'step': 445}, {'eval_loss': 0.5243010520935059, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.6731, 'eval_samples_per_second': 45.658, 'eval_steps_per_second': 5.765, 'epoch': 8.99, 'step': 445}, {'loss': 0.4997, 'learning_rate': 0.0, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.5234290361404419, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.6765, 'eval_samples_per_second': 45.641, 'eval_steps_per_second': 5.763, 'epoch': 9.9, 'step': 490}, {'train_runtime': 439.1554, 'train_samples_per_second': 36.069, 'train_steps_per_second': 1.116, 'total_flos': 9369587600755200.0, 'train_loss': 0.5718005433374521, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.5234290361404419, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.6683, 'eval_samples_per_second': 45.684, 'eval_steps_per_second': 5.768, 'epoch': 9.9, 'step': 490}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:56<00:00, 28.35s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:17<00:00, 38.98s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 10:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.634900</td>\n",
       "      <td>0.575756</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.583700</td>\n",
       "      <td>0.613072</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.545700</td>\n",
       "      <td>0.698903</td>\n",
       "      <td>0.654040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.534200</td>\n",
       "      <td>0.574348</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.575600</td>\n",
       "      <td>0.662424</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>0.778092</td>\n",
       "      <td>0.643939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.596700</td>\n",
       "      <td>0.711759</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.624200</td>\n",
       "      <td>0.634829</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.935111</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.964100</td>\n",
       "      <td>0.856252</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6348291039466858, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.7144, 'eval_samples_per_second': 45.442, 'eval_steps_per_second': 5.738, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.6349, 'learning_rate': 0.00024004770671633355, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5757564902305603, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 8.6193, 'eval_samples_per_second': 45.943, 'eval_steps_per_second': 5.801, 'epoch': 1.0, 'step': 99}, {'loss': 0.5837, 'learning_rate': 0.0004800954134326671, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6130723357200623, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 8.6668, 'eval_samples_per_second': 45.692, 'eval_steps_per_second': 5.769, 'epoch': 2.0, 'step': 198}, {'loss': 0.5457, 'learning_rate': 0.0007201431201490007, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6989028453826904, 'eval_accuracy': 0.6540404040404041, 'eval_runtime': 8.6733, 'eval_samples_per_second': 45.657, 'eval_steps_per_second': 5.765, 'epoch': 3.0, 'step': 297}, {'loss': 0.5342, 'learning_rate': 0.0009601908268653342, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5743482112884521, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 8.6792, 'eval_samples_per_second': 45.626, 'eval_steps_per_second': 5.761, 'epoch': 4.0, 'step': 396}, {'loss': 0.5756, 'learning_rate': 0.0012002385335816677, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6624235510826111, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 8.6838, 'eval_samples_per_second': 45.602, 'eval_steps_per_second': 5.758, 'epoch': 5.0, 'step': 495}, {'loss': 0.5603, 'learning_rate': 0.0014402862402980014, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.7780922055244446, 'eval_accuracy': 0.6439393939393939, 'eval_runtime': 8.6938, 'eval_samples_per_second': 45.549, 'eval_steps_per_second': 5.751, 'epoch': 6.0, 'step': 594}, {'loss': 0.5967, 'learning_rate': 0.001680333947014335, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.7117588520050049, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 8.6821, 'eval_samples_per_second': 45.611, 'eval_steps_per_second': 5.759, 'epoch': 7.0, 'step': 693}, {'loss': 0.6242, 'learning_rate': 0.0019203816537306684, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.6348291039466858, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.6833, 'eval_samples_per_second': 45.605, 'eval_steps_per_second': 5.758, 'epoch': 8.0, 'step': 792}, {'loss': 0.6446, 'learning_rate': 0.002160429360447002, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.9351105093955994, 'eval_accuracy': 0.6590909090909091, 'eval_runtime': 8.6983, 'eval_samples_per_second': 45.526, 'eval_steps_per_second': 5.748, 'epoch': 9.0, 'step': 891}, {'loss': 0.9641, 'learning_rate': 0.0024004770671633355, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.856252133846283, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 8.6933, 'eval_samples_per_second': 45.552, 'eval_steps_per_second': 5.752, 'epoch': 10.0, 'step': 990}, {'train_runtime': 632.2289, 'train_samples_per_second': 25.054, 'train_steps_per_second': 1.566, 'total_flos': 9465195637497600.0, 'train_loss': 0.6264164317737926, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.6348291039466858, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.7144, 'eval_samples_per_second': 45.442, 'eval_steps_per_second': 5.738, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 18:53:52,764] Trial 5 finished with values: [0.6348291039466858, 0.7297979797979798] and parameters: {'lr': 0.0027569115407724367, 'batch': 2, 'accum': 8, 'dropout_rate': 0.2607211054985855, 'weight_decay': 9.5787229327352e-05, 'warmup_pct': 0.14362119201668178, 'lora_rank': 20, 'lora_init_scale': 0.00019059880354827463, 'lora_scaling_rank': 5}. \n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [01:03<00:00, 31.69s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:04<00:00, 32.22s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='396' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [396/990 03:40 < 05:31, 1.79 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.711700</td>\n",
       "      <td>0.578993</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.616600</td>\n",
       "      <td>0.847660</td>\n",
       "      <td>0.626263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.734100</td>\n",
       "      <td>1.358792</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.748836</td>\n",
       "      <td>0.643939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5789932608604431, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 8.7554, 'eval_samples_per_second': 45.229, 'eval_steps_per_second': 5.711, 'epoch': 4.0}\n",
      "History:  [{'loss': 0.7117, 'learning_rate': 0.0009528941035639227, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5789932608604431, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 8.6216, 'eval_samples_per_second': 45.931, 'eval_steps_per_second': 5.799, 'epoch': 1.0, 'step': 99}, {'loss': 0.6166, 'learning_rate': 0.0019057882071278453, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.8476597666740417, 'eval_accuracy': 0.6262626262626263, 'eval_runtime': 8.6707, 'eval_samples_per_second': 45.671, 'eval_steps_per_second': 5.767, 'epoch': 2.0, 'step': 198}, {'loss': 0.7341, 'learning_rate': 0.002858682310691768, 'epoch': 3.0, 'step': 297}, {'eval_loss': 1.3587924242019653, 'eval_accuracy': 0.5833333333333334, 'eval_runtime': 8.6991, 'eval_samples_per_second': 45.522, 'eval_steps_per_second': 5.748, 'epoch': 3.0, 'step': 297}, {'loss': 0.8167, 'learning_rate': 0.0038115764142556906, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.748835563659668, 'eval_accuracy': 0.6439393939393939, 'eval_runtime': 8.7392, 'eval_samples_per_second': 45.313, 'eval_steps_per_second': 5.721, 'epoch': 4.0, 'step': 396}, {'train_runtime': 220.7336, 'train_samples_per_second': 71.761, 'train_steps_per_second': 4.485, 'total_flos': 3786078254999040.0, 'train_loss': 0.7197757393422753, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5789932608604431, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 8.7554, 'eval_samples_per_second': 45.229, 'eval_steps_per_second': 5.711, 'epoch': 4.0, 'step': 396}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 19:00:52,105] Trial 6 finished with values: [0.5789932608604431, 0.6944444444444444] and parameters: {'lr': 0.008999555422548159, 'batch': 4, 'accum': 4, 'dropout_rate': 0.14761758691258767, 'weight_decay': 0.0007377900983509194, 'warmup_pct': 0.23612315033252695, 'lora_rank': 16, 'lora_init_scale': 0.010160199572123862, 'lora_scaling_rank': 4}. \n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:59<00:00, 29.61s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:06<00:00, 33.26s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 792/1980 05:26 < 08:11, 2.42 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.653600</td>\n",
       "      <td>0.577994</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.714200</td>\n",
       "      <td>1.045694</td>\n",
       "      <td>0.616162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>1.967021</td>\n",
       "      <td>0.573232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.307100</td>\n",
       "      <td>1.942472</td>\n",
       "      <td>0.550505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 19:09:33,404] Trial 7 finished with values: [0.5779942274093628, 0.6843434343434344] and parameters: {'lr': 0.004934926329922867, 'batch': 1, 'accum': 8, 'dropout_rate': 0.22195362227820523, 'weight_decay': 2.3351776819301044e-05, 'warmup_pct': 0.057928989187117155, 'lora_rank': 32, 'lora_init_scale': 0.008641960750323212, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5779942274093628, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 8.6768, 'eval_samples_per_second': 45.639, 'eval_steps_per_second': 5.762, 'epoch': 4.0}\n",
      "History:  [{'loss': 0.6536, 'learning_rate': 0.0010655566121316549, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.5779942274093628, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 8.6408, 'eval_samples_per_second': 45.829, 'eval_steps_per_second': 5.786, 'epoch': 1.0, 'step': 198}, {'loss': 0.7142, 'learning_rate': 0.0021311132242633098, 'epoch': 2.0, 'step': 396}, {'eval_loss': 1.0456938743591309, 'eval_accuracy': 0.6161616161616161, 'eval_runtime': 8.6584, 'eval_samples_per_second': 45.736, 'eval_steps_per_second': 5.775, 'epoch': 2.0, 'step': 396}, {'loss': 1.31, 'learning_rate': 0.003196669836394965, 'epoch': 3.0, 'step': 594}, {'eval_loss': 1.9670205116271973, 'eval_accuracy': 0.5732323232323232, 'eval_runtime': 8.6807, 'eval_samples_per_second': 45.618, 'eval_steps_per_second': 5.76, 'epoch': 3.0, 'step': 594}, {'loss': 1.3071, 'learning_rate': 0.0042622264485266195, 'epoch': 4.0, 'step': 792}, {'eval_loss': 1.9424716234207153, 'eval_accuracy': 0.5505050505050505, 'eval_runtime': 8.6657, 'eval_samples_per_second': 45.697, 'eval_steps_per_second': 5.77, 'epoch': 4.0, 'step': 792}, {'train_runtime': 327.32, 'train_samples_per_second': 48.393, 'train_steps_per_second': 6.049, 'total_flos': 3786078254999040.0, 'train_loss': 0.9962206753817472, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5779942274093628, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 8.6768, 'eval_samples_per_second': 45.639, 'eval_steps_per_second': 5.762, 'epoch': 4.0, 'step': 792}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:55<00:00, 27.61s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:11<00:00, 35.96s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 13:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.961700</td>\n",
       "      <td>0.797144</td>\n",
       "      <td>0.631313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.909900</td>\n",
       "      <td>0.791030</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.131100</td>\n",
       "      <td>1.909006</td>\n",
       "      <td>0.618687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.030700</td>\n",
       "      <td>0.923296</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.969100</td>\n",
       "      <td>2.181805</td>\n",
       "      <td>0.598485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.756700</td>\n",
       "      <td>1.034025</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.568400</td>\n",
       "      <td>0.990446</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.270400</td>\n",
       "      <td>0.961296</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.219900</td>\n",
       "      <td>0.891583</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.059500</td>\n",
       "      <td>0.888879</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.9904463887214661, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.6762, 'eval_samples_per_second': 45.642, 'eval_steps_per_second': 5.763, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 19:26:32,546] Trial 8 finished with values: [0.9904463887214661, 0.7348484848484849] and parameters: {'lr': 0.002912953408907577, 'batch': 1, 'accum': 4, 'dropout_rate': 0.4902359944474415, 'weight_decay': 2.0702484546489544e-05, 'warmup_pct': 0.031052102466765805, 'lora_rank': 20, 'lora_init_scale': 0.007870251763224553, 'lora_scaling_rank': 7}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9617, 'learning_rate': 0.0023493473521942984, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.7971442341804504, 'eval_accuracy': 0.6313131313131313, 'eval_runtime': 8.6081, 'eval_samples_per_second': 46.003, 'eval_steps_per_second': 5.808, 'epoch': 1.0, 'step': 396}, {'loss': 1.9099, 'learning_rate': 0.002660200749328107, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.7910295724868774, 'eval_accuracy': 0.6590909090909091, 'eval_runtime': 8.6499, 'eval_samples_per_second': 45.781, 'eval_steps_per_second': 5.78, 'epoch': 2.0, 'step': 792}, {'loss': 2.1311, 'learning_rate': 0.002327675655662094, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 1.909005880355835, 'eval_accuracy': 0.6186868686868687, 'eval_runtime': 8.6704, 'eval_samples_per_second': 45.673, 'eval_steps_per_second': 5.767, 'epoch': 3.0, 'step': 1188}, {'loss': 2.0307, 'learning_rate': 0.0019951505619960805, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.9232956171035767, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.6697, 'eval_samples_per_second': 45.676, 'eval_steps_per_second': 5.767, 'epoch': 4.0, 'step': 1584}, {'loss': 1.9691, 'learning_rate': 0.001662625468330067, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 2.18180513381958, 'eval_accuracy': 0.5984848484848485, 'eval_runtime': 8.6769, 'eval_samples_per_second': 45.639, 'eval_steps_per_second': 5.762, 'epoch': 5.0, 'step': 1980}, {'loss': 1.7567, 'learning_rate': 0.0013301003746640535, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 1.0340253114700317, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.6715, 'eval_samples_per_second': 45.667, 'eval_steps_per_second': 5.766, 'epoch': 6.0, 'step': 2376}, {'loss': 1.5684, 'learning_rate': 0.0009975752809980403, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.9904463887214661, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.6717, 'eval_samples_per_second': 45.666, 'eval_steps_per_second': 5.766, 'epoch': 7.0, 'step': 2772}, {'loss': 1.2704, 'learning_rate': 0.0006650501873320268, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.9612960815429688, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.677, 'eval_samples_per_second': 45.638, 'eval_steps_per_second': 5.762, 'epoch': 8.0, 'step': 3168}, {'loss': 1.2199, 'learning_rate': 0.0003325250936660134, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.8915832042694092, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.6682, 'eval_samples_per_second': 45.684, 'eval_steps_per_second': 5.768, 'epoch': 9.0, 'step': 3564}, {'loss': 1.0595, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.8888789415359497, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.6728, 'eval_samples_per_second': 45.66, 'eval_steps_per_second': 5.765, 'epoch': 10.0, 'step': 3960}, {'train_runtime': 826.5267, 'train_samples_per_second': 19.165, 'train_steps_per_second': 4.791, 'total_flos': 9465195637497600.0, 'train_loss': 1.5877514694676256, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.9904463887214661, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.6762, 'eval_samples_per_second': 45.642, 'eval_steps_per_second': 5.763, 'epoch': 10.0, 'step': 3960}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:56<00:00, 28.44s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:03<00:00, 31.98s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 990/1980 05:18 < 05:19, 3.10 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.666600</td>\n",
       "      <td>0.584397</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.528101</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.548600</td>\n",
       "      <td>0.597071</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.548100</td>\n",
       "      <td>0.551524</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.535600</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 19:35:00,206] Trial 9 finished with values: [0.5281009078025818, 0.7449494949494949] and parameters: {'lr': 0.0007104344311914382, 'batch': 2, 'accum': 4, 'dropout_rate': 0.47515628014197364, 'weight_decay': 4.2680689464591e-05, 'warmup_pct': 0.25978311686311467, 'lora_rank': 24, 'lora_init_scale': 0.00015138221835655442, 'lora_scaling_rank': 7}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5281009078025818, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.7153, 'eval_samples_per_second': 45.437, 'eval_steps_per_second': 5.737, 'epoch': 5.0}\n",
      "History:  [{'loss': 0.6666, 'learning_rate': 6.838406289543254e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.5843965411186218, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 8.6355, 'eval_samples_per_second': 45.857, 'eval_steps_per_second': 5.79, 'epoch': 1.0, 'step': 198}, {'loss': 0.593, 'learning_rate': 0.00013676812579086509, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.5281009078025818, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.6906, 'eval_samples_per_second': 45.566, 'eval_steps_per_second': 5.753, 'epoch': 2.0, 'step': 396}, {'loss': 0.5486, 'learning_rate': 0.00020515218868629763, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.5970714092254639, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 8.6927, 'eval_samples_per_second': 45.556, 'eval_steps_per_second': 5.752, 'epoch': 3.0, 'step': 594}, {'loss': 0.5481, 'learning_rate': 0.00027353625158173017, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5515238046646118, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.6788, 'eval_samples_per_second': 45.628, 'eval_steps_per_second': 5.761, 'epoch': 4.0, 'step': 792}, {'loss': 0.5356, 'learning_rate': 0.00034192031447716274, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5603107213973999, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 8.6867, 'eval_samples_per_second': 45.587, 'eval_steps_per_second': 5.756, 'epoch': 5.0, 'step': 990}, {'train_runtime': 318.8112, 'train_samples_per_second': 49.685, 'train_steps_per_second': 6.211, 'total_flos': 4732597818748800.0, 'train_loss': 0.578352024579289, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5281009078025818, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.7153, 'eval_samples_per_second': 45.437, 'eval_steps_per_second': 5.737, 'epoch': 5.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:55<00:00, 27.51s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:07<00:00, 33.51s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 09:07, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.715300</td>\n",
       "      <td>0.682685</td>\n",
       "      <td>0.550505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>0.631262</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.612300</td>\n",
       "      <td>0.581222</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>0.553331</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.535118</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.511800</td>\n",
       "      <td>0.529092</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 19:47:19,390] Trial 10 finished with values: [0.5290924906730652, 0.7297979797979798] and parameters: {'lr': 5.89484696049294e-05, 'batch': 4, 'accum': 8, 'dropout_rate': 0.5203078434895401, 'weight_decay': 0.0008194509123821745, 'warmup_pct': 0.11303351581895987, 'lora_rank': 4, 'lora_init_scale': 0.015064076499209917, 'lora_scaling_rank': 8}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5290924906730652, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.6806, 'eval_samples_per_second': 45.619, 'eval_steps_per_second': 5.76, 'epoch': 9.9}\n",
      "History:  [{'loss': 0.7153, 'learning_rate': 6.461912775484431e-06, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.6826848387718201, 'eval_accuracy': 0.5505050505050505, 'eval_runtime': 8.6355, 'eval_samples_per_second': 45.857, 'eval_steps_per_second': 5.79, 'epoch': 0.99, 'step': 49}, {'loss': 0.6837, 'learning_rate': 1.3055701321897117e-05, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.6560442447662354, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 8.6945, 'eval_samples_per_second': 45.546, 'eval_steps_per_second': 5.751, 'epoch': 2.0, 'step': 99}, {'loss': 0.6675, 'learning_rate': 1.9517614097381544e-05, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.6312618255615234, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 8.7225, 'eval_samples_per_second': 45.4, 'eval_steps_per_second': 5.732, 'epoch': 2.99, 'step': 148}, {'loss': 0.6282, 'learning_rate': 2.6111402643794233e-05, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.6022919416427612, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.7541, 'eval_samples_per_second': 45.236, 'eval_steps_per_second': 5.712, 'epoch': 4.0, 'step': 198}, {'loss': 0.6123, 'learning_rate': 3.257331541927866e-05, 'epoch': 4.99, 'step': 247}, {'eval_loss': 0.5812215209007263, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.7258, 'eval_samples_per_second': 45.383, 'eval_steps_per_second': 5.73, 'epoch': 4.99, 'step': 247}, {'loss': 0.5802, 'learning_rate': 3.916710396569135e-05, 'epoch': 6.0, 'step': 297}, {'eval_loss': 0.5652943849563599, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 8.6779, 'eval_samples_per_second': 45.633, 'eval_steps_per_second': 5.762, 'epoch': 6.0, 'step': 297}, {'loss': 0.5753, 'learning_rate': 4.5629016741175774e-05, 'epoch': 6.99, 'step': 346}, {'eval_loss': 0.5533308386802673, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.6875, 'eval_samples_per_second': 45.583, 'eval_steps_per_second': 5.755, 'epoch': 6.99, 'step': 346}, {'loss': 0.5467, 'learning_rate': 5.2222805287588466e-05, 'epoch': 8.0, 'step': 396}, {'eval_loss': 0.5424785614013672, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 8.6823, 'eval_samples_per_second': 45.61, 'eval_steps_per_second': 5.759, 'epoch': 8.0, 'step': 396}, {'loss': 0.535, 'learning_rate': 5.868471806307289e-05, 'epoch': 8.99, 'step': 445}, {'eval_loss': 0.535118043422699, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.6801, 'eval_samples_per_second': 45.621, 'eval_steps_per_second': 5.76, 'epoch': 8.99, 'step': 445}, {'loss': 0.5118, 'learning_rate': 0.0, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.5290924906730652, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.685, 'eval_samples_per_second': 45.596, 'eval_steps_per_second': 5.757, 'epoch': 9.9, 'step': 490}, {'train_runtime': 548.5851, 'train_samples_per_second': 28.874, 'train_steps_per_second': 0.893, 'total_flos': 9369587600755200.0, 'train_loss': 0.6063753244828205, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.5290924906730652, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.6806, 'eval_samples_per_second': 45.619, 'eval_steps_per_second': 5.76, 'epoch': 9.9, 'step': 490}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:52<00:00, 26.37s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:06<00:00, 33.02s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='594' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [594/990 06:19 < 04:13, 1.56 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.625699</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.606100</td>\n",
       "      <td>0.560903</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.550100</td>\n",
       "      <td>0.528058</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.504200</td>\n",
       "      <td>0.529247</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.472900</td>\n",
       "      <td>0.582825</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.453300</td>\n",
       "      <td>0.590922</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5280579328536987, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.6919, 'eval_samples_per_second': 45.56, 'eval_steps_per_second': 5.752, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 19:56:46,822] Trial 11 finished with values: [0.5280579328536987, 0.73989898989899] and parameters: {'lr': 0.000446961084768937, 'batch': 2, 'accum': 8, 'dropout_rate': 0.13593676381148, 'weight_decay': 1.792856327687685e-05, 'warmup_pct': 0.2321417677406349, 'lora_rank': 8, 'lora_init_scale': 0.029424776459038814, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6741, 'learning_rate': 2.4074617732385616e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6256986856460571, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 8.6382, 'eval_samples_per_second': 45.843, 'eval_steps_per_second': 5.788, 'epoch': 1.0, 'step': 99}, {'loss': 0.6061, 'learning_rate': 4.814923546477123e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5609028935432434, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.6816, 'eval_samples_per_second': 45.614, 'eval_steps_per_second': 5.759, 'epoch': 2.0, 'step': 198}, {'loss': 0.5501, 'learning_rate': 7.222385319715685e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5280579328536987, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.6687, 'eval_samples_per_second': 45.681, 'eval_steps_per_second': 5.768, 'epoch': 3.0, 'step': 297}, {'loss': 0.5042, 'learning_rate': 9.629847092954246e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5292474031448364, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.68, 'eval_samples_per_second': 45.622, 'eval_steps_per_second': 5.76, 'epoch': 4.0, 'step': 396}, {'loss': 0.4729, 'learning_rate': 0.00012037308866192808, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5828250050544739, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 8.6866, 'eval_samples_per_second': 45.588, 'eval_steps_per_second': 5.756, 'epoch': 5.0, 'step': 495}, {'loss': 0.4533, 'learning_rate': 0.0001444477063943137, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5909222960472107, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 8.6738, 'eval_samples_per_second': 45.655, 'eval_steps_per_second': 5.764, 'epoch': 6.0, 'step': 594}, {'train_runtime': 380.1107, 'train_samples_per_second': 41.672, 'train_steps_per_second': 2.605, 'total_flos': 5679117382498560.0, 'train_loss': 0.5434402632793593, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5280579328536987, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.6919, 'eval_samples_per_second': 45.56, 'eval_steps_per_second': 5.752, 'epoch': 6.0, 'step': 594}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:53<00:00, 26.61s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:05<00:00, 32.85s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2376' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2376/3960 06:27 < 04:18, 6.12 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.680900</td>\n",
       "      <td>0.629230</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.618100</td>\n",
       "      <td>0.566937</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.567100</td>\n",
       "      <td>0.535487</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.536400</td>\n",
       "      <td>0.539764</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.501100</td>\n",
       "      <td>0.547785</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.500700</td>\n",
       "      <td>0.599630</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 20:06:19,561] Trial 12 finished with values: [0.5354869365692139, 0.73989898989899] and parameters: {'lr': 6.713090842842659e-05, 'batch': 2, 'accum': 2, 'dropout_rate': 0.3042910427615749, 'weight_decay': 1.1285404750170886e-05, 'warmup_pct': 0.2804275853982079, 'lora_rank': 20, 'lora_init_scale': 0.00032162137363651595, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5354869365692139, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.7196, 'eval_samples_per_second': 45.415, 'eval_steps_per_second': 5.734, 'epoch': 6.0}\n",
      "History:  [{'loss': 0.6809, 'learning_rate': 1.1974702584530149e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6292296648025513, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 8.6177, 'eval_samples_per_second': 45.952, 'eval_steps_per_second': 5.802, 'epoch': 1.0, 'step': 396}, {'loss': 0.6181, 'learning_rate': 2.3949405169060297e-05, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.5669369101524353, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 8.6661, 'eval_samples_per_second': 45.695, 'eval_steps_per_second': 5.77, 'epoch': 2.0, 'step': 792}, {'loss': 0.5671, 'learning_rate': 3.5924107753590444e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.5354869365692139, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.6707, 'eval_samples_per_second': 45.671, 'eval_steps_per_second': 5.767, 'epoch': 3.0, 'step': 1188}, {'loss': 0.5364, 'learning_rate': 4.7898810338120594e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.5397644639015198, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.7045, 'eval_samples_per_second': 45.494, 'eval_steps_per_second': 5.744, 'epoch': 4.0, 'step': 1584}, {'loss': 0.5011, 'learning_rate': 5.987351292265074e-05, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.547784686088562, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.7022, 'eval_samples_per_second': 45.506, 'eval_steps_per_second': 5.746, 'epoch': 5.0, 'step': 1980}, {'loss': 0.5007, 'learning_rate': 6.111227525898145e-05, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.5996296405792236, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.6823, 'eval_samples_per_second': 45.61, 'eval_steps_per_second': 5.759, 'epoch': 6.0, 'step': 2376}, {'train_runtime': 387.9682, 'train_samples_per_second': 40.828, 'train_steps_per_second': 10.207, 'total_flos': 5679117382498560.0, 'train_loss': 0.5673972556888054, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.5354869365692139, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.7196, 'eval_samples_per_second': 45.415, 'eval_steps_per_second': 5.734, 'epoch': 6.0, 'step': 2376}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:57<00:00, 28.68s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:08<00:00, 34.47s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 10:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.731200</td>\n",
       "      <td>0.691921</td>\n",
       "      <td>0.512626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.724200</td>\n",
       "      <td>0.683760</td>\n",
       "      <td>0.588384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.732800</td>\n",
       "      <td>0.674603</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.708800</td>\n",
       "      <td>0.662667</td>\n",
       "      <td>0.664141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.715900</td>\n",
       "      <td>0.650353</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.637896</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.688300</td>\n",
       "      <td>0.625463</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.666900</td>\n",
       "      <td>0.616140</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.654700</td>\n",
       "      <td>0.604880</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.662100</td>\n",
       "      <td>0.594351</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 20:20:08,442] Trial 13 finished with values: [0.5943505167961121, 0.7146464646464646] and parameters: {'lr': 4.696911119100029e-05, 'batch': 2, 'accum': 8, 'dropout_rate': 0.7658440013151991, 'weight_decay': 0.00037146872962171934, 'warmup_pct': 0.28380215241353346, 'lora_rank': 32, 'lora_init_scale': 0.0002079086093280365, 'lora_scaling_rank': 6}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5943505167961121, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.706, 'eval_samples_per_second': 45.486, 'eval_steps_per_second': 5.743, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7312, 'learning_rate': 2.0694000925273826e-06, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6919211745262146, 'eval_accuracy': 0.5126262626262627, 'eval_runtime': 8.6207, 'eval_samples_per_second': 45.936, 'eval_steps_per_second': 5.8, 'epoch': 1.0, 'step': 99}, {'loss': 0.7242, 'learning_rate': 4.138800185054765e-06, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6837600469589233, 'eval_accuracy': 0.5883838383838383, 'eval_runtime': 8.6659, 'eval_samples_per_second': 45.697, 'eval_steps_per_second': 5.77, 'epoch': 2.0, 'step': 198}, {'loss': 0.7328, 'learning_rate': 6.208200277582148e-06, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6746031045913696, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 8.6737, 'eval_samples_per_second': 45.655, 'eval_steps_per_second': 5.765, 'epoch': 3.0, 'step': 297}, {'loss': 0.7088, 'learning_rate': 8.27760037010953e-06, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.662667453289032, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 8.667, 'eval_samples_per_second': 45.691, 'eval_steps_per_second': 5.769, 'epoch': 4.0, 'step': 396}, {'loss': 0.7159, 'learning_rate': 1.0347000462636913e-05, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.650353193283081, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 8.6777, 'eval_samples_per_second': 45.634, 'eval_steps_per_second': 5.762, 'epoch': 5.0, 'step': 495}, {'loss': 0.7, 'learning_rate': 1.2416400555164296e-05, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.6378961205482483, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 8.6902, 'eval_samples_per_second': 45.569, 'eval_steps_per_second': 5.754, 'epoch': 6.0, 'step': 594}, {'loss': 0.6883, 'learning_rate': 1.4485800647691678e-05, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.6254627108573914, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.6912, 'eval_samples_per_second': 45.563, 'eval_steps_per_second': 5.753, 'epoch': 7.0, 'step': 693}, {'loss': 0.6669, 'learning_rate': 1.655520074021906e-05, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.6161403656005859, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 8.6902, 'eval_samples_per_second': 45.569, 'eval_steps_per_second': 5.754, 'epoch': 8.0, 'step': 792}, {'loss': 0.6547, 'learning_rate': 1.8624600832746444e-05, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.6048795580863953, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.6859, 'eval_samples_per_second': 45.591, 'eval_steps_per_second': 5.756, 'epoch': 9.0, 'step': 891}, {'loss': 0.6621, 'learning_rate': 2.0694000925273827e-05, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5943505167961121, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.6901, 'eval_samples_per_second': 45.569, 'eval_steps_per_second': 5.754, 'epoch': 10.0, 'step': 990}, {'train_runtime': 633.8989, 'train_samples_per_second': 24.988, 'train_steps_per_second': 1.562, 'total_flos': 9465195637497600.0, 'train_loss': 0.6984928632023358, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5943505167961121, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.706, 'eval_samples_per_second': 45.486, 'eval_steps_per_second': 5.743, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:58<00:00, 29.12s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:13<00:00, 36.51s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 990/1980 04:38 < 04:38, 3.55 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.854600</td>\n",
       "      <td>0.634045</td>\n",
       "      <td>0.654040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.751700</td>\n",
       "      <td>0.751921</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.065300</td>\n",
       "      <td>3.188093</td>\n",
       "      <td>0.540404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.899400</td>\n",
       "      <td>8.150720</td>\n",
       "      <td>0.510101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.963400</td>\n",
       "      <td>2.977379</td>\n",
       "      <td>0.603535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 20:28:05,212] Trial 14 finished with values: [0.7519211173057556, 0.6742424242424242] and parameters: {'lr': 0.007153278299969591, 'batch': 4, 'accum': 2, 'dropout_rate': 0.8286598765454943, 'weight_decay': 0.00020522558639561155, 'warmup_pct': 0.22184335115957465, 'lora_rank': 4, 'lora_init_scale': 0.012036324913925051, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.7519211173057556, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 8.7305, 'eval_samples_per_second': 45.358, 'eval_steps_per_second': 5.727, 'epoch': 5.0}\n",
      "History:  [{'loss': 0.8546, 'learning_rate': 0.0016131538763029373, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6340451240539551, 'eval_accuracy': 0.6540404040404041, 'eval_runtime': 8.622, 'eval_samples_per_second': 45.929, 'eval_steps_per_second': 5.799, 'epoch': 1.0, 'step': 198}, {'loss': 1.7517, 'learning_rate': 0.0032263077526058746, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.7519211173057556, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 8.6686, 'eval_samples_per_second': 45.682, 'eval_steps_per_second': 5.768, 'epoch': 2.0, 'step': 396}, {'loss': 3.0653, 'learning_rate': 0.004839461628908812, 'epoch': 3.0, 'step': 594}, {'eval_loss': 3.188093423843384, 'eval_accuracy': 0.5404040404040404, 'eval_runtime': 8.6771, 'eval_samples_per_second': 45.637, 'eval_steps_per_second': 5.762, 'epoch': 3.0, 'step': 594}, {'loss': 4.8994, 'learning_rate': 0.006452615505211749, 'epoch': 4.0, 'step': 792}, {'eval_loss': 8.15071964263916, 'eval_accuracy': 0.51010101010101, 'eval_runtime': 8.6936, 'eval_samples_per_second': 45.551, 'eval_steps_per_second': 5.751, 'epoch': 4.0, 'step': 792}, {'loss': 5.9634, 'learning_rate': 0.006426266349337473, 'epoch': 5.0, 'step': 990}, {'eval_loss': 2.977379083633423, 'eval_accuracy': 0.6035353535353535, 'eval_runtime': 8.7191, 'eval_samples_per_second': 45.418, 'eval_steps_per_second': 5.735, 'epoch': 5.0, 'step': 990}, {'train_runtime': 278.6598, 'train_samples_per_second': 56.844, 'train_steps_per_second': 7.105, 'total_flos': 4732597818748800.0, 'train_loss': 3.30686966096512, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.7519211173057556, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 8.7305, 'eval_samples_per_second': 45.358, 'eval_steps_per_second': 5.727, 'epoch': 5.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:58<00:00, 29.32s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:08<00:00, 34.23s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 990/1980 05:18 < 05:18, 3.10 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.657900</td>\n",
       "      <td>0.582913</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.583500</td>\n",
       "      <td>0.525097</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.530600</td>\n",
       "      <td>0.568752</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.525500</td>\n",
       "      <td>0.564094</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.477800</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 20:36:36,911] Trial 15 finished with values: [0.5250969529151917, 0.7297979797979798] and parameters: {'lr': 0.0005719016304640616, 'batch': 2, 'accum': 4, 'dropout_rate': 0.25342054257467544, 'weight_decay': 4.28892229326991e-05, 'warmup_pct': 0.2662589690747499, 'lora_rank': 4, 'lora_init_scale': 0.0002775263788030031, 'lora_scaling_rank': 7}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5250969529151917, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.6913, 'eval_samples_per_second': 45.563, 'eval_steps_per_second': 5.753, 'epoch': 5.0}\n",
      "History:  [{'loss': 0.6579, 'learning_rate': 5.371751557489763e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.5829125046730042, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 8.6261, 'eval_samples_per_second': 45.907, 'eval_steps_per_second': 5.796, 'epoch': 1.0, 'step': 198}, {'loss': 0.5835, 'learning_rate': 0.00010743503114979526, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.5250969529151917, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.7, 'eval_samples_per_second': 45.517, 'eval_steps_per_second': 5.747, 'epoch': 2.0, 'step': 396}, {'loss': 0.5306, 'learning_rate': 0.00016115254672469288, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.5687522292137146, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.6665, 'eval_samples_per_second': 45.693, 'eval_steps_per_second': 5.769, 'epoch': 3.0, 'step': 594}, {'loss': 0.5255, 'learning_rate': 0.00021487006229959052, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5640941858291626, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 8.6717, 'eval_samples_per_second': 45.666, 'eval_steps_per_second': 5.766, 'epoch': 4.0, 'step': 792}, {'loss': 0.4778, 'learning_rate': 0.00026858757787448815, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6133328080177307, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 8.6867, 'eval_samples_per_second': 45.587, 'eval_steps_per_second': 5.756, 'epoch': 5.0, 'step': 990}, {'train_runtime': 318.5761, 'train_samples_per_second': 49.721, 'train_steps_per_second': 6.215, 'total_flos': 4732597818748800.0, 'train_loss': 0.5550464514530067, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5250969529151917, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.6913, 'eval_samples_per_second': 45.563, 'eval_steps_per_second': 5.753, 'epoch': 5.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [01:01<00:00, 30.95s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:09<00:00, 34.93s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='148' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [148/240 04:22 < 02:45, 0.56 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.677300</td>\n",
       "      <td>0.564605</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.572294</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.520300</td>\n",
       "      <td>0.555377</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.764412</td>\n",
       "      <td>0.626263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.568200</td>\n",
       "      <td>0.600321</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 5.97979797979798: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 20:44:19,629] Trial 16 finished with values: [0.5553765296936035, 0.7247474747474747] and parameters: {'lr': 0.005314710286943046, 'batch': 8, 'accum': 8, 'dropout_rate': 0.35565103982944457, 'weight_decay': 3.1098047423612664e-05, 'warmup_pct': 0.22175643158537206, 'lora_rank': 32, 'lora_init_scale': 0.02692992927097065, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.97979797979798: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5553765296936035, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.6644, 'eval_samples_per_second': 45.704, 'eval_steps_per_second': 5.771, 'epoch': 5.98}\n",
      "History:  [{'loss': 0.6773, 'learning_rate': 0.0002905536375549729, 'epoch': 0.97, 'step': 24}, {'eval_loss': 0.5646046996116638, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 8.6426, 'eval_samples_per_second': 45.82, 'eval_steps_per_second': 5.785, 'epoch': 0.97, 'step': 24}, {'loss': 0.5478, 'learning_rate': 0.0005932136766747363, 'epoch': 1.98, 'step': 49}, {'eval_loss': 0.5722935199737549, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.6611, 'eval_samples_per_second': 45.721, 'eval_steps_per_second': 5.773, 'epoch': 1.98, 'step': 49}, {'loss': 0.5203, 'learning_rate': 0.0008958737157944998, 'epoch': 2.99, 'step': 74}, {'eval_loss': 0.5553765296936035, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.7111, 'eval_samples_per_second': 45.459, 'eval_steps_per_second': 5.74, 'epoch': 2.99, 'step': 74}, {'loss': 0.4893, 'learning_rate': 0.0011985337549142632, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.6917302012443542, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 8.6744, 'eval_samples_per_second': 45.651, 'eval_steps_per_second': 5.764, 'epoch': 4.0, 'step': 99}, {'loss': 0.528, 'learning_rate': 0.0014890873924692362, 'epoch': 4.97, 'step': 123}, {'eval_loss': 0.7644117474555969, 'eval_accuracy': 0.6262626262626263, 'eval_runtime': 8.6712, 'eval_samples_per_second': 45.669, 'eval_steps_per_second': 5.766, 'epoch': 4.97, 'step': 123}, {'loss': 0.5682, 'learning_rate': 0.0017917474315889996, 'epoch': 5.98, 'step': 148}, {'eval_loss': 0.6003207564353943, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 8.6707, 'eval_samples_per_second': 45.671, 'eval_steps_per_second': 5.767, 'epoch': 5.98, 'step': 148}, {'train_runtime': 263.7955, 'train_samples_per_second': 60.047, 'train_steps_per_second': 0.91, 'total_flos': 5679117382498560.0, 'train_loss': 0.5545170307159424, 'epoch': 5.98, 'step': 148}, {'eval_loss': 0.5553765296936035, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.6644, 'eval_samples_per_second': 45.704, 'eval_steps_per_second': 5.771, 'epoch': 5.98, 'step': 148}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:56<00:00, 28.22s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:07<00:00, 33.98s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3564' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3564/3960 09:40 < 01:04, 6.13 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>0.583222</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>0.540311</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.532200</td>\n",
       "      <td>0.553353</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>0.560002</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>0.555174</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.433200</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.423200</td>\n",
       "      <td>0.575328</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>0.573654</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.389000</td>\n",
       "      <td>0.586916</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 20:57:11,145] Trial 17 finished with values: [0.5792003273963928, 0.7449494949494949] and parameters: {'lr': 5.861614685880086e-05, 'batch': 2, 'accum': 2, 'dropout_rate': 0.12363229222308601, 'weight_decay': 0.0001787909943778819, 'warmup_pct': 0.11976972429950468, 'lora_rank': 32, 'lora_init_scale': 0.031720788985642435, 'lora_scaling_rank': 6}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5792003273963928, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.7152, 'eval_samples_per_second': 45.438, 'eval_steps_per_second': 5.737, 'epoch': 9.0}\n",
      "History:  [{'loss': 0.659, 'learning_rate': 2.4485225903043396e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.5832223892211914, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.6161, 'eval_samples_per_second': 45.961, 'eval_steps_per_second': 5.803, 'epoch': 1.0, 'step': 396}, {'loss': 0.5846, 'learning_rate': 4.897045180608679e-05, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.5403109192848206, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.6666, 'eval_samples_per_second': 45.693, 'eval_steps_per_second': 5.769, 'epoch': 2.0, 'step': 792}, {'loss': 0.5322, 'learning_rate': 5.394553754734262e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.553352952003479, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.6699, 'eval_samples_per_second': 45.675, 'eval_steps_per_second': 5.767, 'epoch': 3.0, 'step': 1188}, {'loss': 0.4929, 'learning_rate': 4.6239032183436535e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.5600017309188843, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.6697, 'eval_samples_per_second': 45.676, 'eval_steps_per_second': 5.767, 'epoch': 4.0, 'step': 1584}, {'loss': 0.454, 'learning_rate': 3.853252681953045e-05, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5551736950874329, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.6789, 'eval_samples_per_second': 45.628, 'eval_steps_per_second': 5.761, 'epoch': 5.0, 'step': 1980}, {'loss': 0.4332, 'learning_rate': 3.082602145562435e-05, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.5792003273963928, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.6799, 'eval_samples_per_second': 45.622, 'eval_steps_per_second': 5.76, 'epoch': 6.0, 'step': 2376}, {'loss': 0.4232, 'learning_rate': 2.3119516091718267e-05, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.5753283500671387, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.6794, 'eval_samples_per_second': 45.625, 'eval_steps_per_second': 5.761, 'epoch': 7.0, 'step': 2772}, {'loss': 0.4092, 'learning_rate': 1.5413010727812176e-05, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.5736544728279114, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.6784, 'eval_samples_per_second': 45.63, 'eval_steps_per_second': 5.761, 'epoch': 8.0, 'step': 3168}, {'loss': 0.389, 'learning_rate': 7.706505363906088e-06, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.5869155526161194, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.6946, 'eval_samples_per_second': 45.546, 'eval_steps_per_second': 5.751, 'epoch': 9.0, 'step': 3564}, {'train_runtime': 580.898, 'train_samples_per_second': 27.268, 'train_steps_per_second': 6.817, 'total_flos': 8518676073747840.0, 'train_loss': 0.4863632407654014, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.5792003273963928, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.7152, 'eval_samples_per_second': 45.438, 'eval_steps_per_second': 5.737, 'epoch': 9.0, 'step': 3564}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:54<00:00, 27.25s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:07<00:00, 33.67s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 10:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.707400</td>\n",
       "      <td>0.680873</td>\n",
       "      <td>0.621212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.681600</td>\n",
       "      <td>0.653198</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.670700</td>\n",
       "      <td>0.626701</td>\n",
       "      <td>0.669192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.633500</td>\n",
       "      <td>0.599947</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.629300</td>\n",
       "      <td>0.581536</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.600700</td>\n",
       "      <td>0.562289</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.570200</td>\n",
       "      <td>0.549191</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.555400</td>\n",
       "      <td>0.540098</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.548400</td>\n",
       "      <td>0.534835</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.537100</td>\n",
       "      <td>0.531215</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 21:10:56,683] Trial 18 finished with values: [0.531215488910675, 0.7373737373737373] and parameters: {'lr': 6.724006857418989e-05, 'batch': 2, 'accum': 8, 'dropout_rate': 0.5926798576128591, 'weight_decay': 2.6860258290557064e-05, 'warmup_pct': 0.14012714825778705, 'lora_rank': 16, 'lora_init_scale': 0.02787198897177987, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.531215488910675, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.7028, 'eval_samples_per_second': 45.503, 'eval_steps_per_second': 5.745, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7074, 'learning_rate': 6.002494850175653e-06, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6808733940124512, 'eval_accuracy': 0.6212121212121212, 'eval_runtime': 8.6212, 'eval_samples_per_second': 45.934, 'eval_steps_per_second': 5.8, 'epoch': 1.0, 'step': 99}, {'loss': 0.6816, 'learning_rate': 1.2004989700351306e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6531978845596313, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 8.6743, 'eval_samples_per_second': 45.652, 'eval_steps_per_second': 5.764, 'epoch': 2.0, 'step': 198}, {'loss': 0.6707, 'learning_rate': 1.800748455052696e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6267011165618896, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 8.6829, 'eval_samples_per_second': 45.607, 'eval_steps_per_second': 5.758, 'epoch': 3.0, 'step': 297}, {'loss': 0.6335, 'learning_rate': 2.400997940070261e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5999466776847839, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 8.691, 'eval_samples_per_second': 45.564, 'eval_steps_per_second': 5.753, 'epoch': 4.0, 'step': 396}, {'loss': 0.6293, 'learning_rate': 3.0012474250878264e-05, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5815358757972717, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.6913, 'eval_samples_per_second': 45.563, 'eval_steps_per_second': 5.753, 'epoch': 5.0, 'step': 495}, {'loss': 0.6007, 'learning_rate': 3.601496910105392e-05, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5622891783714294, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.6921, 'eval_samples_per_second': 45.559, 'eval_steps_per_second': 5.752, 'epoch': 6.0, 'step': 594}, {'loss': 0.5702, 'learning_rate': 4.2017463951229575e-05, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5491910576820374, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.6994, 'eval_samples_per_second': 45.52, 'eval_steps_per_second': 5.748, 'epoch': 7.0, 'step': 693}, {'loss': 0.5554, 'learning_rate': 4.801995880140522e-05, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5400984883308411, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.6949, 'eval_samples_per_second': 45.544, 'eval_steps_per_second': 5.75, 'epoch': 8.0, 'step': 792}, {'loss': 0.5484, 'learning_rate': 5.402245365158088e-05, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.5348349809646606, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.7005, 'eval_samples_per_second': 45.515, 'eval_steps_per_second': 5.747, 'epoch': 9.0, 'step': 891}, {'loss': 0.5371, 'learning_rate': 6.002494850175653e-05, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.531215488910675, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.7076, 'eval_samples_per_second': 45.478, 'eval_steps_per_second': 5.742, 'epoch': 10.0, 'step': 990}, {'train_runtime': 635.973, 'train_samples_per_second': 24.907, 'train_steps_per_second': 1.557, 'total_flos': 9465195637497600.0, 'train_loss': 0.6134379724059442, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.531215488910675, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.7028, 'eval_samples_per_second': 45.503, 'eval_steps_per_second': 5.745, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:54<00:00, 27.17s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:10<00:00, 35.26s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 10:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.634900</td>\n",
       "      <td>0.575252</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.557300</td>\n",
       "      <td>0.548165</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482700</td>\n",
       "      <td>0.534077</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.451200</td>\n",
       "      <td>0.559693</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.421700</td>\n",
       "      <td>0.614763</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.399800</td>\n",
       "      <td>0.560401</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.383800</td>\n",
       "      <td>0.582763</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.590178</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.372800</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.344100</td>\n",
       "      <td>0.570909</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 21:24:40,953] Trial 19 finished with values: [0.5709091424942017, 0.7424242424242424] and parameters: {'lr': 0.00025199343097331785, 'batch': 2, 'accum': 8, 'dropout_rate': 0.23385750980680556, 'weight_decay': 0.00017210624751179775, 'warmup_pct': 0.012806802442164446, 'lora_rank': 8, 'lora_init_scale': 0.09825405617337031, 'lora_scaling_rank': 8}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5709091424942017, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7027, 'eval_samples_per_second': 45.503, 'eval_steps_per_second': 5.745, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.6349, 'learning_rate': 0.0002470034620431531, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5752522349357605, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 8.623, 'eval_samples_per_second': 45.924, 'eval_steps_per_second': 5.798, 'epoch': 1.0, 'step': 99}, {'loss': 0.5573, 'learning_rate': 0.00022449808473663414, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5481652021408081, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.6717, 'eval_samples_per_second': 45.666, 'eval_steps_per_second': 5.766, 'epoch': 2.0, 'step': 198}, {'loss': 0.4827, 'learning_rate': 0.00019643582414455483, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5340770483016968, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.6751, 'eval_samples_per_second': 45.648, 'eval_steps_per_second': 5.764, 'epoch': 3.0, 'step': 297}, {'loss': 0.4512, 'learning_rate': 0.00016837356355247558, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5596926808357239, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 8.6784, 'eval_samples_per_second': 45.631, 'eval_steps_per_second': 5.761, 'epoch': 4.0, 'step': 396}, {'loss': 0.4217, 'learning_rate': 0.0001403113029603963, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6147626042366028, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 8.6857, 'eval_samples_per_second': 45.592, 'eval_steps_per_second': 5.757, 'epoch': 5.0, 'step': 495}, {'loss': 0.3998, 'learning_rate': 0.00011224904236831707, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5604007244110107, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.6879, 'eval_samples_per_second': 45.581, 'eval_steps_per_second': 5.755, 'epoch': 6.0, 'step': 594}, {'loss': 0.3838, 'learning_rate': 8.418678177623779e-05, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5827627182006836, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 8.694, 'eval_samples_per_second': 45.548, 'eval_steps_per_second': 5.751, 'epoch': 7.0, 'step': 693}, {'loss': 0.382, 'learning_rate': 5.6124521184158534e-05, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5901780724525452, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.7062, 'eval_samples_per_second': 45.485, 'eval_steps_per_second': 5.743, 'epoch': 8.0, 'step': 792}, {'loss': 0.3728, 'learning_rate': 2.8062260592079267e-05, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.5738635063171387, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.7109, 'eval_samples_per_second': 45.46, 'eval_steps_per_second': 5.74, 'epoch': 9.0, 'step': 891}, {'loss': 0.3441, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5709091424942017, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7021, 'eval_samples_per_second': 45.506, 'eval_steps_per_second': 5.746, 'epoch': 10.0, 'step': 990}, {'train_runtime': 633.1754, 'train_samples_per_second': 25.017, 'train_steps_per_second': 1.564, 'total_flos': 9465195637497600.0, 'train_loss': 0.44302303044482916, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5709091424942017, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7027, 'eval_samples_per_second': 45.503, 'eval_steps_per_second': 5.745, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [01:00<00:00, 30.03s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:07<00:00, 33.61s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 09:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.673800</td>\n",
       "      <td>3.179976</td>\n",
       "      <td>0.517677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.623800</td>\n",
       "      <td>5.690728</td>\n",
       "      <td>0.520202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.799000</td>\n",
       "      <td>2.739230</td>\n",
       "      <td>0.601010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>1.354033</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.705600</td>\n",
       "      <td>1.894738</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.624200</td>\n",
       "      <td>1.387086</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.052300</td>\n",
       "      <td>1.150091</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.384200</td>\n",
       "      <td>1.113437</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.163900</td>\n",
       "      <td>1.081378</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.870700</td>\n",
       "      <td>1.010943</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 21:37:16,243] Trial 20 finished with values: [1.0109426975250244, 0.7146464646464646] and parameters: {'lr': 0.005602460965274027, 'batch': 4, 'accum': 2, 'dropout_rate': 0.8134086411662094, 'weight_decay': 1.4705112642535287e-05, 'warmup_pct': 0.04649328663158226, 'lora_rank': 4, 'lora_init_scale': 0.002432657509044135, 'lora_scaling_rank': 7}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0109426975250244, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.6937, 'eval_samples_per_second': 45.55, 'eval_steps_per_second': 5.751, 'epoch': 10.0}\n",
      "History:  [{'loss': 1.6738, 'learning_rate': 0.0055587892205558554, 'epoch': 1.0, 'step': 198}, {'eval_loss': 3.1799755096435547, 'eval_accuracy': 0.5176767676767676, 'eval_runtime': 8.6195, 'eval_samples_per_second': 45.942, 'eval_steps_per_second': 5.801, 'epoch': 1.0, 'step': 198}, {'loss': 4.6238, 'learning_rate': 0.004941145973827427, 'epoch': 2.0, 'step': 396}, {'eval_loss': 5.690728187561035, 'eval_accuracy': 0.5202020202020202, 'eval_runtime': 8.6709, 'eval_samples_per_second': 45.67, 'eval_steps_per_second': 5.766, 'epoch': 2.0, 'step': 396}, {'loss': 4.799, 'learning_rate': 0.004323502727098998, 'epoch': 3.0, 'step': 594}, {'eval_loss': 2.739230155944824, 'eval_accuracy': 0.601010101010101, 'eval_runtime': 8.6784, 'eval_samples_per_second': 45.631, 'eval_steps_per_second': 5.761, 'epoch': 3.0, 'step': 594}, {'loss': 4.71, 'learning_rate': 0.00370585948037057, 'epoch': 4.0, 'step': 792}, {'eval_loss': 1.3540327548980713, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 8.7228, 'eval_samples_per_second': 45.398, 'eval_steps_per_second': 5.732, 'epoch': 4.0, 'step': 792}, {'loss': 4.7056, 'learning_rate': 0.0030882162336421416, 'epoch': 5.0, 'step': 990}, {'eval_loss': 1.8947378396987915, 'eval_accuracy': 0.6590909090909091, 'eval_runtime': 8.7273, 'eval_samples_per_second': 45.375, 'eval_steps_per_second': 5.729, 'epoch': 5.0, 'step': 990}, {'loss': 4.6242, 'learning_rate': 0.0024705729869137134, 'epoch': 6.0, 'step': 1188}, {'eval_loss': 1.3870861530303955, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 8.6893, 'eval_samples_per_second': 45.573, 'eval_steps_per_second': 5.754, 'epoch': 6.0, 'step': 1188}, {'loss': 4.0523, 'learning_rate': 0.001852929740185285, 'epoch': 7.0, 'step': 1386}, {'eval_loss': 1.1500906944274902, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 8.6872, 'eval_samples_per_second': 45.584, 'eval_steps_per_second': 5.756, 'epoch': 7.0, 'step': 1386}, {'loss': 3.3842, 'learning_rate': 0.0012352864934568567, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 1.1134368181228638, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.6867, 'eval_samples_per_second': 45.587, 'eval_steps_per_second': 5.756, 'epoch': 8.0, 'step': 1584}, {'loss': 3.1639, 'learning_rate': 0.0006176432467284283, 'epoch': 9.0, 'step': 1782}, {'eval_loss': 1.0813778638839722, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 8.6987, 'eval_samples_per_second': 45.524, 'eval_steps_per_second': 5.748, 'epoch': 9.0, 'step': 1782}, {'loss': 2.8707, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 1.0109426975250244, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.6944, 'eval_samples_per_second': 45.547, 'eval_steps_per_second': 5.751, 'epoch': 10.0, 'step': 1980}, {'train_runtime': 559.6495, 'train_samples_per_second': 28.303, 'train_steps_per_second': 3.538, 'total_flos': 9465195637497600.0, 'train_loss': 3.860762116403291, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 1.0109426975250244, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.6937, 'eval_samples_per_second': 45.55, 'eval_steps_per_second': 5.751, 'epoch': 10.0, 'step': 1980}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:56<00:00, 28.41s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:00<00:00, 30.12s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 10:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.745300</td>\n",
       "      <td>0.691377</td>\n",
       "      <td>0.517677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.739700</td>\n",
       "      <td>0.682610</td>\n",
       "      <td>0.616162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.750900</td>\n",
       "      <td>0.672260</td>\n",
       "      <td>0.664141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.713200</td>\n",
       "      <td>0.660251</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.650711</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.714700</td>\n",
       "      <td>0.644576</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.640212</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.704700</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.636107</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.714100</td>\n",
       "      <td>0.635652</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 21:50:56,931] Trial 21 finished with values: [0.6361071467399597, 0.6868686868686869] and parameters: {'lr': 1.0530778995478443e-05, 'batch': 2, 'accum': 8, 'dropout_rate': 0.8248599691883842, 'weight_decay': 0.0003576256038918507, 'warmup_pct': 0.04039230697820164, 'lora_rank': 8, 'lora_init_scale': 0.00016339490523512506, 'lora_scaling_rank': 8}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6361071467399597, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 8.7187, 'eval_samples_per_second': 45.42, 'eval_steps_per_second': 5.735, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7453, 'learning_rate': 3.2681727917002065e-06, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6913770437240601, 'eval_accuracy': 0.5176767676767676, 'eval_runtime': 8.6119, 'eval_samples_per_second': 45.983, 'eval_steps_per_second': 5.806, 'epoch': 1.0, 'step': 99}, {'loss': 0.7397, 'learning_rate': 6.536345583400413e-06, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6826096177101135, 'eval_accuracy': 0.6161616161616161, 'eval_runtime': 8.6687, 'eval_samples_per_second': 45.681, 'eval_steps_per_second': 5.768, 'epoch': 2.0, 'step': 198}, {'loss': 0.7509, 'learning_rate': 9.80451837510062e-06, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6722596883773804, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 8.6741, 'eval_samples_per_second': 45.653, 'eval_steps_per_second': 5.764, 'epoch': 3.0, 'step': 297}, {'loss': 0.7132, 'learning_rate': 9.322328946816983e-06, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.660250723361969, 'eval_accuracy': 0.6363636363636364, 'eval_runtime': 8.6845, 'eval_samples_per_second': 45.598, 'eval_steps_per_second': 5.757, 'epoch': 4.0, 'step': 396}, {'loss': 0.729, 'learning_rate': 7.76860745568082e-06, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6507112383842468, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 8.6844, 'eval_samples_per_second': 45.599, 'eval_steps_per_second': 5.757, 'epoch': 5.0, 'step': 495}, {'loss': 0.7147, 'learning_rate': 6.214885964544655e-06, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.6445762515068054, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 8.6853, 'eval_samples_per_second': 45.594, 'eval_steps_per_second': 5.757, 'epoch': 6.0, 'step': 594}, {'loss': 0.7125, 'learning_rate': 4.6611644734084915e-06, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.6402124762535095, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 8.6855, 'eval_samples_per_second': 45.593, 'eval_steps_per_second': 5.757, 'epoch': 7.0, 'step': 693}, {'loss': 0.7047, 'learning_rate': 3.1074429822723274e-06, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.6375002264976501, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 8.6862, 'eval_samples_per_second': 45.589, 'eval_steps_per_second': 5.756, 'epoch': 8.0, 'step': 792}, {'loss': 0.6958, 'learning_rate': 1.5537214911361637e-06, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.6361071467399597, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 8.6903, 'eval_samples_per_second': 45.568, 'eval_steps_per_second': 5.754, 'epoch': 9.0, 'step': 891}, {'loss': 0.7141, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.635651707649231, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 8.6914, 'eval_samples_per_second': 45.562, 'eval_steps_per_second': 5.753, 'epoch': 10.0, 'step': 990}, {'train_runtime': 633.4259, 'train_samples_per_second': 25.007, 'train_steps_per_second': 1.563, 'total_flos': 9465195637497600.0, 'train_loss': 0.7219695351340554, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.6361071467399597, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 8.7187, 'eval_samples_per_second': 45.42, 'eval_steps_per_second': 5.735, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:53<00:00, 27.00s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [00:59<00:00, 29.71s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 13:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.709400</td>\n",
       "      <td>0.678956</td>\n",
       "      <td>0.626263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.682400</td>\n",
       "      <td>0.651403</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.654900</td>\n",
       "      <td>0.616656</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.623800</td>\n",
       "      <td>0.589414</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.600700</td>\n",
       "      <td>0.570029</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.567200</td>\n",
       "      <td>0.550380</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.560100</td>\n",
       "      <td>0.542270</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.541200</td>\n",
       "      <td>0.534422</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>0.526550</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.510100</td>\n",
       "      <td>0.525596</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 22:07:35,548] Trial 22 finished with values: [0.5265498161315918, 0.7424242424242424] and parameters: {'lr': 9.973090263778709e-05, 'batch': 1, 'accum': 8, 'dropout_rate': 0.5203586360557492, 'weight_decay': 1.539235265329458e-05, 'warmup_pct': 0.29233682033676406, 'lora_rank': 12, 'lora_init_scale': 0.0011417955315952306, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5265498161315918, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.6822, 'eval_samples_per_second': 45.61, 'eval_steps_per_second': 5.759, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7094, 'learning_rate': 4.264950048009038e-06, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6789560317993164, 'eval_accuracy': 0.6262626262626263, 'eval_runtime': 8.6293, 'eval_samples_per_second': 45.89, 'eval_steps_per_second': 5.794, 'epoch': 1.0, 'step': 198}, {'loss': 0.6824, 'learning_rate': 8.529900096018075e-06, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6514033079147339, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 8.6594, 'eval_samples_per_second': 45.731, 'eval_steps_per_second': 5.774, 'epoch': 2.0, 'step': 396}, {'loss': 0.6549, 'learning_rate': 1.2794850144027112e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6166558265686035, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 8.6729, 'eval_samples_per_second': 45.66, 'eval_steps_per_second': 5.765, 'epoch': 3.0, 'step': 594}, {'loss': 0.6238, 'learning_rate': 1.705980019203615e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.589413583278656, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.675, 'eval_samples_per_second': 45.649, 'eval_steps_per_second': 5.764, 'epoch': 4.0, 'step': 792}, {'loss': 0.6007, 'learning_rate': 2.132475024004519e-05, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.570029079914093, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.672, 'eval_samples_per_second': 45.664, 'eval_steps_per_second': 5.766, 'epoch': 5.0, 'step': 990}, {'loss': 0.5672, 'learning_rate': 2.5589700288054225e-05, 'epoch': 6.0, 'step': 1188}, {'eval_loss': 0.5503802299499512, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.674, 'eval_samples_per_second': 45.654, 'eval_steps_per_second': 5.764, 'epoch': 6.0, 'step': 1188}, {'loss': 0.5601, 'learning_rate': 2.985465033606326e-05, 'epoch': 7.0, 'step': 1386}, {'eval_loss': 0.5422698259353638, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.6744, 'eval_samples_per_second': 45.652, 'eval_steps_per_second': 5.764, 'epoch': 7.0, 'step': 1386}, {'loss': 0.5412, 'learning_rate': 3.41196003840723e-05, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.5344220399856567, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 8.676, 'eval_samples_per_second': 45.643, 'eval_steps_per_second': 5.763, 'epoch': 8.0, 'step': 1584}, {'loss': 0.527, 'learning_rate': 3.8384550432081334e-05, 'epoch': 9.0, 'step': 1782}, {'eval_loss': 0.5265498161315918, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.6657, 'eval_samples_per_second': 45.698, 'eval_steps_per_second': 5.77, 'epoch': 9.0, 'step': 1782}, {'loss': 0.5101, 'learning_rate': 4.264950048009038e-05, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 0.525596022605896, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.683, 'eval_samples_per_second': 45.606, 'eval_steps_per_second': 5.758, 'epoch': 10.0, 'step': 1980}, {'train_runtime': 818.7113, 'train_samples_per_second': 19.347, 'train_steps_per_second': 2.418, 'total_flos': 9465195637497600.0, 'train_loss': 0.5976963274406665, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 0.5265498161315918, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.6822, 'eval_samples_per_second': 45.61, 'eval_steps_per_second': 5.759, 'epoch': 10.0, 'step': 1980}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:51<00:00, 25.95s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:05<00:00, 32.75s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/990 05:15 < 05:17, 1.56 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.650100</td>\n",
       "      <td>0.559485</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.589900</td>\n",
       "      <td>0.527175</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.526300</td>\n",
       "      <td>0.575241</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.524200</td>\n",
       "      <td>0.547058</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.528100</td>\n",
       "      <td>0.598321</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 22:15:57,542] Trial 23 finished with values: [0.5271751284599304, 0.7474747474747475] and parameters: {'lr': 0.0028386044645149354, 'batch': 2, 'accum': 8, 'dropout_rate': 0.290601664676174, 'weight_decay': 0.0006659424553708593, 'warmup_pct': 0.27121130031529533, 'lora_rank': 32, 'lora_init_scale': 0.06526579395061742, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5271751284599304, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 8.7006, 'eval_samples_per_second': 45.514, 'eval_steps_per_second': 5.747, 'epoch': 5.0}\n",
      "History:  [{'loss': 0.6501, 'learning_rate': 0.00013089047134931468, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5594850778579712, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 8.6669, 'eval_samples_per_second': 45.691, 'eval_steps_per_second': 5.769, 'epoch': 1.0, 'step': 99}, {'loss': 0.5899, 'learning_rate': 0.00026178094269862937, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5271751284599304, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 8.6983, 'eval_samples_per_second': 45.526, 'eval_steps_per_second': 5.748, 'epoch': 2.0, 'step': 198}, {'loss': 0.5263, 'learning_rate': 0.0003926714140479441, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5752407908439636, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 8.6924, 'eval_samples_per_second': 45.557, 'eval_steps_per_second': 5.752, 'epoch': 3.0, 'step': 297}, {'loss': 0.5242, 'learning_rate': 0.0005235618853972587, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5470582842826843, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.6985, 'eval_samples_per_second': 45.525, 'eval_steps_per_second': 5.748, 'epoch': 4.0, 'step': 396}, {'loss': 0.5281, 'learning_rate': 0.0006544523567465734, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5983213782310486, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 8.6995, 'eval_samples_per_second': 45.52, 'eval_steps_per_second': 5.747, 'epoch': 5.0, 'step': 495}, {'train_runtime': 317.1914, 'train_samples_per_second': 49.938, 'train_steps_per_second': 3.121, 'total_flos': 4732597818748800.0, 'train_loss': 0.5637127192333491, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5271751284599304, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 8.7006, 'eval_samples_per_second': 45.514, 'eval_steps_per_second': 5.747, 'epoch': 5.0, 'step': 495}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:51<00:00, 25.99s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:08<00:00, 34.04s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 09:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.617059</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>0.550942</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.588900</td>\n",
       "      <td>0.528076</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.562200</td>\n",
       "      <td>0.528049</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.569300</td>\n",
       "      <td>0.529215</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.566700</td>\n",
       "      <td>0.572334</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>0.524937</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.514900</td>\n",
       "      <td>0.520925</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.501800</td>\n",
       "      <td>0.522543</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.482700</td>\n",
       "      <td>0.520814</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 22:28:21,355] Trial 24 finished with values: [0.5225428342819214, 0.7525252525252525] and parameters: {'lr': 0.0003459380673689418, 'batch': 4, 'accum': 4, 'dropout_rate': 0.6303139405233136, 'weight_decay': 7.145415686725527e-05, 'warmup_pct': 0.12121786012551566, 'lora_rank': 20, 'lora_init_scale': 0.004413381171295235, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5225428342819214, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 8.7016, 'eval_samples_per_second': 45.509, 'eval_steps_per_second': 5.746, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.698, 'learning_rate': 7.134972639484424e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6170588135719299, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 8.6428, 'eval_samples_per_second': 45.818, 'eval_steps_per_second': 5.785, 'epoch': 1.0, 'step': 99}, {'loss': 0.6234, 'learning_rate': 0.00014269945278968848, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5509417057037354, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.6964, 'eval_samples_per_second': 45.536, 'eval_steps_per_second': 5.75, 'epoch': 2.0, 'step': 198}, {'loss': 0.5889, 'learning_rate': 0.00021404917918453275, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5280761122703552, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.718, 'eval_samples_per_second': 45.423, 'eval_steps_per_second': 5.735, 'epoch': 3.0, 'step': 297}, {'loss': 0.5622, 'learning_rate': 0.00028539890557937697, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5280488729476929, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7187, 'eval_samples_per_second': 45.419, 'eval_steps_per_second': 5.735, 'epoch': 4.0, 'step': 396}, {'loss': 0.5693, 'learning_rate': 0.0003357634183286788, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5292145013809204, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7396, 'eval_samples_per_second': 45.311, 'eval_steps_per_second': 5.721, 'epoch': 5.0, 'step': 495}, {'loss': 0.5667, 'learning_rate': 0.0002686107346629431, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5723336935043335, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 8.7164, 'eval_samples_per_second': 45.431, 'eval_steps_per_second': 5.736, 'epoch': 6.0, 'step': 594}, {'loss': 0.553, 'learning_rate': 0.0002014580509972073, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5249371528625488, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.7208, 'eval_samples_per_second': 45.409, 'eval_steps_per_second': 5.733, 'epoch': 7.0, 'step': 693}, {'loss': 0.5149, 'learning_rate': 0.00013430536733147154, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5209246277809143, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.7095, 'eval_samples_per_second': 45.467, 'eval_steps_per_second': 5.741, 'epoch': 8.0, 'step': 792}, {'loss': 0.5018, 'learning_rate': 6.715268366573577e-05, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.5225428342819214, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 8.6957, 'eval_samples_per_second': 45.54, 'eval_steps_per_second': 5.75, 'epoch': 9.0, 'step': 891}, {'loss': 0.4827, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5208140015602112, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 8.6959, 'eval_samples_per_second': 45.538, 'eval_steps_per_second': 5.75, 'epoch': 10.0, 'step': 990}, {'train_runtime': 555.1405, 'train_samples_per_second': 28.533, 'train_steps_per_second': 1.783, 'total_flos': 9465195637497600.0, 'train_loss': 0.5660824361473623, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5225428342819214, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 8.7016, 'eval_samples_per_second': 45.509, 'eval_steps_per_second': 5.746, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:50<00:00, 25.47s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:04<00:00, 32.01s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 10:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.730700</td>\n",
       "      <td>0.685307</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.723100</td>\n",
       "      <td>0.666578</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.647296</td>\n",
       "      <td>0.633838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.679600</td>\n",
       "      <td>0.619159</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.684200</td>\n",
       "      <td>0.598345</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>0.586314</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.652400</td>\n",
       "      <td>0.573526</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.565149</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.625800</td>\n",
       "      <td>0.562277</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.637300</td>\n",
       "      <td>0.560573</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 22:42:14,630] Trial 25 finished with values: [0.560573160648346, 0.7196969696969697] and parameters: {'lr': 2.4685297244203862e-05, 'batch': 2, 'accum': 2, 'dropout_rate': 0.8023980394643684, 'weight_decay': 0.00032258504304615476, 'warmup_pct': 0.29196768267226764, 'lora_rank': 16, 'lora_init_scale': 0.0008155565653351553, 'lora_scaling_rank': 8}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.560573160648346, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.7116, 'eval_samples_per_second': 45.456, 'eval_steps_per_second': 5.739, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7307, 'learning_rate': 4.228104545287513e-06, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6853069067001343, 'eval_accuracy': 0.5454545454545454, 'eval_runtime': 8.6288, 'eval_samples_per_second': 45.893, 'eval_steps_per_second': 5.795, 'epoch': 1.0, 'step': 396}, {'loss': 0.7231, 'learning_rate': 8.456209090575025e-06, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6665775775909424, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 8.6869, 'eval_samples_per_second': 45.586, 'eval_steps_per_second': 5.756, 'epoch': 2.0, 'step': 792}, {'loss': 0.7241, 'learning_rate': 1.2684313635862538e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6472959518432617, 'eval_accuracy': 0.6338383838383839, 'eval_runtime': 8.6904, 'eval_samples_per_second': 45.567, 'eval_steps_per_second': 5.753, 'epoch': 3.0, 'step': 1188}, {'loss': 0.6796, 'learning_rate': 1.691241818115005e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6191592216491699, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 8.6872, 'eval_samples_per_second': 45.584, 'eval_steps_per_second': 5.756, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6842, 'learning_rate': 2.1140522726437565e-05, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5983450412750244, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.6886, 'eval_samples_per_second': 45.577, 'eval_steps_per_second': 5.755, 'epoch': 5.0, 'step': 1980}, {'loss': 0.6692, 'learning_rate': 2.3726644924040607e-05, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.5863141417503357, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 8.693, 'eval_samples_per_second': 45.554, 'eval_steps_per_second': 5.752, 'epoch': 6.0, 'step': 2376}, {'loss': 0.6524, 'learning_rate': 1.7794983693030453e-05, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.5735262632369995, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 8.6948, 'eval_samples_per_second': 45.544, 'eval_steps_per_second': 5.751, 'epoch': 7.0, 'step': 2772}, {'loss': 0.631, 'learning_rate': 1.1863322462020303e-05, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.5651485323905945, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.6938, 'eval_samples_per_second': 45.55, 'eval_steps_per_second': 5.751, 'epoch': 8.0, 'step': 3168}, {'loss': 0.6258, 'learning_rate': 5.931661231010152e-06, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.5622768402099609, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.6991, 'eval_samples_per_second': 45.522, 'eval_steps_per_second': 5.748, 'epoch': 9.0, 'step': 3564}, {'loss': 0.6373, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.560573160648346, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.7035, 'eval_samples_per_second': 45.499, 'eval_steps_per_second': 5.745, 'epoch': 10.0, 'step': 3960}, {'train_runtime': 649.78, 'train_samples_per_second': 24.377, 'train_steps_per_second': 6.094, 'total_flos': 9465195637497600.0, 'train_loss': 0.6757464668967507, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.560573160648346, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.7116, 'eval_samples_per_second': 45.456, 'eval_steps_per_second': 5.739, 'epoch': 10.0, 'step': 3960}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [01:12<00:00, 36.27s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:08<00:00, 34.45s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 10:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.744700</td>\n",
       "      <td>0.677861</td>\n",
       "      <td>0.643939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.719400</td>\n",
       "      <td>0.648837</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.715300</td>\n",
       "      <td>0.626127</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.673800</td>\n",
       "      <td>0.608383</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.687100</td>\n",
       "      <td>0.598578</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.673400</td>\n",
       "      <td>0.592852</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.668200</td>\n",
       "      <td>0.588148</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>0.586289</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.655700</td>\n",
       "      <td>0.585043</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.661800</td>\n",
       "      <td>0.584541</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 22:56:21,588] Trial 26 finished with values: [0.5850428342819214, 0.7171717171717171] and parameters: {'lr': 3.8071338526048985e-05, 'batch': 2, 'accum': 8, 'dropout_rate': 0.835063446971687, 'weight_decay': 0.0004807502609027021, 'warmup_pct': 0.024105438799975704, 'lora_rank': 4, 'lora_init_scale': 0.00018005405350406627, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5850428342819214, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.7293, 'eval_samples_per_second': 45.364, 'eval_steps_per_second': 5.728, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7447, 'learning_rate': 1.9837171126730784e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6778614521026611, 'eval_accuracy': 0.6439393939393939, 'eval_runtime': 8.635, 'eval_samples_per_second': 45.86, 'eval_steps_per_second': 5.79, 'epoch': 1.0, 'step': 99}, {'loss': 0.7194, 'learning_rate': 3.7690625140788493e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6488370895385742, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 8.6868, 'eval_samples_per_second': 45.586, 'eval_steps_per_second': 5.756, 'epoch': 2.0, 'step': 198}, {'loss': 0.7153, 'learning_rate': 3.2979296998189934e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6261269450187683, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 8.6912, 'eval_samples_per_second': 45.563, 'eval_steps_per_second': 5.753, 'epoch': 3.0, 'step': 297}, {'loss': 0.6738, 'learning_rate': 2.8267968855591372e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6083831191062927, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 8.6806, 'eval_samples_per_second': 45.619, 'eval_steps_per_second': 5.76, 'epoch': 4.0, 'step': 396}, {'loss': 0.6871, 'learning_rate': 2.355664071299281e-05, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5985782742500305, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.7074, 'eval_samples_per_second': 45.479, 'eval_steps_per_second': 5.742, 'epoch': 5.0, 'step': 495}, {'loss': 0.6734, 'learning_rate': 1.8845312570394247e-05, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5928522944450378, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.7068, 'eval_samples_per_second': 45.482, 'eval_steps_per_second': 5.743, 'epoch': 6.0, 'step': 594}, {'loss': 0.6682, 'learning_rate': 1.4133984427795686e-05, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5881479978561401, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.7159, 'eval_samples_per_second': 45.434, 'eval_steps_per_second': 5.737, 'epoch': 7.0, 'step': 693}, {'loss': 0.6576, 'learning_rate': 9.422656285197123e-06, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5862890481948853, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 8.723, 'eval_samples_per_second': 45.397, 'eval_steps_per_second': 5.732, 'epoch': 8.0, 'step': 792}, {'loss': 0.6557, 'learning_rate': 4.711328142598562e-06, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.5850428342819214, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.7224, 'eval_samples_per_second': 45.4, 'eval_steps_per_second': 5.732, 'epoch': 9.0, 'step': 891}, {'loss': 0.6618, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5845409631729126, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.7105, 'eval_samples_per_second': 45.462, 'eval_steps_per_second': 5.74, 'epoch': 10.0, 'step': 990}, {'train_runtime': 636.2233, 'train_samples_per_second': 24.897, 'train_steps_per_second': 1.556, 'total_flos': 9465195637497600.0, 'train_loss': 0.6856912323922822, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5850428342819214, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.7293, 'eval_samples_per_second': 45.364, 'eval_steps_per_second': 5.728, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:53<00:00, 26.60s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:03<00:00, 31.71s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 13:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.709000</td>\n",
       "      <td>0.616595</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>0.566880</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.620500</td>\n",
       "      <td>0.556684</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.653300</td>\n",
       "      <td>0.555915</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.678800</td>\n",
       "      <td>0.580378</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.573139</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.711700</td>\n",
       "      <td>0.549602</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.672700</td>\n",
       "      <td>0.611065</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.571962</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.600900</td>\n",
       "      <td>0.565993</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 23:13:15,290] Trial 27 finished with values: [0.5496017932891846, 0.7222222222222222] and parameters: {'lr': 0.00036211202411594545, 'batch': 1, 'accum': 4, 'dropout_rate': 0.7218944288174935, 'weight_decay': 0.0001544159178025411, 'warmup_pct': 0.15508328048386155, 'lora_rank': 32, 'lora_init_scale': 0.000898900407884569, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5496017932891846, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.6871, 'eval_samples_per_second': 45.585, 'eval_steps_per_second': 5.756, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.709, 'learning_rate': 5.8386140696219215e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6165952086448669, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 8.6364, 'eval_samples_per_second': 45.852, 'eval_steps_per_second': 5.789, 'epoch': 1.0, 'step': 396}, {'loss': 0.6609, 'learning_rate': 0.00011677228139243843, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.5668798685073853, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 8.6711, 'eval_samples_per_second': 45.669, 'eval_steps_per_second': 5.766, 'epoch': 2.0, 'step': 792}, {'loss': 0.6205, 'learning_rate': 0.00017515842208865764, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.5566835403442383, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.6902, 'eval_samples_per_second': 45.569, 'eval_steps_per_second': 5.754, 'epoch': 3.0, 'step': 1188}, {'loss': 0.6533, 'learning_rate': 0.00023354456278487686, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.5559149980545044, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 8.6882, 'eval_samples_per_second': 45.579, 'eval_steps_per_second': 5.755, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6788, 'learning_rate': 0.0002919307034810961, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5803782343864441, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 8.686, 'eval_samples_per_second': 45.59, 'eval_steps_per_second': 5.756, 'epoch': 5.0, 'step': 1980}, {'loss': 0.6896, 'learning_rate': 0.0003503168441773153, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.5731387734413147, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.6813, 'eval_samples_per_second': 45.616, 'eval_steps_per_second': 5.76, 'epoch': 6.0, 'step': 2376}, {'loss': 0.7117, 'learning_rate': 0.0002860299764958399, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.5496017932891846, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.6829, 'eval_samples_per_second': 45.607, 'eval_steps_per_second': 5.758, 'epoch': 7.0, 'step': 2772}, {'loss': 0.6727, 'learning_rate': 0.00019068665099722658, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.6110650300979614, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 8.6808, 'eval_samples_per_second': 45.618, 'eval_steps_per_second': 5.76, 'epoch': 8.0, 'step': 3168}, {'loss': 0.66, 'learning_rate': 9.534332549861329e-05, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.5719619393348694, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.6817, 'eval_samples_per_second': 45.613, 'eval_steps_per_second': 5.759, 'epoch': 9.0, 'step': 3564}, {'loss': 0.6009, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.5659925937652588, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.6923, 'eval_samples_per_second': 45.558, 'eval_steps_per_second': 5.752, 'epoch': 10.0, 'step': 3960}, {'train_runtime': 828.5144, 'train_samples_per_second': 19.119, 'train_steps_per_second': 4.78, 'total_flos': 9465195637497600.0, 'train_loss': 0.6657405814739189, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.5496017932891846, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.6871, 'eval_samples_per_second': 45.585, 'eval_steps_per_second': 5.756, 'epoch': 10.0, 'step': 3960}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [01:14<00:00, 37.47s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:11<00:00, 35.87s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='99' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 99/240 02:54 < 04:13, 0.56 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.689300</td>\n",
       "      <td>0.547782</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.571554</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.592100</td>\n",
       "      <td>0.634950</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.616900</td>\n",
       "      <td>0.558932</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5477822422981262, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.6807, 'eval_samples_per_second': 45.619, 'eval_steps_per_second': 5.76, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 23:19:46,127] Trial 28 finished with values: [0.5477822422981262, 0.7247474747474747] and parameters: {'lr': 0.004107622813659247, 'batch': 8, 'accum': 8, 'dropout_rate': 0.6052216458578873, 'weight_decay': 1.7852317440854752e-05, 'warmup_pct': 0.08892559904333748, 'lora_rank': 28, 'lora_init_scale': 0.014581147376230933, 'lora_scaling_rank': 7}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6893, 'learning_rate': 0.0005601303836808064, 'epoch': 0.97, 'step': 24}, {'eval_loss': 0.5477822422981262, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.6067, 'eval_samples_per_second': 46.011, 'eval_steps_per_second': 5.809, 'epoch': 0.97, 'step': 24}, {'loss': 0.589, 'learning_rate': 0.001143599533348313, 'epoch': 1.98, 'step': 49}, {'eval_loss': 0.5715540647506714, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 8.6633, 'eval_samples_per_second': 45.71, 'eval_steps_per_second': 5.771, 'epoch': 1.98, 'step': 49}, {'loss': 0.5921, 'learning_rate': 0.0017270686830158197, 'epoch': 2.99, 'step': 74}, {'eval_loss': 0.6349501013755798, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 8.7083, 'eval_samples_per_second': 45.474, 'eval_steps_per_second': 5.742, 'epoch': 2.99, 'step': 74}, {'loss': 0.6169, 'learning_rate': 0.0023105378326833265, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.5589317679405212, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 8.6717, 'eval_samples_per_second': 45.666, 'eval_steps_per_second': 5.766, 'epoch': 4.0, 'step': 99}, {'train_runtime': 175.6712, 'train_samples_per_second': 90.168, 'train_steps_per_second': 1.366, 'total_flos': 3786078254999040.0, 'train_loss': 0.6211537255181206, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.5477822422981262, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.6807, 'eval_samples_per_second': 45.619, 'eval_steps_per_second': 5.76, 'epoch': 4.0, 'step': 99}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:53<00:00, 26.68s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:03<00:00, 31.94s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 10:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.702100</td>\n",
       "      <td>0.683885</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.660768</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.635683</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.639800</td>\n",
       "      <td>0.612431</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.633300</td>\n",
       "      <td>0.593116</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.608200</td>\n",
       "      <td>0.573765</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.579400</td>\n",
       "      <td>0.559802</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.562800</td>\n",
       "      <td>0.547623</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.552400</td>\n",
       "      <td>0.540495</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.537100</td>\n",
       "      <td>0.532198</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 23:33:25,541] Trial 29 finished with values: [0.5321978330612183, 0.7424242424242424] and parameters: {'lr': 3.8063604168568044e-05, 'batch': 2, 'accum': 8, 'dropout_rate': 0.5266248075117914, 'weight_decay': 0.00016809927271691145, 'warmup_pct': 0.11948298552698644, 'lora_rank': 28, 'lora_init_scale': 0.00011535723452315945, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5321978330612183, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7322, 'eval_samples_per_second': 45.349, 'eval_steps_per_second': 5.726, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7021, 'learning_rate': 3.983400436245493e-06, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6838853359222412, 'eval_accuracy': 0.5555555555555556, 'eval_runtime': 8.6254, 'eval_samples_per_second': 45.911, 'eval_steps_per_second': 5.797, 'epoch': 1.0, 'step': 99}, {'loss': 0.6819, 'learning_rate': 7.966800872490986e-06, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.660768449306488, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 8.6988, 'eval_samples_per_second': 45.523, 'eval_steps_per_second': 5.748, 'epoch': 2.0, 'step': 198}, {'loss': 0.6719, 'learning_rate': 1.195020130873648e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6356831789016724, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 8.7054, 'eval_samples_per_second': 45.489, 'eval_steps_per_second': 5.744, 'epoch': 3.0, 'step': 297}, {'loss': 0.6398, 'learning_rate': 1.5933601744981973e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6124306321144104, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 8.705, 'eval_samples_per_second': 45.491, 'eval_steps_per_second': 5.744, 'epoch': 4.0, 'step': 396}, {'loss': 0.6333, 'learning_rate': 1.9917002181227468e-05, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5931156277656555, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 8.6741, 'eval_samples_per_second': 45.653, 'eval_steps_per_second': 5.764, 'epoch': 5.0, 'step': 495}, {'loss': 0.6082, 'learning_rate': 2.390040261747296e-05, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5737652778625488, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.7169, 'eval_samples_per_second': 45.429, 'eval_steps_per_second': 5.736, 'epoch': 6.0, 'step': 594}, {'loss': 0.5794, 'learning_rate': 2.788380305371845e-05, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5598017573356628, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.733, 'eval_samples_per_second': 45.345, 'eval_steps_per_second': 5.725, 'epoch': 7.0, 'step': 693}, {'loss': 0.5628, 'learning_rate': 3.1867203489963945e-05, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5476233959197998, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7407, 'eval_samples_per_second': 45.305, 'eval_steps_per_second': 5.72, 'epoch': 8.0, 'step': 792}, {'loss': 0.5524, 'learning_rate': 3.585060392620944e-05, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.5404949188232422, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.6935, 'eval_samples_per_second': 45.552, 'eval_steps_per_second': 5.751, 'epoch': 9.0, 'step': 891}, {'loss': 0.5371, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5321978330612183, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.6925, 'eval_samples_per_second': 45.556, 'eval_steps_per_second': 5.752, 'epoch': 10.0, 'step': 990}, {'train_runtime': 635.5188, 'train_samples_per_second': 24.925, 'train_steps_per_second': 1.558, 'total_flos': 9465195637497600.0, 'train_loss': 0.616914255932124, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5321978330612183, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7322, 'eval_samples_per_second': 45.349, 'eval_steps_per_second': 5.726, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [00:54<00:00, 27.04s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:02<00:00, 31.37s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 10:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.705800</td>\n",
       "      <td>0.617574</td>\n",
       "      <td>0.669192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.669700</td>\n",
       "      <td>0.569025</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.653200</td>\n",
       "      <td>0.559389</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.623500</td>\n",
       "      <td>0.538313</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.624200</td>\n",
       "      <td>0.537909</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.627300</td>\n",
       "      <td>0.538384</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.620400</td>\n",
       "      <td>0.532636</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.591400</td>\n",
       "      <td>0.529070</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.600800</td>\n",
       "      <td>0.529373</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.605100</td>\n",
       "      <td>0.527905</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 23:47:16,773] Trial 30 finished with values: [0.5279045701026917, 0.7323232323232324] and parameters: {'lr': 8.04650360563304e-05, 'batch': 2, 'accum': 2, 'dropout_rate': 0.7980894556694724, 'weight_decay': 1.645122634530466e-05, 'warmup_pct': 0.06077209353998927, 'lora_rank': 32, 'lora_init_scale': 0.0001783091925520885, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5279045701026917, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.7, 'eval_samples_per_second': 45.517, 'eval_steps_per_second': 5.747, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7058, 'learning_rate': 6.624564299024292e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6175742149353027, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 8.6635, 'eval_samples_per_second': 45.709, 'eval_steps_per_second': 5.771, 'epoch': 1.0, 'step': 396}, {'loss': 0.6697, 'learning_rate': 7.327198454339025e-05, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.5690245032310486, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.6923, 'eval_samples_per_second': 45.557, 'eval_steps_per_second': 5.752, 'epoch': 2.0, 'step': 792}, {'loss': 0.6532, 'learning_rate': 6.411298647546648e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.5593888163566589, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.6916, 'eval_samples_per_second': 45.561, 'eval_steps_per_second': 5.753, 'epoch': 3.0, 'step': 1188}, {'loss': 0.6235, 'learning_rate': 5.4953988407542696e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.5383133888244629, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 8.6696, 'eval_samples_per_second': 45.677, 'eval_steps_per_second': 5.767, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6242, 'learning_rate': 4.579499033961891e-05, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.537908673286438, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.6748, 'eval_samples_per_second': 45.649, 'eval_steps_per_second': 5.764, 'epoch': 5.0, 'step': 1980}, {'loss': 0.6273, 'learning_rate': 3.6635992271695126e-05, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.5383840203285217, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.6805, 'eval_samples_per_second': 45.62, 'eval_steps_per_second': 5.76, 'epoch': 6.0, 'step': 2376}, {'loss': 0.6204, 'learning_rate': 2.7476994203771348e-05, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.5326359868049622, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.6819, 'eval_samples_per_second': 45.612, 'eval_steps_per_second': 5.759, 'epoch': 7.0, 'step': 2772}, {'loss': 0.5914, 'learning_rate': 1.8317996135847563e-05, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.5290700197219849, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 8.6781, 'eval_samples_per_second': 45.632, 'eval_steps_per_second': 5.762, 'epoch': 8.0, 'step': 3168}, {'loss': 0.6008, 'learning_rate': 9.158998067923782e-06, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.5293727517127991, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.6774, 'eval_samples_per_second': 45.636, 'eval_steps_per_second': 5.762, 'epoch': 9.0, 'step': 3564}, {'loss': 0.6051, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.5279045701026917, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.6886, 'eval_samples_per_second': 45.577, 'eval_steps_per_second': 5.755, 'epoch': 10.0, 'step': 3960}, {'train_runtime': 648.2832, 'train_samples_per_second': 24.434, 'train_steps_per_second': 6.108, 'total_flos': 9465195637497600.0, 'train_loss': 0.6321547267412898, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.5279045701026917, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.7, 'eval_samples_per_second': 45.517, 'eval_steps_per_second': 5.747, 'epoch': 10.0, 'step': 3960}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [01:11<00:00, 35.74s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [01:07<00:00, 33.78s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 13:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.762100</td>\n",
       "      <td>0.680454</td>\n",
       "      <td>0.646465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.724400</td>\n",
       "      <td>0.651431</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.702200</td>\n",
       "      <td>0.621209</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.667400</td>\n",
       "      <td>0.600964</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.664200</td>\n",
       "      <td>0.589349</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.647200</td>\n",
       "      <td>0.580383</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.647400</td>\n",
       "      <td>0.575496</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.655100</td>\n",
       "      <td>0.574599</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.642300</td>\n",
       "      <td>0.571530</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.633500</td>\n",
       "      <td>0.570795</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-10 00:04:25,934] Trial 31 finished with values: [0.571530282497406, 0.7196969696969697] and parameters: {'lr': 3.1719328701763405e-05, 'batch': 1, 'accum': 8, 'dropout_rate': 0.8183205435710353, 'weight_decay': 0.0007893888883924941, 'warmup_pct': 0.03314033573338419, 'lora_rank': 16, 'lora_init_scale': 0.0001409865183358008, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.571530282497406, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.6782, 'eval_samples_per_second': 45.632, 'eval_steps_per_second': 5.762, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7621, 'learning_rate': 1.1985547868223578e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6804540753364563, 'eval_accuracy': 0.6464646464646465, 'eval_runtime': 8.6207, 'eval_samples_per_second': 45.936, 'eval_steps_per_second': 5.8, 'epoch': 1.0, 'step': 198}, {'loss': 0.7244, 'learning_rate': 2.3971095736447156e-05, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6514310240745544, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 8.657, 'eval_samples_per_second': 45.743, 'eval_steps_per_second': 5.776, 'epoch': 2.0, 'step': 396}, {'loss': 0.7022, 'learning_rate': 3.0194360975717087e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6212090849876404, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 8.673, 'eval_samples_per_second': 45.659, 'eval_steps_per_second': 5.765, 'epoch': 3.0, 'step': 594}, {'loss': 0.6674, 'learning_rate': 2.588088083632893e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.600963830947876, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.6791, 'eval_samples_per_second': 45.627, 'eval_steps_per_second': 5.761, 'epoch': 4.0, 'step': 792}, {'loss': 0.6642, 'learning_rate': 2.156740069694078e-05, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5893494486808777, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.6845, 'eval_samples_per_second': 45.598, 'eval_steps_per_second': 5.757, 'epoch': 5.0, 'step': 990}, {'loss': 0.6472, 'learning_rate': 1.725392055755262e-05, 'epoch': 6.0, 'step': 1188}, {'eval_loss': 0.5803828835487366, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.6778, 'eval_samples_per_second': 45.634, 'eval_steps_per_second': 5.762, 'epoch': 6.0, 'step': 1188}, {'loss': 0.6474, 'learning_rate': 1.2940440418164466e-05, 'epoch': 7.0, 'step': 1386}, {'eval_loss': 0.5754960775375366, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 8.67, 'eval_samples_per_second': 45.675, 'eval_steps_per_second': 5.767, 'epoch': 7.0, 'step': 1386}, {'loss': 0.6551, 'learning_rate': 8.62696027877631e-06, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.5745989084243774, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.6694, 'eval_samples_per_second': 45.678, 'eval_steps_per_second': 5.767, 'epoch': 8.0, 'step': 1584}, {'loss': 0.6423, 'learning_rate': 4.313480139388155e-06, 'epoch': 9.0, 'step': 1782}, {'eval_loss': 0.571530282497406, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.667, 'eval_samples_per_second': 45.69, 'eval_steps_per_second': 5.769, 'epoch': 9.0, 'step': 1782}, {'loss': 0.6335, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 0.5707951784133911, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.6726, 'eval_samples_per_second': 45.661, 'eval_steps_per_second': 5.765, 'epoch': 10.0, 'step': 1980}, {'train_runtime': 820.8714, 'train_samples_per_second': 19.297, 'train_steps_per_second': 2.412, 'total_flos': 9465195637497600.0, 'train_loss': 0.6745649048776338, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 0.571530282497406, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.6782, 'eval_samples_per_second': 45.632, 'eval_steps_per_second': 5.762, 'epoch': 10.0, 'step': 1980}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|████████████████████████████████████████████| 2/2 [00:55<00:00, 27.50s/it]\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [01:22<00:00, 41.32s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 990/1980 05:20 < 05:20, 3.09 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.682600</td>\n",
       "      <td>0.594057</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.605100</td>\n",
       "      <td>0.537582</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.582800</td>\n",
       "      <td>0.550787</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.582500</td>\n",
       "      <td>0.549326</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.584900</td>\n",
       "      <td>0.579326</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-10 00:13:13,966] Trial 32 finished with values: [0.5375822186470032, 0.7373737373737373] and parameters: {'lr': 0.0004221456911762967, 'batch': 2, 'accum': 4, 'dropout_rate': 0.6099816609620968, 'weight_decay': 4.182198217267681e-05, 'warmup_pct': 0.1357540026864248, 'lora_rank': 20, 'lora_init_scale': 0.04471507214796212, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5375822186470032, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.7258, 'eval_samples_per_second': 45.383, 'eval_steps_per_second': 5.73, 'epoch': 5.0}\n",
      "History:  [{'loss': 0.6826, 'learning_rate': 7.77533459096807e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.5940570831298828, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 8.6539, 'eval_samples_per_second': 45.76, 'eval_steps_per_second': 5.778, 'epoch': 1.0, 'step': 198}, {'loss': 0.6051, 'learning_rate': 0.0001555066918193614, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.5375822186470032, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.6971, 'eval_samples_per_second': 45.533, 'eval_steps_per_second': 5.749, 'epoch': 2.0, 'step': 396}, {'loss': 0.5828, 'learning_rate': 0.0002332600377290421, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.5507866740226746, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 8.7001, 'eval_samples_per_second': 45.517, 'eval_steps_per_second': 5.747, 'epoch': 3.0, 'step': 594}, {'loss': 0.5825, 'learning_rate': 0.0003110133836387228, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5493258237838745, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.7025, 'eval_samples_per_second': 45.504, 'eval_steps_per_second': 5.745, 'epoch': 4.0, 'step': 792}, {'loss': 0.5849, 'learning_rate': 0.0003887667295484035, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5793264508247375, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.7024, 'eval_samples_per_second': 45.505, 'eval_steps_per_second': 5.746, 'epoch': 5.0, 'step': 990}, {'train_runtime': 320.3759, 'train_samples_per_second': 49.442, 'train_steps_per_second': 6.18, 'total_flos': 4732597818748800.0, 'train_loss': 0.6075794412632182, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5375822186470032, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.7258, 'eval_samples_per_second': 45.383, 'eval_steps_per_second': 5.73, 'epoch': 5.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|████████████████████████████████████████████| 2/2 [00:55<00:00, 27.57s/it]\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [01:03<00:00, 31.65s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 10:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.703500</td>\n",
       "      <td>0.680528</td>\n",
       "      <td>0.601010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.676500</td>\n",
       "      <td>0.652146</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.622971</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.625100</td>\n",
       "      <td>0.597781</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.616700</td>\n",
       "      <td>0.577347</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.558146</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>0.548562</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>0.542203</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.540300</td>\n",
       "      <td>0.539573</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.535500</td>\n",
       "      <td>0.538478</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5384779572486877, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7237, 'eval_samples_per_second': 45.393, 'eval_steps_per_second': 5.732, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7035, 'learning_rate': 5.165856275298698e-06, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6805280447006226, 'eval_accuracy': 0.601010101010101, 'eval_runtime': 8.6313, 'eval_samples_per_second': 45.88, 'eval_steps_per_second': 5.793, 'epoch': 1.0, 'step': 99}, {'loss': 0.6765, 'learning_rate': 1.0331712550597397e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6521461606025696, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 8.6602, 'eval_samples_per_second': 45.726, 'eval_steps_per_second': 5.774, 'epoch': 2.0, 'step': 198}, {'loss': 0.6605, 'learning_rate': 1.5497568825896095e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6229706406593323, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 8.6735, 'eval_samples_per_second': 45.656, 'eval_steps_per_second': 5.765, 'epoch': 3.0, 'step': 297}, {'loss': 0.6251, 'learning_rate': 2.0663425101194794e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5977808833122253, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 8.6769, 'eval_samples_per_second': 45.638, 'eval_steps_per_second': 5.762, 'epoch': 4.0, 'step': 396}, {'loss': 0.6167, 'learning_rate': 2.5829281376493492e-05, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5773470997810364, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 8.6828, 'eval_samples_per_second': 45.607, 'eval_steps_per_second': 5.758, 'epoch': 5.0, 'step': 495}, {'loss': 0.587, 'learning_rate': 2.863004682695664e-05, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5581462979316711, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.6823, 'eval_samples_per_second': 45.61, 'eval_steps_per_second': 5.759, 'epoch': 6.0, 'step': 594}, {'loss': 0.5603, 'learning_rate': 2.147253512021748e-05, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5485624670982361, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.6874, 'eval_samples_per_second': 45.584, 'eval_steps_per_second': 5.755, 'epoch': 7.0, 'step': 693}, {'loss': 0.551, 'learning_rate': 1.431502341347832e-05, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5422030687332153, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.6854, 'eval_samples_per_second': 45.594, 'eval_steps_per_second': 5.757, 'epoch': 8.0, 'step': 792}, {'loss': 0.5403, 'learning_rate': 7.15751170673916e-06, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.5395727157592773, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.6862, 'eval_samples_per_second': 45.589, 'eval_steps_per_second': 5.756, 'epoch': 9.0, 'step': 891}, {'loss': 0.5355, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5384779572486877, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7082, 'eval_samples_per_second': 45.474, 'eval_steps_per_second': 5.742, 'epoch': 10.0, 'step': 990}, {'train_runtime': 634.3344, 'train_samples_per_second': 24.971, 'train_steps_per_second': 1.561, 'total_flos': 9465195637497600.0, 'train_loss': 0.6056491736209754, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5384779572486877, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7237, 'eval_samples_per_second': 45.393, 'eval_steps_per_second': 5.732, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-10 00:26:56,699] Trial 33 finished with values: [0.5384779572486877, 0.7424242424242424] and parameters: {'lr': 3.0003710689866176e-05, 'batch': 2, 'accum': 8, 'dropout_rate': 0.5030553147177205, 'weight_decay': 0.00022564844724190592, 'warmup_pct': 0.07270636561006796, 'lora_rank': 4, 'lora_init_scale': 0.00044213716629277236, 'lora_scaling_rank': 4}. \n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|████████████████████████████████████████████| 2/2 [00:55<00:00, 27.93s/it]\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████| 2/2 [01:08<00:00, 34.22s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to be optimized\n",
    "    # Updated to use suggest_float with log=True for loguniform distribution\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    batch = trial.suggest_categorical('batch', [1, 2, 4, 8])\n",
    "    accum = trial.suggest_categorical('accum', [2, 4, 8])\n",
    "    # Updated to use suggest_float for uniform distribution\n",
    "    dropout = trial.suggest_float('dropout_rate', 0.1, 0.9)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    warmup_pct = trial.suggest_float(\"warmup_pct\", 0.01, 0.3)  # Warmup percentage between 1% and 30%\n",
    "    lora_rank = trial.suggest_int('lora_rank', 4, 32, step=4)\n",
    "    lora_init_scale = trial.suggest_float('lora_init_scale', 1e-4, 1e-1, log=True)\n",
    "    lora_scaling_rank = trial.suggest_int('lora_scaling_rank', 1, 8)\n",
    "\n",
    "\n",
    "    # Training and evaluation\n",
    "    tokenizer, model, history = train_per_protein(\n",
    "        train_dataset=train_set, \n",
    "        valid_dataset=valid_set, \n",
    "        num_labels=2, \n",
    "        batch=batch, \n",
    "        accum=accum, \n",
    "        epochs=10,  # Fewer epochs for the trial runs\n",
    "        lr=lr,\n",
    "        dropout=dropout,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_pct=warmup_pct,\n",
    "        lora_rank=lora_rank,\n",
    "        lora_init_scale=lora_init_scale,\n",
    "        lora_scaling_rank=lora_scaling_rank,\n",
    "    )\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    # torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"History: \", history)\n",
    "    \n",
    "    # Extract the last validation accuracy from the history\n",
    "    val_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry][-1]\n",
    "    val_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry][-1]\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "directions=['minimize', 'maximize']  # Set the direction to maximize the validation accuracy, can also be 'minimize'\n",
    "study = optuna.create_study(directions=directions,\n",
    "                            storage=\"sqlite:///all_dephos_withLORA_esm2_10epochs.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"all_dephos_withLORA_esm2_10epochs\")\n",
    "study.optimize(objective, n_trials=50)  # Adjust the number of trials based on your computational resources\n",
    "\n",
    "# Analyzing results\n",
    "pareto_front = study.best_trials  # Get the Pareto front (best non-dominated solutions)\n",
    "for trial in pareto_front:\n",
    "    print(f\"Loss: {trial.values[0]}, Accuracy: {trial.values[1]}\")  # Note the negation of accuracy\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# print(\"  Value: \", study.best_trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in study.best_trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a28d3c1-8e24-4437-a1d9-dda9cefccfd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:37.168731Z",
     "iopub.status.busy": "2024-04-05T14:04:37.168220Z",
     "iopub.status.idle": "2024-04-05T14:04:38.081706Z",
     "shell.execute_reply": "2024-04-05T14:04:38.080275Z",
     "shell.execute_reply.started": "2024-04-05T14:04:37.168675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Truncate the longer list to the size of the shorter one\n",
    "min_length = min(len(loss), len(val_loss))\n",
    "loss = loss[:min_length]\n",
    "val_loss = val_loss[:min_length]\n",
    "\n",
    "# Get spearman (for regression) or accuracy value (for classification)\n",
    "if [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x] != []:\n",
    "    metric = [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x]\n",
    "else:\n",
    "    metric = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n",
    "\n",
    "epochs = [x['epoch'] for x in history if 'loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "line1 = ax1.plot(epochs, loss, label='train_loss')\n",
    "line2 = ax1.plot(epochs, val_loss, label='validation_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "#line3 = ax2.plot(epochs, metric, color='red', label='validation_metric')\n",
    "ax2.set_ylabel('Metric')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Add grid lines\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 \n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History for fine-tuning\")\n",
    "plt.savefig(f\"../Plots/Without_3rdline_Training_History_new.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4ef6f",
   "metadata": {},
   "source": [
    "lr 0.0003459380673689418\n",
    "batch 4\n",
    "accum 4\n",
    "dropout_rate 0.6303139405233136\n",
    "weight_decay 7.145415686725527e-05\n",
    "warmup_pct 0.12121786012551566\n",
    "lora_rank 20\n",
    "lora_init_scale 0.004413381171295235\n",
    "lora_scaling_rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccb1bbda-d70e-4b4c-a8d4-24600495171a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:38.083526Z",
     "iopub.status.busy": "2024-04-05T14:04:38.083162Z",
     "iopub.status.idle": "2024-04-05T14:04:38.092729Z",
     "shell.execute_reply": "2024-04-05T14:04:38.091278Z",
     "shell.execute_reply.started": "2024-04-05T14:04:38.083490Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "def load_model(filepath, num_labels=2):\n",
    "# Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "    # load a new model\n",
    "    model, tokenizer = ESM_classification_model(num_labels=num_labels, dropout=0.6303139405233136, lora_rank=20, lora_init_scale=0.004413381171295235, lora_scaling_rank=3)\n",
    "    # model_checkpoint = \"facebook/esm2_t36_3B_UR50D\"\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "    # model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c97fa52-3aea-42e8-b72f-c4bb84808576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:05:24.020589Z",
     "iopub.status.busy": "2024-04-05T14:05:24.019788Z",
     "iopub.status.idle": "2024-04-05T14:08:10.428922Z",
     "shell.execute_reply": "2024-04-05T14:08:10.426805Z",
     "shell.execute_reply.started": "2024-04-05T14:05:24.020524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████| 2/2 [01:10<00:00, 35.41s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.55s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_all_esm2.pth\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2c20e75-5f40-4ca1-9579-5df49b738fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:10.432313Z",
     "iopub.status.busy": "2024-04-05T14:08:10.431835Z",
     "iopub.status.idle": "2024-04-05T14:08:19.838631Z",
     "shell.execute_reply": "2024-04-05T14:08:19.836988Z",
     "shell.execute_reply.started": "2024-04-05T14:08:10.432274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have different weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50b8a403-e7c5-4912-9c7a-f404c060c32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.841225Z",
     "iopub.status.busy": "2024-04-05T14:08:19.840752Z",
     "iopub.status.idle": "2024-04-05T14:08:19.864579Z",
     "shell.execute_reply": "2024-04-05T14:08:19.862993Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.841173Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WUI4|HDAC7_HUMAN%342%358</td>\n",
       "      <td>ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|Q13950|RUNX2_HUMAN%416%432</td>\n",
       "      <td>THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q15796|SMAD2_HUMAN%229%245</td>\n",
       "      <td>DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%416%432</td>\n",
       "      <td>TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2798%2814</td>\n",
       "      <td>MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0   sp|Q8WUI4|HDAC7_HUMAN%342%358  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
       "1   sp|Q13950|RUNX2_HUMAN%416%432  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
       "2   sp|Q15796|SMAD2_HUMAN%229%245  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
       "3    sp|P05787|K2C8_HUMAN%416%432  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2798%2814  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "    \n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_Y.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2d18716-fd26-49fe-9ba4-b84c936a364c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.867076Z",
     "iopub.status.busy": "2024-04-05T14:08:19.866598Z",
     "iopub.status.idle": "2024-04-05T14:08:19.887853Z",
     "shell.execute_reply": "2024-04-05T14:08:19.886215Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.867024Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sequence  label\n",
      "0  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
      "1  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
      "2  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
      "3  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
      "4  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1\n"
     ]
    }
   ],
   "source": [
    "my_test=df[[\"sequence\", \"label\"]]\n",
    "\n",
    "print(my_test.head(5))\n",
    "\n",
    "'''\n",
    "my_test[\"sequence\"]=my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "my_test['sequence']=my_test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "'''\n",
    "\n",
    "#Using .loc ensures that you are modifying the original DataFrame rather than a view of it, which helps avoid the SettingWithCopyWarning.\n",
    "# Replace characters in the \"sequence\" column\n",
    "my_test.loc[:, \"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Convert each sequence to a space-separated string\n",
    "my_test.loc[:, 'sequence'] = my_test.apply(lambda row: \" \".join(row[\"sequence\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eee8fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = sequence.split()\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "my_test['middle_char'] = my_test['sequence'].apply(get_middle_char)\n",
    "\n",
    "# Split the DataFrame\n",
    "my_test_S = my_test[my_test['middle_char'] == 'S'].drop(columns=['middle_char'])\n",
    "my_test_T = my_test[my_test['middle_char'] == 'T'].drop(columns=['middle_char'])\n",
    "my_test_Y = my_test[my_test['middle_char'] == 'Y'].drop(columns=['middle_char'])\n",
    "my_test_ST = my_test[my_test['middle_char'].isin(['S', 'T'])].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcd9ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0dff151-a667-4717-af18-401818bc4c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.889951Z",
     "iopub.status.busy": "2024-04-05T14:08:19.889601Z",
     "iopub.status.idle": "2024-04-05T14:08:22.641629Z",
     "shell.execute_reply": "2024-04-05T14:08:22.639919Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.889916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.762821 |      0.846154 |      0.916667 |       0.88 |  0.956731 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[22  4]\n",
      " [ 2 22]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ce2f51a-887c-4684-82b9-22ea5fffd334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:22.647264Z",
     "iopub.status.busy": "2024-04-05T14:08:22.646121Z",
     "iopub.status.idle": "2024-04-05T14:08:23.557189Z",
     "shell.execute_reply": "2024-04-05T14:08:23.555594Z",
     "shell.execute_reply.started": "2024-04-05T14:08:22.647207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['0', '1']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"../Plots/Confusion_matrix_for_dephos_new.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07603226",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5e0d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [00:08<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.536105 |        0.6875 |      0.842342 |   0.764574 |  0.854448 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[154  70]\n",
      " [ 35 187]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5528dc-6e06-456d-920f-8f05055d0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, n_neighbors=5, min_dist=0.01, metric='euclidean'):\n",
    "    umap_model = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric\n",
    "    )\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    df = pd.DataFrame({\n",
    "        \"UMAP1\": embeddings[:, 0],\n",
    "        \"UMAP2\": embeddings[:, 1],\n",
    "        \"Label\": labels\n",
    "    })\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = sns.scatterplot(\n",
    "        x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9\n",
    "    )\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.legend(title='Label', bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_ST.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "    embeddings = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch = sequences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "            embeddings.extend(hidden_states[:, 0, :])\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(sequences) // batch_size + 1}\")\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7718f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = list(sequence)\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "valid_df = df\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "valid_df['middle_char'] = valid_df['sequence'].apply(get_middle_char)\n",
    "\n",
    "valid_df = valid_df[valid_df['middle_char'] == 'T'].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a162964f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sp|Q9GZM8|NDEL1_HUMAN%203%219</td>\n",
       "      <td>CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>sp|Q8N163|CCAR2_HUMAN%438%454</td>\n",
       "      <td>EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>sp|P10636-8|TAU_HUMAN%196%212</td>\n",
       "      <td>GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>sp|Q02241|KIF23_HUMAN%434%450</td>\n",
       "      <td>QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sp|Q04206|TF65_HUMAN%419%435</td>\n",
       "      <td>QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>sp|Q76N33|STALP_MOUSE%326%342</td>\n",
       "      <td>ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>sp|P49790|NU153_HUMAN%1098%1114</td>\n",
       "      <td>FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>sp|Q8NFC6|BD1L1_HUMAN%2789%2805</td>\n",
       "      <td>DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>sp|Q5T6F2|UBAP2_HUMAN%514%530</td>\n",
       "      <td>SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>sp|Q9H040|SPRTN_HUMAN%265%281</td>\n",
       "      <td>NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name                           sequence  label\n",
       "180    sp|Q9GZM8|NDEL1_HUMAN%203%219  CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI      1\n",
       "181    sp|Q8N163|CCAR2_HUMAN%438%454  EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA      1\n",
       "182    sp|P10636-8|TAU_HUMAN%196%212  GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV      1\n",
       "183    sp|Q02241|KIF23_HUMAN%434%450  QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE      1\n",
       "184     sp|Q04206|TF65_HUMAN%419%435  QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG      1\n",
       "..                               ...                                ...    ...\n",
       "441    sp|Q76N33|STALP_MOUSE%326%342  ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS      0\n",
       "442  sp|P49790|NU153_HUMAN%1098%1114  FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ      0\n",
       "443  sp|Q8NFC6|BD1L1_HUMAN%2789%2805  DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL      0\n",
       "444    sp|Q5T6F2|UBAP2_HUMAN%514%530  SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS      0\n",
       "445    sp|Q9H040|SPRTN_HUMAN%265%281  NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN      0\n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a44d9187-1ac5-4e36-89a0-8f827a7f0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 3559427.0\n",
      "\n",
      "Processed batch 1/3\n",
      "Processed batch 2/3\n",
      "Processed batch 3/3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_df = my_valid\n",
    "\n",
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_ST.pth\",num_labels=2)\n",
    "\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "valid_sequences = list(valid_df['sequence'])\n",
    "valid_embeddings = get_embeddings(model_reload, tokenizer, valid_sequences)\n",
    "\n",
    "umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "\n",
    "labels = list(valid_df['label'])\n",
    "\n",
    "plot_umap(umap_embeddings, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f029bcf-42ef-4476-b575-3c14adb71b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da0e6c-e921-493b-9304-8ba9aad07d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

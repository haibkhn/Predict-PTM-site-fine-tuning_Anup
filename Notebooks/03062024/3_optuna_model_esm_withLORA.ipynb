{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2319a5",
   "metadata": {},
   "source": [
    "This notebook will implement changing lora settings and separate dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1959ca-a3c9-46d8-8519-064c38f52007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:48:44.051741Z",
     "iopub.status.busy": "2024-04-05T12:48:44.050047Z",
     "iopub.status.idle": "2024-04-05T12:52:49.260801Z",
     "shell.execute_reply": "2024-04-05T12:52:49.259100Z",
     "shell.execute_reply.started": "2024-04-05T12:48:44.051657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torch==2.1.1 torchaudio torchvision tqdm==4.66.1 accelerate==0.24.1 biopython==1.81 numpy==1.26.2 pandas==2.1.3 \\\n",
    "# transformers==4.35.2 datasets==2.15.0 scikit-learn==1.3.2 umap-learn==0.5.5 sentencepiece==0.1.99 seaborn==0.13.0 scipy==1.11.4 \\\n",
    "# matplotlib==3.8.2 evaluate==0.4.1 deepspeed==0.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060d0bba-32ad-4dc9-b1b8-d1124da1336c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a377270-2995-4da1-a673-5369769a6279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:52:49.264011Z",
     "iopub.status.busy": "2024-04-05T12:52:49.263502Z",
     "iopub.status.idle": "2024-04-05T12:53:29.491461Z",
     "shell.execute_reply": "2024-04-05T12:53:29.490156Z",
     "shell.execute_reply.started": "2024-04-05T12:52:49.263956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "# from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "# from transformers import ESMTokenizer, ESMForSequenceClassification\n",
    "import esm\n",
    "\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install umap-learn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0148ff8f-80eb-4bbd-aac7-fe1f371da27a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.508233Z",
     "iopub.status.busy": "2024-04-05T12:53:29.507801Z",
     "iopub.status.idle": "2024-04-05T12:53:29.536614Z",
     "shell.execute_reply": "2024-04-05T12:53:29.514877Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.508197Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.1.1+cu121\n",
      "Cuda version:  12.1\n",
      "Numpy version:  1.26.4\n",
      "Pandas version:  2.2.2\n",
      "Transformers version:  4.35.2\n",
      "Datasets version:  2.19.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96bd9396-a81c-4d87-a722-0d2020627dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.538488Z",
     "iopub.status.busy": "2024-04-05T12:53:29.538089Z",
     "iopub.status.idle": "2024-04-05T12:53:29.768968Z",
     "shell.execute_reply": "2024-04-05T12:53:29.767620Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.538452Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|P24928|RPB1_HUMAN%1775%1791</td>\n",
       "      <td>NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%58%74</td>\n",
       "      <td>SGMGGITAVTVNQSLLSPLVLEVDPNIQAVRTQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q14832|GRM3_HUMAN%829%845</td>\n",
       "      <td>QPQKNVVTHRLHLNRFSVSGTGTTYSQSSASTY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P01106|MYC_HUMAN%46%62</td>\n",
       "      <td>SEDIWKKFELLPTPPLSPSRRSGLCSPSYVAVT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2792%2808</td>\n",
       "      <td>TREGDSMALYNRTRRISQTSQVSVDAAHGYSPR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0  sp|P24928|RPB1_HUMAN%1775%1791  NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS      1\n",
       "1      sp|P05787|K2C8_HUMAN%58%74  SGMGGITAVTVNQSLLSPLVLEVDPNIQAVRTQ      1\n",
       "2    sp|Q14832|GRM3_HUMAN%829%845  QPQKNVVTHRLHLNRFSVSGTGTTYSQSSASTY      1\n",
       "3       sp|P01106|MYC_HUMAN%46%62  SEDIWKKFELLPTPPLSPSRRSGLCSPSYVAVT      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2792%2808  TREGDSMALYNRTRRISQTSQVSVDAAHGYSPR      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/train_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/train_Pos_Neg_Y.fasta'\n",
    "\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b784f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to get the middle character\n",
    "# def get_middle_char(sequence):\n",
    "#     chars = list(sequence)\n",
    "#     middle_index = len(chars) // 2\n",
    "#     return chars[middle_index]\n",
    "\n",
    "# # Apply the function to get the middle characters\n",
    "# df['middle_char'] = df['sequence'].apply(get_middle_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a68724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to count 'S', 'T', 'Y' in a sequence\n",
    "# def count_chars(sequence, char):\n",
    "#     return sequence.count(char)\n",
    "\n",
    "# # Count the occurrences of 'S', 'T', and 'Y' in the sequences\n",
    "# df['count_S'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'S'))\n",
    "# df['count_T'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'T'))\n",
    "# df['count_Y'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'Y'))\n",
    "\n",
    "# # Sum the counts to get the total occurrences in the DataFrame\n",
    "# total_S = df['count_S'].sum()\n",
    "# total_T = df['count_T'].sum()\n",
    "# total_Y = df['count_Y'].sum()\n",
    "\n",
    "# print(f\"Total number of 'S': {total_S}\")\n",
    "# print(f\"Total number of 'T': {total_T}\")\n",
    "# print(f\"Total number of 'Y': {total_Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9c28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group by label and sum the counts\n",
    "# grouped_counts = df.groupby('label')[['count_S', 'count_T', 'count_Y']].sum().reset_index()\n",
    "\n",
    "# # Display the grouped counts\n",
    "# print(grouped_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c189b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate the DataFrame by middle character\n",
    "# df_S = df[df['middle_char'] == 'S']\n",
    "# df_T = df[df['middle_char'] == 'T']\n",
    "# df_Y = df[df['middle_char'] == 'Y']\n",
    "\n",
    "# # Separate each subset by label\n",
    "# df_S_0 = df_S[df_S['label'] == 0]\n",
    "# df_S_1 = df_S[df_S['label'] == 1]\n",
    "# df_T_0 = df_T[df_T['label'] == 0]\n",
    "# df_T_1 = df_T[df_T['label'] == 1]\n",
    "# df_Y_0 = df_Y[df_Y['label'] == 0]\n",
    "# df_Y_1 = df_Y[df_Y['label'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "333000b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "# # Desired number of samples per group\n",
    "# n_samples_S = 500\n",
    "# n_sampple_T = 300\n",
    "# n_sampple_Y = 200\n",
    "# # Perform stratified sampling\n",
    "# df_S_0_resampled = resample(df_S_0, replace=False, n_samples=n_samples_S, random_state=42)\n",
    "# df_S_1_resampled = resample(df_S_1, replace=False, n_samples=n_samples_S, random_state=42)\n",
    "# df_T_0_resampled = resample(df_T_0, replace=True, n_samples=n_sampple_T, random_state=42)\n",
    "# df_T_1_resampled = resample(df_T_1, replace=True, n_samples=n_sampple_T, random_state=42)\n",
    "# df_Y_0_resampled = resample(df_Y_0, replace=True, n_samples=n_sampple_Y, random_state=42)\n",
    "# df_Y_1_resampled = resample(df_Y_1, replace=True, n_samples=n_sampple_Y, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31710914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine the resampled subsets\n",
    "# balanced_df = pd.concat([\n",
    "#     df_S_0_resampled, df_S_1_resampled,\n",
    "#     df_T_0_resampled, df_T_1_resampled,\n",
    "#     df_Y_0_resampled, df_Y_1_resampled\n",
    "# ])\n",
    "\n",
    "# # Shuffle the combined DataFrame\n",
    "# balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# print(\"Balanced DataFrame:\")\n",
    "# print(balanced_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46617eaa-de6d-4d12-82cb-08ec66b4f56a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.771322Z",
     "iopub.status.busy": "2024-04-05T12:53:29.770859Z",
     "iopub.status.idle": "2024-04-05T12:53:29.786558Z",
     "shell.execute_reply": "2024-04-05T12:53:29.785263Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.771275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the dataset into training and validation sets\n",
    "# my_train, my_valid = train_test_split(\n",
    "#     balanced_df, \n",
    "#     test_size=0.2, \n",
    "#     random_state=42, \n",
    "#     stratify=balanced_df[['label', 'middle_char']]\n",
    "# )\n",
    "\n",
    "# my_train=my_train[[\"sequence\", \"label\"]]\n",
    "# my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# # Print the first 5 rows of the training set\n",
    "# print(\"Training Set:\")\n",
    "# print(my_train.shape)\n",
    "\n",
    "# # Print the first 5 rows of the validation set\n",
    "# print(\"\\nValidation Set:\")\n",
    "# print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76760f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "(1584, 2)\n",
      "\n",
      "Validation Set:\n",
      "(396, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "my_train, my_valid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "my_train=my_train[[\"sequence\", \"label\"]]\n",
    "my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the training set\n",
    "print(\"Training Set:\")\n",
    "print(my_train.shape)\n",
    "\n",
    "# Print the first 5 rows of the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a424877b-787c-44fe-bf87-33346ffd3be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.789138Z",
     "iopub.status.busy": "2024-04-05T12:53:29.788675Z",
     "iopub.status.idle": "2024-04-05T12:53:29.816779Z",
     "shell.execute_reply": "2024-04-05T12:53:29.815341Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.789094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifies an existing transformer and introduce the LoRA layers\n",
    "\n",
    "class LoRAConfig:\n",
    "    def __init__(self, lora_rank=4, lora_init_scale=0.01, lora_scaling_rank=1):\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_init_scale = lora_init_scale\n",
    "        self.lora_modules = \".*SelfAttention|.*EncDecAttention\"\n",
    "        self.lora_layers = \"q|k|v|o\"\n",
    "        self.trainable_param_names = \".*layer_norm.*|.*lora_[ab].*\"\n",
    "        self.lora_scaling_rank = lora_scaling_rank\n",
    "        # lora_modules and lora_layers are specified with regular expressions\n",
    "        # see https://www.w3schools.com/python/python_regex.asp for reference\n",
    "        \n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, scaling_rank, init_scale):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.rank = rank\n",
    "        self.scaling_rank = scaling_rank\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        if self.rank > 0:\n",
    "            self.lora_a = nn.Parameter(torch.randn(rank, linear_layer.in_features) * init_scale)\n",
    "            if init_scale < 0:\n",
    "                self.lora_b = nn.Parameter(torch.randn(linear_layer.out_features, rank) * init_scale)\n",
    "            else:\n",
    "                self.lora_b = nn.Parameter(torch.zeros(linear_layer.out_features, rank))\n",
    "        if self.scaling_rank:\n",
    "            self.multi_lora_a = nn.Parameter(\n",
    "                torch.ones(self.scaling_rank, linear_layer.in_features)\n",
    "                + torch.randn(self.scaling_rank, linear_layer.in_features) * init_scale\n",
    "            )\n",
    "            if init_scale < 0:\n",
    "                self.multi_lora_b = nn.Parameter(\n",
    "                    torch.ones(linear_layer.out_features, self.scaling_rank)\n",
    "                    + torch.randn(linear_layer.out_features, self.scaling_rank) * init_scale\n",
    "                )\n",
    "            else:\n",
    "                self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, self.scaling_rank))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.scaling_rank == 1 and self.rank == 0:\n",
    "            # parsimonious implementation for ia3 and lora scaling\n",
    "            if self.multi_lora_a.requires_grad:\n",
    "                hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n",
    "            else:\n",
    "                hidden = F.linear(input, self.weight, self.bias)\n",
    "            if self.multi_lora_b.requires_grad:\n",
    "                hidden = hidden * self.multi_lora_b.flatten()\n",
    "            return hidden\n",
    "        else:\n",
    "            # general implementation for lora (adding and scaling)\n",
    "            weight = self.weight\n",
    "            if self.scaling_rank:\n",
    "                weight = weight * torch.matmul(self.multi_lora_b, self.multi_lora_a) / self.scaling_rank\n",
    "            if self.rank:\n",
    "                weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n",
    "            return F.linear(input, weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, rank={}, scaling_rank={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.rank, self.scaling_rank\n",
    "        )\n",
    "\n",
    "\n",
    "def modify_with_lora(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.lora_modules, m_name):\n",
    "            for c_name, layer in dict(module.named_children()).items():\n",
    "                if re.fullmatch(config.lora_layers, c_name):\n",
    "                    assert isinstance(\n",
    "                        layer, nn.Linear\n",
    "                    ), f\"LoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        c_name,\n",
    "                        LoRALinear(layer, config.lora_rank, config.lora_scaling_rank, config.lora_init_scale),\n",
    "                    )\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e79b323-4677-4723-a5fd-a60dc13a3b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.819433Z",
     "iopub.status.busy": "2024-04-05T12:53:29.818965Z",
     "iopub.status.idle": "2024-04-05T12:53:29.845976Z",
     "shell.execute_reply": "2024-04-05T12:53:29.844438Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.819335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.7, num_labels=2):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class T5EncoderClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, class_config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "        \n",
    "        # Trainable emphasis factor\n",
    "        self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        seq_length = hidden_states.size(1)\n",
    "        middle_idx = seq_length // 2\n",
    "        middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "        # Apply trainable emphasis factor\n",
    "        emphasized_middle_embedding = middle_embedding * self.emphasis_factor\n",
    "\n",
    "        # Combine with the average embedding\n",
    "        average_embedding = torch.mean(hidden_states, dim=1)\n",
    "        combined_embedding = emphasized_middle_embedding + average_embedding\n",
    "\n",
    "        x = self.dropout(combined_embedding)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.out_proj(x)\n",
    "        return logits\n",
    "\n",
    "    # def forward(self, hidden_states):\n",
    "\n",
    "    #     hidden_states =  torch.mean(hidden_states,dim=1)  # avg embedding\n",
    "\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.dense(hidden_states)\n",
    "    #     hidden_states = torch.tanh(hidden_states)\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.out_proj(hidden_states)\n",
    "    #     return hidden_states\n",
    "    \n",
    "    # def forward(self, hidden_states):\n",
    "    #     # Original sequence length and middle index\n",
    "    #     seq_length = hidden_states.size(1)\n",
    "    #     middle_idx = seq_length // 2\n",
    "\n",
    "    #     # Extract the middle embedding vector\n",
    "    #     middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "    #     # Amplify the influence of the middle embedding\n",
    "    #     amplified_middle_embedding = middle_embedding * 2\n",
    "\n",
    "    #     # Combine with average to retain context\n",
    "    #     average_embedding = torch.mean(hidden_states, dim=1)\n",
    "    #     combined_embedding = 0.5 * amplified_middle_embedding + 0.5 * average_embedding\n",
    "\n",
    "    #     # Classification layers\n",
    "    #     x = self.dropout(combined_embedding)\n",
    "    #     x = self.dense(x)\n",
    "    #     x = torch.tanh(x)\n",
    "    #     x = self.dropout(x)\n",
    "    #     logits = self.out_proj(x)\n",
    "    #     return logits\n",
    "\n",
    "\n",
    "# class T5EncoderForSimpleSequenceClassification(T5PreTrainedModel):\n",
    "\n",
    "#     def __init__(self, config: T5Config, class_config):\n",
    "#         super().__init__(config)\n",
    "#         self.num_labels = class_config.num_labels\n",
    "#         self.config = config\n",
    "\n",
    "#         self.shared = nn.Embedding(config.vocab_size, config.d_model)\n",
    "\n",
    "#         encoder_config = copy.deepcopy(config)\n",
    "#         encoder_config.use_cache = False\n",
    "#         encoder_config.is_encoder_decoder = False\n",
    "#         self.encoder = T5Stack(encoder_config, self.shared)\n",
    "\n",
    "#         self.dropout = nn.Dropout(class_config.dropout_rate) \n",
    "#         self.classifier = T5EncoderClassificationHead(config, class_config)\n",
    "\n",
    "#         # Initialize weights and apply final processing\n",
    "#         self.post_init()\n",
    "\n",
    "#         # Model parallel\n",
    "#         self.model_parallel = False\n",
    "#         self.device_map = None\n",
    "\n",
    "#     def parallelize(self, device_map=None):\n",
    "#         self.device_map = (\n",
    "#             get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
    "#             if device_map is None\n",
    "#             else device_map\n",
    "#         )\n",
    "#         assert_device_map(self.device_map, len(self.encoder.block))\n",
    "#         self.encoder.parallelize(self.device_map)\n",
    "#         self.classifier = self.classifier.to(self.encoder.first_device)\n",
    "#         self.model_parallel = True\n",
    "\n",
    "#     def deparallelize(self):\n",
    "#         self.encoder.deparallelize()\n",
    "#         self.encoder = self.encoder.to(\"cpu\")\n",
    "#         self.model_parallel = False\n",
    "#         self.device_map = None\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#     def get_input_embeddings(self):\n",
    "#         return self.shared\n",
    "\n",
    "#     def set_input_embeddings(self, new_embeddings):\n",
    "#         self.shared = new_embeddings\n",
    "#         self.encoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "#     def get_encoder(self):\n",
    "#         return self.encoder\n",
    "\n",
    "#     def _prune_heads(self, heads_to_prune):\n",
    "#         \"\"\"\n",
    "#         Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "#         class PreTrainedModel\n",
    "#         \"\"\"\n",
    "#         for layer, heads in heads_to_prune.items():\n",
    "#             self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         input_ids=None,\n",
    "#         attention_mask=None,\n",
    "#         head_mask=None,\n",
    "#         inputs_embeds=None,\n",
    "#         labels=None,\n",
    "#         output_attentions=None,\n",
    "#         output_hidden_states=None,\n",
    "#         return_dict=None,\n",
    "#     ):\n",
    "#         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "#         outputs = self.encoder(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             inputs_embeds=inputs_embeds,\n",
    "#             head_mask=head_mask,\n",
    "#             output_attentions=output_attentions,\n",
    "#             output_hidden_states=True,\n",
    "#             return_dict=return_dict,\n",
    "#         )\n",
    "\n",
    "#         hidden_states = outputs[0]\n",
    "#         logits = self.classifier(hidden_states)\n",
    "\n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             if self.config.problem_type is None:\n",
    "#                 if self.num_labels == 1:\n",
    "#                     self.config.problem_type = \"regression\"\n",
    "#                 elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "#                     self.config.problem_type = \"single_label_classification\"\n",
    "#                 else:\n",
    "#                     self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "#             if self.config.problem_type == \"regression\":\n",
    "#                 loss_fct = MSELoss()\n",
    "#                 if self.num_labels == 1:\n",
    "#                     loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "#                 else:\n",
    "#                     loss = loss_fct(logits, labels)\n",
    "#             elif self.config.problem_type == \"single_label_classification\":\n",
    "#                 loss_fct = CrossEntropyLoss()\n",
    "#                 loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "#             elif self.config.problem_type == \"multi_label_classification\":\n",
    "#                 loss_fct = BCEWithLogitsLoss()\n",
    "#                 loss = loss_fct(logits, labels)\n",
    "#         if not return_dict:\n",
    "#             output = (logits,) + outputs[1:]\n",
    "#             return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "#         return SequenceClassifierOutput(\n",
    "#             loss=loss,\n",
    "#             logits=logits,\n",
    "#             hidden_states=outputs.hidden_states,\n",
    "#             attentions=outputs.attentions,\n",
    "#         )\n",
    "        \n",
    "# import esm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class ESMEncoderForSimpleSequenceClassification(nn.Module):\n",
    "    def __init__(self, esm_model, class_config):\n",
    "        super().__init__()\n",
    "        self.esm_model = esm_model\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        \n",
    "        # Get the dimension of the embeddings\n",
    "        embed_dim = esm_model.args.embed_dim\n",
    "        self.classifier = nn.Linear(embed_dim, class_config.num_labels)\n",
    "\n",
    "        # Trainable emphasis factor\n",
    "        self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        # Get the hidden states from the ESM model\n",
    "        outputs = self.esm_model(input_ids, repr_layers=[33])\n",
    "        hidden_states = outputs[\"representations\"][33]\n",
    "\n",
    "        # Emphasize the middle token representation\n",
    "        seq_length = hidden_states.size(1)\n",
    "        middle_idx = seq_length // 2\n",
    "        middle_embedding = hidden_states[:, middle_idx, :]\n",
    "        emphasized_middle_embedding = middle_embedding * self.emphasis_factor\n",
    "\n",
    "        # Combine with average embedding\n",
    "        average_embedding = torch.mean(hidden_states, dim=1)\n",
    "        combined_embedding = emphasized_middle_embedding + average_embedding\n",
    "\n",
    "        x = self.dropout(combined_embedding)\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=hidden_states,\n",
    "            attentions=None,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "# # Load ESM model\n",
    "# esm_model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "\n",
    "# # Initialize class configuration\n",
    "# class_config = ClassConfig(dropout=0.7, num_labels=2)\n",
    "\n",
    "# # Initialize the model with ESM encoder\n",
    "# model = ESMEncoderForSimpleSequenceClassification(esm_model, class_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71394626-6f8b-4ca5-80f3-c697e4320bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.848217Z",
     "iopub.status.busy": "2024-04-05T12:53:29.847782Z",
     "iopub.status.idle": "2024-04-05T12:53:29.859841Z",
     "shell.execute_reply": "2024-04-05T12:53:29.858398Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.848182Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def PT5_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "#     # Load PT5 and tokenizer\n",
    "#     model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "#     tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", do_lower_case=False, force_download=True) \n",
    "    \n",
    "#     # Create new Classifier model with PT5 dimensions\n",
    "#     class_config=ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "#     class_model=T5EncoderForSimpleSequenceClassification(model.config,class_config)\n",
    "    \n",
    "#     # Set encoder and embedding weights to checkpoint weights\n",
    "#     class_model.shared=model.shared\n",
    "#     class_model.encoder=model.encoder    \n",
    "    \n",
    "#     # Delete the checkpoint model\n",
    "#     model=class_model\n",
    "#     del class_model\n",
    "    \n",
    "#     # Print number of trainable parameters\n",
    "#     model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "#     params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "#     print(\"ProtT5_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "#     # Add model modification lora\n",
    "#     config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "#     # Add LoRA layers\n",
    "#     model = modify_with_lora(model, config)\n",
    "    \n",
    "#     # Freeze Embeddings and Encoder (except LoRA)\n",
    "#     for (param_name, param) in model.shared.named_parameters():\n",
    "#                 param.requires_grad = False\n",
    "#     for (param_name, param) in model.encoder.named_parameters():\n",
    "#                 param.requires_grad = False       \n",
    "\n",
    "#     for (param_name, param) in model.named_parameters():\n",
    "#             if re.fullmatch(config.trainable_param_names, param_name):\n",
    "#                 param.requires_grad = True\n",
    "\n",
    "#     # Print trainable Parameter          \n",
    "#     model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "#     params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "#     print(\"ProtT5_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "#     return model, tokenizer\n",
    "\n",
    "# import esm\n",
    "def ESM_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "    # Load ESM model and alphabet\n",
    "    # esm2_t33_650M_UR50D\n",
    "    esm_model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    \n",
    "    # Define class configuration\n",
    "    class_config = ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "    \n",
    "    # Create new classifier model with ESM dimensions\n",
    "    class_model = ESMEncoderForSimpleSequenceClassification(esm_model, class_config)\n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, class_model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ESM_Classfier\\nTrainable Parameter: \" + str(params))\n",
    "    \n",
    "    # Add model modification LoRA\n",
    "    config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "    # Add LoRA layers\n",
    "    class_model = modify_with_lora(class_model, config)\n",
    "    \n",
    "    # Freeze Embeddings and Encoder (except LoRA)\n",
    "    for param_name, param in class_model.esm_model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param_name, param in class_model.named_parameters():\n",
    "        if re.fullmatch(config.trainable_param_names, param_name):\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, class_model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ESM_LoRA_Classfier\\nTrainable Parameter: \" + str(params) + \"\\n\")\n",
    "    \n",
    "    return class_model, batch_converter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4d56b2-c9ca-460d-b977-a1e4ae1e9568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.864172Z",
     "iopub.status.busy": "2024-04-05T12:53:29.863760Z",
     "iopub.status.idle": "2024-04-05T12:53:29.873119Z",
     "shell.execute_reply": "2024-04-05T12:53:29.871609Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.864135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4550fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    \"\"\"Custom early stopping callback that can monitor loss or accuracy.\"\"\"\n",
    "    \n",
    "    def __init__(self, metric_name='eval_loss', early_stopping_patience=3, minimize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric_name (str): Metric to monitor, default 'eval_loss'.\n",
    "            early_stopping_patience (int): Number of checks with no improvement after which training will be stopped.\n",
    "            minimize (bool): Set to True if the metric should be minimized, False if it should be maximized.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_counter = 0\n",
    "        self.minimize = minimize\n",
    "        self.best_metric = float('inf') if minimize else float('-inf')\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        current_metric = kwargs['metrics'][self.metric_name]\n",
    "        \n",
    "        if (self.minimize and current_metric < self.best_metric) or (not self.minimize and current_metric > self.best_metric):\n",
    "            self.best_metric = current_metric\n",
    "            self.early_stopping_counter = 0\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "        \n",
    "        if self.early_stopping_counter >= self.early_stopping_patience:\n",
    "            control.should_training_stop = True\n",
    "            print(f'Stopping early! No improvement in {self.metric_name} for {self.early_stopping_patience} evaluation steps.')\n",
    "\n",
    "\n",
    "class MultiObjectiveEarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        # Extract current validation loss and accuracy\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "\n",
    "        # Check if current loss and accuracy improved significantly\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            # Update best scores and reset wait time\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            # If no improvement, increment the wait counter\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                # If wait exceeds the patience, stop training\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "class MultiObjectiveEarlyStoppingAndSaveCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001, output_dir='./model_output', filename='finetuned_model'):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "        self.output_dir = output_dir\n",
    "        self.filename = filename\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "        model = kwargs['model']\n",
    "\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "            # Save the model as the best so far\n",
    "            self.save_finetuned_parameters(model, os.path.join(self.output_dir, self.filename))\n",
    "            print(f\"Saved improved model to {self.output_dir}/{self.filename}\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "    def save_finetuned_parameters(self, model, filepath):\n",
    "        # Create a dictionary to hold the non-frozen parameters\n",
    "        non_frozen_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "        # Save only the finetuned parameters \n",
    "        torch.save(non_frozen_params, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ea2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['HF_HOME'] = '/home/ubuntu/data/hai/huggingface_cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb8bb11-79b0-4936-9099-f9f8ef97e105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.875565Z",
     "iopub.status.busy": "2024-04-05T12:53:29.875038Z",
     "iopub.status.idle": "2024-04-05T12:53:30.214710Z",
     "shell.execute_reply": "2024-04-05T12:53:30.213349Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.875495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# #!pip install seaborn\n",
    "# import seaborn as sns\n",
    "# import gc\n",
    "\n",
    "# # Set random seeds for reproducibility of your trainings run\n",
    "# def set_seeds(s):\n",
    "#     torch.manual_seed(s)\n",
    "#     np.random.seed(s)\n",
    "#     random.seed(s)\n",
    "#     set_seed(s)\n",
    "\n",
    "# def apply_umap(embeddings, n_components=2, min_dist=0.01):\n",
    "#     umap_model = umap.UMAP(n_components=n_components)\n",
    "#     umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "#     return umap_embeddings\n",
    "\n",
    "# def plot_umap(embeddings, labels):\n",
    "#     data = {\"UMAP1\": embeddings[:, 0], \"UMAP2\": embeddings[:, 1], \"Label\": labels}\n",
    "#     df = pd.DataFrame(data)\n",
    "    \n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.scatterplot(x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9)\n",
    "#     plt.title(\"UMAP Visualization of Embeddings\")\n",
    "#     plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_new.pdf\")\n",
    "#     plt.show()\n",
    "    \n",
    "# # Main training fuction\n",
    "# def train_per_protein(\n",
    "#         train_dataset,         #training data\n",
    "#         valid_dataset,         #validation data      \n",
    "#         weight_decay,\n",
    "#         warmup_pct,\n",
    "#         num_labels= 2,    #1 for regression, >1 for classification\n",
    "    \n",
    "#         # effective training batch size is batch * accum\n",
    "#         # we recommend an effective batch size of 8 \n",
    "#         batch= 4,         #for training\n",
    "#         accum= 2,         #gradient accumulation\n",
    "    \n",
    "#         val_batch = 16,   #batch size for evaluation\n",
    "#         epochs=1,       #training epochs\n",
    "#         lr= 3e-4,         #recommended learning rate\n",
    "#         seed= 42,         #random seed\n",
    "#         deepspeed=False,  #if gpu is large enough disable deepspeed for training speedup\n",
    "#         gpu= 1,\n",
    "#         dropout=0.5, #dropout rate\n",
    "#          #L2 weight regularization\n",
    "#         lora_rank=4,      #lora rank\n",
    "#         lora_init_scale=0.01, #lora scaling rank\n",
    "#         lora_scaling_rank=1,       #lora a\n",
    "#         ):         #gpu selection (1 for first gpu)\n",
    "\n",
    "#     # Set gpu device\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "#     # Set all random seeds\n",
    "#     set_seeds(seed)\n",
    "    \n",
    "#     # load model\n",
    "#     model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=dropout, lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "\n",
    "#     # Huggingface Trainer arguments\n",
    "#     total_steps = epochs * len(train_dataset) // batch\n",
    "#     warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "#     # Define TrainingArguments\n",
    "#     args = TrainingArguments(\n",
    "#         output_dir='./results',              # where to save the model\n",
    "#         evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "#         logging_strategy='epoch',\n",
    "#         save_strategy='no',\n",
    "#         learning_rate=lr,                    # initial learning rate\n",
    "#         per_device_train_batch_size=batch,   # batch size per device\n",
    "#         gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "#         num_train_epochs=epochs,             # number of epochs to train\n",
    "#         weight_decay=weight_decay,           # L2 weight regularization\n",
    "#         warmup_steps=warmup_steps,           # 10% of total steps\n",
    "#         load_best_model_at_end=False,         # load the best model at the end of training\n",
    "#         seed=seed,                           # random seed\n",
    "#         push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "#         logging_dir='./logs',\n",
    "#     )\n",
    "#     # metric_for_best_model='eval_loss|accuracy'\n",
    "\n",
    "#     # Metric definition for validation data\n",
    "#     def compute_metrics(eval_pred):\n",
    "#         predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "#         # Check if predictions have the expected shape\n",
    "#         if isinstance(predictions, tuple):\n",
    "#             predictions = predictions[0]\n",
    "#         if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "#             predictions = np.argmax(predictions, axis=1)\n",
    "#         # Now, compute the metric (e.g., accuracy)\n",
    "#         accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "#         # Return the metric(s) as a dictionary\n",
    "#         return {\"accuracy\": accuracy}\n",
    "    \n",
    "#     # For minimizing loss\n",
    "#     early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "#     # For maximizing accuracy\n",
    "#     early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "#     # Trainer          \n",
    "#     trainer = Trainer(\n",
    "#         model,\n",
    "#         args,\n",
    "#         train_dataset=train_dataset,\n",
    "#         eval_dataset=valid_dataset,\n",
    "#         tokenizer=tokenizer,\n",
    "#         compute_metrics=compute_metrics,\n",
    "#         callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "#             early_stopping_patience=3,\n",
    "#             min_delta=0.001,\n",
    "#             output_dir='./model_output',\n",
    "#             filename='finetuned_model_all_bfd.pth'\n",
    "#         )],\n",
    "#     )    \n",
    "\n",
    "#     def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "#         embeddings = []\n",
    "#         model = model.to(device)\n",
    "#         model.eval()\n",
    "    \n",
    "#         # Iterate over the sequences in batches\n",
    "#         for i in range(0, len(sequences), batch_size):\n",
    "#             # Extract a batch of sequences\n",
    "#             batch = sequences[i:i + batch_size]\n",
    "    \n",
    "#             # Tokenize the batch using the specified tokenizer and convert to PyTorch tensors\n",
    "#             inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "#             with torch.no_grad():\n",
    "#                 # Forward pass through the model to obtain outputs\n",
    "#                 outputs = model(**inputs)\n",
    "    \n",
    "#             # Extract hidden states from the second-to-last layer (penultimate layer)\n",
    "#             hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "    \n",
    "#             # Take the embeddings from the second-to-last layer\n",
    "#             embeddings_from_layer = hidden_states[:, 0, :]\n",
    "    \n",
    "#             # Extend the list with the generated embeddings\n",
    "#             embeddings.extend(embeddings_from_layer)\n",
    "    \n",
    "#             print(f\"Batch {i // batch_size + 1}, Second-to-Last Layer Embeddings Shape: {embeddings_from_layer.shape}\")\n",
    "    \n",
    "#         return np.array(embeddings)\n",
    "\n",
    "        \n",
    "#     # Train model\n",
    "#     trainer.train()\n",
    "\n",
    "#     # Get the best model\n",
    "#     # model = trainer.model\n",
    "#     # Ensure the best model is loaded\n",
    "#     best_model_path = os.path.join('./model_output', 'finetuned_model_all_bfd.pth')\n",
    "#     if os.path.exists(best_model_path):\n",
    "#         state_dict = torch.load(best_model_path)\n",
    "#         model.load_state_dict(state_dict, strict=False)\n",
    "#         print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "#     # Evaluate the best model\n",
    "#     eval_results = trainer.evaluate()\n",
    "#     print(eval_results)\n",
    "    \n",
    "#     # Print the current learning rate\n",
    "#     # current_lr = trainer.optimizer.param_groups[0]['lr']\n",
    "#     # print(f\"Current learning rate: {current_lr}\")\n",
    "    \n",
    "#     # valid_sequences = list(valid_dataset['sequence'])\n",
    "#     # valid_embeddings = get_embeddings(model, tokenizer, valid_sequences)\n",
    "\n",
    "#     # # Apply UMAP for dimensionality reduction\n",
    "#     # umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "#     # # Plot UMAP embeddings\n",
    "#     # labels = list(valid_dataset['label'])\n",
    "#     # plot_umap(umap_embeddings, labels)\n",
    "    \n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "\n",
    "#     return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aa2bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, min_dist=0.01):\n",
    "    umap_model = umap.UMAP(n_components=n_components)\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    data = {\"UMAP1\": embeddings[:, 0], \"UMAP2\": embeddings[:, 1], \"Label\": labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9)\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_new.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Main training function\n",
    "def train_per_protein(\n",
    "        train_dataset,         # training data\n",
    "        valid_dataset,         # validation data\n",
    "        weight_decay,\n",
    "        warmup_pct,\n",
    "        num_labels=2,    # 1 for regression, >1 for classification\n",
    "        batch=4,         # for training\n",
    "        accum=2,         # gradient accumulation\n",
    "        val_batch=16,   # batch size for evaluation\n",
    "        epochs=1,       # training epochs\n",
    "        lr=3e-4,         # recommended learning rate\n",
    "        seed=42,         # random seed\n",
    "        deepspeed=False,  # if GPU is large enough, disable deepspeed for training speedup\n",
    "        gpu=1,\n",
    "        dropout=0.5,     # dropout rate\n",
    "        lora_rank=4,     # LoRA rank\n",
    "        lora_init_scale=0.01, # LoRA scaling rank\n",
    "        lora_scaling_rank=1,  # LoRA a\n",
    "        ):\n",
    "    \n",
    "    # Set GPU device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # Load model\n",
    "    model, batch_converter = ESM_classification_model(num_labels=num_labels, dropout=dropout, lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    total_steps = epochs * len(train_dataset) // batch\n",
    "    warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "    # Define TrainingArguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir='./results',              # where to save the model\n",
    "        evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "        logging_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        learning_rate=lr,                    # initial learning rate\n",
    "        per_device_train_batch_size=batch,   # batch size per device\n",
    "        gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "        num_train_epochs=epochs,             # number of epochs to train\n",
    "        weight_decay=weight_decay,           # L2 weight regularization\n",
    "        warmup_steps=warmup_steps,           # 10% of total steps\n",
    "        load_best_model_at_end=False,        # load the best model at the end of training\n",
    "        seed=seed,                           # random seed\n",
    "        push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "        logging_dir='./logs',\n",
    "    )\n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        # Check if predictions have the expected shape\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "        # Now, compute the metric (e.g., accuracy)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        # Return the metric(s) as a dictionary\n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    # For minimizing loss\n",
    "    # early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "    # # For maximizing accuracy\n",
    "    # early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=None,  # ESM model doesn't use a HuggingFace tokenizer\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "            early_stopping_patience=3,\n",
    "            min_delta=0.001,\n",
    "            output_dir='./model_output',\n",
    "            filename='finetuned_model_all_esm.pth'\n",
    "        )],    )    \n",
    "\n",
    "    def get_embeddings(model, sequences, batch_size=32, device=\"cuda\"):\n",
    "        embeddings = []\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "    \n",
    "        # Iterate over the sequences in batches\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            # Extract a batch of sequences\n",
    "            batch = sequences[i:i + batch_size]\n",
    "    \n",
    "            # Convert sequences to tokens using batch_converter\n",
    "            batch_labels, batch_strs, batch_tokens = batch_converter(batch)\n",
    "            batch_tokens = batch_tokens.to(device)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                # Forward pass through the model to obtain outputs\n",
    "                outputs = model(batch_tokens)\n",
    "    \n",
    "            # Extract hidden states from the penultimate layer\n",
    "            hidden_states = outputs[\"logits\"].detach().cpu().numpy()\n",
    "    \n",
    "            # Take the embeddings from the second-to-last layer\n",
    "            embeddings_from_layer = hidden_states[:, 0, :]\n",
    "    \n",
    "            # Extend the list with the generated embeddings\n",
    "            embeddings.extend(embeddings_from_layer)\n",
    "    \n",
    "            print(f\"Batch {i // batch_size + 1}, Second-to-Last Layer Embeddings Shape: {embeddings_from_layer.shape}\")\n",
    "    \n",
    "        return np.array(embeddings)\n",
    "\n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    # Get the best model\n",
    "    best_model_path = os.path.join('./model_output', 'finetuned_model_all_esm.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        state_dict = torch.load(best_model_path)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "    # Evaluate the best model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(eval_results)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return None, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "248cf4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "import esm\n",
    "\n",
    "# Function to create dataset\n",
    "def create_dataset(sequences, labels, batch_converter):\n",
    "    # Use the batch_converter to tokenize sequences\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(list(zip(labels, sequences)))\n",
    "    \n",
    "    # Create a dataset from the tokenized sequences\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"input_ids\": batch_tokens.tolist(),\n",
    "        \"labels\": labels\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "# Initialize the ESM model and batch_converter\n",
    "esm_model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "# Assume train_df and valid_df are your training and validation DataFrames\n",
    "train_df = my_train\n",
    "valid_df = my_valid\n",
    "\n",
    "# Preprocess inputs\n",
    "# Replace uncommon AAs with \"X\"\n",
    "train_df[\"sequence\"] = train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]), \"X\", regex=True)\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Create Datasets\n",
    "train_set = create_dataset(list(train_df['sequence']), list(train_df['label']), batch_converter)\n",
    "valid_set = create_dataset(list(valid_df['sequence']), list(valid_df['label']), batch_converter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b300952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# # Dataset creation\n",
    "# def create_dataset(tokenizer,seqs,labels):\n",
    "#     tokenized = tokenizer(seqs, max_length=1024, padding=True, truncation=True)\n",
    "#     dataset = Dataset.from_dict(tokenized)\n",
    "#     dataset = dataset.add_column(\"labels\", labels)\n",
    "\n",
    "#     return dataset\n",
    "\n",
    "# # Initialize the tokenizer\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", do_lower_case=False) \n",
    "\n",
    "# train_df = my_train\n",
    "# valid_df = my_valid\n",
    "\n",
    "# # Preprocess inputs\n",
    "# # Replace uncommon AAs with \"X\"\n",
    "# train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "# valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "# # Add spaces between each amino acid for PT5 to correctly use them\n",
    "# train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "# valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "# # Create Datasets\n",
    "# train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']))\n",
    "# valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f20a2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm all_dephos_withLORA_esm_10epochs.sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcbe5f",
   "metadata": {},
   "source": [
    "lr 0.0023435064802818234\n",
    "\n",
    "batch 1\n",
    "\n",
    "accum 8\n",
    "\n",
    "dropout_rate 0.33527687224006164\n",
    "\n",
    "weight_decay 0.0006469636851107557\n",
    "\n",
    "warmup_pct 0.15119836825913632\n",
    "\n",
    "lora_rank 16\n",
    "\n",
    "lora_init_scale 0.01713843597721974\n",
    "\n",
    "lora_scaling_rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a57f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ca1393b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1782' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1782/3960 11:32 < 14:07, 2.57 it/s, Epoch 9/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.810300</td>\n",
       "      <td>0.669697</td>\n",
       "      <td>0.633838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.648500</td>\n",
       "      <td>0.565503</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.517700</td>\n",
       "      <td>0.529520</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.448800</td>\n",
       "      <td>0.543991</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.702732</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.321200</td>\n",
       "      <td>0.741294</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.248800</td>\n",
       "      <td>0.830743</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>1.081780</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>1.434112</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.7412935495376587, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.4145, 'eval_samples_per_second': 164.012, 'eval_steps_per_second': 20.709, 'epoch': 9.0}\n"
     ]
    }
   ],
   "source": [
    "# Assume train_set and valid_set are already created datasets\n",
    "\n",
    "_, model, history = train_per_protein(\n",
    "    train_set, \n",
    "    valid_set, \n",
    "    weight_decay=0.0006469636851107557, \n",
    "    warmup_pct=0.15119836825913632, \n",
    "    num_labels=2, \n",
    "    batch=1, \n",
    "    accum=8, \n",
    "    epochs=20, \n",
    "    seed=42, \n",
    "    lr=0.0023435064802818234, \n",
    "    dropout=0.33527687224006164, \n",
    "    lora_rank=16, \n",
    "    lora_init_scale=0.01713843597721974, \n",
    "    lora_scaling_rank=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ebf90f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 11:22:07,163] A new study created in RDB with name: all_dephos_withLORA_esm_10epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='123' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [123/240 01:45 < 01:41, 1.15 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.131700</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.664141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.630900</td>\n",
       "      <td>0.573216</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.552500</td>\n",
       "      <td>0.574999</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.977800</td>\n",
       "      <td>0.852407</td>\n",
       "      <td>0.530303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 4.96969696969697: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.96969696969697: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5732157826423645, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.4008, 'eval_samples_per_second': 164.942, 'eval_steps_per_second': 20.826, 'epoch': 4.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 11:24:09,157] Trial 0 finished with values: [0.5732157826423645, 0.7247474747474747] and parameters: {'lr': 0.008313095924502398, 'batch': 8, 'accum': 8, 'dropout_rate': 0.8286934361942507, 'weight_decay': 0.0001360828628331714, 'warmup_pct': 0.11954352026973641, 'lora_rank': 12, 'lora_init_scale': 0.037928409027273284, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1317, 'learning_rate': 0.0008453995855426168, 'epoch': 0.97, 'step': 24}, {'eval_loss': 0.6549491286277771, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 2.4137, 'eval_samples_per_second': 164.064, 'eval_steps_per_second': 20.715, 'epoch': 0.97, 'step': 24}, {'loss': 0.6309, 'learning_rate': 0.0017260241538161758, 'epoch': 1.98, 'step': 49}, {'eval_loss': 0.5732157826423645, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3766, 'eval_samples_per_second': 166.624, 'eval_steps_per_second': 21.038, 'epoch': 1.98, 'step': 49}, {'loss': 0.5525, 'learning_rate': 0.002606648722089735, 'epoch': 2.99, 'step': 74}, {'eval_loss': 0.5749985575675964, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.3715, 'eval_samples_per_second': 166.986, 'eval_steps_per_second': 21.084, 'epoch': 2.99, 'step': 74}, {'loss': 0.5454, 'learning_rate': 0.003487273290363294, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.7420788407325745, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 2.3812, 'eval_samples_per_second': 166.305, 'eval_steps_per_second': 20.998, 'epoch': 4.0, 'step': 99}, {'loss': 0.9778, 'learning_rate': 0.004332672875905911, 'epoch': 4.97, 'step': 123}, {'eval_loss': 0.852406919002533, 'eval_accuracy': 0.5303030303030303, 'eval_runtime': 2.383, 'eval_samples_per_second': 166.179, 'eval_steps_per_second': 20.982, 'epoch': 4.97, 'step': 123}, {'train_runtime': 106.4651, 'train_samples_per_second': 148.781, 'train_steps_per_second': 2.254, 'total_flos': 0.0, 'train_loss': 0.7629648689332047, 'epoch': 4.97, 'step': 123}, {'eval_loss': 0.5732157826423645, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.4008, 'eval_samples_per_second': 164.942, 'eval_steps_per_second': 20.826, 'epoch': 4.97, 'step': 123}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [792/990 02:53 < 00:43, 4.54 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.910500</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.771300</td>\n",
       "      <td>0.677933</td>\n",
       "      <td>0.608586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.637334</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>0.593446</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.555600</td>\n",
       "      <td>0.564472</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.572547</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.424700</td>\n",
       "      <td>0.584784</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.375100</td>\n",
       "      <td>0.607304</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5644723773002625, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.4083, 'eval_samples_per_second': 164.434, 'eval_steps_per_second': 20.762, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 11:27:18,601] Trial 1 finished with values: [0.5644723773002625, 0.7323232323232324] and parameters: {'lr': 0.00013436213188625, 'batch': 8, 'accum': 2, 'dropout_rate': 0.4077477104665824, 'weight_decay': 0.0004126017703916773, 'warmup_pct': 0.23079022102295751, 'lora_rank': 12, 'lora_init_scale': 0.05679712256685267, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9105, 'learning_rate': 2.917072600162007e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.7458509206771851, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.4127, 'eval_samples_per_second': 164.129, 'eval_steps_per_second': 20.723, 'epoch': 1.0, 'step': 99}, {'loss': 0.7713, 'learning_rate': 5.834145200324014e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6779327988624573, 'eval_accuracy': 0.6085858585858586, 'eval_runtime': 2.3916, 'eval_samples_per_second': 165.577, 'eval_steps_per_second': 20.906, 'epoch': 2.0, 'step': 198}, {'loss': 0.6975, 'learning_rate': 8.75121780048602e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.637333869934082, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.768, 'eval_steps_per_second': 20.93, 'epoch': 3.0, 'step': 297}, {'loss': 0.629, 'learning_rate': 0.00011668290400648027, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5934463739395142, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.383, 'eval_samples_per_second': 166.175, 'eval_steps_per_second': 20.982, 'epoch': 4.0, 'step': 396}, {'loss': 0.5556, 'learning_rate': 0.00012454916719792838, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5644723773002625, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3798, 'eval_samples_per_second': 166.403, 'eval_steps_per_second': 21.01, 'epoch': 5.0, 'step': 495}, {'loss': 0.4933, 'learning_rate': 9.963933375834271e-05, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5725470781326294, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 2.3841, 'eval_samples_per_second': 166.097, 'eval_steps_per_second': 20.972, 'epoch': 6.0, 'step': 594}, {'loss': 0.4247, 'learning_rate': 7.472950031875703e-05, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5847835540771484, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3763, 'eval_samples_per_second': 166.649, 'eval_steps_per_second': 21.041, 'epoch': 7.0, 'step': 693}, {'loss': 0.3751, 'learning_rate': 4.9819666879171356e-05, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.6073042750358582, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3866, 'eval_samples_per_second': 165.926, 'eval_steps_per_second': 20.95, 'epoch': 8.0, 'step': 792}, {'train_runtime': 174.0597, 'train_samples_per_second': 91.003, 'train_steps_per_second': 5.688, 'total_flos': 0.0, 'train_loss': 0.6071273004165804, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5644723773002625, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.4083, 'eval_samples_per_second': 164.434, 'eval_steps_per_second': 20.762, 'epoch': 8.0, 'step': 792}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 13:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.920500</td>\n",
       "      <td>0.830848</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.870400</td>\n",
       "      <td>0.768315</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.786100</td>\n",
       "      <td>0.711623</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.753200</td>\n",
       "      <td>0.688801</td>\n",
       "      <td>0.560606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.713900</td>\n",
       "      <td>0.673931</td>\n",
       "      <td>0.616162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.683600</td>\n",
       "      <td>0.657558</td>\n",
       "      <td>0.648990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.658800</td>\n",
       "      <td>0.642164</td>\n",
       "      <td>0.664141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.637000</td>\n",
       "      <td>0.631159</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.621200</td>\n",
       "      <td>0.624608</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>0.622570</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6225695610046387, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3846, 'eval_samples_per_second': 166.064, 'eval_steps_per_second': 20.968, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 11:41:12,778] Trial 2 finished with values: [0.6225695610046387, 0.6843434343434344] and parameters: {'lr': 2.2788945246246797e-05, 'batch': 1, 'accum': 8, 'dropout_rate': 0.2719655570990307, 'weight_decay': 0.0001589656443909959, 'warmup_pct': 0.08439453996875355, 'lora_rank': 8, 'lora_init_scale': 0.09980481046204862, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9205, 'learning_rate': 3.3774035619437617e-06, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.830847978591919, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4146, 'eval_samples_per_second': 164.001, 'eval_steps_per_second': 20.707, 'epoch': 1.0, 'step': 198}, {'loss': 0.8704, 'learning_rate': 6.7548071238875235e-06, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.7683149576187134, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.389, 'eval_samples_per_second': 165.763, 'eval_steps_per_second': 20.93, 'epoch': 2.0, 'step': 396}, {'loss': 0.7861, 'learning_rate': 1.0132210685831285e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.7116231322288513, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3954, 'eval_samples_per_second': 165.316, 'eval_steps_per_second': 20.873, 'epoch': 3.0, 'step': 594}, {'loss': 0.7532, 'learning_rate': 1.3509614247775047e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6888009905815125, 'eval_accuracy': 0.5606060606060606, 'eval_runtime': 2.3996, 'eval_samples_per_second': 165.025, 'eval_steps_per_second': 20.836, 'epoch': 4.0, 'step': 792}, {'loss': 0.7139, 'learning_rate': 1.6887017809718807e-05, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6739312410354614, 'eval_accuracy': 0.6161616161616161, 'eval_runtime': 2.4051, 'eval_samples_per_second': 164.652, 'eval_steps_per_second': 20.789, 'epoch': 5.0, 'step': 990}, {'loss': 0.6836, 'learning_rate': 2.026442137166257e-05, 'epoch': 6.0, 'step': 1188}, {'eval_loss': 0.657558262348175, 'eval_accuracy': 0.648989898989899, 'eval_runtime': 2.4002, 'eval_samples_per_second': 164.983, 'eval_steps_per_second': 20.831, 'epoch': 6.0, 'step': 1188}, {'loss': 0.6588, 'learning_rate': 2.1019617199177945e-05, 'epoch': 7.0, 'step': 1386}, {'eval_loss': 0.6421636939048767, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 2.3925, 'eval_samples_per_second': 165.519, 'eval_steps_per_second': 20.899, 'epoch': 7.0, 'step': 1386}, {'loss': 0.637, 'learning_rate': 1.4013078132785299e-05, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.6311590075492859, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 2.388, 'eval_samples_per_second': 165.828, 'eval_steps_per_second': 20.938, 'epoch': 8.0, 'step': 1584}, {'loss': 0.6212, 'learning_rate': 7.0065390663926495e-06, 'epoch': 9.0, 'step': 1782}, {'eval_loss': 0.6246078014373779, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 2.4002, 'eval_samples_per_second': 164.984, 'eval_steps_per_second': 20.831, 'epoch': 9.0, 'step': 1782}, {'loss': 0.6122, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 0.6225695610046387, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3869, 'eval_samples_per_second': 165.906, 'eval_steps_per_second': 20.948, 'epoch': 10.0, 'step': 1980}, {'train_runtime': 818.7289, 'train_samples_per_second': 19.347, 'train_steps_per_second': 2.418, 'total_flos': 0.0, 'train_loss': 0.7256917510369811, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 0.6225695610046387, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3846, 'eval_samples_per_second': 166.064, 'eval_steps_per_second': 20.968, 'epoch': 10.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 12:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.752810</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.735400</td>\n",
       "      <td>0.683845</td>\n",
       "      <td>0.580808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.668400</td>\n",
       "      <td>0.652670</td>\n",
       "      <td>0.661616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.623410</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.600554</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.536600</td>\n",
       "      <td>0.596369</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.628178</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.433100</td>\n",
       "      <td>0.700272</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>0.892179</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>1.060409</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.7002719044685364, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.767, 'eval_steps_per_second': 20.93, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 11:54:09,783] Trial 3 finished with values: [0.7002719044685364, 0.7297979797979798] and parameters: {'lr': 9.130496386927845e-05, 'batch': 1, 'accum': 4, 'dropout_rate': 0.14091685106889723, 'weight_decay': 2.7073550112429672e-05, 'warmup_pct': 0.2403841540636094, 'lora_rank': 8, 'lora_init_scale': 0.000329285561837396, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.856, 'learning_rate': 9.497443050232273e-06, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.7528099417686462, 'eval_accuracy': 0.5, 'eval_runtime': 2.4189, 'eval_samples_per_second': 163.714, 'eval_steps_per_second': 20.671, 'epoch': 1.0, 'step': 396}, {'loss': 0.7354, 'learning_rate': 1.8994886100464547e-05, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6838446855545044, 'eval_accuracy': 0.5808080808080808, 'eval_runtime': 2.3946, 'eval_samples_per_second': 165.374, 'eval_steps_per_second': 20.881, 'epoch': 2.0, 'step': 792}, {'loss': 0.6684, 'learning_rate': 2.8492329150696822e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6526700258255005, 'eval_accuracy': 0.6616161616161617, 'eval_runtime': 2.3851, 'eval_samples_per_second': 166.028, 'eval_steps_per_second': 20.963, 'epoch': 3.0, 'step': 1188}, {'loss': 0.6425, 'learning_rate': 3.7989772200929094e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6234104037284851, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 2.3852, 'eval_samples_per_second': 166.024, 'eval_steps_per_second': 20.963, 'epoch': 4.0, 'step': 1584}, {'loss': 0.5855, 'learning_rate': 4.7487215251161365e-05, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6005539298057556, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3843, 'eval_samples_per_second': 166.084, 'eval_steps_per_second': 20.97, 'epoch': 5.0, 'step': 1980}, {'loss': 0.5366, 'learning_rate': 5.6984658301393644e-05, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.5963685512542725, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 2.389, 'eval_samples_per_second': 165.761, 'eval_steps_per_second': 20.929, 'epoch': 6.0, 'step': 2376}, {'loss': 0.4822, 'learning_rate': 6.648210135162592e-05, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.6281778216362, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.708, 'eval_steps_per_second': 20.923, 'epoch': 7.0, 'step': 2772}, {'loss': 0.4331, 'learning_rate': 7.597954440185819e-05, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.7002719044685364, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.854, 'eval_steps_per_second': 20.941, 'epoch': 8.0, 'step': 3168}, {'loss': 0.3706, 'learning_rate': 8.547698745209047e-05, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.8921787142753601, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3887, 'eval_samples_per_second': 165.78, 'eval_steps_per_second': 20.932, 'epoch': 9.0, 'step': 3564}, {'loss': 0.3036, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 1.0604089498519897, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3958, 'eval_samples_per_second': 165.287, 'eval_steps_per_second': 20.87, 'epoch': 10.0, 'step': 3960}, {'train_runtime': 762.5224, 'train_samples_per_second': 20.773, 'train_steps_per_second': 5.193, 'total_flos': 0.0, 'train_loss': 0.561394947707051, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.7002719044685364, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.767, 'eval_steps_per_second': 20.93, 'epoch': 10.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 06:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.001000</td>\n",
       "      <td>0.761501</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.903400</td>\n",
       "      <td>0.687201</td>\n",
       "      <td>0.560606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.713800</td>\n",
       "      <td>0.647506</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.599533</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.558600</td>\n",
       "      <td>0.574242</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.560755</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.595268</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.341200</td>\n",
       "      <td>0.602872</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.785343</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.977274</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7853426933288574, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.4118, 'eval_samples_per_second': 164.192, 'eval_steps_per_second': 20.731, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 12:01:12,660] Trial 4 finished with values: [0.7853426933288574, 0.7449494949494949] and parameters: {'lr': 0.000716663420678671, 'batch': 2, 'accum': 8, 'dropout_rate': 0.5888133025286354, 'weight_decay': 0.0006040657284646621, 'warmup_pct': 0.2738947168432789, 'lora_rank': 8, 'lora_init_scale': 0.04026036898020997, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.001, 'learning_rate': 3.271077853720075e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.7615012526512146, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4428, 'eval_samples_per_second': 162.108, 'eval_steps_per_second': 20.468, 'epoch': 1.0, 'step': 99}, {'loss': 0.9034, 'learning_rate': 6.54215570744015e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6872008442878723, 'eval_accuracy': 0.5606060606060606, 'eval_runtime': 2.4129, 'eval_samples_per_second': 164.116, 'eval_steps_per_second': 20.722, 'epoch': 2.0, 'step': 198}, {'loss': 0.7138, 'learning_rate': 9.813233561160227e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6475056409835815, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.3982, 'eval_samples_per_second': 165.127, 'eval_steps_per_second': 20.849, 'epoch': 3.0, 'step': 297}, {'loss': 0.63, 'learning_rate': 0.000130843114148803, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5995333790779114, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.3951, 'eval_samples_per_second': 165.335, 'eval_steps_per_second': 20.876, 'epoch': 4.0, 'step': 396}, {'loss': 0.5586, 'learning_rate': 0.00016355389268600377, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5742424130439758, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3879, 'eval_samples_per_second': 165.838, 'eval_steps_per_second': 20.939, 'epoch': 5.0, 'step': 495}, {'loss': 0.502, 'learning_rate': 0.00019626467122320454, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5607548952102661, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3907, 'eval_samples_per_second': 165.641, 'eval_steps_per_second': 20.914, 'epoch': 6.0, 'step': 594}, {'loss': 0.4226, 'learning_rate': 0.00022897544976040524, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5952684879302979, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.39, 'eval_samples_per_second': 165.694, 'eval_steps_per_second': 20.921, 'epoch': 7.0, 'step': 693}, {'loss': 0.3412, 'learning_rate': 0.000261686228297606, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.6028718948364258, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.388, 'eval_samples_per_second': 165.832, 'eval_steps_per_second': 20.938, 'epoch': 8.0, 'step': 792}, {'loss': 0.2351, 'learning_rate': 0.00029439700683480676, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.7853426933288574, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.3861, 'eval_samples_per_second': 165.96, 'eval_steps_per_second': 20.955, 'epoch': 9.0, 'step': 891}, {'loss': 0.1713, 'learning_rate': 0.00032710778537200754, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.9772739410400391, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 2.3864, 'eval_samples_per_second': 165.944, 'eval_steps_per_second': 20.952, 'epoch': 10.0, 'step': 990}, {'train_runtime': 409.0534, 'train_samples_per_second': 38.724, 'train_steps_per_second': 2.42, 'total_flos': 0.0, 'train_loss': 0.5479103261774236, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.7853426933288574, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.4118, 'eval_samples_per_second': 164.192, 'eval_steps_per_second': 20.731, 'epoch': 10.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3168' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3168/3960 10:19 < 02:35, 5.11 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.915200</td>\n",
       "      <td>0.683875</td>\n",
       "      <td>0.553030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.680500</td>\n",
       "      <td>0.597802</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.562200</td>\n",
       "      <td>0.671284</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.521400</td>\n",
       "      <td>0.596322</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.470200</td>\n",
       "      <td>0.724567</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.414900</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>1.266762</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>1.596543</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.7245669960975647, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 2.4262, 'eval_samples_per_second': 163.221, 'eval_steps_per_second': 20.609, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 12:11:45,982] Trial 5 finished with values: [0.7245669960975647, 0.7676767676767676] and parameters: {'lr': 0.0007364608208158579, 'batch': 1, 'accum': 4, 'dropout_rate': 0.5750339142579587, 'weight_decay': 0.00022868558724740016, 'warmup_pct': 0.2411195009634011, 'lora_rank': 8, 'lora_init_scale': 0.0008429406400238452, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9152, 'learning_rate': 7.636514402803867e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6838749647140503, 'eval_accuracy': 0.553030303030303, 'eval_runtime': 2.414, 'eval_samples_per_second': 164.046, 'eval_steps_per_second': 20.713, 'epoch': 1.0, 'step': 396}, {'loss': 0.6805, 'learning_rate': 0.00015273028805607735, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.597802460193634, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.388, 'eval_samples_per_second': 165.832, 'eval_steps_per_second': 20.938, 'epoch': 2.0, 'step': 792}, {'loss': 0.5622, 'learning_rate': 0.00022909543208411603, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6712841987609863, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.389, 'eval_samples_per_second': 165.756, 'eval_steps_per_second': 20.929, 'epoch': 3.0, 'step': 1188}, {'loss': 0.5214, 'learning_rate': 0.0003054605761121547, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.5963216423988342, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3929, 'eval_samples_per_second': 165.492, 'eval_steps_per_second': 20.895, 'epoch': 4.0, 'step': 1584}, {'loss': 0.4702, 'learning_rate': 0.00038182572014019343, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.7245669960975647, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 2.389, 'eval_samples_per_second': 165.759, 'eval_steps_per_second': 20.929, 'epoch': 5.0, 'step': 1980}, {'loss': 0.4149, 'learning_rate': 0.00045819086416823207, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.9915974736213684, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3893, 'eval_samples_per_second': 165.741, 'eval_steps_per_second': 20.927, 'epoch': 6.0, 'step': 2376}, {'loss': 0.3736, 'learning_rate': 0.0005345560081962708, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 1.2667615413665771, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3916, 'eval_samples_per_second': 165.579, 'eval_steps_per_second': 20.906, 'epoch': 7.0, 'step': 2772}, {'loss': 0.2297, 'learning_rate': 0.0006109211522243094, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 1.5965428352355957, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3924, 'eval_samples_per_second': 165.524, 'eval_steps_per_second': 20.899, 'epoch': 8.0, 'step': 3168}, {'train_runtime': 619.9209, 'train_samples_per_second': 25.552, 'train_steps_per_second': 6.388, 'total_flos': 0.0, 'train_loss': 0.5209734174940321, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.7245669960975647, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 2.4262, 'eval_samples_per_second': 163.221, 'eval_steps_per_second': 20.609, 'epoch': 8.0, 'step': 3168}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 792/1980 05:40 < 08:32, 2.32 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.739500</td>\n",
       "      <td>0.535953</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>0.569553</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>0.686217</td>\n",
       "      <td>0.507576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.787600</td>\n",
       "      <td>0.663761</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5359531044960022, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3848, 'eval_samples_per_second': 166.049, 'eval_steps_per_second': 20.966, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 12:17:42,187] Trial 6 finished with values: [0.5359531044960022, 0.7626262626262627] and parameters: {'lr': 0.002328629003730025, 'batch': 1, 'accum': 8, 'dropout_rate': 0.5751541797384621, 'weight_decay': 8.153111211902404e-05, 'warmup_pct': 0.033082997112609765, 'lora_rank': 8, 'lora_init_scale': 0.010445050303875925, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7395, 'learning_rate': 0.0008799017991193606, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.5359531044960022, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.4234, 'eval_samples_per_second': 163.409, 'eval_steps_per_second': 20.632, 'epoch': 1.0, 'step': 198}, {'loss': 0.6042, 'learning_rate': 0.0017598035982387213, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.5695531368255615, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 2.3883, 'eval_samples_per_second': 165.808, 'eval_steps_per_second': 20.935, 'epoch': 2.0, 'step': 396}, {'loss': 0.9058, 'learning_rate': 0.0022166756862430042, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6862174272537231, 'eval_accuracy': 0.5075757575757576, 'eval_runtime': 2.3886, 'eval_samples_per_second': 165.788, 'eval_steps_per_second': 20.933, 'epoch': 3.0, 'step': 594}, {'loss': 0.7876, 'learning_rate': 0.0019000077310654324, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6637611985206604, 'eval_accuracy': 0.6388888888888888, 'eval_runtime': 2.3858, 'eval_samples_per_second': 165.984, 'eval_steps_per_second': 20.958, 'epoch': 4.0, 'step': 792}, {'train_runtime': 340.8954, 'train_samples_per_second': 46.466, 'train_steps_per_second': 5.808, 'total_flos': 0.0, 'train_loss': 0.7592569794317688, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5359531044960022, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3848, 'eval_samples_per_second': 166.049, 'eval_steps_per_second': 20.966, 'epoch': 4.0, 'step': 792}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2772' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2772/3960 09:25 < 04:02, 4.89 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.029300</td>\n",
       "      <td>0.639337</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.569943</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.663200</td>\n",
       "      <td>0.611476</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.738700</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.689300</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.817600</td>\n",
       "      <td>0.850742</td>\n",
       "      <td>0.560606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.830900</td>\n",
       "      <td>0.621761</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5806995630264282, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.4227, 'eval_samples_per_second': 163.456, 'eval_steps_per_second': 20.638, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 12:27:23,538] Trial 7 finished with values: [0.5806995630264282, 0.76010101010101] and parameters: {'lr': 0.0035810063154670165, 'batch': 1, 'accum': 4, 'dropout_rate': 0.8707010765871591, 'weight_decay': 4.069757523219517e-05, 'warmup_pct': 0.2548112951285394, 'lora_rank': 16, 'lora_init_scale': 0.036217359786828815, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.0293, 'learning_rate': 0.00035135740855424643, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6393365263938904, 'eval_accuracy': 0.6388888888888888, 'eval_runtime': 2.4264, 'eval_samples_per_second': 163.206, 'eval_steps_per_second': 20.607, 'epoch': 1.0, 'step': 396}, {'loss': 0.669, 'learning_rate': 0.0007027148171084929, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.5699434876441956, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3798, 'eval_samples_per_second': 166.402, 'eval_steps_per_second': 21.01, 'epoch': 2.0, 'step': 792}, {'loss': 0.6632, 'learning_rate': 0.0010540722256627392, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6114760041236877, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3963, 'eval_samples_per_second': 165.254, 'eval_steps_per_second': 20.865, 'epoch': 3.0, 'step': 1188}, {'loss': 0.7387, 'learning_rate': 0.0014054296342169857, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.5806995630264282, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3886, 'eval_samples_per_second': 165.787, 'eval_steps_per_second': 20.933, 'epoch': 4.0, 'step': 1584}, {'loss': 0.8275, 'learning_rate': 0.0017567870427712322, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6892997026443481, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.393, 'eval_samples_per_second': 165.479, 'eval_steps_per_second': 20.894, 'epoch': 5.0, 'step': 1980}, {'loss': 0.8176, 'learning_rate': 0.0021081444513254785, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.8507416248321533, 'eval_accuracy': 0.5606060606060606, 'eval_runtime': 2.3957, 'eval_samples_per_second': 165.296, 'eval_steps_per_second': 20.871, 'epoch': 6.0, 'step': 2376}, {'loss': 0.8309, 'learning_rate': 0.002459501859879725, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.6217609643936157, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.4009, 'eval_samples_per_second': 164.94, 'eval_steps_per_second': 20.826, 'epoch': 7.0, 'step': 2772}, {'train_runtime': 566.1981, 'train_samples_per_second': 27.976, 'train_steps_per_second': 6.994, 'total_flos': 0.0, 'train_loss': 0.796609314317139, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.5806995630264282, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.4227, 'eval_samples_per_second': 163.456, 'eval_steps_per_second': 20.638, 'epoch': 7.0, 'step': 2772}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.135800</td>\n",
       "      <td>0.830879</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.051100</td>\n",
       "      <td>0.766950</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.964400</td>\n",
       "      <td>0.711948</td>\n",
       "      <td>0.507576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.874200</td>\n",
       "      <td>0.685812</td>\n",
       "      <td>0.553030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.775200</td>\n",
       "      <td>0.672968</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.747600</td>\n",
       "      <td>0.663387</td>\n",
       "      <td>0.648990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.704900</td>\n",
       "      <td>0.656641</td>\n",
       "      <td>0.654040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>0.651932</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.668800</td>\n",
       "      <td>0.649604</td>\n",
       "      <td>0.669192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.681600</td>\n",
       "      <td>0.648801</td>\n",
       "      <td>0.669192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6496039628982544, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.4122, 'eval_samples_per_second': 164.163, 'eval_steps_per_second': 20.728, 'epoch': 10.0}\n",
      "History:  [{'loss': 1.1358, 'learning_rate': 1.0809964646556313e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.830879271030426, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4252, 'eval_samples_per_second': 163.284, 'eval_steps_per_second': 20.617, 'epoch': 1.0, 'step': 99}, {'loss': 1.0511, 'learning_rate': 2.1619929293112626e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.7669495940208435, 'eval_accuracy': 0.5, 'eval_runtime': 2.3906, 'eval_samples_per_second': 165.65, 'eval_steps_per_second': 20.915, 'epoch': 2.0, 'step': 198}, {'loss': 0.9644, 'learning_rate': 3.2429893939668936e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.7119477987289429, 'eval_accuracy': 0.5075757575757576, 'eval_runtime': 2.3926, 'eval_samples_per_second': 165.509, 'eval_steps_per_second': 20.898, 'epoch': 3.0, 'step': 297}, {'loss': 0.8742, 'learning_rate': 2.9153667465529618e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6858115196228027, 'eval_accuracy': 0.553030303030303, 'eval_runtime': 2.3953, 'eval_samples_per_second': 165.321, 'eval_steps_per_second': 20.874, 'epoch': 4.0, 'step': 396}, {'loss': 0.7752, 'learning_rate': 2.429472288794135e-05, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6729680895805359, 'eval_accuracy': 0.6111111111111112, 'eval_runtime': 2.3934, 'eval_samples_per_second': 165.453, 'eval_steps_per_second': 20.89, 'epoch': 5.0, 'step': 495}, {'loss': 0.7476, 'learning_rate': 1.943577831035308e-05, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.6633868217468262, 'eval_accuracy': 0.648989898989899, 'eval_runtime': 2.3942, 'eval_samples_per_second': 165.398, 'eval_steps_per_second': 20.884, 'epoch': 6.0, 'step': 594}, {'loss': 0.7049, 'learning_rate': 1.4576833732764809e-05, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.6566411852836609, 'eval_accuracy': 0.6540404040404041, 'eval_runtime': 2.3978, 'eval_samples_per_second': 165.149, 'eval_steps_per_second': 20.852, 'epoch': 7.0, 'step': 693}, {'loss': 0.6876, 'learning_rate': 9.71788915517654e-06, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.6519322395324707, 'eval_accuracy': 0.6590909090909091, 'eval_runtime': 2.3929, 'eval_samples_per_second': 165.491, 'eval_steps_per_second': 20.895, 'epoch': 8.0, 'step': 792}, {'loss': 0.6688, 'learning_rate': 4.85894457758827e-06, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.6496039628982544, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.3915, 'eval_samples_per_second': 165.588, 'eval_steps_per_second': 20.908, 'epoch': 9.0, 'step': 891}, {'loss': 0.6816, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.6488013863563538, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.3913, 'eval_samples_per_second': 165.602, 'eval_steps_per_second': 20.909, 'epoch': 10.0, 'step': 990}, {'train_runtime': 216.6626, 'train_samples_per_second': 73.109, 'train_steps_per_second': 4.569, 'total_flos': 0.0, 'train_loss': 0.8291290668526081, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.6496039628982544, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.4122, 'eval_samples_per_second': 164.163, 'eval_steps_per_second': 20.728, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 12:31:15,184] Trial 8 finished with values: [0.6496039628982544, 0.6691919191919192] and parameters: {'lr': 3.3521809560533214e-05, 'batch': 8, 'accum': 2, 'dropout_rate': 0.7035644357014292, 'weight_decay': 1.682824751944833e-05, 'warmup_pct': 0.155240233033885, 'lora_rank': 8, 'lora_init_scale': 0.00028107193591477405, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 07:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.975500</td>\n",
       "      <td>0.751853</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.831300</td>\n",
       "      <td>0.677429</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.682100</td>\n",
       "      <td>0.648573</td>\n",
       "      <td>0.664141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.636700</td>\n",
       "      <td>0.626458</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.604300</td>\n",
       "      <td>0.613728</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.574600</td>\n",
       "      <td>0.609667</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.555500</td>\n",
       "      <td>0.606878</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.539900</td>\n",
       "      <td>0.604940</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.534100</td>\n",
       "      <td>0.603749</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.525700</td>\n",
       "      <td>0.604375</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6037492156028748, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.4026, 'eval_samples_per_second': 164.824, 'eval_steps_per_second': 20.811, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 12:38:41,618] Trial 9 finished with values: [0.6037492156028748, 0.6919191919191919] and parameters: {'lr': 3.7069048057696996e-05, 'batch': 2, 'accum': 2, 'dropout_rate': 0.5752290713496431, 'weight_decay': 0.00014297959947988804, 'warmup_pct': 0.0735651240641315, 'lora_rank': 12, 'lora_init_scale': 0.002503050428442575, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9755, 'learning_rate': 2.5222238884618575e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.7518531084060669, 'eval_accuracy': 0.5, 'eval_runtime': 2.4176, 'eval_samples_per_second': 163.8, 'eval_steps_per_second': 20.682, 'epoch': 1.0, 'step': 396}, {'loss': 0.8313, 'learning_rate': 3.476457792977623e-05, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6774289608001709, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 2.3888, 'eval_samples_per_second': 165.776, 'eval_steps_per_second': 20.931, 'epoch': 2.0, 'step': 792}, {'loss': 0.6821, 'learning_rate': 3.0419005688554196e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6485732197761536, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 2.3883, 'eval_samples_per_second': 165.812, 'eval_steps_per_second': 20.936, 'epoch': 3.0, 'step': 1188}, {'loss': 0.6367, 'learning_rate': 2.607343344733217e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6264575719833374, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 2.3872, 'eval_samples_per_second': 165.882, 'eval_steps_per_second': 20.945, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6043, 'learning_rate': 2.1727861206110142e-05, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6137283444404602, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3866, 'eval_samples_per_second': 165.928, 'eval_steps_per_second': 20.951, 'epoch': 5.0, 'step': 1980}, {'loss': 0.5746, 'learning_rate': 1.7382288964888114e-05, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.6096673607826233, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.85, 'eval_steps_per_second': 20.941, 'epoch': 6.0, 'step': 2376}, {'loss': 0.5555, 'learning_rate': 1.3036716723666085e-05, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.6068778038024902, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.4013, 'eval_samples_per_second': 164.914, 'eval_steps_per_second': 20.822, 'epoch': 7.0, 'step': 2772}, {'loss': 0.5399, 'learning_rate': 8.691144482444057e-06, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.6049395203590393, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 2.3966, 'eval_samples_per_second': 165.232, 'eval_steps_per_second': 20.863, 'epoch': 8.0, 'step': 3168}, {'loss': 0.5341, 'learning_rate': 4.3455722412220285e-06, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.6037492156028748, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.4117, 'eval_samples_per_second': 164.198, 'eval_steps_per_second': 20.732, 'epoch': 9.0, 'step': 3564}, {'loss': 0.5257, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.6043751239776611, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.4023, 'eval_samples_per_second': 164.844, 'eval_steps_per_second': 20.814, 'epoch': 10.0, 'step': 3960}, {'train_runtime': 431.8702, 'train_samples_per_second': 36.678, 'train_steps_per_second': 9.169, 'total_flos': 0.0, 'train_loss': 0.6459690594913984, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.6037492156028748, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.4026, 'eval_samples_per_second': 164.824, 'eval_steps_per_second': 20.811, 'epoch': 10.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 04:25, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.845200</td>\n",
       "      <td>0.694377</td>\n",
       "      <td>0.542929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.606400</td>\n",
       "      <td>0.567826</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.450100</td>\n",
       "      <td>0.595867</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.700955</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.129600</td>\n",
       "      <td>0.890270</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.975580</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 9.8989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.8989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.7009547352790833, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.4179, 'eval_samples_per_second': 163.781, 'eval_steps_per_second': 20.679, 'epoch': 9.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 12:43:20,779] Trial 10 finished with values: [0.7009547352790833, 0.7525252525252525] and parameters: {'lr': 0.0014209936187503545, 'batch': 4, 'accum': 8, 'dropout_rate': 0.2521942032764427, 'weight_decay': 4.99910068175699e-05, 'warmup_pct': 0.18585618580697677, 'lora_rank': 16, 'lora_init_scale': 0.005718633885589439, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8452, 'learning_rate': 9.47329079166903e-05, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.6943768858909607, 'eval_accuracy': 0.5429292929292929, 'eval_runtime': 2.4181, 'eval_samples_per_second': 163.766, 'eval_steps_per_second': 20.677, 'epoch': 0.99, 'step': 49}, {'loss': 0.6915, 'learning_rate': 0.00019139914048474163, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.6359814405441284, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 2.3916, 'eval_samples_per_second': 165.579, 'eval_steps_per_second': 20.906, 'epoch': 2.0, 'step': 99}, {'loss': 0.6064, 'learning_rate': 0.00028613204840143193, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.5678256154060364, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3894, 'eval_samples_per_second': 165.729, 'eval_steps_per_second': 20.925, 'epoch': 2.99, 'step': 148}, {'loss': 0.5101, 'learning_rate': 0.00038279828096948325, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5668447613716125, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3905, 'eval_samples_per_second': 165.654, 'eval_steps_per_second': 20.916, 'epoch': 4.0, 'step': 198}, {'loss': 0.4501, 'learning_rate': 0.0004775311888861735, 'epoch': 4.99, 'step': 247}, {'eval_loss': 0.5958667397499084, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.4006, 'eval_samples_per_second': 164.962, 'eval_steps_per_second': 20.829, 'epoch': 4.99, 'step': 247}, {'loss': 0.3641, 'learning_rate': 0.000574197421454225, 'epoch': 6.0, 'step': 297}, {'eval_loss': 0.6128448843955994, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.3945, 'eval_samples_per_second': 165.382, 'eval_steps_per_second': 20.882, 'epoch': 6.0, 'step': 297}, {'loss': 0.2517, 'learning_rate': 0.0006689303293709152, 'epoch': 6.99, 'step': 346}, {'eval_loss': 0.7009547352790833, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.701, 'eval_steps_per_second': 20.922, 'epoch': 6.99, 'step': 346}, {'loss': 0.1728, 'learning_rate': 0.0007655965619389665, 'epoch': 8.0, 'step': 396}, {'eval_loss': 0.8737459778785706, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 2.3934, 'eval_samples_per_second': 165.457, 'eval_steps_per_second': 20.891, 'epoch': 8.0, 'step': 396}, {'loss': 0.1296, 'learning_rate': 0.0008603294698556568, 'epoch': 8.99, 'step': 445}, {'eval_loss': 0.8902697563171387, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3932, 'eval_samples_per_second': 165.469, 'eval_steps_per_second': 20.893, 'epoch': 8.99, 'step': 445}, {'loss': 0.1002, 'learning_rate': 0.000947329079166903, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.9755803346633911, 'eval_accuracy': 0.75, 'eval_runtime': 2.3939, 'eval_samples_per_second': 165.423, 'eval_steps_per_second': 20.887, 'epoch': 9.9, 'step': 490}, {'train_runtime': 265.7983, 'train_samples_per_second': 59.594, 'train_steps_per_second': 1.844, 'total_flos': 0.0, 'train_loss': 0.41488918090353205, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.7009547352790833, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.4179, 'eval_samples_per_second': 163.781, 'eval_steps_per_second': 20.679, 'epoch': 9.9, 'step': 490}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 04:25, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.889100</td>\n",
       "      <td>0.819046</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.729900</td>\n",
       "      <td>0.691803</td>\n",
       "      <td>0.565657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.674600</td>\n",
       "      <td>0.651085</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.609200</td>\n",
       "      <td>0.613357</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.540200</td>\n",
       "      <td>0.586007</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.484700</td>\n",
       "      <td>0.575172</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5751721858978271, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.768, 'eval_steps_per_second': 20.93, 'epoch': 9.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 12:47:59,433] Trial 11 finished with values: [0.5751721858978271, 0.7247474747474747] and parameters: {'lr': 0.0002101116010027447, 'batch': 4, 'accum': 8, 'dropout_rate': 0.12818354187506786, 'weight_decay': 0.00013921166243396275, 'warmup_pct': 0.25464406134719475, 'lora_rank': 8, 'lora_init_scale': 0.05631791107246473, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8891, 'learning_rate': 1.0213758382077867e-05, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.8190462589263916, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4162, 'eval_samples_per_second': 163.894, 'eval_steps_per_second': 20.694, 'epoch': 0.99, 'step': 49}, {'loss': 0.7941, 'learning_rate': 2.0635960812769568e-05, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.7329304218292236, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.3918, 'eval_samples_per_second': 165.569, 'eval_steps_per_second': 20.905, 'epoch': 2.0, 'step': 99}, {'loss': 0.7299, 'learning_rate': 3.0849719194847437e-05, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.6918031573295593, 'eval_accuracy': 0.5656565656565656, 'eval_runtime': 2.3907, 'eval_samples_per_second': 165.644, 'eval_steps_per_second': 20.915, 'epoch': 2.99, 'step': 148}, {'loss': 0.6874, 'learning_rate': 4.1271921625539135e-05, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.6719661951065063, 'eval_accuracy': 0.6161616161616161, 'eval_runtime': 2.3918, 'eval_samples_per_second': 165.566, 'eval_steps_per_second': 20.905, 'epoch': 4.0, 'step': 198}, {'loss': 0.6746, 'learning_rate': 5.1485680007617e-05, 'epoch': 4.99, 'step': 247}, {'eval_loss': 0.6510846018791199, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.3907, 'eval_samples_per_second': 165.644, 'eval_steps_per_second': 20.915, 'epoch': 4.99, 'step': 247}, {'loss': 0.633, 'learning_rate': 6.19078824383087e-05, 'epoch': 6.0, 'step': 297}, {'eval_loss': 0.6264550685882568, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.3897, 'eval_samples_per_second': 165.71, 'eval_steps_per_second': 20.923, 'epoch': 6.0, 'step': 297}, {'loss': 0.6092, 'learning_rate': 7.212164082038656e-05, 'epoch': 6.99, 'step': 346}, {'eval_loss': 0.6133565306663513, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.3945, 'eval_samples_per_second': 165.378, 'eval_steps_per_second': 20.881, 'epoch': 6.99, 'step': 346}, {'loss': 0.5674, 'learning_rate': 8.254384325107827e-05, 'epoch': 8.0, 'step': 396}, {'eval_loss': 0.5957819223403931, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3985, 'eval_samples_per_second': 165.1, 'eval_steps_per_second': 20.846, 'epoch': 8.0, 'step': 396}, {'loss': 0.5402, 'learning_rate': 9.275760163315613e-05, 'epoch': 8.99, 'step': 445}, {'eval_loss': 0.5860069990158081, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.391, 'eval_samples_per_second': 165.622, 'eval_steps_per_second': 20.912, 'epoch': 8.99, 'step': 445}, {'loss': 0.4847, 'learning_rate': 0.00010213758382077867, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.5751721858978271, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3951, 'eval_samples_per_second': 165.335, 'eval_steps_per_second': 20.876, 'epoch': 9.9, 'step': 490}, {'train_runtime': 265.7027, 'train_samples_per_second': 59.615, 'train_steps_per_second': 1.844, 'total_flos': 0.0, 'train_loss': 0.6624852550273039, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.5751721858978271, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.768, 'eval_steps_per_second': 20.93, 'epoch': 9.9, 'step': 490}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='396' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [396/990 02:38 < 03:58, 2.49 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.795200</td>\n",
       "      <td>0.561962</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.619300</td>\n",
       "      <td>1.000819</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.831900</td>\n",
       "      <td>0.687996</td>\n",
       "      <td>0.525253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.782700</td>\n",
       "      <td>0.643793</td>\n",
       "      <td>0.643939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5619620084762573, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.4085, 'eval_samples_per_second': 164.416, 'eval_steps_per_second': 20.76, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 12:50:51,102] Trial 12 finished with values: [0.5619620084762573, 0.7449494949494949] and parameters: {'lr': 0.00714591677636744, 'batch': 2, 'accum': 8, 'dropout_rate': 0.6893480106730226, 'weight_decay': 0.00018670748443409778, 'warmup_pct': 0.09856839263072469, 'lora_rank': 8, 'lora_init_scale': 0.00265258594183673, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7952, 'learning_rate': 0.0009069817446927905, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5619620084762573, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.419, 'eval_samples_per_second': 163.704, 'eval_steps_per_second': 20.67, 'epoch': 1.0, 'step': 99}, {'loss': 0.6193, 'learning_rate': 0.001813963489385581, 'epoch': 2.0, 'step': 198}, {'eval_loss': 1.0008193254470825, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3869, 'eval_samples_per_second': 165.906, 'eval_steps_per_second': 20.948, 'epoch': 2.0, 'step': 198}, {'loss': 0.8319, 'learning_rate': 0.0027209452340783715, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6879958510398865, 'eval_accuracy': 0.5252525252525253, 'eval_runtime': 2.3886, 'eval_samples_per_second': 165.784, 'eval_steps_per_second': 20.932, 'epoch': 3.0, 'step': 297}, {'loss': 0.7827, 'learning_rate': 0.003627926978771162, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6437932252883911, 'eval_accuracy': 0.6439393939393939, 'eval_runtime': 2.3881, 'eval_samples_per_second': 165.823, 'eval_steps_per_second': 20.937, 'epoch': 4.0, 'step': 396}, {'train_runtime': 158.5574, 'train_samples_per_second': 99.901, 'train_steps_per_second': 6.244, 'total_flos': 0.0, 'train_loss': 0.7572696955517085, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5619620084762573, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.4085, 'eval_samples_per_second': 164.416, 'eval_steps_per_second': 20.76, 'epoch': 4.0, 'step': 396}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 03:31, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.919600</td>\n",
       "      <td>0.783790</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.739700</td>\n",
       "      <td>0.671058</td>\n",
       "      <td>0.631313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.638700</td>\n",
       "      <td>0.605970</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.525200</td>\n",
       "      <td>0.568688</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.410300</td>\n",
       "      <td>0.615159</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.621091</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 9.8989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.8989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.568687915802002, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.4079, 'eval_samples_per_second': 164.457, 'eval_steps_per_second': 20.765, 'epoch': 9.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 12:54:35,514] Trial 13 finished with values: [0.568687915802002, 0.7297979797979798] and parameters: {'lr': 0.00015792783079163992, 'batch': 8, 'accum': 4, 'dropout_rate': 0.3501977479117806, 'weight_decay': 0.00013233758849799464, 'warmup_pct': 0.17387697677898586, 'lora_rank': 16, 'lora_init_scale': 0.02651732009998173, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9196, 'learning_rate': 2.2495534037181268e-05, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.783790111541748, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4168, 'eval_samples_per_second': 163.853, 'eval_steps_per_second': 20.689, 'epoch': 0.99, 'step': 49}, {'loss': 0.7836, 'learning_rate': 4.545016060573358e-05, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.6959328651428223, 'eval_accuracy': 0.5505050505050505, 'eval_runtime': 2.3888, 'eval_samples_per_second': 165.774, 'eval_steps_per_second': 20.931, 'epoch': 2.0, 'step': 99}, {'loss': 0.7397, 'learning_rate': 6.794569464291485e-05, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.6710576415061951, 'eval_accuracy': 0.6313131313131313, 'eval_runtime': 2.3959, 'eval_samples_per_second': 165.283, 'eval_steps_per_second': 20.869, 'epoch': 2.99, 'step': 148}, {'loss': 0.692, 'learning_rate': 9.090032121146716e-05, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.6419885754585266, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3969, 'eval_samples_per_second': 165.213, 'eval_steps_per_second': 20.86, 'epoch': 4.0, 'step': 198}, {'loss': 0.6387, 'learning_rate': 0.00011339585524864844, 'epoch': 4.99, 'step': 247}, {'eval_loss': 0.6059699654579163, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.3909, 'eval_samples_per_second': 165.626, 'eval_steps_per_second': 20.912, 'epoch': 4.99, 'step': 247}, {'loss': 0.5672, 'learning_rate': 0.00013635048181720073, 'epoch': 6.0, 'step': 297}, {'eval_loss': 0.5852565765380859, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 2.388, 'eval_samples_per_second': 165.833, 'eval_steps_per_second': 20.938, 'epoch': 6.0, 'step': 297}, {'loss': 0.5252, 'learning_rate': 0.00015576443584928868, 'epoch': 6.99, 'step': 346}, {'eval_loss': 0.568687915802002, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.3883, 'eval_samples_per_second': 165.809, 'eval_steps_per_second': 20.935, 'epoch': 6.99, 'step': 346}, {'loss': 0.4538, 'learning_rate': 0.0001016795622905079, 'epoch': 8.0, 'step': 396}, {'eval_loss': 0.5725492835044861, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3892, 'eval_samples_per_second': 165.749, 'eval_steps_per_second': 20.928, 'epoch': 8.0, 'step': 396}, {'loss': 0.4103, 'learning_rate': 4.867638620290271e-05, 'epoch': 8.99, 'step': 445}, {'eval_loss': 0.6151592135429382, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.3915, 'eval_samples_per_second': 165.588, 'eval_steps_per_second': 20.908, 'epoch': 8.99, 'step': 445}, {'loss': 0.3753, 'learning_rate': 0.0, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.6210905313491821, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.389, 'eval_samples_per_second': 165.762, 'eval_steps_per_second': 20.93, 'epoch': 9.9, 'step': 490}, {'train_runtime': 211.4882, 'train_samples_per_second': 74.898, 'train_steps_per_second': 2.317, 'total_flos': 0.0, 'train_loss': 0.6125741141183035, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.568687915802002, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.4079, 'eval_samples_per_second': 164.457, 'eval_steps_per_second': 20.765, 'epoch': 9.9, 'step': 490}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='693' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [693/990 04:38 < 01:59, 2.48 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.874500</td>\n",
       "      <td>0.664950</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.543509</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.507600</td>\n",
       "      <td>0.538466</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.461600</td>\n",
       "      <td>0.514602</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>0.749689</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.353100</td>\n",
       "      <td>0.662149</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>0.788044</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5146018862724304, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.4123, 'eval_samples_per_second': 164.156, 'eval_steps_per_second': 20.727, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 12:59:27,559] Trial 14 finished with values: [0.5146018862724304, 0.7550505050505051] and parameters: {'lr': 0.004049918124673987, 'batch': 2, 'accum': 8, 'dropout_rate': 0.5538740522500336, 'weight_decay': 0.0006043255233367907, 'warmup_pct': 0.24318597924806068, 'lora_rank': 16, 'lora_init_scale': 0.00038009667436455954, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8745, 'learning_rate': 0.00020817336154866286, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6649498343467712, 'eval_accuracy': 0.6388888888888888, 'eval_runtime': 2.4299, 'eval_samples_per_second': 162.972, 'eval_steps_per_second': 20.577, 'epoch': 1.0, 'step': 99}, {'loss': 0.641, 'learning_rate': 0.0004163467230973257, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5435091257095337, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3868, 'eval_samples_per_second': 165.911, 'eval_steps_per_second': 20.948, 'epoch': 2.0, 'step': 198}, {'loss': 0.5076, 'learning_rate': 0.0006245200846459886, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5384657979011536, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.3986, 'eval_samples_per_second': 165.096, 'eval_steps_per_second': 20.845, 'epoch': 3.0, 'step': 297}, {'loss': 0.4616, 'learning_rate': 0.0008326934461946514, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5146018862724304, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.856, 'eval_steps_per_second': 20.941, 'epoch': 4.0, 'step': 396}, {'loss': 0.4098, 'learning_rate': 0.0010408668077433142, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.7496886849403381, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 2.3905, 'eval_samples_per_second': 165.659, 'eval_steps_per_second': 20.917, 'epoch': 5.0, 'step': 495}, {'loss': 0.3531, 'learning_rate': 0.0012490401692919772, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.6621490120887756, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.396, 'eval_samples_per_second': 165.277, 'eval_steps_per_second': 20.868, 'epoch': 6.0, 'step': 594}, {'loss': 0.2818, 'learning_rate': 0.00145721353084064, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.7880441546440125, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3958, 'eval_samples_per_second': 165.293, 'eval_steps_per_second': 20.87, 'epoch': 7.0, 'step': 693}, {'train_runtime': 279.0893, 'train_samples_per_second': 56.756, 'train_steps_per_second': 3.547, 'total_flos': 0.0, 'train_loss': 0.5042048560248481, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5146018862724304, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.4123, 'eval_samples_per_second': 164.156, 'eval_steps_per_second': 20.727, 'epoch': 7.0, 'step': 693}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 792/1980 01:51 < 02:47, 7.08 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.686900</td>\n",
       "      <td>0.613326</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.810500</td>\n",
       "      <td>0.797356</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.748700</td>\n",
       "      <td>0.653544</td>\n",
       "      <td>0.664141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>0.683898</td>\n",
       "      <td>0.558081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6133261919021606, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.4093, 'eval_samples_per_second': 164.36, 'eval_steps_per_second': 20.753, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 13:01:32,279] Trial 15 finished with values: [0.6133261919021606, 0.6767676767676768] and parameters: {'lr': 0.0033923199400914543, 'batch': 4, 'accum': 2, 'dropout_rate': 0.38803596710370325, 'weight_decay': 2.1169224010281868e-05, 'warmup_pct': 0.06768180283037803, 'lora_rank': 8, 'lora_init_scale': 0.0012054077904625345, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6869, 'learning_rate': 0.002506266224395925, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6133261919021606, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.4241, 'eval_samples_per_second': 163.359, 'eval_steps_per_second': 20.626, 'epoch': 1.0, 'step': 198}, {'loss': 0.8105, 'learning_rate': 0.003138688542701439, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.7973557114601135, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4051, 'eval_samples_per_second': 164.65, 'eval_steps_per_second': 20.789, 'epoch': 2.0, 'step': 396}, {'loss': 0.7487, 'learning_rate': 0.002746352474863759, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6535444259643555, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 2.3944, 'eval_samples_per_second': 165.389, 'eval_steps_per_second': 20.882, 'epoch': 3.0, 'step': 594}, {'loss': 0.7066, 'learning_rate': 0.002354016407026079, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6838980913162231, 'eval_accuracy': 0.5580808080808081, 'eval_runtime': 2.3932, 'eval_samples_per_second': 165.469, 'eval_steps_per_second': 20.893, 'epoch': 4.0, 'step': 792}, {'train_runtime': 111.7701, 'train_samples_per_second': 141.719, 'train_steps_per_second': 17.715, 'total_flos': 0.0, 'train_loss': 0.7381700457948627, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6133261919021606, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.4093, 'eval_samples_per_second': 164.36, 'eval_steps_per_second': 20.753, 'epoch': 4.0, 'step': 792}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 04:24, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.045000</td>\n",
       "      <td>0.850713</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.977600</td>\n",
       "      <td>0.788402</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.929700</td>\n",
       "      <td>0.717805</td>\n",
       "      <td>0.505051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.831800</td>\n",
       "      <td>0.690955</td>\n",
       "      <td>0.547980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.831300</td>\n",
       "      <td>0.684009</td>\n",
       "      <td>0.573232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.802500</td>\n",
       "      <td>0.683274</td>\n",
       "      <td>0.570707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6840089559555054, 'eval_accuracy': 0.5732323232323232, 'eval_runtime': 2.4094, 'eval_samples_per_second': 164.354, 'eval_steps_per_second': 20.752, 'epoch': 9.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 13:06:10,800] Trial 16 finished with values: [0.6840089559555054, 0.5732323232323232] and parameters: {'lr': 1.8796537669304513e-05, 'batch': 4, 'accum': 8, 'dropout_rate': 0.5532556182683379, 'weight_decay': 0.0003195009514225752, 'warmup_pct': 0.07550800817869688, 'lora_rank': 4, 'lora_init_scale': 0.0017854833018590077, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.045, 'learning_rate': 3.0803690494846863e-06, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.8507132530212402, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4158, 'eval_samples_per_second': 163.92, 'eval_steps_per_second': 20.697, 'epoch': 0.99, 'step': 49}, {'loss': 1.0002, 'learning_rate': 6.223602773448651e-06, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.8243589401245117, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3879, 'eval_samples_per_second': 165.834, 'eval_steps_per_second': 20.939, 'epoch': 2.0, 'step': 99}, {'loss': 0.9776, 'learning_rate': 9.303971822933337e-06, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.7884021997451782, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3933, 'eval_samples_per_second': 165.465, 'eval_steps_per_second': 20.892, 'epoch': 2.99, 'step': 148}, {'loss': 0.941, 'learning_rate': 1.2447205546897302e-05, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.7480114102363586, 'eval_accuracy': 0.5, 'eval_runtime': 2.3897, 'eval_samples_per_second': 165.708, 'eval_steps_per_second': 20.923, 'epoch': 4.0, 'step': 198}, {'loss': 0.9297, 'learning_rate': 1.552757459638199e-05, 'epoch': 4.99, 'step': 247}, {'eval_loss': 0.7178049683570862, 'eval_accuracy': 0.5050505050505051, 'eval_runtime': 2.3937, 'eval_samples_per_second': 165.431, 'eval_steps_per_second': 20.888, 'epoch': 4.99, 'step': 247}, {'loss': 0.8389, 'learning_rate': 1.8670808320345956e-05, 'epoch': 6.0, 'step': 297}, {'eval_loss': 0.7009067535400391, 'eval_accuracy': 0.5126262626262627, 'eval_runtime': 2.3926, 'eval_samples_per_second': 165.509, 'eval_steps_per_second': 20.898, 'epoch': 6.0, 'step': 297}, {'loss': 0.8318, 'learning_rate': 1.4171211645967801e-05, 'epoch': 6.99, 'step': 346}, {'eval_loss': 0.6909545063972473, 'eval_accuracy': 0.547979797979798, 'eval_runtime': 2.399, 'eval_samples_per_second': 165.071, 'eval_steps_per_second': 20.842, 'epoch': 6.99, 'step': 346}, {'loss': 0.8077, 'learning_rate': 9.250652046673426e-06, 'epoch': 8.0, 'step': 396}, {'eval_loss': 0.6864540576934814, 'eval_accuracy': 0.5631313131313131, 'eval_runtime': 2.3973, 'eval_samples_per_second': 165.184, 'eval_steps_per_second': 20.857, 'epoch': 8.0, 'step': 396}, {'loss': 0.8313, 'learning_rate': 4.428503639364938e-06, 'epoch': 8.99, 'step': 445}, {'eval_loss': 0.6840089559555054, 'eval_accuracy': 0.5732323232323232, 'eval_runtime': 2.3936, 'eval_samples_per_second': 165.444, 'eval_steps_per_second': 20.889, 'epoch': 8.99, 'step': 445}, {'loss': 0.8025, 'learning_rate': 0.0, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.6832743883132935, 'eval_accuracy': 0.5707070707070707, 'eval_runtime': 2.395, 'eval_samples_per_second': 165.345, 'eval_steps_per_second': 20.877, 'epoch': 9.9, 'step': 490}, {'train_runtime': 265.499, 'train_samples_per_second': 59.661, 'train_steps_per_second': 1.846, 'total_flos': 0.0, 'train_loss': 0.9013386551214724, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.6840089559555054, 'eval_accuracy': 0.5732323232323232, 'eval_runtime': 2.4094, 'eval_samples_per_second': 164.354, 'eval_steps_per_second': 20.752, 'epoch': 9.9, 'step': 490}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1584' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1584/1980 03:42 < 00:55, 7.13 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.041200</td>\n",
       "      <td>0.825927</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.714900</td>\n",
       "      <td>0.638847</td>\n",
       "      <td>0.654040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.630500</td>\n",
       "      <td>0.619715</td>\n",
       "      <td>0.664141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.597600</td>\n",
       "      <td>0.606548</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>0.589127</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.564800</td>\n",
       "      <td>0.609894</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.550300</td>\n",
       "      <td>0.616904</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>0.606990</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5891267657279968, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.4068, 'eval_samples_per_second': 164.537, 'eval_steps_per_second': 20.775, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 13:10:05,813] Trial 17 finished with values: [0.5891267657279968, 0.6944444444444444] and parameters: {'lr': 0.007281114648578333, 'batch': 4, 'accum': 2, 'dropout_rate': 0.7958586797611824, 'weight_decay': 0.0008872680334967108, 'warmup_pct': 0.025152555459964483, 'lora_rank': 8, 'lora_init_scale': 0.00044694810968700185, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.0412, 'learning_rate': 0.006897898088126842, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.8259267210960388, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.4222, 'eval_samples_per_second': 163.486, 'eval_steps_per_second': 20.642, 'epoch': 1.0, 'step': 198}, {'loss': 0.7149, 'learning_rate': 0.00613146496722386, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.638846755027771, 'eval_accuracy': 0.6540404040404041, 'eval_runtime': 2.4031, 'eval_samples_per_second': 164.789, 'eval_steps_per_second': 20.807, 'epoch': 2.0, 'step': 396}, {'loss': 0.6305, 'learning_rate': 0.005365031846320877, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6197148561477661, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 2.3902, 'eval_samples_per_second': 165.675, 'eval_steps_per_second': 20.919, 'epoch': 3.0, 'step': 594}, {'loss': 0.5976, 'learning_rate': 0.004598598725417895, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6065479516983032, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.3858, 'eval_samples_per_second': 165.984, 'eval_steps_per_second': 20.958, 'epoch': 4.0, 'step': 792}, {'loss': 0.5848, 'learning_rate': 0.0038321656045149123, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5891267657279968, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.3897, 'eval_samples_per_second': 165.711, 'eval_steps_per_second': 20.923, 'epoch': 5.0, 'step': 990}, {'loss': 0.5648, 'learning_rate': 0.00306573248361193, 'epoch': 6.0, 'step': 1188}, {'eval_loss': 0.6098940968513489, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.853, 'eval_steps_per_second': 20.941, 'epoch': 6.0, 'step': 1188}, {'loss': 0.5503, 'learning_rate': 0.0022992993627089474, 'epoch': 7.0, 'step': 1386}, {'eval_loss': 0.616904079914093, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.764, 'eval_steps_per_second': 20.93, 'epoch': 7.0, 'step': 1386}, {'loss': 0.5433, 'learning_rate': 0.001532866241805965, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.6069902777671814, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.3851, 'eval_samples_per_second': 166.034, 'eval_steps_per_second': 20.964, 'epoch': 8.0, 'step': 1584}, {'train_runtime': 222.1696, 'train_samples_per_second': 71.297, 'train_steps_per_second': 8.912, 'total_flos': 0.0, 'train_loss': 0.6534421034533568, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.5891267657279968, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.4068, 'eval_samples_per_second': 164.537, 'eval_steps_per_second': 20.775, 'epoch': 8.0, 'step': 1584}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='891' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [891/990 04:03 < 00:27, 3.65 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.165900</td>\n",
       "      <td>0.753538</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.932200</td>\n",
       "      <td>0.662764</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.652400</td>\n",
       "      <td>0.595059</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.580600</td>\n",
       "      <td>0.544175</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.533500</td>\n",
       "      <td>0.539462</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.472500</td>\n",
       "      <td>0.535974</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.420200</td>\n",
       "      <td>0.578007</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>0.543887</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.535974383354187, 'eval_accuracy': 0.75, 'eval_runtime': 2.4117, 'eval_samples_per_second': 164.201, 'eval_steps_per_second': 20.732, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 13:14:22,763] Trial 18 finished with values: [0.535974383354187, 0.75] and parameters: {'lr': 0.0008872670731822096, 'batch': 4, 'accum': 4, 'dropout_rate': 0.8338317890908682, 'weight_decay': 0.00020717866398800737, 'warmup_pct': 0.24230230406354678, 'lora_rank': 16, 'lora_init_scale': 0.00410266006990889, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1659, 'learning_rate': 9.15948282012917e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.7535383701324463, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4151, 'eval_samples_per_second': 163.97, 'eval_steps_per_second': 20.703, 'epoch': 1.0, 'step': 99}, {'loss': 0.9322, 'learning_rate': 0.0001831896564025834, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6627642512321472, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 2.3922, 'eval_samples_per_second': 165.539, 'eval_steps_per_second': 20.901, 'epoch': 2.0, 'step': 198}, {'loss': 0.6524, 'learning_rate': 0.0002747844846038751, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5950589179992676, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3947, 'eval_samples_per_second': 165.365, 'eval_steps_per_second': 20.879, 'epoch': 3.0, 'step': 297}, {'loss': 0.5806, 'learning_rate': 0.0003663793128051668, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5441754460334778, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3864, 'eval_samples_per_second': 165.941, 'eval_steps_per_second': 20.952, 'epoch': 4.0, 'step': 396}, {'loss': 0.5335, 'learning_rate': 0.00045797414100645856, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5394618511199951, 'eval_accuracy': 0.7651515151515151, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.854, 'eval_steps_per_second': 20.941, 'epoch': 5.0, 'step': 495}, {'loss': 0.4725, 'learning_rate': 0.0005495689692077503, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.535974383354187, 'eval_accuracy': 0.75, 'eval_runtime': 2.3892, 'eval_samples_per_second': 165.746, 'eval_steps_per_second': 20.928, 'epoch': 6.0, 'step': 594}, {'loss': 0.4202, 'learning_rate': 0.0006411637974090419, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5780070424079895, 'eval_accuracy': 0.75, 'eval_runtime': 2.391, 'eval_samples_per_second': 165.622, 'eval_steps_per_second': 20.912, 'epoch': 7.0, 'step': 693}, {'loss': 0.3788, 'learning_rate': 0.0007327586256103336, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5438874959945679, 'eval_accuracy': 0.7651515151515151, 'eval_runtime': 2.3896, 'eval_samples_per_second': 165.717, 'eval_steps_per_second': 20.924, 'epoch': 8.0, 'step': 792}, {'loss': 0.3309, 'learning_rate': 0.0008243534538116253, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.7746171951293945, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3878, 'eval_samples_per_second': 165.842, 'eval_steps_per_second': 20.94, 'epoch': 9.0, 'step': 891}, {'train_runtime': 243.9708, 'train_samples_per_second': 64.926, 'train_steps_per_second': 4.058, 'total_flos': 0.0, 'train_loss': 0.6074424169949276, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.535974383354187, 'eval_accuracy': 0.75, 'eval_runtime': 2.4117, 'eval_samples_per_second': 164.201, 'eval_steps_per_second': 20.732, 'epoch': 9.0, 'step': 891}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 03:25, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.135500</td>\n",
       "      <td>0.857724</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.054200</td>\n",
       "      <td>0.847192</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.050100</td>\n",
       "      <td>0.830019</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.019800</td>\n",
       "      <td>0.787974</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.024400</td>\n",
       "      <td>0.766079</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.970900</td>\n",
       "      <td>0.744884</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.715838</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.917900</td>\n",
       "      <td>0.707740</td>\n",
       "      <td>0.510101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7077397108078003, 'eval_accuracy': 0.51010101010101, 'eval_runtime': 2.3966, 'eval_samples_per_second': 165.233, 'eval_steps_per_second': 20.863, 'epoch': 9.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 13:18:02,577] Trial 19 finished with values: [0.7077397108078003, 0.51010101010101] and parameters: {'lr': 3.9781452404542374e-05, 'batch': 8, 'accum': 8, 'dropout_rate': 0.6522549553872479, 'weight_decay': 0.0002789352140863346, 'warmup_pct': 0.24865759564524353, 'lora_rank': 12, 'lora_init_scale': 0.0007194841157629348, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1355, 'learning_rate': 1.940558653880116e-06, 'epoch': 0.97, 'step': 24}, {'eval_loss': 0.8577241897583008, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4109, 'eval_samples_per_second': 164.252, 'eval_steps_per_second': 20.739, 'epoch': 0.97, 'step': 24}, {'loss': 1.0542, 'learning_rate': 3.96197391833857e-06, 'epoch': 1.98, 'step': 49}, {'eval_loss': 0.8471918702125549, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3867, 'eval_samples_per_second': 165.918, 'eval_steps_per_second': 20.949, 'epoch': 1.98, 'step': 49}, {'loss': 1.0501, 'learning_rate': 5.983389182797024e-06, 'epoch': 2.99, 'step': 74}, {'eval_loss': 0.8300194144248962, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3915, 'eval_samples_per_second': 165.584, 'eval_steps_per_second': 20.907, 'epoch': 2.99, 'step': 74}, {'loss': 1.049, 'learning_rate': 8.004804447255478e-06, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.8096891641616821, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3895, 'eval_samples_per_second': 165.726, 'eval_steps_per_second': 20.925, 'epoch': 4.0, 'step': 99}, {'loss': 1.0198, 'learning_rate': 9.945363101135593e-06, 'epoch': 4.97, 'step': 123}, {'eval_loss': 0.7879740595817566, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4015, 'eval_samples_per_second': 164.895, 'eval_steps_per_second': 20.82, 'epoch': 4.97, 'step': 123}, {'loss': 1.0244, 'learning_rate': 1.1966778365594048e-05, 'epoch': 5.98, 'step': 148}, {'eval_loss': 0.7660794258117676, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3926, 'eval_samples_per_second': 165.51, 'eval_steps_per_second': 20.898, 'epoch': 5.98, 'step': 148}, {'loss': 0.9709, 'learning_rate': 1.3988193630052502e-05, 'epoch': 6.99, 'step': 173}, {'eval_loss': 0.7448840737342834, 'eval_accuracy': 0.5, 'eval_runtime': 2.3947, 'eval_samples_per_second': 165.366, 'eval_steps_per_second': 20.88, 'epoch': 6.99, 'step': 173}, {'loss': 0.9777, 'learning_rate': 1.6009608894510955e-05, 'epoch': 8.0, 'step': 198}, {'eval_loss': 0.7275983095169067, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3955, 'eval_samples_per_second': 165.309, 'eval_steps_per_second': 20.872, 'epoch': 8.0, 'step': 198}, {'loss': 0.97, 'learning_rate': 1.795016754839107e-05, 'epoch': 8.97, 'step': 222}, {'eval_loss': 0.7158380150794983, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.395, 'eval_samples_per_second': 165.342, 'eval_steps_per_second': 20.877, 'epoch': 8.97, 'step': 222}, {'loss': 0.9179, 'learning_rate': 1.940558653880116e-05, 'epoch': 9.7, 'step': 240}, {'eval_loss': 0.7077397108078003, 'eval_accuracy': 0.51010101010101, 'eval_runtime': 2.3931, 'eval_samples_per_second': 165.473, 'eval_steps_per_second': 20.893, 'epoch': 9.7, 'step': 240}, {'train_runtime': 206.4742, 'train_samples_per_second': 76.717, 'train_steps_per_second': 1.162, 'total_flos': 0.0, 'train_loss': 1.019535764058431, 'epoch': 9.7, 'step': 240}, {'eval_loss': 0.7077397108078003, 'eval_accuracy': 0.51010101010101, 'eval_runtime': 2.3966, 'eval_samples_per_second': 165.233, 'eval_steps_per_second': 20.863, 'epoch': 9.7, 'step': 240}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7920' max='7920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7920/7920 12:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>0.762361</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.716300</td>\n",
       "      <td>0.670428</td>\n",
       "      <td>0.608586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.676100</td>\n",
       "      <td>0.625602</td>\n",
       "      <td>0.669192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>0.664763</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.646600</td>\n",
       "      <td>0.688544</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.617600</td>\n",
       "      <td>0.789330</td>\n",
       "      <td>0.628788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.608200</td>\n",
       "      <td>0.732486</td>\n",
       "      <td>0.654040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>0.660273</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.548500</td>\n",
       "      <td>0.684222</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.537600</td>\n",
       "      <td>0.713589</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.713588535785675, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3902, 'eval_samples_per_second': 165.679, 'eval_steps_per_second': 20.919, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 13:31:09,210] Trial 20 finished with values: [0.713588535785675, 0.702020202020202] and parameters: {'lr': 0.007483076043792765, 'batch': 1, 'accum': 2, 'dropout_rate': 0.23225587967967645, 'weight_decay': 0.000489894122208522, 'warmup_pct': 0.06915091386465477, 'lora_rank': 12, 'lora_init_scale': 0.015125267347356084, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9917, 'learning_rate': 0.005412416645373398, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.7623606324195862, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4164, 'eval_samples_per_second': 163.878, 'eval_steps_per_second': 20.692, 'epoch': 1.0, 'step': 792}, {'loss': 0.7163, 'learning_rate': 0.006946925979995746, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6704277992248535, 'eval_accuracy': 0.6085858585858586, 'eval_runtime': 2.3918, 'eval_samples_per_second': 165.564, 'eval_steps_per_second': 20.905, 'epoch': 2.0, 'step': 1584}, {'loss': 0.6761, 'learning_rate': 0.006078560232496277, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.6256015300750732, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.401, 'eval_samples_per_second': 164.928, 'eval_steps_per_second': 20.824, 'epoch': 3.0, 'step': 2376}, {'loss': 0.6462, 'learning_rate': 0.005210194484996809, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.6647627949714661, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.3874, 'eval_samples_per_second': 165.873, 'eval_steps_per_second': 20.944, 'epoch': 4.0, 'step': 3168}, {'loss': 0.6466, 'learning_rate': 0.004341828737497341, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.6885437369346619, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.3892, 'eval_samples_per_second': 165.749, 'eval_steps_per_second': 20.928, 'epoch': 5.0, 'step': 3960}, {'loss': 0.6176, 'learning_rate': 0.003473462989997873, 'epoch': 6.0, 'step': 4752}, {'eval_loss': 0.7893295884132385, 'eval_accuracy': 0.6287878787878788, 'eval_runtime': 2.388, 'eval_samples_per_second': 165.832, 'eval_steps_per_second': 20.938, 'epoch': 6.0, 'step': 4752}, {'loss': 0.6082, 'learning_rate': 0.0026050972424984044, 'epoch': 7.0, 'step': 5544}, {'eval_loss': 0.7324864268302917, 'eval_accuracy': 0.6540404040404041, 'eval_runtime': 2.3864, 'eval_samples_per_second': 165.943, 'eval_steps_per_second': 20.952, 'epoch': 7.0, 'step': 5544}, {'loss': 0.5768, 'learning_rate': 0.0017367314949989364, 'epoch': 8.0, 'step': 6336}, {'eval_loss': 0.6602727174758911, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.3956, 'eval_samples_per_second': 165.304, 'eval_steps_per_second': 20.872, 'epoch': 8.0, 'step': 6336}, {'loss': 0.5485, 'learning_rate': 0.0008683657474994682, 'epoch': 9.0, 'step': 7128}, {'eval_loss': 0.6842216849327087, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.3881, 'eval_samples_per_second': 165.824, 'eval_steps_per_second': 20.937, 'epoch': 9.0, 'step': 7128}, {'loss': 0.5376, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 7920}, {'eval_loss': 0.713588535785675, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3947, 'eval_samples_per_second': 165.365, 'eval_steps_per_second': 20.879, 'epoch': 10.0, 'step': 7920}, {'train_runtime': 772.6234, 'train_samples_per_second': 20.502, 'train_steps_per_second': 10.251, 'total_flos': 0.0, 'train_loss': 0.6565609402126736, 'epoch': 10.0, 'step': 7920}, {'eval_loss': 0.713588535785675, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3902, 'eval_samples_per_second': 165.679, 'eval_steps_per_second': 20.919, 'epoch': 10.0, 'step': 7920}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7920' max='7920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7920/7920 13:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.956700</td>\n",
       "      <td>0.770612</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.825400</td>\n",
       "      <td>0.676108</td>\n",
       "      <td>0.560606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.623963</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.609300</td>\n",
       "      <td>0.621516</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.584700</td>\n",
       "      <td>0.656818</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.566100</td>\n",
       "      <td>0.750907</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.559800</td>\n",
       "      <td>0.848770</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.546200</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.961624</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.520900</td>\n",
       "      <td>0.977829</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.8487695455551147, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3805, 'eval_samples_per_second': 166.354, 'eval_steps_per_second': 21.004, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 13:44:59,796] Trial 21 finished with values: [0.8487695455551147, 0.7121212121212122] and parameters: {'lr': 3.915975440161392e-05, 'batch': 1, 'accum': 2, 'dropout_rate': 0.47829482315301053, 'weight_decay': 1.2804342019478104e-05, 'warmup_pct': 0.1255434701446084, 'lora_rank': 12, 'lora_init_scale': 0.0001810824538705408, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9567, 'learning_rate': 1.5600867950743575e-05, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.7706118226051331, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4232, 'eval_samples_per_second': 163.422, 'eval_steps_per_second': 20.634, 'epoch': 1.0, 'step': 792}, {'loss': 0.8254, 'learning_rate': 3.120173590148715e-05, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6761080026626587, 'eval_accuracy': 0.5606060606060606, 'eval_runtime': 2.3936, 'eval_samples_per_second': 165.44, 'eval_steps_per_second': 20.889, 'epoch': 2.0, 'step': 1584}, {'loss': 0.684, 'learning_rate': 3.6598394875682334e-05, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.6239632368087769, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 2.3937, 'eval_samples_per_second': 165.432, 'eval_steps_per_second': 20.888, 'epoch': 3.0, 'step': 2376}, {'loss': 0.6093, 'learning_rate': 3.137005275058486e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.6215162873268127, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 2.393, 'eval_samples_per_second': 165.482, 'eval_steps_per_second': 20.894, 'epoch': 4.0, 'step': 3168}, {'loss': 0.5847, 'learning_rate': 2.614171062548738e-05, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.6568184494972229, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.3893, 'eval_samples_per_second': 165.741, 'eval_steps_per_second': 20.927, 'epoch': 5.0, 'step': 3960}, {'loss': 0.5661, 'learning_rate': 2.0913368500389902e-05, 'epoch': 6.0, 'step': 4752}, {'eval_loss': 0.7509073615074158, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.3932, 'eval_samples_per_second': 165.47, 'eval_steps_per_second': 20.893, 'epoch': 6.0, 'step': 4752}, {'loss': 0.5598, 'learning_rate': 1.568502637529243e-05, 'epoch': 7.0, 'step': 5544}, {'eval_loss': 0.8487695455551147, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3934, 'eval_samples_per_second': 165.455, 'eval_steps_per_second': 20.891, 'epoch': 7.0, 'step': 5544}, {'loss': 0.5462, 'learning_rate': 1.0456684250194951e-05, 'epoch': 8.0, 'step': 6336}, {'eval_loss': 0.9019607305526733, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3909, 'eval_samples_per_second': 165.628, 'eval_steps_per_second': 20.913, 'epoch': 8.0, 'step': 6336}, {'loss': 0.5476, 'learning_rate': 5.2283421250974755e-06, 'epoch': 9.0, 'step': 7128}, {'eval_loss': 0.9616244435310364, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.4004, 'eval_samples_per_second': 164.975, 'eval_steps_per_second': 20.83, 'epoch': 9.0, 'step': 7128}, {'loss': 0.5209, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 7920}, {'eval_loss': 0.9778291583061218, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3957, 'eval_samples_per_second': 165.296, 'eval_steps_per_second': 20.871, 'epoch': 10.0, 'step': 7920}, {'train_runtime': 816.463, 'train_samples_per_second': 19.401, 'train_steps_per_second': 9.7, 'total_flos': 0.0, 'train_loss': 0.6400679386023319, 'epoch': 10.0, 'step': 7920}, {'eval_loss': 0.8487695455551147, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3805, 'eval_samples_per_second': 166.354, 'eval_steps_per_second': 21.004, 'epoch': 10.0, 'step': 7920}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='693' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [693/990 02:32 < 01:05, 4.53 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.070300</td>\n",
       "      <td>0.717396</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.786900</td>\n",
       "      <td>0.651067</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.641300</td>\n",
       "      <td>0.596239</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.562800</td>\n",
       "      <td>0.560266</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.518800</td>\n",
       "      <td>0.559528</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.469200</td>\n",
       "      <td>0.561689</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.431300</td>\n",
       "      <td>0.569775</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 13:47:48,415] Trial 22 finished with values: [0.5602655410766602, 0.7474747474747475] and parameters: {'lr': 0.0001435245391068975, 'batch': 8, 'accum': 2, 'dropout_rate': 0.6863516045783153, 'weight_decay': 0.0003382968651003714, 'warmup_pct': 0.08177449892588111, 'lora_rank': 4, 'lora_init_scale': 0.001312073908129456, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5602655410766602, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3927, 'eval_samples_per_second': 165.503, 'eval_steps_per_second': 20.897, 'epoch': 7.0}\n",
      "History:  [{'loss': 1.0703, 'learning_rate': 8.825421969927238e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.7173958420753479, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4239, 'eval_samples_per_second': 163.374, 'eval_steps_per_second': 20.628, 'epoch': 1.0, 'step': 99}, {'loss': 0.7869, 'learning_rate': 0.0001371187394121385, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6510666608810425, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 2.4002, 'eval_samples_per_second': 164.987, 'eval_steps_per_second': 20.832, 'epoch': 2.0, 'step': 198}, {'loss': 0.6413, 'learning_rate': 0.00011997889698562118, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5962393879890442, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 2.3895, 'eval_samples_per_second': 165.726, 'eval_steps_per_second': 20.925, 'epoch': 3.0, 'step': 297}, {'loss': 0.5628, 'learning_rate': 0.00010283905455910388, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5602655410766602, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3937, 'eval_samples_per_second': 165.433, 'eval_steps_per_second': 20.888, 'epoch': 4.0, 'step': 396}, {'loss': 0.5188, 'learning_rate': 8.569921213258656e-05, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5595279932022095, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3926, 'eval_samples_per_second': 165.508, 'eval_steps_per_second': 20.898, 'epoch': 5.0, 'step': 495}, {'loss': 0.4692, 'learning_rate': 6.855936970606924e-05, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.5616886615753174, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3965, 'eval_samples_per_second': 165.242, 'eval_steps_per_second': 20.864, 'epoch': 6.0, 'step': 594}, {'loss': 0.4313, 'learning_rate': 5.141952727955194e-05, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5697749853134155, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3972, 'eval_samples_per_second': 165.19, 'eval_steps_per_second': 20.857, 'epoch': 7.0, 'step': 693}, {'train_runtime': 152.7318, 'train_samples_per_second': 103.711, 'train_steps_per_second': 6.482, 'total_flos': 0.0, 'train_loss': 0.6400889001711451, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5602655410766602, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3927, 'eval_samples_per_second': 165.503, 'eval_steps_per_second': 20.897, 'epoch': 7.0, 'step': 693}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 04:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.724600</td>\n",
       "      <td>0.676297</td>\n",
       "      <td>0.547980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.834956</td>\n",
       "      <td>0.510101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.695500</td>\n",
       "      <td>0.722681</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.662700</td>\n",
       "      <td>0.649676</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.647641</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.578500</td>\n",
       "      <td>0.613847</td>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.553200</td>\n",
       "      <td>0.613628</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.591388</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.517300</td>\n",
       "      <td>0.602080</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.498700</td>\n",
       "      <td>0.607719</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5913878679275513, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.4161, 'eval_samples_per_second': 163.902, 'eval_steps_per_second': 20.695, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 13:52:42,486] Trial 23 finished with values: [0.5913878679275513, 0.6944444444444444] and parameters: {'lr': 0.004086146084170576, 'batch': 4, 'accum': 2, 'dropout_rate': 0.44944482681659126, 'weight_decay': 5.1616489380956605e-05, 'warmup_pct': 0.0815829294073959, 'lora_rank': 8, 'lora_init_scale': 0.07358151750152714, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7246, 'learning_rate': 0.0025048202002036345, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6762973666191101, 'eval_accuracy': 0.547979797979798, 'eval_runtime': 2.4288, 'eval_samples_per_second': 163.041, 'eval_steps_per_second': 20.586, 'epoch': 1.0, 'step': 198}, {'loss': 0.865, 'learning_rate': 0.0039061287853507497, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.8349558711051941, 'eval_accuracy': 0.51010101010101, 'eval_runtime': 2.3944, 'eval_samples_per_second': 165.388, 'eval_steps_per_second': 20.882, 'epoch': 2.0, 'step': 396}, {'loss': 0.6955, 'learning_rate': 0.003417862687181906, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.7226809859275818, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.4125, 'eval_samples_per_second': 164.142, 'eval_steps_per_second': 20.725, 'epoch': 3.0, 'step': 594}, {'loss': 0.6627, 'learning_rate': 0.002929596589013062, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6496756672859192, 'eval_accuracy': 0.6363636363636364, 'eval_runtime': 2.3985, 'eval_samples_per_second': 165.103, 'eval_steps_per_second': 20.846, 'epoch': 4.0, 'step': 792}, {'loss': 0.6213, 'learning_rate': 0.0024413304908442184, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.647640585899353, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.4073, 'eval_samples_per_second': 164.5, 'eval_steps_per_second': 20.77, 'epoch': 5.0, 'step': 990}, {'loss': 0.5785, 'learning_rate': 0.0019530643926753749, 'epoch': 6.0, 'step': 1188}, {'eval_loss': 0.6138473749160767, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.4123, 'eval_samples_per_second': 164.156, 'eval_steps_per_second': 20.727, 'epoch': 6.0, 'step': 1188}, {'loss': 0.5532, 'learning_rate': 0.001464798294506531, 'epoch': 7.0, 'step': 1386}, {'eval_loss': 0.6136276721954346, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.4125, 'eval_samples_per_second': 164.148, 'eval_steps_per_second': 20.726, 'epoch': 7.0, 'step': 1386}, {'loss': 0.545, 'learning_rate': 0.0009765321963376874, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.5913878679275513, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.3926, 'eval_samples_per_second': 165.511, 'eval_steps_per_second': 20.898, 'epoch': 8.0, 'step': 1584}, {'loss': 0.5173, 'learning_rate': 0.0004882660981688437, 'epoch': 9.0, 'step': 1782}, {'eval_loss': 0.6020801663398743, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.3935, 'eval_samples_per_second': 165.451, 'eval_steps_per_second': 20.89, 'epoch': 9.0, 'step': 1782}, {'loss': 0.4987, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 0.607719361782074, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.3964, 'eval_samples_per_second': 165.246, 'eval_steps_per_second': 20.864, 'epoch': 10.0, 'step': 1980}, {'train_runtime': 280.3079, 'train_samples_per_second': 56.509, 'train_steps_per_second': 7.064, 'total_flos': 0.0, 'train_loss': 0.6261919195001776, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 0.5913878679275513, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.4161, 'eval_samples_per_second': 163.902, 'eval_steps_per_second': 20.695, 'epoch': 10.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 04:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.674271</td>\n",
       "      <td>0.623737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.662300</td>\n",
       "      <td>0.594935</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.555082</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.527200</td>\n",
       "      <td>0.562266</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.511400</td>\n",
       "      <td>0.594701</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.571460</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.815434</td>\n",
       "      <td>0.775253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.179500</td>\n",
       "      <td>0.948970</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>1.517098</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>1.529271</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.8154343366622925, 'eval_accuracy': 0.7752525252525253, 'eval_runtime': 2.4322, 'eval_samples_per_second': 162.816, 'eval_steps_per_second': 20.558, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 13:57:36,261] Trial 24 finished with values: [0.8154343366622925, 0.7752525252525253] and parameters: {'lr': 0.0007848495607529741, 'batch': 4, 'accum': 2, 'dropout_rate': 0.756688643077596, 'weight_decay': 5.531190552196978e-05, 'warmup_pct': 0.225231670458402, 'lora_rank': 16, 'lora_init_scale': 0.0022080440496709173, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9875, 'learning_rate': 0.0001744110135006609, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6742706298828125, 'eval_accuracy': 0.6237373737373737, 'eval_runtime': 2.4241, 'eval_samples_per_second': 163.362, 'eval_steps_per_second': 20.627, 'epoch': 1.0, 'step': 198}, {'loss': 0.6623, 'learning_rate': 0.0003488220270013218, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.5949347615242004, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3937, 'eval_samples_per_second': 165.434, 'eval_steps_per_second': 20.888, 'epoch': 2.0, 'step': 396}, {'loss': 0.5575, 'learning_rate': 0.0005232330405019827, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.555081844329834, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3968, 'eval_samples_per_second': 165.219, 'eval_steps_per_second': 20.861, 'epoch': 3.0, 'step': 594}, {'loss': 0.5272, 'learning_rate': 0.0006976440540026436, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5622662901878357, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3907, 'eval_samples_per_second': 165.643, 'eval_steps_per_second': 20.915, 'epoch': 4.0, 'step': 792}, {'loss': 0.5114, 'learning_rate': 0.0007134996006845219, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5947012305259705, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.3986, 'eval_samples_per_second': 165.098, 'eval_steps_per_second': 20.846, 'epoch': 5.0, 'step': 990}, {'loss': 0.4266, 'learning_rate': 0.0005707996805476176, 'epoch': 6.0, 'step': 1188}, {'eval_loss': 0.5714595317840576, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.4, 'eval_samples_per_second': 164.997, 'eval_steps_per_second': 20.833, 'epoch': 6.0, 'step': 1188}, {'loss': 0.2965, 'learning_rate': 0.0004280997604107131, 'epoch': 7.0, 'step': 1386}, {'eval_loss': 0.8154343366622925, 'eval_accuracy': 0.7752525252525253, 'eval_runtime': 2.4272, 'eval_samples_per_second': 163.149, 'eval_steps_per_second': 20.6, 'epoch': 7.0, 'step': 1386}, {'loss': 0.1795, 'learning_rate': 0.0002853998402738088, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.9489696621894836, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.4167, 'eval_samples_per_second': 163.862, 'eval_steps_per_second': 20.69, 'epoch': 8.0, 'step': 1584}, {'loss': 0.0462, 'learning_rate': 0.0001426999201369044, 'epoch': 9.0, 'step': 1782}, {'eval_loss': 1.517098307609558, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.404, 'eval_samples_per_second': 164.725, 'eval_steps_per_second': 20.799, 'epoch': 9.0, 'step': 1782}, {'loss': 0.021, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 1.5292705297470093, 'eval_accuracy': 0.75, 'eval_runtime': 2.4038, 'eval_samples_per_second': 164.739, 'eval_steps_per_second': 20.8, 'epoch': 10.0, 'step': 1980}, {'train_runtime': 279.8819, 'train_samples_per_second': 56.595, 'train_steps_per_second': 7.074, 'total_flos': 0.0, 'train_loss': 0.421577412913544, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 0.8154343366622925, 'eval_accuracy': 0.7752525252525253, 'eval_runtime': 2.4322, 'eval_samples_per_second': 162.816, 'eval_steps_per_second': 20.558, 'epoch': 10.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1584' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1584/3960 05:05 < 07:38, 5.18 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.700200</td>\n",
       "      <td>0.575854</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.653400</td>\n",
       "      <td>0.680688</td>\n",
       "      <td>0.550505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.685300</td>\n",
       "      <td>0.660746</td>\n",
       "      <td>0.608586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>0.664119</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5758541226387024, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.4135, 'eval_samples_per_second': 164.079, 'eval_steps_per_second': 20.717, 'epoch': 4.0}\n",
      "History:  [{'loss': 0.7002, 'learning_rate': 0.00023801827399940915, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.5758541226387024, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 5.2811, 'eval_samples_per_second': 74.984, 'eval_steps_per_second': 9.468, 'epoch': 1.0, 'step': 396}, {'loss': 0.6534, 'learning_rate': 0.0003650138803192865, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6806882619857788, 'eval_accuracy': 0.5505050505050505, 'eval_runtime': 5.283, 'eval_samples_per_second': 74.958, 'eval_steps_per_second': 9.464, 'epoch': 2.0, 'step': 792}, {'loss': 0.6853, 'learning_rate': 0.00031938714527937574, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6607455611228943, 'eval_accuracy': 0.6085858585858586, 'eval_runtime': 5.2725, 'eval_samples_per_second': 75.107, 'eval_steps_per_second': 9.483, 'epoch': 3.0, 'step': 1188}, {'loss': 0.6596, 'learning_rate': 0.00027376041023946486, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6641188859939575, 'eval_accuracy': 0.6060606060606061, 'eval_runtime': 2.4094, 'eval_samples_per_second': 164.359, 'eval_steps_per_second': 20.752, 'epoch': 4.0, 'step': 1584}, {'train_runtime': 305.6932, 'train_samples_per_second': 51.817, 'train_steps_per_second': 12.954, 'total_flos': 0.0, 'train_loss': 0.6746329490584556, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.5758541226387024, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.4135, 'eval_samples_per_second': 164.079, 'eval_steps_per_second': 20.717, 'epoch': 4.0, 'step': 1584}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 14:02:58,321] Trial 25 finished with values: [0.5758541226387024, 0.702020202020202] and parameters: {'lr': 0.0003828728296404637, 'batch': 2, 'accum': 2, 'dropout_rate': 0.11979203755544941, 'weight_decay': 0.0006981610552309288, 'warmup_pct': 0.08052506259231282, 'lora_rank': 8, 'lora_init_scale': 0.00021849746136378944, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2772' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2772/3960 13:12 < 05:39, 3.50 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>0.752959</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.819800</td>\n",
       "      <td>0.671768</td>\n",
       "      <td>0.593434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.675400</td>\n",
       "      <td>0.621446</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.588800</td>\n",
       "      <td>0.571457</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.536200</td>\n",
       "      <td>0.577914</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>0.627668</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.373800</td>\n",
       "      <td>0.767138</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5714567303657532, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.4039, 'eval_samples_per_second': 164.73, 'eval_steps_per_second': 20.799, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 14:16:28,065] Trial 26 finished with values: [0.5714567303657532, 0.7474747474747475] and parameters: {'lr': 0.00010384308953816032, 'batch': 1, 'accum': 4, 'dropout_rate': 0.599964565328297, 'weight_decay': 2.3009141216666917e-05, 'warmup_pct': 0.10197525592405694, 'lora_rank': 16, 'lora_init_scale': 0.06779986311844488, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9956, 'learning_rate': 2.546245415301021e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.7529589533805847, 'eval_accuracy': 0.5, 'eval_runtime': 5.3432, 'eval_samples_per_second': 74.113, 'eval_steps_per_second': 9.358, 'epoch': 1.0, 'step': 396}, {'loss': 0.8198, 'learning_rate': 5.092490830602042e-05, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6717678904533386, 'eval_accuracy': 0.5934343434343434, 'eval_runtime': 5.2777, 'eval_samples_per_second': 75.033, 'eval_steps_per_second': 9.474, 'epoch': 2.0, 'step': 792}, {'loss': 0.6754, 'learning_rate': 7.638736245903063e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6214463114738464, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 5.2821, 'eval_samples_per_second': 74.97, 'eval_steps_per_second': 9.466, 'epoch': 3.0, 'step': 1188}, {'loss': 0.5888, 'learning_rate': 0.00010184981661204084, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.5714567303657532, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 5.2665, 'eval_samples_per_second': 75.192, 'eval_steps_per_second': 9.494, 'epoch': 4.0, 'step': 1584}, {'loss': 0.5362, 'learning_rate': 8.767987943947011e-05, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5779137015342712, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 5.2752, 'eval_samples_per_second': 75.068, 'eval_steps_per_second': 9.478, 'epoch': 5.0, 'step': 1980}, {'loss': 0.4395, 'learning_rate': 7.01439035515761e-05, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.6276682615280151, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3707, 'eval_samples_per_second': 167.041, 'eval_steps_per_second': 21.091, 'epoch': 6.0, 'step': 2376}, {'loss': 0.3738, 'learning_rate': 5.260792766368208e-05, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.7671379446983337, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3914, 'eval_samples_per_second': 165.595, 'eval_steps_per_second': 20.908, 'epoch': 7.0, 'step': 2772}, {'train_runtime': 792.5683, 'train_samples_per_second': 19.986, 'train_steps_per_second': 4.996, 'total_flos': 0.0, 'train_loss': 0.6327327381480824, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.5714567303657532, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.4039, 'eval_samples_per_second': 164.73, 'eval_steps_per_second': 20.799, 'epoch': 7.0, 'step': 2772}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1584' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1584/1980 10:34 < 02:38, 2.49 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>0.634273</td>\n",
       "      <td>0.648990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.580200</td>\n",
       "      <td>0.518556</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.484100</td>\n",
       "      <td>0.510475</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>0.587210</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.390500</td>\n",
       "      <td>0.623761</td>\n",
       "      <td>0.775253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.787165</td>\n",
       "      <td>0.775253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.337800</td>\n",
       "      <td>0.834386</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.279500</td>\n",
       "      <td>0.976897</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6237613558769226, 'eval_accuracy': 0.7752525252525253, 'eval_runtime': 2.3894, 'eval_samples_per_second': 165.732, 'eval_steps_per_second': 20.926, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 14:27:18,768] Trial 27 finished with values: [0.6237613558769226, 0.7752525252525253] and parameters: {'lr': 0.0023435064802818234, 'batch': 1, 'accum': 8, 'dropout_rate': 0.33527687224006164, 'weight_decay': 0.0006469636851107557, 'warmup_pct': 0.15119836825913632, 'lora_rank': 16, 'lora_init_scale': 0.01713843597721974, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7725, 'learning_rate': 0.000193823844233835, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6342731714248657, 'eval_accuracy': 0.648989898989899, 'eval_runtime': 2.4477, 'eval_samples_per_second': 161.783, 'eval_steps_per_second': 20.427, 'epoch': 1.0, 'step': 198}, {'loss': 0.5802, 'learning_rate': 0.00038764768846767, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.5185562968254089, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3751, 'eval_samples_per_second': 166.732, 'eval_steps_per_second': 21.052, 'epoch': 2.0, 'step': 396}, {'loss': 0.4841, 'learning_rate': 0.000581471532701505, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.5104749798774719, 'eval_accuracy': 0.75, 'eval_runtime': 2.3879, 'eval_samples_per_second': 165.835, 'eval_steps_per_second': 20.939, 'epoch': 3.0, 'step': 594}, {'loss': 0.4594, 'learning_rate': 0.00077529537693534, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5872101783752441, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.3753, 'eval_samples_per_second': 166.714, 'eval_steps_per_second': 21.05, 'epoch': 4.0, 'step': 792}, {'loss': 0.3905, 'learning_rate': 0.000969119221169175, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6237613558769226, 'eval_accuracy': 0.7752525252525253, 'eval_runtime': 2.388, 'eval_samples_per_second': 165.827, 'eval_steps_per_second': 20.938, 'epoch': 5.0, 'step': 990}, {'loss': 0.3425, 'learning_rate': 0.00116294306540301, 'epoch': 6.0, 'step': 1188}, {'eval_loss': 0.7871654033660889, 'eval_accuracy': 0.7752525252525253, 'eval_runtime': 2.3948, 'eval_samples_per_second': 165.36, 'eval_steps_per_second': 20.879, 'epoch': 6.0, 'step': 1188}, {'loss': 0.3378, 'learning_rate': 0.0013567669096368451, 'epoch': 7.0, 'step': 1386}, {'eval_loss': 0.834385871887207, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 2.3946, 'eval_samples_per_second': 165.375, 'eval_steps_per_second': 20.881, 'epoch': 7.0, 'step': 1386}, {'loss': 0.2795, 'learning_rate': 0.00155059075387068, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.9768968820571899, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.3931, 'eval_samples_per_second': 165.477, 'eval_steps_per_second': 20.894, 'epoch': 8.0, 'step': 1584}, {'train_runtime': 635.2426, 'train_samples_per_second': 24.935, 'train_steps_per_second': 3.117, 'total_flos': 0.0, 'train_loss': 0.4558117317430901, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.6237613558769226, 'eval_accuracy': 0.7752525252525253, 'eval_runtime': 2.3894, 'eval_samples_per_second': 165.732, 'eval_steps_per_second': 20.926, 'epoch': 8.0, 'step': 1584}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.985800</td>\n",
       "      <td>0.769172</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.884700</td>\n",
       "      <td>0.721732</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.864900</td>\n",
       "      <td>0.703634</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.836800</td>\n",
       "      <td>0.694546</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.796100</td>\n",
       "      <td>0.687720</td>\n",
       "      <td>0.560606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.794600</td>\n",
       "      <td>0.683546</td>\n",
       "      <td>0.573232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.778200</td>\n",
       "      <td>0.680976</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.765300</td>\n",
       "      <td>0.678683</td>\n",
       "      <td>0.585859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.756300</td>\n",
       "      <td>0.677752</td>\n",
       "      <td>0.588384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.766800</td>\n",
       "      <td>0.677411</td>\n",
       "      <td>0.588384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6777521967887878, 'eval_accuracy': 0.5883838383838383, 'eval_runtime': 2.4145, 'eval_samples_per_second': 164.006, 'eval_steps_per_second': 20.708, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 14:31:15,386] Trial 28 finished with values: [0.6777521967887878, 0.5883838383838383] and parameters: {'lr': 1.5085105464352594e-05, 'batch': 8, 'accum': 2, 'dropout_rate': 0.5666849472091137, 'weight_decay': 5.206214519001889e-05, 'warmup_pct': 0.0115327560640831, 'lora_rank': 8, 'lora_init_scale': 0.09718970055073102, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9858, 'learning_rate': 1.3885153893324547e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.7691718935966492, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.436, 'eval_samples_per_second': 162.561, 'eval_steps_per_second': 20.525, 'epoch': 1.0, 'step': 99}, {'loss': 0.8847, 'learning_rate': 1.2342359016288486e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.7217318415641785, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3792, 'eval_samples_per_second': 166.446, 'eval_steps_per_second': 21.016, 'epoch': 2.0, 'step': 198}, {'loss': 0.8649, 'learning_rate': 1.0799564139252426e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.7036342620849609, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3788, 'eval_samples_per_second': 166.468, 'eval_steps_per_second': 21.019, 'epoch': 3.0, 'step': 297}, {'loss': 0.8368, 'learning_rate': 9.256769262216365e-06, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6945456862449646, 'eval_accuracy': 0.5277777777777778, 'eval_runtime': 2.4039, 'eval_samples_per_second': 164.735, 'eval_steps_per_second': 20.8, 'epoch': 4.0, 'step': 396}, {'loss': 0.7961, 'learning_rate': 7.713974385180303e-06, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6877204179763794, 'eval_accuracy': 0.5606060606060606, 'eval_runtime': 2.397, 'eval_samples_per_second': 165.203, 'eval_steps_per_second': 20.859, 'epoch': 5.0, 'step': 495}, {'loss': 0.7946, 'learning_rate': 6.171179508144243e-06, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.6835463047027588, 'eval_accuracy': 0.5732323232323232, 'eval_runtime': 2.3907, 'eval_samples_per_second': 165.643, 'eval_steps_per_second': 20.915, 'epoch': 6.0, 'step': 594}, {'loss': 0.7782, 'learning_rate': 4.6283846311081825e-06, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.6809758543968201, 'eval_accuracy': 0.5833333333333334, 'eval_runtime': 2.3963, 'eval_samples_per_second': 165.253, 'eval_steps_per_second': 20.865, 'epoch': 7.0, 'step': 693}, {'loss': 0.7653, 'learning_rate': 3.0855897540721215e-06, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.6786832213401794, 'eval_accuracy': 0.5858585858585859, 'eval_runtime': 2.3939, 'eval_samples_per_second': 165.418, 'eval_steps_per_second': 20.886, 'epoch': 8.0, 'step': 792}, {'loss': 0.7563, 'learning_rate': 1.5427948770360608e-06, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.6777521967887878, 'eval_accuracy': 0.5883838383838383, 'eval_runtime': 2.3891, 'eval_samples_per_second': 165.753, 'eval_steps_per_second': 20.928, 'epoch': 9.0, 'step': 891}, {'loss': 0.7668, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.6774110198020935, 'eval_accuracy': 0.5883838383838383, 'eval_runtime': 2.3951, 'eval_samples_per_second': 165.341, 'eval_steps_per_second': 20.876, 'epoch': 10.0, 'step': 990}, {'train_runtime': 217.3013, 'train_samples_per_second': 72.894, 'train_steps_per_second': 4.556, 'total_flos': 0.0, 'train_loss': 0.8229507985741201, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.6777521967887878, 'eval_accuracy': 0.5883838383838383, 'eval_runtime': 2.4145, 'eval_samples_per_second': 164.006, 'eval_steps_per_second': 20.708, 'epoch': 10.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 13:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.307500</td>\n",
       "      <td>0.848492</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.245200</td>\n",
       "      <td>0.820834</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.191500</td>\n",
       "      <td>0.776004</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.068200</td>\n",
       "      <td>0.732038</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.953600</td>\n",
       "      <td>0.707211</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.675991</td>\n",
       "      <td>0.565657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.752300</td>\n",
       "      <td>0.662649</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.705300</td>\n",
       "      <td>0.647386</td>\n",
       "      <td>0.661616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.661800</td>\n",
       "      <td>0.633573</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.647400</td>\n",
       "      <td>0.629866</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6298658847808838, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.4105, 'eval_samples_per_second': 164.28, 'eval_steps_per_second': 20.742, 'epoch': 10.0}\n",
      "History:  [{'loss': 1.3075, 'learning_rate': 5.192289018117887e-06, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.8484915494918823, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4283, 'eval_samples_per_second': 163.079, 'eval_steps_per_second': 20.591, 'epoch': 1.0, 'step': 198}, {'loss': 1.2452, 'learning_rate': 1.0384578036235773e-05, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.8208338618278503, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3895, 'eval_samples_per_second': 165.725, 'eval_steps_per_second': 20.925, 'epoch': 2.0, 'step': 396}, {'loss': 1.1915, 'learning_rate': 1.557686705435366e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.7760041952133179, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3907, 'eval_samples_per_second': 165.64, 'eval_steps_per_second': 20.914, 'epoch': 3.0, 'step': 594}, {'loss': 1.0682, 'learning_rate': 2.0769156072471547e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.7320384979248047, 'eval_accuracy': 0.5, 'eval_runtime': 2.3941, 'eval_samples_per_second': 165.407, 'eval_steps_per_second': 20.885, 'epoch': 4.0, 'step': 792}, {'loss': 0.9536, 'learning_rate': 2.5961445090589437e-05, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.7072112560272217, 'eval_accuracy': 0.5, 'eval_runtime': 2.3897, 'eval_samples_per_second': 165.714, 'eval_steps_per_second': 20.923, 'epoch': 5.0, 'step': 990}, {'loss': 0.861, 'learning_rate': 3.115373410870732e-05, 'epoch': 6.0, 'step': 1188}, {'eval_loss': 0.6759912371635437, 'eval_accuracy': 0.5656565656565656, 'eval_runtime': 2.3951, 'eval_samples_per_second': 165.34, 'eval_steps_per_second': 20.876, 'epoch': 6.0, 'step': 1188}, {'loss': 0.7523, 'learning_rate': 3.63460231268252e-05, 'epoch': 7.0, 'step': 1386}, {'eval_loss': 0.6626486778259277, 'eval_accuracy': 0.6363636363636364, 'eval_runtime': 2.3935, 'eval_samples_per_second': 165.448, 'eval_steps_per_second': 20.89, 'epoch': 7.0, 'step': 1386}, {'loss': 0.7053, 'learning_rate': 4.153831214494309e-05, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.6473863124847412, 'eval_accuracy': 0.6616161616161617, 'eval_runtime': 2.3913, 'eval_samples_per_second': 165.602, 'eval_steps_per_second': 20.909, 'epoch': 8.0, 'step': 1584}, {'loss': 0.6618, 'learning_rate': 2.336530058153049e-05, 'epoch': 9.0, 'step': 1782}, {'eval_loss': 0.6335731148719788, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.4013, 'eval_samples_per_second': 164.911, 'eval_steps_per_second': 20.822, 'epoch': 9.0, 'step': 1782}, {'loss': 0.6474, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 0.6298658847808838, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.4054, 'eval_samples_per_second': 164.631, 'eval_steps_per_second': 20.787, 'epoch': 10.0, 'step': 1980}, {'train_runtime': 832.025, 'train_samples_per_second': 19.038, 'train_steps_per_second': 2.38, 'total_flos': 0.0, 'train_loss': 0.9393766383932094, 'epoch': 10.0, 'step': 1980}, {'eval_loss': 0.6298658847808838, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.4105, 'eval_samples_per_second': 164.28, 'eval_steps_per_second': 20.742, 'epoch': 10.0, 'step': 1980}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 14:45:22,445] Trial 29 finished with values: [0.6298658847808838, 0.6919191919191919] and parameters: {'lr': 4.24823646936918e-05, 'batch': 1, 'accum': 8, 'dropout_rate': 0.8409400132580304, 'weight_decay': 5.64754330485164e-05, 'warmup_pct': 0.10232386557100094, 'lora_rank': 4, 'lora_init_scale': 0.005347348257807107, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='445' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [445/490 03:11 < 00:19, 2.31 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.843900</td>\n",
       "      <td>0.738671</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.636692</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>0.564121</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.418900</td>\n",
       "      <td>0.587474</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.750848</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 8.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5594683885574341, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.4204, 'eval_samples_per_second': 163.607, 'eval_steps_per_second': 20.657, 'epoch': 8.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 14:48:49,117] Trial 30 finished with values: [0.5594683885574341, 0.7474747474747475] and parameters: {'lr': 0.0002783102302553824, 'batch': 8, 'accum': 4, 'dropout_rate': 0.10776963734713699, 'weight_decay': 0.0006751027932034982, 'warmup_pct': 0.18219555759661857, 'lora_rank': 8, 'lora_init_scale': 0.022178600647243602, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8439, 'learning_rate': 3.7881114673649264e-05, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.7386711835861206, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.4152, 'eval_samples_per_second': 163.963, 'eval_steps_per_second': 20.702, 'epoch': 0.99, 'step': 49}, {'loss': 0.706, 'learning_rate': 7.653531332023016e-05, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.6731604933738708, 'eval_accuracy': 0.6161616161616161, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.764, 'eval_steps_per_second': 20.93, 'epoch': 2.0, 'step': 99}, {'loss': 0.6614, 'learning_rate': 0.00011441642799387943, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.6366921663284302, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.3884, 'eval_samples_per_second': 165.802, 'eval_steps_per_second': 20.935, 'epoch': 2.99, 'step': 148}, {'loss': 0.5969, 'learning_rate': 0.00015307062664046033, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5962193608283997, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.389, 'eval_samples_per_second': 165.76, 'eval_steps_per_second': 20.929, 'epoch': 4.0, 'step': 198}, {'loss': 0.5436, 'learning_rate': 0.0001909517413141096, 'epoch': 4.99, 'step': 247}, {'eval_loss': 0.5641208291053772, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.395, 'eval_samples_per_second': 165.346, 'eval_steps_per_second': 20.877, 'epoch': 4.99, 'step': 247}, {'loss': 0.4839, 'learning_rate': 0.00022960593996069047, 'epoch': 6.0, 'step': 297}, {'eval_loss': 0.5594683885574341, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.396, 'eval_samples_per_second': 165.273, 'eval_steps_per_second': 20.868, 'epoch': 6.0, 'step': 297}, {'loss': 0.4189, 'learning_rate': 0.00026748705463433976, 'epoch': 6.99, 'step': 346}, {'eval_loss': 0.5874737501144409, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.3984, 'eval_samples_per_second': 165.11, 'eval_steps_per_second': 20.847, 'epoch': 6.99, 'step': 346}, {'loss': 0.3248, 'learning_rate': 0.0002012397049538919, 'epoch': 8.0, 'step': 396}, {'eval_loss': 0.6439968347549438, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3945, 'eval_samples_per_second': 165.382, 'eval_steps_per_second': 20.882, 'epoch': 8.0, 'step': 396}, {'loss': 0.2267, 'learning_rate': 9.633815662686313e-05, 'epoch': 8.99, 'step': 445}, {'eval_loss': 0.7508479952812195, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.3965, 'eval_samples_per_second': 165.243, 'eval_steps_per_second': 20.864, 'epoch': 8.99, 'step': 445}, {'train_runtime': 192.2689, 'train_samples_per_second': 82.385, 'train_steps_per_second': 2.549, 'total_flos': 0.0, 'train_loss': 0.5339475653144751, 'epoch': 8.99, 'step': 445}, {'eval_loss': 0.5594683885574341, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.4204, 'eval_samples_per_second': 163.607, 'eval_steps_per_second': 20.657, 'epoch': 8.99, 'step': 445}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7920' max='7920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7920/7920 12:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.264100</td>\n",
       "      <td>0.825560</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.133700</td>\n",
       "      <td>0.753619</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.954200</td>\n",
       "      <td>0.694840</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.799700</td>\n",
       "      <td>0.657497</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.710400</td>\n",
       "      <td>0.630859</td>\n",
       "      <td>0.664141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.651600</td>\n",
       "      <td>0.604833</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.607200</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.600200</td>\n",
       "      <td>0.621656</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.575100</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.570800</td>\n",
       "      <td>0.645969</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6459689736366272, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.4217, 'eval_samples_per_second': 163.524, 'eval_steps_per_second': 20.647, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 15:02:00,274] Trial 31 finished with values: [0.6459689736366272, 0.7121212121212122] and parameters: {'lr': 4.1145758979953084e-05, 'batch': 1, 'accum': 2, 'dropout_rate': 0.8303461105228828, 'weight_decay': 1.9721203911893555e-05, 'warmup_pct': 0.24464330694520708, 'lora_rank': 12, 'lora_init_scale': 0.004728117740146572, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.2641, 'learning_rate': 8.409662222483315e-06, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.825560450553894, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4194, 'eval_samples_per_second': 163.675, 'eval_steps_per_second': 20.666, 'epoch': 1.0, 'step': 792}, {'loss': 1.1337, 'learning_rate': 1.681932444496663e-05, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.7536191940307617, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3938, 'eval_samples_per_second': 165.427, 'eval_steps_per_second': 20.887, 'epoch': 2.0, 'step': 1584}, {'loss': 0.9542, 'learning_rate': 2.522898666744994e-05, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.6948398351669312, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.387, 'eval_samples_per_second': 165.898, 'eval_steps_per_second': 20.947, 'epoch': 3.0, 'step': 2376}, {'loss': 0.7997, 'learning_rate': 3.363864888993326e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.6574965715408325, 'eval_accuracy': 0.6060606060606061, 'eval_runtime': 2.3923, 'eval_samples_per_second': 165.53, 'eval_steps_per_second': 20.9, 'epoch': 4.0, 'step': 3168}, {'loss': 0.7104, 'learning_rate': 4.0281138581116e-05, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.6308590173721313, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 2.3901, 'eval_samples_per_second': 165.686, 'eval_steps_per_second': 20.92, 'epoch': 5.0, 'step': 3960}, {'loss': 0.6516, 'learning_rate': 3.22249108648928e-05, 'epoch': 6.0, 'step': 4752}, {'eval_loss': 0.6048334240913391, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.3891, 'eval_samples_per_second': 165.753, 'eval_steps_per_second': 20.928, 'epoch': 6.0, 'step': 4752}, {'loss': 0.6072, 'learning_rate': 2.4168683148669598e-05, 'epoch': 7.0, 'step': 5544}, {'eval_loss': 0.607843279838562, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.4271, 'eval_samples_per_second': 163.156, 'eval_steps_per_second': 20.6, 'epoch': 7.0, 'step': 5544}, {'loss': 0.6002, 'learning_rate': 1.61124554324464e-05, 'epoch': 8.0, 'step': 6336}, {'eval_loss': 0.6216560006141663, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.389, 'eval_samples_per_second': 165.757, 'eval_steps_per_second': 20.929, 'epoch': 8.0, 'step': 6336}, {'loss': 0.5751, 'learning_rate': 8.0562277162232e-06, 'epoch': 9.0, 'step': 7128}, {'eval_loss': 0.6395348310470581, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.3913, 'eval_samples_per_second': 165.599, 'eval_steps_per_second': 20.909, 'epoch': 9.0, 'step': 7128}, {'loss': 0.5708, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 7920}, {'eval_loss': 0.6459689736366272, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3878, 'eval_samples_per_second': 165.846, 'eval_steps_per_second': 20.94, 'epoch': 10.0, 'step': 7920}, {'train_runtime': 776.2129, 'train_samples_per_second': 20.407, 'train_steps_per_second': 10.203, 'total_flos': 0.0, 'train_loss': 0.7866986708207564, 'epoch': 10.0, 'step': 7920}, {'eval_loss': 0.6459689736366272, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.4217, 'eval_samples_per_second': 163.524, 'eval_steps_per_second': 20.647, 'epoch': 10.0, 'step': 7920}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 03:31, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.924100</td>\n",
       "      <td>0.782719</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.741200</td>\n",
       "      <td>0.669059</td>\n",
       "      <td>0.643939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.634400</td>\n",
       "      <td>0.605864</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.571225</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.624465</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.691053</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 9.8989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.8989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5712248682975769, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.4291, 'eval_samples_per_second': 163.024, 'eval_steps_per_second': 20.584, 'epoch': 9.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 15:05:47,503] Trial 32 finished with values: [0.5712248682975769, 0.7247474747474747] and parameters: {'lr': 0.00024089518132940424, 'batch': 8, 'accum': 4, 'dropout_rate': 0.3637934791669174, 'weight_decay': 5.6983259174202946e-05, 'warmup_pct': 0.2596371771304293, 'lora_rank': 4, 'lora_init_scale': 0.00031396870938359616, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9241, 'learning_rate': 2.2964715729845927e-05, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.7827189564704895, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4285, 'eval_samples_per_second': 163.064, 'eval_steps_per_second': 20.589, 'epoch': 0.99, 'step': 49}, {'loss': 0.7895, 'learning_rate': 4.63980991276479e-05, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.6953433156013489, 'eval_accuracy': 0.5580808080808081, 'eval_runtime': 2.3927, 'eval_samples_per_second': 165.503, 'eval_steps_per_second': 20.897, 'epoch': 2.0, 'step': 99}, {'loss': 0.7412, 'learning_rate': 6.936281485749382e-05, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.6690585017204285, 'eval_accuracy': 0.6439393939393939, 'eval_runtime': 2.3926, 'eval_samples_per_second': 165.507, 'eval_steps_per_second': 20.897, 'epoch': 2.99, 'step': 148}, {'loss': 0.6892, 'learning_rate': 9.27961982552958e-05, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.6403570175170898, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.4012, 'eval_samples_per_second': 164.915, 'eval_steps_per_second': 20.823, 'epoch': 4.0, 'step': 198}, {'loss': 0.6344, 'learning_rate': 0.00011576091398514172, 'epoch': 4.99, 'step': 247}, {'eval_loss': 0.605863630771637, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.3922, 'eval_samples_per_second': 165.535, 'eval_steps_per_second': 20.901, 'epoch': 4.99, 'step': 247}, {'loss': 0.5644, 'learning_rate': 0.0001391942973829437, 'epoch': 6.0, 'step': 297}, {'eval_loss': 0.5850266814231873, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3955, 'eval_samples_per_second': 165.31, 'eval_steps_per_second': 20.872, 'epoch': 6.0, 'step': 297}, {'loss': 0.5189, 'learning_rate': 0.00016215901311278963, 'epoch': 6.99, 'step': 346}, {'eval_loss': 0.5712248682975769, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3993, 'eval_samples_per_second': 165.045, 'eval_steps_per_second': 20.839, 'epoch': 6.99, 'step': 346}, {'loss': 0.4465, 'learning_rate': 0.0001855923965105916, 'epoch': 8.0, 'step': 396}, {'eval_loss': 0.5806390047073364, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.4162, 'eval_samples_per_second': 163.896, 'eval_steps_per_second': 20.694, 'epoch': 8.0, 'step': 396}, {'loss': 0.3898, 'learning_rate': 0.00020855711224043754, 'epoch': 8.99, 'step': 445}, {'eval_loss': 0.6244649291038513, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.4159, 'eval_samples_per_second': 163.912, 'eval_steps_per_second': 20.696, 'epoch': 8.99, 'step': 445}, {'loss': 0.3266, 'learning_rate': 0.0002296471572984593, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.6910526752471924, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.4081, 'eval_samples_per_second': 164.444, 'eval_steps_per_second': 20.763, 'epoch': 9.9, 'step': 490}, {'train_runtime': 212.0696, 'train_samples_per_second': 74.692, 'train_steps_per_second': 2.311, 'total_flos': 0.0, 'train_loss': 0.6048695447493573, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.5712248682975769, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.4291, 'eval_samples_per_second': 163.024, 'eval_steps_per_second': 20.584, 'epoch': 9.9, 'step': 490}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 13:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.205200</td>\n",
       "      <td>0.852582</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.194100</td>\n",
       "      <td>0.829413</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.145300</td>\n",
       "      <td>0.793193</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.093100</td>\n",
       "      <td>0.755960</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.973400</td>\n",
       "      <td>0.731531</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.919200</td>\n",
       "      <td>0.697693</td>\n",
       "      <td>0.505051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.811900</td>\n",
       "      <td>0.677973</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.784200</td>\n",
       "      <td>0.666905</td>\n",
       "      <td>0.573232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.723200</td>\n",
       "      <td>0.653461</td>\n",
       "      <td>0.654040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.638224</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6382235288619995, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3979, 'eval_samples_per_second': 165.148, 'eval_steps_per_second': 20.852, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 15:19:02,511] Trial 33 finished with values: [0.6382235288619995, 0.6843434343434344] and parameters: {'lr': 2.801370498985585e-05, 'batch': 1, 'accum': 4, 'dropout_rate': 0.8063660331424223, 'weight_decay': 4.3564579106322776e-05, 'warmup_pct': 0.29003798939629644, 'lora_rank': 8, 'lora_init_scale': 0.0003347603647252364, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.2052, 'learning_rate': 2.4147642960345926e-06, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.8525823950767517, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4134, 'eval_samples_per_second': 164.085, 'eval_steps_per_second': 20.718, 'epoch': 1.0, 'step': 396}, {'loss': 1.1941, 'learning_rate': 4.829528592069185e-06, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.8294125199317932, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3867, 'eval_samples_per_second': 165.917, 'eval_steps_per_second': 20.949, 'epoch': 2.0, 'step': 792}, {'loss': 1.1453, 'learning_rate': 7.2442928881037775e-06, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.7931928634643555, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3888, 'eval_samples_per_second': 165.777, 'eval_steps_per_second': 20.931, 'epoch': 3.0, 'step': 1188}, {'loss': 1.0931, 'learning_rate': 9.65905718413837e-06, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.7559601664543152, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.851, 'eval_steps_per_second': 20.941, 'epoch': 4.0, 'step': 1584}, {'loss': 0.9734, 'learning_rate': 1.2073821480172961e-05, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.7315311431884766, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3809, 'eval_samples_per_second': 166.322, 'eval_steps_per_second': 21.0, 'epoch': 5.0, 'step': 1980}, {'loss': 0.9192, 'learning_rate': 1.4488585776207555e-05, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.6976934671401978, 'eval_accuracy': 0.5050505050505051, 'eval_runtime': 2.3734, 'eval_samples_per_second': 166.848, 'eval_steps_per_second': 21.067, 'epoch': 6.0, 'step': 2376}, {'loss': 0.8119, 'learning_rate': 1.6903350072242147e-05, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.6779730916023254, 'eval_accuracy': 0.5454545454545454, 'eval_runtime': 2.3856, 'eval_samples_per_second': 165.994, 'eval_steps_per_second': 20.959, 'epoch': 7.0, 'step': 2772}, {'loss': 0.7842, 'learning_rate': 1.931811436827674e-05, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.6669048070907593, 'eval_accuracy': 0.5732323232323232, 'eval_runtime': 2.382, 'eval_samples_per_second': 166.243, 'eval_steps_per_second': 20.99, 'epoch': 8.0, 'step': 3168}, {'loss': 0.7232, 'learning_rate': 2.173287866431133e-05, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.6534605622291565, 'eval_accuracy': 0.6540404040404041, 'eval_runtime': 2.4017, 'eval_samples_per_second': 164.882, 'eval_steps_per_second': 20.818, 'epoch': 9.0, 'step': 3564}, {'loss': 0.6719, 'learning_rate': 2.4147642960345922e-05, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.6382235288619995, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3909, 'eval_samples_per_second': 165.629, 'eval_steps_per_second': 20.913, 'epoch': 10.0, 'step': 3960}, {'train_runtime': 781.9601, 'train_samples_per_second': 20.257, 'train_steps_per_second': 5.064, 'total_flos': 0.0, 'train_loss': 0.9521475666701191, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.6382235288619995, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3979, 'eval_samples_per_second': 165.148, 'eval_steps_per_second': 20.852, 'epoch': 10.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 07:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.722300</td>\n",
       "      <td>0.661622</td>\n",
       "      <td>0.669192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.745900</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>0.618687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.842700</td>\n",
       "      <td>0.641731</td>\n",
       "      <td>0.628788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.733500</td>\n",
       "      <td>0.712828</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.669800</td>\n",
       "      <td>0.672191</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.624500</td>\n",
       "      <td>0.684743</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.660322</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.593200</td>\n",
       "      <td>0.625120</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>0.654786</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.551200</td>\n",
       "      <td>0.651412</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6514116525650024, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 2.3867, 'eval_samples_per_second': 165.92, 'eval_steps_per_second': 20.95, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7223, 'learning_rate': 0.0009323308387578984, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.661622166633606, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.4334, 'eval_samples_per_second': 162.734, 'eval_steps_per_second': 20.547, 'epoch': 1.0, 'step': 396}, {'loss': 0.7459, 'learning_rate': 0.0016715668824716571, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.663607656955719, 'eval_accuracy': 0.6186868686868687, 'eval_runtime': 2.393, 'eval_samples_per_second': 165.48, 'eval_steps_per_second': 20.894, 'epoch': 2.0, 'step': 792}, {'loss': 0.8427, 'learning_rate': 0.0014626210221627, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6417312026023865, 'eval_accuracy': 0.6287878787878788, 'eval_runtime': 2.3935, 'eval_samples_per_second': 165.449, 'eval_steps_per_second': 20.89, 'epoch': 3.0, 'step': 1188}, {'loss': 0.7335, 'learning_rate': 0.0012536751618537427, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.712827742099762, 'eval_accuracy': 0.5833333333333334, 'eval_runtime': 2.3938, 'eval_samples_per_second': 165.427, 'eval_steps_per_second': 20.887, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6698, 'learning_rate': 0.0010447293015447858, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.67219078540802, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 2.3959, 'eval_samples_per_second': 165.281, 'eval_steps_per_second': 20.869, 'epoch': 5.0, 'step': 1980}, {'loss': 0.6245, 'learning_rate': 0.0008357834412358286, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.684743344783783, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.3919, 'eval_samples_per_second': 165.561, 'eval_steps_per_second': 20.904, 'epoch': 6.0, 'step': 2376}, {'loss': 0.604, 'learning_rate': 0.0006268375809268714, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.6603219509124756, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 2.4075, 'eval_samples_per_second': 164.483, 'eval_steps_per_second': 20.768, 'epoch': 7.0, 'step': 2772}, {'loss': 0.5932, 'learning_rate': 0.0004178917206179143, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.6251195073127747, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3956, 'eval_samples_per_second': 165.303, 'eval_steps_per_second': 20.872, 'epoch': 8.0, 'step': 3168}, {'loss': 0.571, 'learning_rate': 0.00020894586030895714, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.6547864675521851, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.3912, 'eval_samples_per_second': 165.609, 'eval_steps_per_second': 20.91, 'epoch': 9.0, 'step': 3564}, {'loss': 0.5512, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.6514116525650024, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 2.3869, 'eval_samples_per_second': 165.903, 'eval_steps_per_second': 20.947, 'epoch': 10.0, 'step': 3960}, {'train_runtime': 425.5673, 'train_samples_per_second': 37.221, 'train_steps_per_second': 9.305, 'total_flos': 0.0, 'train_loss': 0.6658036010433929, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.6514116525650024, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 2.3867, 'eval_samples_per_second': 165.92, 'eval_steps_per_second': 20.95, 'epoch': 10.0, 'step': 3960}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 15:26:22,004] Trial 34 finished with values: [0.6514116525650024, 0.7171717171717171] and parameters: {'lr': 0.0017069188335845362, 'batch': 2, 'accum': 2, 'dropout_rate': 0.6036095001119859, 'weight_decay': 0.0004347733347295187, 'warmup_pct': 0.09162942427748778, 'lora_rank': 16, 'lora_init_scale': 0.0025824730662348267, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 03:31, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.946700</td>\n",
       "      <td>0.843001</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.866200</td>\n",
       "      <td>0.740451</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.769500</td>\n",
       "      <td>0.687739</td>\n",
       "      <td>0.573232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.726100</td>\n",
       "      <td>0.662741</td>\n",
       "      <td>0.646465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.666600</td>\n",
       "      <td>0.635571</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.639800</td>\n",
       "      <td>0.621950</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6219495534896851, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.3693, 'eval_samples_per_second': 167.136, 'eval_steps_per_second': 21.103, 'epoch': 9.9}\n",
      "History:  [{'loss': 0.9467, 'learning_rate': 4.68020081206932e-06, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.8430007696151733, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4193, 'eval_samples_per_second': 163.681, 'eval_steps_per_second': 20.667, 'epoch': 0.99, 'step': 49}, {'loss': 0.8896, 'learning_rate': 9.455915926425769e-06, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.7951360940933228, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3894, 'eval_samples_per_second': 165.735, 'eval_steps_per_second': 20.926, 'epoch': 2.0, 'step': 99}, {'loss': 0.8662, 'learning_rate': 1.4136116738495088e-05, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.7404509782791138, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3891, 'eval_samples_per_second': 165.751, 'eval_steps_per_second': 20.928, 'epoch': 2.99, 'step': 148}, {'loss': 0.8099, 'learning_rate': 1.8911831852851537e-05, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.705784797668457, 'eval_accuracy': 0.49242424242424243, 'eval_runtime': 2.3903, 'eval_samples_per_second': 165.671, 'eval_steps_per_second': 20.918, 'epoch': 4.0, 'step': 198}, {'loss': 0.7695, 'learning_rate': 2.3592032664920858e-05, 'epoch': 4.99, 'step': 247}, {'eval_loss': 0.6877388954162598, 'eval_accuracy': 0.5732323232323232, 'eval_runtime': 2.3915, 'eval_samples_per_second': 165.588, 'eval_steps_per_second': 20.908, 'epoch': 4.99, 'step': 247}, {'loss': 0.7309, 'learning_rate': 2.8367747779277306e-05, 'epoch': 6.0, 'step': 297}, {'eval_loss': 0.6753352284431458, 'eval_accuracy': 0.6136363636363636, 'eval_runtime': 2.4341, 'eval_samples_per_second': 162.689, 'eval_steps_per_second': 20.542, 'epoch': 6.0, 'step': 297}, {'loss': 0.7261, 'learning_rate': 3.3047948591346623e-05, 'epoch': 6.99, 'step': 346}, {'eval_loss': 0.6627413034439087, 'eval_accuracy': 0.6464646464646465, 'eval_runtime': 2.4173, 'eval_samples_per_second': 163.816, 'eval_steps_per_second': 20.684, 'epoch': 6.99, 'step': 346}, {'loss': 0.6869, 'learning_rate': 3.7823663705703075e-05, 'epoch': 8.0, 'step': 396}, {'eval_loss': 0.649021327495575, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 2.3719, 'eval_samples_per_second': 166.952, 'eval_steps_per_second': 21.08, 'epoch': 8.0, 'step': 396}, {'loss': 0.6666, 'learning_rate': 4.250386451777239e-05, 'epoch': 8.99, 'step': 445}, {'eval_loss': 0.6355712413787842, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3691, 'eval_samples_per_second': 167.149, 'eval_steps_per_second': 21.105, 'epoch': 8.99, 'step': 445}, {'loss': 0.6398, 'learning_rate': 0.0, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.6219495534896851, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.3699, 'eval_samples_per_second': 167.098, 'eval_steps_per_second': 21.098, 'epoch': 9.9, 'step': 490}, {'train_runtime': 212.0812, 'train_samples_per_second': 74.688, 'train_steps_per_second': 2.31, 'total_flos': 0.0, 'train_loss': 0.7743579085992307, 'epoch': 9.9, 'step': 490}, {'eval_loss': 0.6219495534896851, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.3693, 'eval_samples_per_second': 167.136, 'eval_steps_per_second': 21.103, 'epoch': 9.9, 'step': 490}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 15:30:10,517] Trial 35 finished with values: [0.6219495534896851, 0.6742424242424242] and parameters: {'lr': 4.6802008120693195e-05, 'batch': 8, 'accum': 4, 'dropout_rate': 0.3833497919080082, 'weight_decay': 8.132803345441889e-05, 'warmup_pct': 0.24755741388314134, 'lora_rank': 4, 'lora_init_scale': 0.003240611608959475, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/990 02:15 < 02:15, 3.64 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.915900</td>\n",
       "      <td>0.623567</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.612400</td>\n",
       "      <td>0.522588</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.580500</td>\n",
       "      <td>0.590238</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.633700</td>\n",
       "      <td>1.020635</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.708498</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5225875377655029, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3989, 'eval_samples_per_second': 165.077, 'eval_steps_per_second': 20.843, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 15:32:39,985] Trial 36 finished with values: [0.5225875377655029, 0.7474747474747475] and parameters: {'lr': 0.00883573476097017, 'batch': 4, 'accum': 4, 'dropout_rate': 0.8050060880856376, 'weight_decay': 0.0009465711099767719, 'warmup_pct': 0.2985596870127803, 'lora_rank': 4, 'lora_init_scale': 0.0001358819280262773, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9159, 'learning_rate': 0.0007400488505381107, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6235674619674683, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 2.4127, 'eval_samples_per_second': 164.133, 'eval_steps_per_second': 20.724, 'epoch': 1.0, 'step': 99}, {'loss': 0.6124, 'learning_rate': 0.0014800977010762215, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5225875377655029, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3777, 'eval_samples_per_second': 166.546, 'eval_steps_per_second': 21.029, 'epoch': 2.0, 'step': 198}, {'loss': 0.5805, 'learning_rate': 0.002220146551614332, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5902376770973206, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.3864, 'eval_samples_per_second': 165.94, 'eval_steps_per_second': 20.952, 'epoch': 3.0, 'step': 297}, {'loss': 0.6337, 'learning_rate': 0.002960195402152443, 'epoch': 4.0, 'step': 396}, {'eval_loss': 1.0206354856491089, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3793, 'eval_samples_per_second': 166.436, 'eval_steps_per_second': 21.015, 'epoch': 4.0, 'step': 396}, {'loss': 0.973, 'learning_rate': 0.0037002442526905535, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.7084984183311462, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3782, 'eval_samples_per_second': 166.513, 'eval_steps_per_second': 21.024, 'epoch': 5.0, 'step': 495}, {'train_runtime': 135.5937, 'train_samples_per_second': 116.82, 'train_steps_per_second': 7.301, 'total_flos': 0.0, 'train_loss': 0.7431015477035985, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5225875377655029, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3989, 'eval_samples_per_second': 165.077, 'eval_steps_per_second': 20.843, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1584' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1584/1980 03:41 < 00:55, 7.14 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.870700</td>\n",
       "      <td>0.731699</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.738800</td>\n",
       "      <td>0.672657</td>\n",
       "      <td>0.618687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.633133</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.608600</td>\n",
       "      <td>0.597612</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.536700</td>\n",
       "      <td>0.557888</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.578383</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>0.618125</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.345800</td>\n",
       "      <td>0.652448</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5578884482383728, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.4064, 'eval_samples_per_second': 164.563, 'eval_steps_per_second': 20.778, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 15:36:39,791] Trial 37 finished with values: [0.5578884482383728, 0.7449494949494949] and parameters: {'lr': 9.993758333934062e-05, 'batch': 4, 'accum': 2, 'dropout_rate': 0.25665963527714575, 'weight_decay': 2.4659692183578073e-05, 'warmup_pct': 0.23650434852192093, 'lora_rank': 4, 'lora_init_scale': 0.00014145282156886069, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8707, 'learning_rate': 2.11406426294759e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.7316988706588745, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.404, 'eval_samples_per_second': 164.728, 'eval_steps_per_second': 20.799, 'epoch': 1.0, 'step': 198}, {'loss': 0.7388, 'learning_rate': 4.22812852589518e-05, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6726567149162292, 'eval_accuracy': 0.6186868686868687, 'eval_runtime': 2.3827, 'eval_samples_per_second': 166.197, 'eval_steps_per_second': 20.985, 'epoch': 2.0, 'step': 396}, {'loss': 0.666, 'learning_rate': 6.34219278884277e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6331327557563782, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.3823, 'eval_samples_per_second': 166.224, 'eval_steps_per_second': 20.988, 'epoch': 3.0, 'step': 594}, {'loss': 0.6086, 'learning_rate': 8.45625705179036e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5976116061210632, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.3844, 'eval_samples_per_second': 166.079, 'eval_steps_per_second': 20.97, 'epoch': 4.0, 'step': 792}, {'loss': 0.5367, 'learning_rate': 9.476839799420232e-05, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5578884482383728, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.3806, 'eval_samples_per_second': 166.345, 'eval_steps_per_second': 21.003, 'epoch': 5.0, 'step': 990}, {'loss': 0.4739, 'learning_rate': 7.581471839536185e-05, 'epoch': 6.0, 'step': 1188}, {'eval_loss': 0.5783828496932983, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3841, 'eval_samples_per_second': 166.102, 'eval_steps_per_second': 20.973, 'epoch': 6.0, 'step': 1188}, {'loss': 0.406, 'learning_rate': 5.686103879652139e-05, 'epoch': 7.0, 'step': 1386}, {'eval_loss': 0.618125319480896, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 2.3824, 'eval_samples_per_second': 166.218, 'eval_steps_per_second': 20.987, 'epoch': 7.0, 'step': 1386}, {'loss': 0.3458, 'learning_rate': 3.7907359197680925e-05, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.6524477601051331, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3815, 'eval_samples_per_second': 166.282, 'eval_steps_per_second': 20.995, 'epoch': 8.0, 'step': 1584}, {'train_runtime': 221.7731, 'train_samples_per_second': 71.424, 'train_steps_per_second': 8.928, 'total_flos': 0.0, 'train_loss': 0.5808180317734227, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.5578884482383728, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.4064, 'eval_samples_per_second': 164.563, 'eval_steps_per_second': 20.778, 'epoch': 8.0, 'step': 1584}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5544' max='7920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5544/7920 09:02 < 03:52, 10.22 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.788600</td>\n",
       "      <td>0.719912</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.776200</td>\n",
       "      <td>0.859900</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.730900</td>\n",
       "      <td>1.042287</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.573700</td>\n",
       "      <td>1.181834</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.372300</td>\n",
       "      <td>1.549954</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>1.904299</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>2.189289</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 1.1818336248397827, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 2.3911, 'eval_samples_per_second': 165.617, 'eval_steps_per_second': 20.911, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 15:46:03,283] Trial 38 finished with values: [1.1818336248397827, 0.7727272727272727] and parameters: {'lr': 0.00036959998985941527, 'batch': 1, 'accum': 2, 'dropout_rate': 0.5433009976116325, 'weight_decay': 4.022663200510196e-05, 'warmup_pct': 0.04573319766390904, 'lora_rank': 12, 'lora_init_scale': 0.00030122310952433105, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7886, 'learning_rate': 0.0003661073829513497, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.7199123501777649, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.4145, 'eval_samples_per_second': 164.011, 'eval_steps_per_second': 20.708, 'epoch': 1.0, 'step': 792}, {'loss': 0.7762, 'learning_rate': 0.0003254287848456441, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.8599004745483398, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3851, 'eval_samples_per_second': 166.031, 'eval_steps_per_second': 20.964, 'epoch': 2.0, 'step': 1584}, {'loss': 0.7309, 'learning_rate': 0.0002847501867399386, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 1.0422868728637695, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3881, 'eval_samples_per_second': 165.821, 'eval_steps_per_second': 20.937, 'epoch': 3.0, 'step': 2376}, {'loss': 0.5737, 'learning_rate': 0.0002440715886342331, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 1.1818336248397827, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 2.3936, 'eval_samples_per_second': 165.439, 'eval_steps_per_second': 20.889, 'epoch': 4.0, 'step': 3168}, {'loss': 0.3723, 'learning_rate': 0.0002033929905285276, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 1.5499541759490967, 'eval_accuracy': 0.7651515151515151, 'eval_runtime': 2.4064, 'eval_samples_per_second': 164.559, 'eval_steps_per_second': 20.778, 'epoch': 5.0, 'step': 3960}, {'loss': 0.184, 'learning_rate': 0.00016271439242282205, 'epoch': 6.0, 'step': 4752}, {'eval_loss': 1.9042989015579224, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3916, 'eval_samples_per_second': 165.578, 'eval_steps_per_second': 20.906, 'epoch': 6.0, 'step': 4752}, {'loss': 0.1042, 'learning_rate': 0.00012203579431711655, 'epoch': 7.0, 'step': 5544}, {'eval_loss': 2.1892893314361572, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3895, 'eval_samples_per_second': 165.728, 'eval_steps_per_second': 20.925, 'epoch': 7.0, 'step': 5544}, {'train_runtime': 542.6171, 'train_samples_per_second': 29.192, 'train_steps_per_second': 14.596, 'total_flos': 0.0, 'train_loss': 0.5042772568321503, 'epoch': 7.0, 'step': 5544}, {'eval_loss': 1.1818336248397827, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 2.3911, 'eval_samples_per_second': 165.617, 'eval_steps_per_second': 20.911, 'epoch': 7.0, 'step': 5544}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 06:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.746900</td>\n",
       "      <td>0.753442</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.778400</td>\n",
       "      <td>0.851265</td>\n",
       "      <td>0.517677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.677400</td>\n",
       "      <td>0.645319</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.630200</td>\n",
       "      <td>0.600871</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.587400</td>\n",
       "      <td>0.589498</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.579600</td>\n",
       "      <td>0.624786</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.563300</td>\n",
       "      <td>0.583739</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>0.571286</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.564964</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>0.565325</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.564964234828949, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.4109, 'eval_samples_per_second': 164.251, 'eval_steps_per_second': 20.739, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.7469, 'learning_rate': 0.004823955532220944, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.7534422278404236, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4124, 'eval_samples_per_second': 164.151, 'eval_steps_per_second': 20.726, 'epoch': 1.0, 'step': 99}, {'loss': 0.7784, 'learning_rate': 0.004287960473085283, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.851265013217926, 'eval_accuracy': 0.5176767676767676, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.848, 'eval_steps_per_second': 20.94, 'epoch': 2.0, 'step': 198}, {'loss': 0.6774, 'learning_rate': 0.003751965413949623, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6453187465667725, 'eval_accuracy': 0.6590909090909091, 'eval_runtime': 2.3902, 'eval_samples_per_second': 165.674, 'eval_steps_per_second': 20.918, 'epoch': 3.0, 'step': 297}, {'loss': 0.6302, 'learning_rate': 0.0032159703548139624, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6008711457252502, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3907, 'eval_samples_per_second': 165.645, 'eval_steps_per_second': 20.915, 'epoch': 4.0, 'step': 396}, {'loss': 0.5874, 'learning_rate': 0.0026799752956783024, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5894982814788818, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3869, 'eval_samples_per_second': 165.903, 'eval_steps_per_second': 20.947, 'epoch': 5.0, 'step': 495}, {'loss': 0.5796, 'learning_rate': 0.0021439802365426416, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.6247856020927429, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.3851, 'eval_samples_per_second': 166.03, 'eval_steps_per_second': 20.963, 'epoch': 6.0, 'step': 594}, {'loss': 0.5633, 'learning_rate': 0.0016079851774069812, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5837387442588806, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.3853, 'eval_samples_per_second': 166.015, 'eval_steps_per_second': 20.962, 'epoch': 7.0, 'step': 693}, {'loss': 0.551, 'learning_rate': 0.0010719901182713208, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5712858438491821, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.3851, 'eval_samples_per_second': 166.027, 'eval_steps_per_second': 20.963, 'epoch': 8.0, 'step': 792}, {'loss': 0.53, 'learning_rate': 0.0005359950591356604, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.564964234828949, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.3945, 'eval_samples_per_second': 165.381, 'eval_steps_per_second': 20.881, 'epoch': 9.0, 'step': 891}, {'loss': 0.5148, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5653250813484192, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.854, 'eval_steps_per_second': 20.941, 'epoch': 10.0, 'step': 990}, {'train_runtime': 400.3167, 'train_samples_per_second': 39.569, 'train_steps_per_second': 2.473, 'total_flos': 0.0, 'train_loss': 0.6159020472054529, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.564964234828949, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.4109, 'eval_samples_per_second': 164.251, 'eval_steps_per_second': 20.739, 'epoch': 10.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 15:53:00,313] Trial 39 finished with values: [0.564964234828949, 0.7146464646464646] and parameters: {'lr': 0.004823955532220944, 'batch': 2, 'accum': 8, 'dropout_rate': 0.3764187332023293, 'weight_decay': 0.00034460178496069604, 'warmup_pct': 0.012503098191379854, 'lora_rank': 8, 'lora_init_scale': 0.011126949431987054, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [792/990 05:33 < 01:23, 2.37 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.782400</td>\n",
       "      <td>0.572384</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.563000</td>\n",
       "      <td>0.539794</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.554100</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.632600</td>\n",
       "      <td>0.573321</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>0.543698</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.820100</td>\n",
       "      <td>0.695219</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.732800</td>\n",
       "      <td>0.590479</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.652600</td>\n",
       "      <td>0.595648</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5436978340148926, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3847, 'eval_samples_per_second': 166.06, 'eval_steps_per_second': 20.967, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 15:58:51,170] Trial 40 finished with values: [0.5436978340148926, 0.7424242424242424] and parameters: {'lr': 0.004406958327591198, 'batch': 2, 'accum': 8, 'dropout_rate': 0.5784148076311245, 'weight_decay': 5.932862141691429e-05, 'warmup_pct': 0.08061519658193, 'lora_rank': 16, 'lora_init_scale': 0.010687535354483777, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7824, 'learning_rate': 0.0006838383611779445, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5723843574523926, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.4115, 'eval_samples_per_second': 164.21, 'eval_steps_per_second': 20.734, 'epoch': 1.0, 'step': 99}, {'loss': 0.563, 'learning_rate': 0.001367676722355889, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.539793848991394, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.383, 'eval_samples_per_second': 166.178, 'eval_steps_per_second': 20.982, 'epoch': 2.0, 'step': 198}, {'loss': 0.5541, 'learning_rate': 0.0020515150835338333, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5698323845863342, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3848, 'eval_samples_per_second': 166.052, 'eval_steps_per_second': 20.966, 'epoch': 3.0, 'step': 297}, {'loss': 0.6326, 'learning_rate': 0.002735353444711778, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5733205676078796, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 2.3811, 'eval_samples_per_second': 166.312, 'eval_steps_per_second': 20.999, 'epoch': 4.0, 'step': 396}, {'loss': 0.6388, 'learning_rate': 0.0034191918058897224, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5436978340148926, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3954, 'eval_samples_per_second': 165.316, 'eval_steps_per_second': 20.873, 'epoch': 5.0, 'step': 495}, {'loss': 0.8201, 'learning_rate': 0.004103030167067667, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.6952192783355713, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3968, 'eval_samples_per_second': 165.219, 'eval_steps_per_second': 20.861, 'epoch': 6.0, 'step': 594}, {'loss': 0.7328, 'learning_rate': 0.0037183710889050732, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5904786586761475, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3935, 'eval_samples_per_second': 165.45, 'eval_steps_per_second': 20.89, 'epoch': 7.0, 'step': 693}, {'loss': 0.6526, 'learning_rate': 0.002478914059270049, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5956484079360962, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 2.3871, 'eval_samples_per_second': 165.893, 'eval_steps_per_second': 20.946, 'epoch': 8.0, 'step': 792}, {'train_runtime': 334.2164, 'train_samples_per_second': 47.394, 'train_steps_per_second': 2.962, 'total_flos': 0.0, 'train_loss': 0.6720465265139185, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5436978340148926, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3847, 'eval_samples_per_second': 166.06, 'eval_steps_per_second': 20.967, 'epoch': 8.0, 'step': 792}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [792/990 02:53 < 00:43, 4.56 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.820300</td>\n",
       "      <td>0.694378</td>\n",
       "      <td>0.530303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.687900</td>\n",
       "      <td>0.641500</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.585505</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.539616</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.447200</td>\n",
       "      <td>0.549638</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>0.607323</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.250200</td>\n",
       "      <td>0.730940</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.155100</td>\n",
       "      <td>0.897877</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5496378540992737, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3981, 'eval_samples_per_second': 165.133, 'eval_steps_per_second': 20.85, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 16:02:02,823] Trial 41 finished with values: [0.5496378540992737, 0.76010101010101] and parameters: {'lr': 0.0002594849676508292, 'batch': 8, 'accum': 2, 'dropout_rate': 0.2013897984996146, 'weight_decay': 0.0009811581233928725, 'warmup_pct': 0.24489302496281587, 'lora_rank': 4, 'lora_init_scale': 0.01373737789980818, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8203, 'learning_rate': 5.307647065585143e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6943783760070801, 'eval_accuracy': 0.5303030303030303, 'eval_runtime': 2.415, 'eval_samples_per_second': 163.976, 'eval_steps_per_second': 20.704, 'epoch': 1.0, 'step': 99}, {'loss': 0.6879, 'learning_rate': 0.00010615294131170286, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6414998173713684, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.3857, 'eval_samples_per_second': 165.992, 'eval_steps_per_second': 20.959, 'epoch': 2.0, 'step': 198}, {'loss': 0.6081, 'learning_rate': 0.00015922941196755427, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5855048298835754, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3862, 'eval_samples_per_second': 165.953, 'eval_steps_per_second': 20.954, 'epoch': 3.0, 'step': 297}, {'loss': 0.5192, 'learning_rate': 0.0002123058826234057, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5396162271499634, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.4598, 'eval_samples_per_second': 160.989, 'eval_steps_per_second': 20.327, 'epoch': 4.0, 'step': 396}, {'loss': 0.4472, 'learning_rate': 0.0002538439900932025, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5496378540992737, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3908, 'eval_samples_per_second': 165.635, 'eval_steps_per_second': 20.913, 'epoch': 5.0, 'step': 495}, {'loss': 0.3623, 'learning_rate': 0.00020307519207456197, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.6073234677314758, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3937, 'eval_samples_per_second': 165.433, 'eval_steps_per_second': 20.888, 'epoch': 6.0, 'step': 594}, {'loss': 0.2502, 'learning_rate': 0.0001523063940559215, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.7309396862983704, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3861, 'eval_samples_per_second': 165.962, 'eval_steps_per_second': 20.955, 'epoch': 7.0, 'step': 693}, {'loss': 0.1551, 'learning_rate': 0.00010153759603728099, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.897877037525177, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 2.3717, 'eval_samples_per_second': 166.967, 'eval_steps_per_second': 21.082, 'epoch': 8.0, 'step': 792}, {'train_runtime': 173.5702, 'train_samples_per_second': 91.26, 'train_steps_per_second': 5.704, 'total_flos': 0.0, 'train_loss': 0.4812881392661971, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5496378540992737, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3981, 'eval_samples_per_second': 165.133, 'eval_steps_per_second': 20.85, 'epoch': 8.0, 'step': 792}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='297' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [297/490 02:51 < 01:52, 1.72 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.671155</td>\n",
       "      <td>0.616162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.522600</td>\n",
       "      <td>0.515346</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.590418</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.607187</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5153455138206482, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 4.7298, 'eval_samples_per_second': 83.725, 'eval_steps_per_second': 10.571, 'epoch': 6.0}\n",
      "History:  [{'loss': 0.8175, 'learning_rate': 0.0002059258635999956, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.6711554527282715, 'eval_accuracy': 0.6161616161616161, 'eval_runtime': 2.3942, 'eval_samples_per_second': 165.398, 'eval_steps_per_second': 20.884, 'epoch': 0.99, 'step': 49}, {'loss': 0.6341, 'learning_rate': 0.0004160542958448891, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.5759450793266296, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.3695, 'eval_samples_per_second': 167.124, 'eval_steps_per_second': 21.101, 'epoch': 2.0, 'step': 99}, {'loss': 0.5226, 'learning_rate': 0.0006219801594448847, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.5153455138206482, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 2.3903, 'eval_samples_per_second': 165.672, 'eval_steps_per_second': 20.918, 'epoch': 2.99, 'step': 148}, {'loss': 0.4403, 'learning_rate': 0.0008321085916897783, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5810092687606812, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 3.9872, 'eval_samples_per_second': 99.317, 'eval_steps_per_second': 12.54, 'epoch': 4.0, 'step': 198}, {'loss': 0.3565, 'learning_rate': 0.001038034455289774, 'epoch': 4.99, 'step': 247}, {'eval_loss': 0.5904179811477661, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 4.6786, 'eval_samples_per_second': 84.64, 'eval_steps_per_second': 10.687, 'epoch': 4.99, 'step': 247}, {'loss': 0.2805, 'learning_rate': 0.0012481628875346674, 'epoch': 6.0, 'step': 297}, {'eval_loss': 0.6071866750717163, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 4.7035, 'eval_samples_per_second': 84.193, 'eval_steps_per_second': 10.63, 'epoch': 6.0, 'step': 297}, {'train_runtime': 171.6369, 'train_samples_per_second': 92.288, 'train_steps_per_second': 2.855, 'total_flos': 0.0, 'train_loss': 0.5080049688165839, 'epoch': 6.0, 'step': 297}, {'eval_loss': 0.5153455138206482, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 4.7298, 'eval_samples_per_second': 83.725, 'eval_steps_per_second': 10.571, 'epoch': 6.0, 'step': 297}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 16:05:13,600] Trial 42 finished with values: [0.5153455138206482, 0.7676767676767676] and parameters: {'lr': 0.0023996666962366837, 'batch': 8, 'accum': 4, 'dropout_rate': 0.32670537609983896, 'weight_decay': 0.0003111133349842366, 'warmup_pct': 0.28861033075271864, 'lora_rank': 16, 'lora_init_scale': 0.00027021345072799485, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7920' max='7920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7920/7920 14:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.992900</td>\n",
       "      <td>0.826774</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.932300</td>\n",
       "      <td>0.758322</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.837800</td>\n",
       "      <td>0.711438</td>\n",
       "      <td>0.507576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.779800</td>\n",
       "      <td>0.674427</td>\n",
       "      <td>0.563131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.706100</td>\n",
       "      <td>0.641009</td>\n",
       "      <td>0.646465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.634300</td>\n",
       "      <td>0.617141</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.590900</td>\n",
       "      <td>0.615066</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.568800</td>\n",
       "      <td>0.633498</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.560600</td>\n",
       "      <td>0.647634</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>0.655359</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6476342678070068, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.4134, 'eval_samples_per_second': 164.082, 'eval_steps_per_second': 20.717, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 16:20:18,398] Trial 43 finished with values: [0.6476342678070068, 0.7095959595959596] and parameters: {'lr': 2.6351823303571276e-05, 'batch': 1, 'accum': 2, 'dropout_rate': 0.5181247055798548, 'weight_decay': 2.2925872523539572e-05, 'warmup_pct': 0.27615722270165266, 'lora_rank': 16, 'lora_init_scale': 0.018910011846354574, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9929, 'learning_rate': 4.771523561140478e-06, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.826774001121521, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 4.8773, 'eval_samples_per_second': 81.192, 'eval_steps_per_second': 10.252, 'epoch': 1.0, 'step': 792}, {'loss': 0.9323, 'learning_rate': 9.543047122280956e-06, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.7583222985267639, 'eval_accuracy': 0.5, 'eval_runtime': 2.3711, 'eval_samples_per_second': 167.01, 'eval_steps_per_second': 21.087, 'epoch': 2.0, 'step': 1584}, {'loss': 0.8378, 'learning_rate': 1.4314570683421433e-05, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.7114384174346924, 'eval_accuracy': 0.5075757575757576, 'eval_runtime': 2.3726, 'eval_samples_per_second': 166.909, 'eval_steps_per_second': 21.074, 'epoch': 3.0, 'step': 2376}, {'loss': 0.7798, 'learning_rate': 1.9086094244561912e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.6744269728660583, 'eval_accuracy': 0.5631313131313131, 'eval_runtime': 2.3862, 'eval_samples_per_second': 165.951, 'eval_steps_per_second': 20.953, 'epoch': 4.0, 'step': 3168}, {'loss': 0.7061, 'learning_rate': 2.3857617805702388e-05, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.6410092711448669, 'eval_accuracy': 0.6464646464646465, 'eval_runtime': 2.3784, 'eval_samples_per_second': 166.502, 'eval_steps_per_second': 21.023, 'epoch': 5.0, 'step': 3960}, {'loss': 0.6343, 'learning_rate': 2.3542745692530682e-05, 'epoch': 6.0, 'step': 4752}, {'eval_loss': 0.6171410083770752, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.3934, 'eval_samples_per_second': 165.452, 'eval_steps_per_second': 20.89, 'epoch': 6.0, 'step': 4752}, {'loss': 0.5909, 'learning_rate': 1.765705926939801e-05, 'epoch': 7.0, 'step': 5544}, {'eval_loss': 0.6150661706924438, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3973, 'eval_samples_per_second': 165.183, 'eval_steps_per_second': 20.856, 'epoch': 7.0, 'step': 5544}, {'loss': 0.5688, 'learning_rate': 1.1771372846265341e-05, 'epoch': 8.0, 'step': 6336}, {'eval_loss': 0.6334983110427856, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3841, 'eval_samples_per_second': 166.101, 'eval_steps_per_second': 20.972, 'epoch': 8.0, 'step': 6336}, {'loss': 0.5606, 'learning_rate': 5.885686423132671e-06, 'epoch': 9.0, 'step': 7128}, {'eval_loss': 0.6476342678070068, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.3929, 'eval_samples_per_second': 165.488, 'eval_steps_per_second': 20.895, 'epoch': 9.0, 'step': 7128}, {'loss': 0.5535, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 7920}, {'eval_loss': 0.6553586721420288, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.3959, 'eval_samples_per_second': 165.284, 'eval_steps_per_second': 20.869, 'epoch': 10.0, 'step': 7920}, {'train_runtime': 889.9459, 'train_samples_per_second': 17.799, 'train_steps_per_second': 8.899, 'total_flos': 0.0, 'train_loss': 0.7156940190479009, 'epoch': 10.0, 'step': 7920}, {'eval_loss': 0.6476342678070068, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.4134, 'eval_samples_per_second': 164.082, 'eval_steps_per_second': 20.717, 'epoch': 10.0, 'step': 7920}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 03:28, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.194900</td>\n",
       "      <td>0.859337</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.135600</td>\n",
       "      <td>0.853535</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.101700</td>\n",
       "      <td>0.843134</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.095300</td>\n",
       "      <td>0.815910</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.115600</td>\n",
       "      <td>0.800698</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.104400</td>\n",
       "      <td>0.785158</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.057000</td>\n",
       "      <td>0.756502</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.051700</td>\n",
       "      <td>0.747032</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7470319271087646, 'eval_accuracy': 0.5, 'eval_runtime': 2.3691, 'eval_samples_per_second': 167.15, 'eval_steps_per_second': 21.105, 'epoch': 9.7}\n",
      "History:  [{'loss': 1.1949, 'learning_rate': 1.4257690330848235e-06, 'epoch': 0.97, 'step': 24}, {'eval_loss': 0.859336793422699, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4246, 'eval_samples_per_second': 163.327, 'eval_steps_per_second': 20.622, 'epoch': 0.97, 'step': 24}, {'loss': 1.1356, 'learning_rate': 2.910945109214848e-06, 'epoch': 1.98, 'step': 49}, {'eval_loss': 0.8535351157188416, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3862, 'eval_samples_per_second': 165.953, 'eval_steps_per_second': 20.954, 'epoch': 1.98, 'step': 49}, {'loss': 1.1017, 'learning_rate': 4.396121185344872e-06, 'epoch': 2.99, 'step': 74}, {'eval_loss': 0.8431335687637329, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3974, 'eval_samples_per_second': 165.181, 'eval_steps_per_second': 20.856, 'epoch': 2.99, 'step': 74}, {'loss': 1.1438, 'learning_rate': 5.881297261474897e-06, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.8302197456359863, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3686, 'eval_samples_per_second': 167.189, 'eval_steps_per_second': 21.11, 'epoch': 4.0, 'step': 99}, {'loss': 1.0953, 'learning_rate': 7.30706629455972e-06, 'epoch': 4.97, 'step': 123}, {'eval_loss': 0.8159098029136658, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3707, 'eval_samples_per_second': 167.042, 'eval_steps_per_second': 21.091, 'epoch': 4.97, 'step': 123}, {'loss': 1.1156, 'learning_rate': 8.792242370689744e-06, 'epoch': 5.98, 'step': 148}, {'eval_loss': 0.8006983995437622, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3822, 'eval_samples_per_second': 166.233, 'eval_steps_per_second': 20.989, 'epoch': 5.98, 'step': 148}, {'loss': 1.1044, 'learning_rate': 1.0277418446819768e-05, 'epoch': 6.99, 'step': 173}, {'eval_loss': 0.7851575016975403, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3768, 'eval_samples_per_second': 166.611, 'eval_steps_per_second': 21.037, 'epoch': 6.99, 'step': 173}, {'loss': 1.1136, 'learning_rate': 1.1762594522949793e-05, 'epoch': 8.0, 'step': 198}, {'eval_loss': 0.7687864303588867, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.378, 'eval_samples_per_second': 166.528, 'eval_steps_per_second': 21.026, 'epoch': 8.0, 'step': 198}, {'loss': 1.057, 'learning_rate': 1.3188363556034617e-05, 'epoch': 8.97, 'step': 222}, {'eval_loss': 0.7565023303031921, 'eval_accuracy': 0.5, 'eval_runtime': 2.3724, 'eval_samples_per_second': 166.923, 'eval_steps_per_second': 21.076, 'epoch': 8.97, 'step': 222}, {'loss': 1.0517, 'learning_rate': 1.4257690330848233e-05, 'epoch': 9.7, 'step': 240}, {'eval_loss': 0.7470319271087646, 'eval_accuracy': 0.5, 'eval_runtime': 2.3761, 'eval_samples_per_second': 166.659, 'eval_steps_per_second': 21.043, 'epoch': 9.7, 'step': 240}, {'train_runtime': 209.5981, 'train_samples_per_second': 75.573, 'train_steps_per_second': 1.145, 'total_flos': 0.0, 'train_loss': 1.113050365447998, 'epoch': 9.7, 'step': 240}, {'eval_loss': 0.7470319271087646, 'eval_accuracy': 0.5, 'eval_runtime': 2.3691, 'eval_samples_per_second': 167.15, 'eval_steps_per_second': 21.105, 'epoch': 9.7, 'step': 240}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 16:24:04,165] Trial 44 finished with values: [0.7470319271087646, 0.5] and parameters: {'lr': 2.4772736949848808e-05, 'batch': 8, 'accum': 8, 'dropout_rate': 0.7514612443360948, 'weight_decay': 2.387555687615536e-05, 'warmup_pct': 0.21101694774587426, 'lora_rank': 16, 'lora_init_scale': 0.0037132542374481645, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2376' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2376/3960 08:10 < 05:27, 4.84 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.951400</td>\n",
       "      <td>0.634379</td>\n",
       "      <td>0.626263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.672925</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.679300</td>\n",
       "      <td>0.574290</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.715900</td>\n",
       "      <td>0.944944</td>\n",
       "      <td>0.616162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.827000</td>\n",
       "      <td>0.612752</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.640940</td>\n",
       "      <td>0.648990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.57429039478302, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.393, 'eval_samples_per_second': 165.479, 'eval_steps_per_second': 20.894, 'epoch': 6.0}\n",
      "History:  [{'loss': 0.9514, 'learning_rate': 0.000405673019976844, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6343792080879211, 'eval_accuracy': 0.6262626262626263, 'eval_runtime': 2.424, 'eval_samples_per_second': 163.369, 'eval_steps_per_second': 20.627, 'epoch': 1.0, 'step': 396}, {'loss': 0.6432, 'learning_rate': 0.000811346039953688, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6729252338409424, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.3727, 'eval_samples_per_second': 166.899, 'eval_steps_per_second': 21.073, 'epoch': 2.0, 'step': 792}, {'loss': 0.6793, 'learning_rate': 0.001217019059930532, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.57429039478302, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3848, 'eval_samples_per_second': 166.048, 'eval_steps_per_second': 20.966, 'epoch': 3.0, 'step': 1188}, {'loss': 0.7159, 'learning_rate': 0.001622692079907376, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.9449439644813538, 'eval_accuracy': 0.6161616161616161, 'eval_runtime': 2.3819, 'eval_samples_per_second': 166.251, 'eval_steps_per_second': 20.991, 'epoch': 4.0, 'step': 1584}, {'loss': 0.827, 'learning_rate': 0.00202836509988422, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6127521991729736, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.3869, 'eval_samples_per_second': 165.908, 'eval_steps_per_second': 20.948, 'epoch': 5.0, 'step': 1980}, {'loss': 0.797, 'learning_rate': 0.002434038119861064, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.6409397125244141, 'eval_accuracy': 0.648989898989899, 'eval_runtime': 2.4007, 'eval_samples_per_second': 164.954, 'eval_steps_per_second': 20.828, 'epoch': 6.0, 'step': 2376}, {'train_runtime': 490.856, 'train_samples_per_second': 32.27, 'train_steps_per_second': 8.068, 'total_flos': 0.0, 'train_loss': 0.7689523857450645, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.57429039478302, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.393, 'eval_samples_per_second': 165.479, 'eval_steps_per_second': 20.894, 'epoch': 6.0, 'step': 2376}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 16:32:38,681] Trial 45 finished with values: [0.57429039478302, 0.7525252525252525] and parameters: {'lr': 0.003835454007053798, 'batch': 1, 'accum': 4, 'dropout_rate': 0.828188372761985, 'weight_decay': 0.00019989640171987703, 'warmup_pct': 0.23642396607981703, 'lora_rank': 8, 'lora_init_scale': 0.00249057316809111, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6336' max='7920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6336/7920 12:26 < 03:06, 8.49 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.910700</td>\n",
       "      <td>0.716329</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.718500</td>\n",
       "      <td>0.609413</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.613900</td>\n",
       "      <td>0.703134</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>1.003458</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.602800</td>\n",
       "      <td>1.244528</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.435984</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>1.854845</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>2.125405</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 1.2445275783538818, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3805, 'eval_samples_per_second': 166.35, 'eval_steps_per_second': 21.004, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 16:45:26,700] Trial 46 finished with values: [1.2445275783538818, 0.73989898989899] and parameters: {'lr': 0.0001668796144669782, 'batch': 1, 'accum': 2, 'dropout_rate': 0.4669279100714483, 'weight_decay': 4.1689918376485814e-05, 'warmup_pct': 0.22440716311837497, 'lora_rank': 16, 'lora_init_scale': 0.0002224696382385846, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9107, 'learning_rate': 3.7188704180598405e-05, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.716328501701355, 'eval_accuracy': 0.5, 'eval_runtime': 2.4413, 'eval_samples_per_second': 162.208, 'eval_steps_per_second': 20.481, 'epoch': 1.0, 'step': 792}, {'loss': 0.7185, 'learning_rate': 7.437740836119681e-05, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6094132661819458, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.764, 'eval_steps_per_second': 20.93, 'epoch': 2.0, 'step': 1584}, {'loss': 0.6139, 'learning_rate': 0.00011156611254179521, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.7031341195106506, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 4.6967, 'eval_samples_per_second': 84.315, 'eval_steps_per_second': 10.646, 'epoch': 3.0, 'step': 2376}, {'loss': 0.677, 'learning_rate': 0.00014875481672239362, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 1.0034575462341309, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 4.7092, 'eval_samples_per_second': 84.091, 'eval_steps_per_second': 10.618, 'epoch': 4.0, 'step': 3168}, {'loss': 0.6028, 'learning_rate': 0.00015136126277811123, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 1.2445275783538818, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3721, 'eval_samples_per_second': 166.94, 'eval_steps_per_second': 21.078, 'epoch': 5.0, 'step': 3960}, {'loss': 0.375, 'learning_rate': 0.000121089010222489, 'epoch': 6.0, 'step': 4752}, {'eval_loss': 1.4359837770462036, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.4112, 'eval_samples_per_second': 164.234, 'eval_steps_per_second': 20.737, 'epoch': 6.0, 'step': 4752}, {'loss': 0.202, 'learning_rate': 9.081675766686674e-05, 'epoch': 7.0, 'step': 5544}, {'eval_loss': 1.854845404624939, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3826, 'eval_samples_per_second': 166.203, 'eval_steps_per_second': 20.985, 'epoch': 7.0, 'step': 5544}, {'loss': 0.08, 'learning_rate': 6.05445051112445e-05, 'epoch': 8.0, 'step': 6336}, {'eval_loss': 2.1254053115844727, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3802, 'eval_samples_per_second': 166.375, 'eval_steps_per_second': 21.007, 'epoch': 8.0, 'step': 6336}, {'train_runtime': 746.6034, 'train_samples_per_second': 21.216, 'train_steps_per_second': 10.608, 'total_flos': 0.0, 'train_loss': 0.5224803650017941, 'epoch': 8.0, 'step': 6336}, {'eval_loss': 1.2445275783538818, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3805, 'eval_samples_per_second': 166.35, 'eval_steps_per_second': 21.004, 'epoch': 8.0, 'step': 6336}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1584' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1584/1980 05:27 < 01:22, 4.83 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.859600</td>\n",
       "      <td>0.686536</td>\n",
       "      <td>0.563131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.628872</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.579700</td>\n",
       "      <td>0.544537</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.499300</td>\n",
       "      <td>0.550436</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.417500</td>\n",
       "      <td>0.561716</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.303400</td>\n",
       "      <td>0.671765</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.868431</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>1.132031</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.561715841293335, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3874, 'eval_samples_per_second': 165.871, 'eval_steps_per_second': 20.943, 'epoch': 8.0}\n",
      "History:  [{'loss': 0.8596, 'learning_rate': 5.94985963321912e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6865363717079163, 'eval_accuracy': 0.5631313131313131, 'eval_runtime': 2.4045, 'eval_samples_per_second': 164.694, 'eval_steps_per_second': 20.795, 'epoch': 1.0, 'step': 198}, {'loss': 0.6976, 'learning_rate': 0.0001189971926643824, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6288720369338989, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.3793, 'eval_samples_per_second': 166.435, 'eval_steps_per_second': 21.015, 'epoch': 2.0, 'step': 396}, {'loss': 0.5797, 'learning_rate': 0.00017849578899657362, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.5445367693901062, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.3835, 'eval_samples_per_second': 166.141, 'eval_steps_per_second': 20.977, 'epoch': 3.0, 'step': 594}, {'loss': 0.4993, 'learning_rate': 0.00021258402589599985, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5504363179206848, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.3832, 'eval_samples_per_second': 166.162, 'eval_steps_per_second': 20.98, 'epoch': 4.0, 'step': 792}, {'loss': 0.4175, 'learning_rate': 0.0001771533549133332, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.561715841293335, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3859, 'eval_samples_per_second': 165.973, 'eval_steps_per_second': 20.956, 'epoch': 5.0, 'step': 990}, {'loss': 0.3034, 'learning_rate': 0.00014172268393066655, 'epoch': 6.0, 'step': 1188}, {'eval_loss': 0.6717647314071655, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3905, 'eval_samples_per_second': 165.658, 'eval_steps_per_second': 20.916, 'epoch': 6.0, 'step': 1188}, {'loss': 0.1867, 'learning_rate': 0.00010629201294799992, 'epoch': 7.0, 'step': 1386}, {'eval_loss': 0.8684313297271729, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 2.3943, 'eval_samples_per_second': 165.395, 'eval_steps_per_second': 20.883, 'epoch': 7.0, 'step': 1386}, {'loss': 0.0986, 'learning_rate': 7.086134196533327e-05, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 1.132030725479126, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.3911, 'eval_samples_per_second': 165.614, 'eval_steps_per_second': 20.911, 'epoch': 8.0, 'step': 1584}, {'train_runtime': 327.8319, 'train_samples_per_second': 48.317, 'train_steps_per_second': 6.04, 'total_flos': 0.0, 'train_loss': 0.4552958673901028, 'epoch': 8.0, 'step': 1584}, {'eval_loss': 0.561715841293335, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3874, 'eval_samples_per_second': 165.871, 'eval_steps_per_second': 20.943, 'epoch': 8.0, 'step': 1584}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 16:51:11,242] Trial 47 finished with values: [0.561715841293335, 0.7626262626262627] and parameters: {'lr': 0.0002220679933812591, 'batch': 2, 'accum': 4, 'dropout_rate': 0.36138871145898155, 'weight_decay': 0.0007242570303371053, 'warmup_pct': 0.09341789213824225, 'lora_rank': 8, 'lora_init_scale': 0.09042590819116314, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 07:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.858400</td>\n",
       "      <td>0.644108</td>\n",
       "      <td>0.623737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.745700</td>\n",
       "      <td>0.654955</td>\n",
       "      <td>0.631313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.650400</td>\n",
       "      <td>0.604481</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.603100</td>\n",
       "      <td>0.596686</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.607654</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.560700</td>\n",
       "      <td>0.670578</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.564600</td>\n",
       "      <td>0.596841</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.532200</td>\n",
       "      <td>0.622326</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.510200</td>\n",
       "      <td>0.621302</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5968406200408936, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 2.3873, 'eval_samples_per_second': 165.879, 'eval_steps_per_second': 20.944, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.71, 'learning_rate': 0.0016745722909772488, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.7538852095603943, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.418, 'eval_samples_per_second': 163.768, 'eval_steps_per_second': 20.678, 'epoch': 1.0, 'step': 396}, {'loss': 0.8584, 'learning_rate': 0.0033491445819544977, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.644108235836029, 'eval_accuracy': 0.6237373737373737, 'eval_runtime': 2.3928, 'eval_samples_per_second': 165.494, 'eval_steps_per_second': 20.896, 'epoch': 2.0, 'step': 792}, {'loss': 0.7457, 'learning_rate': 0.0046400468027395685, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6549545526504517, 'eval_accuracy': 0.6313131313131313, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.769, 'eval_steps_per_second': 20.93, 'epoch': 3.0, 'step': 1188}, {'loss': 0.6504, 'learning_rate': 0.003977182973776773, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6044809818267822, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 2.3908, 'eval_samples_per_second': 165.635, 'eval_steps_per_second': 20.913, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6031, 'learning_rate': 0.0033143191448139772, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5966857075691223, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.3954, 'eval_samples_per_second': 165.317, 'eval_steps_per_second': 20.873, 'epoch': 5.0, 'step': 1980}, {'loss': 0.5876, 'learning_rate': 0.0026514553158511816, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.6076541543006897, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 2.3903, 'eval_samples_per_second': 165.67, 'eval_steps_per_second': 20.918, 'epoch': 6.0, 'step': 2376}, {'loss': 0.5607, 'learning_rate': 0.0019885914868883864, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 0.6705780029296875, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 2.3899, 'eval_samples_per_second': 165.698, 'eval_steps_per_second': 20.921, 'epoch': 7.0, 'step': 2772}, {'loss': 0.5646, 'learning_rate': 0.0013257276579255908, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.5968406200408936, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 2.3945, 'eval_samples_per_second': 165.376, 'eval_steps_per_second': 20.881, 'epoch': 8.0, 'step': 3168}, {'loss': 0.5322, 'learning_rate': 0.0006628638289627954, 'epoch': 9.0, 'step': 3564}, {'eval_loss': 0.622325599193573, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.3932, 'eval_samples_per_second': 165.468, 'eval_steps_per_second': 20.892, 'epoch': 9.0, 'step': 3564}, {'loss': 0.5102, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.6213016510009766, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.3921, 'eval_samples_per_second': 165.547, 'eval_steps_per_second': 20.902, 'epoch': 10.0, 'step': 3960}, {'train_runtime': 422.8787, 'train_samples_per_second': 37.458, 'train_steps_per_second': 9.364, 'total_flos': 0.0, 'train_loss': 0.632296371459961, 'epoch': 10.0, 'step': 3960}, {'eval_loss': 0.5968406200408936, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 2.3873, 'eval_samples_per_second': 165.879, 'eval_steps_per_second': 20.944, 'epoch': 10.0, 'step': 3960}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 16:58:30,734] Trial 48 finished with values: [0.5968406200408936, 0.7222222222222222] and parameters: {'lr': 0.004748850209008714, 'batch': 2, 'accum': 2, 'dropout_rate': 0.4465399838284112, 'weight_decay': 1.3117784062862826e-05, 'warmup_pct': 0.1418903785399832, 'lora_rank': 8, 'lora_init_scale': 0.06548414618308034, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.117200</td>\n",
       "      <td>0.804024</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.993300</td>\n",
       "      <td>0.716012</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.833600</td>\n",
       "      <td>0.672282</td>\n",
       "      <td>0.598485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.713300</td>\n",
       "      <td>0.644542</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.621693</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.615100</td>\n",
       "      <td>0.607117</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.587200</td>\n",
       "      <td>0.597603</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.573600</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.559300</td>\n",
       "      <td>0.587527</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.564100</td>\n",
       "      <td>0.586376</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5863755941390991, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.4062, 'eval_samples_per_second': 164.572, 'eval_steps_per_second': 20.779, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 17:02:25,520] Trial 49 finished with values: [0.5863755941390991, 0.7373737373737373] and parameters: {'lr': 6.997092550280336e-05, 'batch': 8, 'accum': 2, 'dropout_rate': 0.7205964870054747, 'weight_decay': 0.00010614484511076835, 'warmup_pct': 0.13522961123168917, 'lora_rank': 12, 'lora_init_scale': 0.05075689965892459, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1172, 'learning_rate': 2.5944275748230464e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.8040235042572021, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4271, 'eval_samples_per_second': 163.155, 'eval_steps_per_second': 20.6, 'epoch': 1.0, 'step': 99}, {'loss': 0.9933, 'learning_rate': 5.188855149646093e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.7160120606422424, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3968, 'eval_samples_per_second': 165.221, 'eval_steps_per_second': 20.861, 'epoch': 2.0, 'step': 198}, {'loss': 0.8336, 'learning_rate': 6.706756759812273e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6722821593284607, 'eval_accuracy': 0.5984848484848485, 'eval_runtime': 2.3921, 'eval_samples_per_second': 165.544, 'eval_steps_per_second': 20.902, 'epoch': 3.0, 'step': 297}, {'loss': 0.7133, 'learning_rate': 5.748648651267662e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6445420980453491, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.3939, 'eval_samples_per_second': 165.422, 'eval_steps_per_second': 20.887, 'epoch': 4.0, 'step': 396}, {'loss': 0.6446, 'learning_rate': 4.790540542723052e-05, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6216932535171509, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3915, 'eval_samples_per_second': 165.583, 'eval_steps_per_second': 20.907, 'epoch': 5.0, 'step': 495}, {'loss': 0.6151, 'learning_rate': 3.832432434178442e-05, 'epoch': 6.0, 'step': 594}, {'eval_loss': 0.6071172952651978, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 2.3952, 'eval_samples_per_second': 165.328, 'eval_steps_per_second': 20.875, 'epoch': 6.0, 'step': 594}, {'loss': 0.5872, 'learning_rate': 2.874324325633831e-05, 'epoch': 7.0, 'step': 693}, {'eval_loss': 0.5976027846336365, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3919, 'eval_samples_per_second': 165.558, 'eval_steps_per_second': 20.904, 'epoch': 7.0, 'step': 693}, {'loss': 0.5736, 'learning_rate': 1.916216217089221e-05, 'epoch': 8.0, 'step': 792}, {'eval_loss': 0.5906254649162292, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3948, 'eval_samples_per_second': 165.355, 'eval_steps_per_second': 20.878, 'epoch': 8.0, 'step': 792}, {'loss': 0.5593, 'learning_rate': 9.581081085446106e-06, 'epoch': 9.0, 'step': 891}, {'eval_loss': 0.5875265598297119, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.4079, 'eval_samples_per_second': 164.457, 'eval_steps_per_second': 20.765, 'epoch': 9.0, 'step': 891}, {'loss': 0.5641, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5863755941390991, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.4075, 'eval_samples_per_second': 164.485, 'eval_steps_per_second': 20.768, 'epoch': 10.0, 'step': 990}, {'train_runtime': 217.1884, 'train_samples_per_second': 72.932, 'train_steps_per_second': 4.558, 'total_flos': 0.0, 'train_loss': 0.7201205243968001, 'epoch': 10.0, 'step': 990}, {'eval_loss': 0.5863755941390991, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.4062, 'eval_samples_per_second': 164.572, 'eval_steps_per_second': 20.779, 'epoch': 10.0, 'step': 990}]\n",
      "Loss: 0.5146018862724304, Accuracy: 0.7550505050505051\n",
      "Loss: 0.6237613558769226, Accuracy: 0.7752525252525253\n",
      "Loss: 0.5153455138206482, Accuracy: 0.7676767676767676\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to be optimized\n",
    "    # Updated to use suggest_float with log=True for loguniform distribution\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    batch = trial.suggest_categorical('batch', [1, 2, 4, 8])\n",
    "    accum = trial.suggest_categorical('accum', [2, 4, 8])\n",
    "    # Updated to use suggest_float for uniform distribution\n",
    "    dropout = trial.suggest_float('dropout_rate', 0.1, 0.9)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    warmup_pct = trial.suggest_float(\"warmup_pct\", 0.01, 0.3)  # Warmup percentage between 1% and 30%\n",
    "    lora_rank = trial.suggest_int('lora_rank', 4, 16, step=4)\n",
    "    lora_init_scale = trial.suggest_float('lora_init_scale', 1e-4, 1e-1, log=True)\n",
    "    lora_scaling_rank = trial.suggest_int('lora_scaling_rank', 1, 4)\n",
    "\n",
    "\n",
    "    # Training and evaluation\n",
    "    tokenizer, model, history = train_per_protein(\n",
    "        train_dataset=train_set, \n",
    "        valid_dataset=valid_set, \n",
    "        num_labels=2, \n",
    "        batch=batch, \n",
    "        accum=accum, \n",
    "        epochs=10,  # Fewer epochs for the trial runs\n",
    "        lr=lr,\n",
    "        dropout=dropout,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_pct=warmup_pct,\n",
    "        lora_rank=lora_rank,\n",
    "        lora_init_scale=lora_init_scale,\n",
    "        lora_scaling_rank=lora_scaling_rank,\n",
    "    )\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    # torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"History: \", history)\n",
    "    \n",
    "    # Extract the last validation accuracy from the history\n",
    "    val_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry][-1]\n",
    "    val_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry][-1]\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "directions=['minimize', 'maximize']  # Set the direction to maximize the validation accuracy, can also be 'minimize'\n",
    "study = optuna.create_study(directions=directions,\n",
    "                            storage=\"sqlite:///all_dephos_withLORA_esm_10epochs.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"all_dephos_withLORA_esm_10epochs\")\n",
    "study.optimize(objective, n_trials=50)  # Adjust the number of trials based on your computational resources\n",
    "\n",
    "# Analyzing results\n",
    "pareto_front = study.best_trials  # Get the Pareto front (best non-dominated solutions)\n",
    "for trial in pareto_front:\n",
    "    print(f\"Loss: {trial.values[0]}, Accuracy: {trial.values[1]}\")  # Note the negation of accuracy\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# print(\"  Value: \", study.best_trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in study.best_trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a28d3c1-8e24-4437-a1d9-dda9cefccfd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:37.168731Z",
     "iopub.status.busy": "2024-04-05T14:04:37.168220Z",
     "iopub.status.idle": "2024-04-05T14:04:38.081706Z",
     "shell.execute_reply": "2024-04-05T14:04:38.080275Z",
     "shell.execute_reply.started": "2024-04-05T14:04:37.168675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Truncate the longer list to the size of the shorter one\n",
    "min_length = min(len(loss), len(val_loss))\n",
    "loss = loss[:min_length]\n",
    "val_loss = val_loss[:min_length]\n",
    "\n",
    "# Get spearman (for regression) or accuracy value (for classification)\n",
    "if [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x] != []:\n",
    "    metric = [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x]\n",
    "else:\n",
    "    metric = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n",
    "\n",
    "epochs = [x['epoch'] for x in history if 'loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "line1 = ax1.plot(epochs, loss, label='train_loss')\n",
    "line2 = ax1.plot(epochs, val_loss, label='validation_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "#line3 = ax2.plot(epochs, metric, color='red', label='validation_metric')\n",
    "ax2.set_ylabel('Metric')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Add grid lines\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 \n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History for fine-tuning\")\n",
    "plt.savefig(f\"../Plots/Without_3rdline_Training_History_new.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccb1bbda-d70e-4b4c-a8d4-24600495171a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:38.083526Z",
     "iopub.status.busy": "2024-04-05T14:04:38.083162Z",
     "iopub.status.idle": "2024-04-05T14:04:38.092729Z",
     "shell.execute_reply": "2024-04-05T14:04:38.091278Z",
     "shell.execute_reply.started": "2024-04-05T14:04:38.083490Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "# def load_model(filepath, num_labels=2):\n",
    "# # Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "#     # load a new model\n",
    "#     model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=0.4540649581660329, lora_rank=8, lora_init_scale=0.01054546478690803, lora_scaling_rank=3)\n",
    "    \n",
    "#     # Load the non-frozen parameters from the saved file\n",
    "#     non_frozen_params = torch.load(filepath)\n",
    "\n",
    "#     # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "#     for param_name, param in model.named_parameters():\n",
    "#         if param_name in non_frozen_params:\n",
    "#             param.data = non_frozen_params[param_name].data\n",
    "\n",
    "#     return tokenizer, model\n",
    "\n",
    "# dropout_rate 0.33527687224006164\n",
    "\n",
    "# lora_rank 16\n",
    "\n",
    "# lora_init_scale 0.01713843597721974\n",
    "\n",
    "# lora_scaling_rank 3\n",
    "def load_model(filepath, num_labels=2):\n",
    "    # Creates a new ESM model and loads the finetuned weights from a file\n",
    "\n",
    "    # Load a new model\n",
    "    model, batch_converter = ESM_classification_model(num_labels=num_labels, dropout=0.33527687224006164, lora_rank=16, lora_init_scale=0.01713843597721974, lora_scaling_rank=3)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return model, batch_converter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c97fa52-3aea-42e8-b72f-c4bb84808576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:05:24.020589Z",
     "iopub.status.busy": "2024-04-05T14:05:24.019788Z",
     "iopub.status.idle": "2024-04-05T14:08:10.428922Z",
     "shell.execute_reply": "2024-04-05T14:08:10.426805Z",
     "shell.execute_reply.started": "2024-04-05T14:05:24.020524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "# tokenizer, model_reload = load_model(\"model_output/finetuned_model_all_bfd.pth\",num_labels=2)\n",
    "\n",
    "model_reload, batch_converter = load_model(\"model_output/finetuned_model_all_esm.pth\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c20e75-5f40-4ca1-9579-5df49b738fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:10.432313Z",
     "iopub.status.busy": "2024-04-05T14:08:10.431835Z",
     "iopub.status.idle": "2024-04-05T14:08:19.838631Z",
     "shell.execute_reply": "2024-04-05T14:08:19.836988Z",
     "shell.execute_reply.started": "2024-04-05T14:08:10.432274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have identical weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a62aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = from_pretrained(\"model_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50b8a403-e7c5-4912-9c7a-f404c060c32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.841225Z",
     "iopub.status.busy": "2024-04-05T14:08:19.840752Z",
     "iopub.status.idle": "2024-04-05T14:08:19.864579Z",
     "shell.execute_reply": "2024-04-05T14:08:19.862993Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.841173Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WUI4|HDAC7_HUMAN%342%358</td>\n",
       "      <td>ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|Q13950|RUNX2_HUMAN%416%432</td>\n",
       "      <td>THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q15796|SMAD2_HUMAN%229%245</td>\n",
       "      <td>DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%416%432</td>\n",
       "      <td>TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2798%2814</td>\n",
       "      <td>MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0   sp|Q8WUI4|HDAC7_HUMAN%342%358  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
       "1   sp|Q13950|RUNX2_HUMAN%416%432  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
       "2   sp|Q15796|SMAD2_HUMAN%229%245  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
       "3    sp|P05787|K2C8_HUMAN%416%432  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2798%2814  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "    \n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_Y.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2d18716-fd26-49fe-9ba4-b84c936a364c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.867076Z",
     "iopub.status.busy": "2024-04-05T14:08:19.866598Z",
     "iopub.status.idle": "2024-04-05T14:08:19.887853Z",
     "shell.execute_reply": "2024-04-05T14:08:19.886215Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.867024Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sequence  label\n",
      "0  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
      "1  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
      "2  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
      "3  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
      "4  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1\n"
     ]
    }
   ],
   "source": [
    "my_test=df[[\"sequence\", \"label\"]]\n",
    "\n",
    "print(my_test.head(5))\n",
    "\n",
    "'''\n",
    "my_test[\"sequence\"]=my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "my_test['sequence']=my_test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "'''\n",
    "\n",
    "#Using .loc ensures that you are modifying the original DataFrame rather than a view of it, which helps avoid the SettingWithCopyWarning.\n",
    "# Replace characters in the \"sequence\" column\n",
    "my_test.loc[:, \"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Convert each sequence to a space-separated string\n",
    "my_test.loc[:, 'sequence'] = my_test.apply(lambda row: \" \".join(row[\"sequence\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eee8fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = sequence.split()\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "my_test['middle_char'] = my_test['sequence'].apply(get_middle_char)\n",
    "\n",
    "# Split the DataFrame\n",
    "my_test_S = my_test[my_test['middle_char'] == 'S'].drop(columns=['middle_char'])\n",
    "my_test_T = my_test[my_test['middle_char'] == 'T'].drop(columns=['middle_char'])\n",
    "my_test_Y = my_test[my_test['middle_char'] == 'Y'].drop(columns=['middle_char'])\n",
    "my_test_ST = my_test[my_test['middle_char'].isin(['S', 'T'])].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcd9ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0dff151-a667-4717-af18-401818bc4c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.889951Z",
     "iopub.status.busy": "2024-04-05T14:08:19.889601Z",
     "iopub.status.idle": "2024-04-05T14:08:22.641629Z",
     "shell.execute_reply": "2024-04-05T14:08:22.639919Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.889916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.599359 |      0.807692 |      0.791667 |        0.8 |  0.873397 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[21  5]\n",
      " [ 5 19]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "# from tabulate import tabulate\n",
    "\n",
    "# # Set the device to use\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# model_reload.to(device)\n",
    "\n",
    "# # create Dataset\n",
    "# test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# # make compatible with torch DataLoader\n",
    "# test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# # Create a dataloader for the test dataset\n",
    "# test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# # Put the model in evaluation mode\n",
    "# model_reload.eval()\n",
    "\n",
    "# # Make predictions on the test dataset\n",
    "# raw_logits = []\n",
    "# labels = []\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_dataloader):\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         # add batch results (logits) to predictions\n",
    "#         raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "#         labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# # Convert logits to predictions\n",
    "# raw_logits = np.array(raw_logits)\n",
    "# predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# # Calculate metrics\n",
    "# conf_matrix = confusion_matrix(labels, predictions)\n",
    "# tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# mcc = matthews_corrcoef(labels, predictions)\n",
    "# specificity = tn / (tn + fp)\n",
    "# sensitivity = tp / (tp + fn)\n",
    "# accuracy = accuracy_score(labels, predictions)\n",
    "# roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "# metrics_table = [\n",
    "#     [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "#     [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "# ]\n",
    "\n",
    "# print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "# print(conf_matrix)\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import esm\n",
    "\n",
    "# Ensure the device is set correctly\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# Function to create dataset for ESM model\n",
    "def create_dataset(sequences, labels, batch_converter):\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(list(zip(labels, sequences)))\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"input_ids\": batch_tokens.tolist(),\n",
    "        \"labels\": labels\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "# Assuming my_test is a DataFrame containing test sequences and labels\n",
    "# Replace uncommon AAs with \"X\"\n",
    "my_test[\"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Create test dataset\n",
    "test_set = create_dataset(list(my_test['sequence']), list(my_test['label']), batch_converter)\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        outputs = model_reload(input_ids)\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "        raw_logits.append(logits)\n",
    "        labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.concatenate(raw_logits, axis=0)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ce2f51a-887c-4684-82b9-22ea5fffd334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:22.647264Z",
     "iopub.status.busy": "2024-04-05T14:08:22.646121Z",
     "iopub.status.idle": "2024-04-05T14:08:23.557189Z",
     "shell.execute_reply": "2024-04-05T14:08:23.555594Z",
     "shell.execute_reply.started": "2024-04-05T14:08:22.647207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['0', '1']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"../Plots/Confusion_matrix_for_dephos_new.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07603226",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5e0d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [00:02<00:00, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.529215 |      0.758929 |       0.77027 |   0.764574 |  0.843408 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[170  54]\n",
      " [ 51 171]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "# from tabulate import tabulate\n",
    "\n",
    "# # Set the device to use\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# model_reload.to(device)\n",
    "\n",
    "# # create Dataset\n",
    "# test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# # make compatible with torch DataLoader\n",
    "# test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# # Create a dataloader for the test dataset\n",
    "# test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# # Put the model in evaluation mode\n",
    "# model_reload.eval()\n",
    "\n",
    "# # Make predictions on the test dataset\n",
    "# raw_logits = []\n",
    "# labels = []\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_dataloader):\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         # add batch results (logits) to predictions\n",
    "#         raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "#         labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# # Convert logits to predictions\n",
    "# raw_logits = np.array(raw_logits)\n",
    "# predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# # Calculate metrics\n",
    "# conf_matrix = confusion_matrix(labels, predictions)\n",
    "# tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# mcc = matthews_corrcoef(labels, predictions)\n",
    "# specificity = tn / (tn + fp)\n",
    "# sensitivity = tp / (tp + fn)\n",
    "# accuracy = accuracy_score(labels, predictions)\n",
    "# roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "# metrics_table = [\n",
    "#     [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "#     [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "# ]\n",
    "\n",
    "# print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "# print(conf_matrix)\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import esm\n",
    "\n",
    "# Ensure the device is set correctly\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# Function to create dataset for ESM model\n",
    "def create_dataset(sequences, labels, batch_converter):\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(list(zip(labels, sequences)))\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"input_ids\": batch_tokens.tolist(),\n",
    "        \"labels\": labels\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "# Assuming my_test is a DataFrame containing test sequences and labels\n",
    "# Replace uncommon AAs with \"X\"\n",
    "my_test[\"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Create test dataset\n",
    "test_set = create_dataset(list(my_test['sequence']), list(my_test['label']), batch_converter)\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        outputs = model_reload(input_ids)\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "        raw_logits.append(logits)\n",
    "        labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.concatenate(raw_logits, axis=0)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5528dc-6e06-456d-920f-8f05055d0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, n_neighbors=5, min_dist=0.01, metric='euclidean'):\n",
    "    umap_model = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric\n",
    "    )\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    df = pd.DataFrame({\n",
    "        \"UMAP1\": embeddings[:, 0],\n",
    "        \"UMAP2\": embeddings[:, 1],\n",
    "        \"Label\": labels\n",
    "    })\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = sns.scatterplot(\n",
    "        x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9\n",
    "    )\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.legend(title='Label', bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_ST.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "    embeddings = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch = sequences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "            embeddings.extend(hidden_states[:, 0, :])\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(sequences) // batch_size + 1}\")\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7718f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = list(sequence)\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "valid_df = df\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "valid_df['middle_char'] = valid_df['sequence'].apply(get_middle_char)\n",
    "\n",
    "valid_df = valid_df[valid_df['middle_char'] == 'T'].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a162964f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sp|Q9GZM8|NDEL1_HUMAN%203%219</td>\n",
       "      <td>CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>sp|Q8N163|CCAR2_HUMAN%438%454</td>\n",
       "      <td>EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>sp|P10636-8|TAU_HUMAN%196%212</td>\n",
       "      <td>GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>sp|Q02241|KIF23_HUMAN%434%450</td>\n",
       "      <td>QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sp|Q04206|TF65_HUMAN%419%435</td>\n",
       "      <td>QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>sp|Q76N33|STALP_MOUSE%326%342</td>\n",
       "      <td>ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>sp|P49790|NU153_HUMAN%1098%1114</td>\n",
       "      <td>FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>sp|Q8NFC6|BD1L1_HUMAN%2789%2805</td>\n",
       "      <td>DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>sp|Q5T6F2|UBAP2_HUMAN%514%530</td>\n",
       "      <td>SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>sp|Q9H040|SPRTN_HUMAN%265%281</td>\n",
       "      <td>NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name                           sequence  label\n",
       "180    sp|Q9GZM8|NDEL1_HUMAN%203%219  CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI      1\n",
       "181    sp|Q8N163|CCAR2_HUMAN%438%454  EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA      1\n",
       "182    sp|P10636-8|TAU_HUMAN%196%212  GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV      1\n",
       "183    sp|Q02241|KIF23_HUMAN%434%450  QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE      1\n",
       "184     sp|Q04206|TF65_HUMAN%419%435  QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG      1\n",
       "..                               ...                                ...    ...\n",
       "441    sp|Q76N33|STALP_MOUSE%326%342  ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS      0\n",
       "442  sp|P49790|NU153_HUMAN%1098%1114  FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ      0\n",
       "443  sp|Q8NFC6|BD1L1_HUMAN%2789%2805  DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL      0\n",
       "444    sp|Q5T6F2|UBAP2_HUMAN%514%530  SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS      0\n",
       "445    sp|Q9H040|SPRTN_HUMAN%265%281  NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN      0\n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a44d9187-1ac5-4e36-89a0-8f827a7f0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 3559427.0\n",
      "\n",
      "Processed batch 1/3\n",
      "Processed batch 2/3\n",
      "Processed batch 3/3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_df = my_valid\n",
    "\n",
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_ST.pth\",num_labels=2)\n",
    "\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "valid_sequences = list(valid_df['sequence'])\n",
    "valid_embeddings = get_embeddings(model_reload, tokenizer, valid_sequences)\n",
    "\n",
    "umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "\n",
    "labels = list(valid_df['label'])\n",
    "\n",
    "plot_umap(umap_embeddings, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f029bcf-42ef-4476-b575-3c14adb71b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da0e6c-e921-493b-9304-8ba9aad07d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2319a5",
   "metadata": {},
   "source": [
    "This notebook will implement combining D + P dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bab9a05",
   "metadata": {},
   "source": [
    "The dataset is balance \n",
    "This is before \n",
    "Number of LABEL=1 entries: 991\n",
    "  S: 723\n",
    "  T: 167\n",
    "  Y: 101\n",
    "Number of LABEL=0 entries: 989\n",
    "  S: 722\n",
    "  T: 167\n",
    "  Y: 100\n",
    "\n",
    "  Now we add some more from phos dataset and it looks like this\n",
    "  Number of LABEL=1 entries: \n",
    "  S: 723\n",
    "  T: 723\n",
    "  Y: 723\n",
    "Number of LABEL=0 entries: \n",
    "  S: 722\n",
    "  T: 722\n",
    "  Y: 722\n",
    "  We do not sample any more S entries as it is already balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a377270-2995-4da1-a673-5369769a6279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:52:49.264011Z",
     "iopub.status.busy": "2024-04-05T12:52:49.263502Z",
     "iopub.status.idle": "2024-04-05T12:53:29.491461Z",
     "shell.execute_reply": "2024-04-05T12:53:29.490156Z",
     "shell.execute_reply.started": "2024-04-05T12:52:49.263956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install umap-learn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0148ff8f-80eb-4bbd-aac7-fe1f371da27a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.508233Z",
     "iopub.status.busy": "2024-04-05T12:53:29.507801Z",
     "iopub.status.idle": "2024-04-05T12:53:29.536614Z",
     "shell.execute_reply": "2024-04-05T12:53:29.514877Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.508197Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.1.1+cu121\n",
      "Cuda version:  12.1\n",
      "Numpy version:  1.26.2\n",
      "Pandas version:  2.1.3\n",
      "Transformers version:  4.35.2\n",
      "Datasets version:  2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96bd9396-a81c-4d87-a722-0d2020627dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.538488Z",
     "iopub.status.busy": "2024-04-05T12:53:29.538089Z",
     "iopub.status.idle": "2024-04-05T12:53:29.768968Z",
     "shell.execute_reply": "2024-04-05T12:53:29.767620Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.538452Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WWI1|LMO7_HUMAN%260%276</td>\n",
       "      <td>SCSSDITLRGGREGFESDTDSEFTFKMQDYNKD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|sp|Q07157|ZO1_HUMAN|Tight</td>\n",
       "      <td>RSKGKLKMVVQRDERATLLNVPDLSDSIHSANA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|P24928|RPB1_HUMAN%1775%1791</td>\n",
       "      <td>NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|sp|Q9Y2U8|MAN1_HUMAN|Inner</td>\n",
       "      <td>PHSWWGARRPAGPELQTPPGKDGAVEDEEGEGE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q14980|NUMA1_HUMAN%2061%2077</td>\n",
       "      <td>NSLLRRGASKKALSKASPNTRSGTRRSPRIATT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name                           sequence  label\n",
       "0     sp|Q8WWI1|LMO7_HUMAN%260%276  SCSSDITLRGGREGFESDTDSEFTFKMQDYNKD      1\n",
       "1     sp|sp|Q07157|ZO1_HUMAN|Tight  RSKGKLKMVVQRDERATLLNVPDLSDSIHSANA      1\n",
       "2   sp|P24928|RPB1_HUMAN%1775%1791  NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS      1\n",
       "3    sp|sp|Q9Y2U8|MAN1_HUMAN|Inner  PHSWWGARRPAGPELQTPPGKDGAVEDEEGEGE      1\n",
       "4  sp|Q14980|NUMA1_HUMAN%2061%2077  NSLLRRGASKKALSKASPNTRSGTRRSPRIATT      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/merged_output_D+P_balance_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/merged_output_D+P_balance_Y.fasta'\n",
    "\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b784f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to get the middle character\n",
    "# def get_middle_char(sequence):\n",
    "#     chars = list(sequence)\n",
    "#     middle_index = len(chars) // 2\n",
    "#     return chars[middle_index]\n",
    "\n",
    "# # Apply the function to get the middle characters\n",
    "# df['middle_char'] = df['sequence'].apply(get_middle_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a68724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to count 'S', 'T', 'Y' in a sequence\n",
    "# def count_chars(sequence, char):\n",
    "#     return sequence.count(char)\n",
    "\n",
    "# # Count the occurrences of 'S', 'T', and 'Y' in the sequences\n",
    "# df['count_S'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'S'))\n",
    "# df['count_T'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'T'))\n",
    "# df['count_Y'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'Y'))\n",
    "\n",
    "# # Sum the counts to get the total occurrences in the DataFrame\n",
    "# total_S = df['count_S'].sum()\n",
    "# total_T = df['count_T'].sum()\n",
    "# total_Y = df['count_Y'].sum()\n",
    "\n",
    "# print(f\"Total number of 'S': {total_S}\")\n",
    "# print(f\"Total number of 'T': {total_T}\")\n",
    "# print(f\"Total number of 'Y': {total_Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9c28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group by label and sum the counts\n",
    "# grouped_counts = df.groupby('label')[['count_S', 'count_T', 'count_Y']].sum().reset_index()\n",
    "\n",
    "# # Display the grouped counts\n",
    "# print(grouped_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c189b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate the DataFrame by middle character\n",
    "# df_S = df[df['middle_char'] == 'S']\n",
    "# df_T = df[df['middle_char'] == 'T']\n",
    "# df_Y = df[df['middle_char'] == 'Y']\n",
    "\n",
    "# # Separate each subset by label\n",
    "# df_S_0 = df_S[df_S['label'] == 0]\n",
    "# df_S_1 = df_S[df_S['label'] == 1]\n",
    "# df_T_0 = df_T[df_T['label'] == 0]\n",
    "# df_T_1 = df_T[df_T['label'] == 1]\n",
    "# df_Y_0 = df_Y[df_Y['label'] == 0]\n",
    "# df_Y_1 = df_Y[df_Y['label'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "333000b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "# # Desired number of samples per group\n",
    "# n_samples_S = 500\n",
    "# n_sampple_T = 300\n",
    "# n_sampple_Y = 200\n",
    "# # Perform stratified sampling\n",
    "# df_S_0_resampled = resample(df_S_0, replace=False, n_samples=n_samples_S, random_state=42)\n",
    "# df_S_1_resampled = resample(df_S_1, replace=False, n_samples=n_samples_S, random_state=42)\n",
    "# df_T_0_resampled = resample(df_T_0, replace=True, n_samples=n_sampple_T, random_state=42)\n",
    "# df_T_1_resampled = resample(df_T_1, replace=True, n_samples=n_sampple_T, random_state=42)\n",
    "# df_Y_0_resampled = resample(df_Y_0, replace=True, n_samples=n_sampple_Y, random_state=42)\n",
    "# df_Y_1_resampled = resample(df_Y_1, replace=True, n_samples=n_sampple_Y, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31710914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine the resampled subsets\n",
    "# balanced_df = pd.concat([\n",
    "#     df_S_0_resampled, df_S_1_resampled,\n",
    "#     df_T_0_resampled, df_T_1_resampled,\n",
    "#     df_Y_0_resampled, df_Y_1_resampled\n",
    "# ])\n",
    "\n",
    "# # Shuffle the combined DataFrame\n",
    "# balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# print(\"Balanced DataFrame:\")\n",
    "# print(balanced_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46617eaa-de6d-4d12-82cb-08ec66b4f56a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.771322Z",
     "iopub.status.busy": "2024-04-05T12:53:29.770859Z",
     "iopub.status.idle": "2024-04-05T12:53:29.786558Z",
     "shell.execute_reply": "2024-04-05T12:53:29.785263Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.771275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the dataset into training and validation sets\n",
    "# my_train, my_valid = train_test_split(\n",
    "#     balanced_df, \n",
    "#     test_size=0.2, \n",
    "#     random_state=42, \n",
    "#     stratify=balanced_df[['label', 'middle_char']]\n",
    "# )\n",
    "\n",
    "# my_train=my_train[[\"sequence\", \"label\"]]\n",
    "# my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# # Print the first 5 rows of the training set\n",
    "# print(\"Training Set:\")\n",
    "# print(my_train.shape)\n",
    "\n",
    "# # Print the first 5 rows of the validation set\n",
    "# print(\"\\nValidation Set:\")\n",
    "# print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76760f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "(3468, 2)\n",
      "\n",
      "Validation Set:\n",
      "(867, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "my_train, my_valid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "my_train=my_train[[\"sequence\", \"label\"]]\n",
    "my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the training set\n",
    "print(\"Training Set:\")\n",
    "print(my_train.shape)\n",
    "\n",
    "# Print the first 5 rows of the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a424877b-787c-44fe-bf87-33346ffd3be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.789138Z",
     "iopub.status.busy": "2024-04-05T12:53:29.788675Z",
     "iopub.status.idle": "2024-04-05T12:53:29.816779Z",
     "shell.execute_reply": "2024-04-05T12:53:29.815341Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.789094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifies an existing transformer and introduce the LoRA layers\n",
    "\n",
    "class LoRAConfig:\n",
    "    def __init__(self, lora_rank=8, lora_init_scale=0.01, lora_scaling_rank=2):\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_init_scale = lora_init_scale\n",
    "        self.lora_modules = \".*SelfAttention|.*EncDecAttention\"\n",
    "        self.lora_layers = \"q|k|v|o\"\n",
    "        self.trainable_param_names = \".*layer_norm.*|.*lora_[ab].*\"\n",
    "        self.lora_scaling_rank = lora_scaling_rank\n",
    "        # lora_modules and lora_layers are specified with regular expressions\n",
    "        # see https://www.w3schools.com/python/python_regex.asp for reference\n",
    "        \n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, scaling_rank, init_scale):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.rank = rank\n",
    "        self.scaling_rank = scaling_rank\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        if self.rank > 0:\n",
    "            self.lora_a = nn.Parameter(torch.randn(rank, linear_layer.in_features) * init_scale)\n",
    "            if init_scale < 0:\n",
    "                self.lora_b = nn.Parameter(torch.randn(linear_layer.out_features, rank) * init_scale)\n",
    "            else:\n",
    "                self.lora_b = nn.Parameter(torch.zeros(linear_layer.out_features, rank))\n",
    "        if self.scaling_rank:\n",
    "            self.multi_lora_a = nn.Parameter(\n",
    "                torch.ones(self.scaling_rank, linear_layer.in_features)\n",
    "                + torch.randn(self.scaling_rank, linear_layer.in_features) * init_scale\n",
    "            )\n",
    "            if init_scale < 0:\n",
    "                self.multi_lora_b = nn.Parameter(\n",
    "                    torch.ones(linear_layer.out_features, self.scaling_rank)\n",
    "                    + torch.randn(linear_layer.out_features, self.scaling_rank) * init_scale\n",
    "                )\n",
    "            else:\n",
    "                self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, self.scaling_rank))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.scaling_rank == 1 and self.rank == 0:\n",
    "            # parsimonious implementation for ia3 and lora scaling\n",
    "            if self.multi_lora_a.requires_grad:\n",
    "                hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n",
    "            else:\n",
    "                hidden = F.linear(input, self.weight, self.bias)\n",
    "            if self.multi_lora_b.requires_grad:\n",
    "                hidden = hidden * self.multi_lora_b.flatten()\n",
    "            return hidden\n",
    "        else:\n",
    "            # general implementation for lora (adding and scaling)\n",
    "            weight = self.weight\n",
    "            if self.scaling_rank:\n",
    "                weight = weight * torch.matmul(self.multi_lora_b, self.multi_lora_a) / self.scaling_rank\n",
    "            if self.rank:\n",
    "                weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n",
    "            return F.linear(input, weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, rank={}, scaling_rank={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.rank, self.scaling_rank\n",
    "        )\n",
    "\n",
    "\n",
    "def modify_with_lora(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.lora_modules, m_name):\n",
    "            for c_name, layer in dict(module.named_children()).items():\n",
    "                if re.fullmatch(config.lora_layers, c_name):\n",
    "                    assert isinstance(\n",
    "                        layer, nn.Linear\n",
    "                    ), f\"LoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        c_name,\n",
    "                        LoRALinear(layer, config.lora_rank, config.lora_scaling_rank, config.lora_init_scale),\n",
    "                    )\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e79b323-4677-4723-a5fd-a60dc13a3b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.819433Z",
     "iopub.status.busy": "2024-04-05T12:53:29.818965Z",
     "iopub.status.idle": "2024-04-05T12:53:29.845976Z",
     "shell.execute_reply": "2024-04-05T12:53:29.844438Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.819335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.7, num_labels=2):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class T5EncoderClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, class_config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "        \n",
    "        # Trainable emphasis factor\n",
    "        # self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "    # def forward(self, hidden_states):\n",
    "    #     seq_length = hidden_states.size(1)\n",
    "    #     middle_idx = seq_length // 2\n",
    "    #     middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "    #     # Apply trainable emphasis factor\n",
    "    #     emphasized_middle_embedding = middle_embedding * self.emphasis_factor\n",
    "\n",
    "    #     # Combine with the average embedding\n",
    "    #     average_embedding = torch.mean(hidden_states, dim=1)\n",
    "    #     combined_embedding = emphasized_middle_embedding + average_embedding\n",
    "\n",
    "    #     x = self.dropout(combined_embedding)\n",
    "    #     x = self.dense(x)\n",
    "    #     x = torch.tanh(x)\n",
    "    #     x = self.dropout(x)\n",
    "    #     logits = self.out_proj(x)\n",
    "    #     return logits\n",
    "\n",
    "    # def forward(self, hidden_states):\n",
    "\n",
    "    #     hidden_states =  torch.mean(hidden_states,dim=1)  # avg embedding\n",
    "\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.dense(hidden_states)\n",
    "    #     hidden_states = torch.tanh(hidden_states)\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.out_proj(hidden_states)\n",
    "    #     return hidden_states\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        # Original sequence length and middle index\n",
    "        seq_length = hidden_states.size(1)\n",
    "        middle_idx = seq_length // 2\n",
    "\n",
    "        # Extract the middle embedding vector\n",
    "        middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "        # Amplify the influence of the middle embedding\n",
    "        amplified_middle_embedding = middle_embedding * 2\n",
    "\n",
    "        # Combine with average to retain context\n",
    "        average_embedding = torch.mean(hidden_states, dim=1)\n",
    "        combined_embedding = 0.5 * amplified_middle_embedding + 0.5 * average_embedding\n",
    "\n",
    "        # Classification layers\n",
    "        x = self.dropout(combined_embedding)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.out_proj(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class T5EncoderForSimpleSequenceClassification(T5PreTrainedModel):\n",
    "\n",
    "    def __init__(self, config: T5Config, class_config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n",
    "\n",
    "        encoder_config = copy.deepcopy(config)\n",
    "        encoder_config.use_cache = False\n",
    "        encoder_config.is_encoder_decoder = False\n",
    "        self.encoder = T5Stack(encoder_config, self.shared)\n",
    "\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate) \n",
    "        self.classifier = T5EncoderClassificationHead(config, class_config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "    def parallelize(self, device_map=None):\n",
    "        self.device_map = (\n",
    "            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
    "            if device_map is None\n",
    "            else device_map\n",
    "        )\n",
    "        assert_device_map(self.device_map, len(self.encoder.block))\n",
    "        self.encoder.parallelize(self.device_map)\n",
    "        self.classifier = self.classifier.to(self.encoder.first_device)\n",
    "        self.model_parallel = True\n",
    "\n",
    "    def deparallelize(self):\n",
    "        self.encoder.deparallelize()\n",
    "        self.encoder = self.encoder.to(\"cpu\")\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.shared\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.shared = new_embeddings\n",
    "        self.encoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "        logits = self.classifier(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71394626-6f8b-4ca5-80f3-c697e4320bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.848217Z",
     "iopub.status.busy": "2024-04-05T12:53:29.847782Z",
     "iopub.status.idle": "2024-04-05T12:53:29.859841Z",
     "shell.execute_reply": "2024-04-05T12:53:29.858398Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.848182Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PT5_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "    # Load PT5 and tokenizer\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\") \n",
    "    \n",
    "    # Create new Classifier model with PT5 dimensions\n",
    "    class_config=ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "    class_model=T5EncoderForSimpleSequenceClassification(model.config,class_config)\n",
    "    \n",
    "    # Set encoder and embedding weights to checkpoint weights\n",
    "    class_model.shared=model.shared\n",
    "    class_model.encoder=model.encoder    \n",
    "    \n",
    "    # Delete the checkpoint model\n",
    "    model=class_model\n",
    "    del class_model\n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "    # Add model modification lora\n",
    "    config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "    # Add LoRA layers\n",
    "    model = modify_with_lora(model, config)\n",
    "    \n",
    "    # Freeze Embeddings and Encoder (except LoRA)\n",
    "    for (param_name, param) in model.shared.named_parameters():\n",
    "                param.requires_grad = False\n",
    "    for (param_name, param) in model.encoder.named_parameters():\n",
    "                param.requires_grad = False       \n",
    "\n",
    "    for (param_name, param) in model.named_parameters():\n",
    "            if re.fullmatch(config.trainable_param_names, param_name):\n",
    "                param.requires_grad = True\n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c4d56b2-c9ca-460d-b977-a1e4ae1e9568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.864172Z",
     "iopub.status.busy": "2024-04-05T12:53:29.863760Z",
     "iopub.status.idle": "2024-04-05T12:53:29.873119Z",
     "shell.execute_reply": "2024-04-05T12:53:29.871609Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.864135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4550fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    \"\"\"Custom early stopping callback that can monitor loss or accuracy.\"\"\"\n",
    "    \n",
    "    def __init__(self, metric_name='eval_loss', early_stopping_patience=3, minimize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric_name (str): Metric to monitor, default 'eval_loss'.\n",
    "            early_stopping_patience (int): Number of checks with no improvement after which training will be stopped.\n",
    "            minimize (bool): Set to True if the metric should be minimized, False if it should be maximized.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_counter = 0\n",
    "        self.minimize = minimize\n",
    "        self.best_metric = float('inf') if minimize else float('-inf')\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        current_metric = kwargs['metrics'][self.metric_name]\n",
    "        \n",
    "        if (self.minimize and current_metric < self.best_metric) or (not self.minimize and current_metric > self.best_metric):\n",
    "            self.best_metric = current_metric\n",
    "            self.early_stopping_counter = 0\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "        \n",
    "        if self.early_stopping_counter >= self.early_stopping_patience:\n",
    "            control.should_training_stop = True\n",
    "            print(f'Stopping early! No improvement in {self.metric_name} for {self.early_stopping_patience} evaluation steps.')\n",
    "\n",
    "\n",
    "class MultiObjectiveEarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        # Extract current validation loss and accuracy\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "\n",
    "        # Check if current loss and accuracy improved significantly\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            # Update best scores and reset wait time\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            # If no improvement, increment the wait counter\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                # If wait exceeds the patience, stop training\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "class MultiObjectiveEarlyStoppingAndSaveCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001, output_dir='./model_output', filename='finetuned_model'):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "        self.output_dir = output_dir\n",
    "        self.filename = filename\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "        model = kwargs['model']\n",
    "\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "            # Save the model as the best so far\n",
    "            self.save_finetuned_parameters(model, os.path.join(self.output_dir, self.filename))\n",
    "            print(f\"Saved improved model to {self.output_dir}/{self.filename}\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "    def save_finetuned_parameters(self, model, filepath):\n",
    "        # Create a dictionary to hold the non-frozen parameters\n",
    "        non_frozen_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "        # Save only the finetuned parameters \n",
    "        torch.save(non_frozen_params, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfb8bb11-79b0-4936-9099-f9f8ef97e105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.875565Z",
     "iopub.status.busy": "2024-04-05T12:53:29.875038Z",
     "iopub.status.idle": "2024-04-05T12:53:30.214710Z",
     "shell.execute_reply": "2024-04-05T12:53:30.213349Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.875495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "# Set random seeds for reproducibility of your trainings run\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, min_dist=0.01):\n",
    "    umap_model = umap.UMAP(n_components=n_components)\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    data = {\"UMAP1\": embeddings[:, 0], \"UMAP2\": embeddings[:, 1], \"Label\": labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9)\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_new.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "# Main training fuction\n",
    "def train_per_protein(\n",
    "        train_dataset,         #training data\n",
    "        valid_dataset,         #validation data      \n",
    "        weight_decay,\n",
    "        warmup_pct,\n",
    "        num_labels= 2,    #1 for regression, >1 for classification\n",
    "    \n",
    "        # effective training batch size is batch * accum\n",
    "        # we recommend an effective batch size of 8 \n",
    "        batch= 4,         #for training\n",
    "        accum= 2,         #gradient accumulation\n",
    "    \n",
    "        val_batch = 16,   #batch size for evaluation\n",
    "        epochs=1,       #training epochs\n",
    "        lr= 3e-4,         #recommended learning rate\n",
    "        seed= 42,         #random seed\n",
    "        deepspeed=False,  #if gpu is large enough disable deepspeed for training speedup\n",
    "        gpu= 1,\n",
    "        dropout=0.5, #dropout rate\n",
    "         #L2 weight regularization\n",
    "        lora_rank=4,      #lora rank\n",
    "        lora_init_scale=0.01, #lora scaling rank\n",
    "        lora_scaling_rank=1,       #lora a\n",
    "        ):         #gpu selection (1 for first gpu)\n",
    "\n",
    "    # Set gpu device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # load model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=dropout, lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    total_steps = epochs * len(train_dataset) // batch\n",
    "    warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "    # Define TrainingArguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir='./results',              # where to save the model\n",
    "        evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "        logging_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        learning_rate=lr,                    # initial learning rate\n",
    "        per_device_train_batch_size=batch,   # batch size per device\n",
    "        gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "        num_train_epochs=epochs,             # number of epochs to train\n",
    "        weight_decay=weight_decay,           # L2 weight regularization\n",
    "        warmup_steps=warmup_steps,           # 10% of total steps\n",
    "        load_best_model_at_end=False,         # load the best model at the end of training\n",
    "        seed=seed,                           # random seed\n",
    "        push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "        logging_dir='./logs',\n",
    "    )\n",
    "    # metric_for_best_model='eval_loss|accuracy'\n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        # Check if predictions have the expected shape\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "        # Now, compute the metric (e.g., accuracy)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        # Return the metric(s) as a dictionary\n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    # For minimizing loss\n",
    "    early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "    # For maximizing accuracy\n",
    "    early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "            early_stopping_patience=3,\n",
    "            min_delta=0.001,\n",
    "            output_dir='./model_output',\n",
    "            filename='finetuned_model_D_and_P_balance_dataset.pth'\n",
    "        )],\n",
    "    )    \n",
    "\n",
    "    def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "        embeddings = []\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "    \n",
    "        # Iterate over the sequences in batches\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            # Extract a batch of sequences\n",
    "            batch = sequences[i:i + batch_size]\n",
    "    \n",
    "            # Tokenize the batch using the specified tokenizer and convert to PyTorch tensors\n",
    "            inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                # Forward pass through the model to obtain outputs\n",
    "                outputs = model(**inputs)\n",
    "    \n",
    "            # Extract hidden states from the second-to-last layer (penultimate layer)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "    \n",
    "            # Take the embeddings from the second-to-last layer\n",
    "            embeddings_from_layer = hidden_states[:, 0, :]\n",
    "    \n",
    "            # Extend the list with the generated embeddings\n",
    "            embeddings.extend(embeddings_from_layer)\n",
    "    \n",
    "            print(f\"Batch {i // batch_size + 1}, Second-to-Last Layer Embeddings Shape: {embeddings_from_layer.shape}\")\n",
    "    \n",
    "        return np.array(embeddings)\n",
    "\n",
    "        \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    # Get the best model\n",
    "    # model = trainer.model\n",
    "    # Ensure the best model is loaded\n",
    "    best_model_path = os.path.join('./model_output', 'finetuned_model_D_and_P_balance_dataset.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        state_dict = torch.load(best_model_path)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "    # Evaluate the best model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(eval_results)\n",
    "    \n",
    "    # Print the current learning rate\n",
    "    # current_lr = trainer.optimizer.param_groups[0]['lr']\n",
    "    # print(f\"Current learning rate: {current_lr}\")\n",
    "    \n",
    "    # valid_sequences = list(valid_dataset['sequence'])\n",
    "    # valid_embeddings = get_embeddings(model, tokenizer, valid_sequences)\n",
    "\n",
    "    # # Apply UMAP for dimensionality reduction\n",
    "    # umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "    # # Plot UMAP embeddings\n",
    "    # labels = list(valid_dataset['label'])\n",
    "    # plot_umap(umap_embeddings, labels)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b300952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Dataset creation\n",
    "def create_dataset(tokenizer,seqs,labels):\n",
    "    tokenized = tokenizer(seqs, max_length=1024, padding=True, truncation=True)\n",
    "    dataset = Dataset.from_dict(tokenized)\n",
    "    dataset = dataset.add_column(\"labels\", labels)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\") \n",
    "\n",
    "train_df = my_train\n",
    "valid_df = my_valid\n",
    "\n",
    "# Preprocess inputs\n",
    "# Replace uncommon AAs with \"X\"\n",
    "train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "# Add spaces between each amino acid for PT5 to correctly use them\n",
    "train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "# Create Datasets\n",
    "train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']))\n",
    "valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f20a2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm all_dephos_withLORA_datasetloader.sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcbe5f",
   "metadata": {},
   "source": [
    "{'lr': 0.00010175943017273118, 'batch': 8, 'accum': 2, 'dropout_rate': 0.4882243131202929, 'weight_decay': 0.00014993579804161342, 'warmup_pct': 0.18496515086758566, 'lora_rank': 24, 'lora_init_scale': 0.01370043600756871, 'lora_scaling_rank': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a57f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddfce510-da2b-4b95-9491-49f9ae8efb06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T13:08:03.246094Z",
     "iopub.status.busy": "2024-04-05T13:08:03.244479Z",
     "iopub.status.idle": "2024-04-05T14:04:37.162324Z",
     "shell.execute_reply": "2024-04-05T14:04:37.160516Z",
     "shell.execute_reply.started": "2024-04-05T13:08:03.246029Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='4340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  31/4340 00:13 < 33:00, 2.18 it/s, Epoch 0.14/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer, model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_per_protein\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.00010175943017273118\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4882243131202929\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.00014993579804161342\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.18496515086758566\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_init_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01370043600756871\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_scaling_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 153\u001b[0m, in \u001b[0;36mtrain_per_protein\u001b[0;34m(train_dataset, valid_dataset, weight_decay, warmup_pct, num_labels, batch, accum, val_batch, epochs, lr, seed, deepspeed, gpu, dropout, lora_rank, lora_init_scale, lora_scaling_rank)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(embeddings)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Get the best model\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# model = trainer.model\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Ensure the best model is loaded\u001b[39;00m\n\u001b[1;32m    158\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model_output\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetuned_model_D_and_P_balance_dataset.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1860\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:2725\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2724\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2725\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2728\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:2748\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2747\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2748\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2749\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2750\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 145\u001b[0m, in \u001b[0;36mT5EncoderForSimpleSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    134\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ):\n\u001b[1;32m    143\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 145\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    156\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(hidden_states)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1113\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1099\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1100\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         output_attentions,\n\u001b[1;32m   1111\u001b[0m     )\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1113\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:754\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    751\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m attention_outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:343\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    342\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 343\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDenseReluDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwarded_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(forwarded_states)\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:288\u001b[0m, in \u001b[0;36mT5DenseActDense.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m--> 288\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(hidden_states)\n\u001b[1;32m    290\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer, model, history = train_per_protein(train_set, valid_set, num_labels=2, batch=8, accum=2, epochs=20, seed=42, lr=0.00010175943017273118, dropout=0.4882243131202929, weight_decay=0.00014993579804161342, warmup_pct=0.18496515086758566, lora_rank=24, lora_init_scale=0.01370043600756871, lora_scaling_rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ebf90f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 08:42:45,813] A new study created in RDB with name: finetuned_model_D_and_P_balance_dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 6508547.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 1:04:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.686417</td>\n",
       "      <td>0.573241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.658634</td>\n",
       "      <td>0.707036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.660600</td>\n",
       "      <td>0.626107</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.635100</td>\n",
       "      <td>0.593098</td>\n",
       "      <td>0.712803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.603600</td>\n",
       "      <td>0.564025</td>\n",
       "      <td>0.720877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.581500</td>\n",
       "      <td>0.545022</td>\n",
       "      <td>0.728950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.576500</td>\n",
       "      <td>0.529589</td>\n",
       "      <td>0.749712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.563600</td>\n",
       "      <td>0.518078</td>\n",
       "      <td>0.756632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.557200</td>\n",
       "      <td>0.516792</td>\n",
       "      <td>0.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.510511</td>\n",
       "      <td>0.769319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5105111002922058, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 13.1314, 'eval_samples_per_second': 66.025, 'eval_steps_per_second': 8.301, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 09:48:16,368] Trial 0 finished with values: [0.5105111002922058, 0.7693194925028836] and parameters: {'lr': 3.758762055180164e-05, 'batch': 1, 'accum': 4, 'dropout_rate': 0.7320932156900825, 'weight_decay': 0.0005031075722602088, 'warmup_pct': 0.2463007406840469, 'lora_rank': 4, 'lora_init_scale': 0.0008209558837694562, 'lora_scaling_rank': 7}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7054, 'learning_rate': 3.815532960825667e-06, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.6864169836044312, 'eval_accuracy': 0.5732410611303345, 'eval_runtime': 14.495, 'eval_samples_per_second': 59.814, 'eval_steps_per_second': 7.52, 'epoch': 1.0, 'step': 867}, {'loss': 0.6884, 'learning_rate': 7.631065921651334e-06, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.6586339473724365, 'eval_accuracy': 0.707035755478662, 'eval_runtime': 13.4709, 'eval_samples_per_second': 64.361, 'eval_steps_per_second': 8.092, 'epoch': 2.0, 'step': 1734}, {'loss': 0.6606, 'learning_rate': 1.1446598882477001e-05, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.6261072158813477, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 13.452, 'eval_samples_per_second': 64.451, 'eval_steps_per_second': 8.103, 'epoch': 3.0, 'step': 2601}, {'loss': 0.6351, 'learning_rate': 1.5262131843302667e-05, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.5930981040000916, 'eval_accuracy': 0.71280276816609, 'eval_runtime': 13.3781, 'eval_samples_per_second': 64.807, 'eval_steps_per_second': 8.148, 'epoch': 4.0, 'step': 3468}, {'loss': 0.6036, 'learning_rate': 1.9077664804128337e-05, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5640249848365784, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 13.3442, 'eval_samples_per_second': 64.972, 'eval_steps_per_second': 8.168, 'epoch': 5.0, 'step': 4335}, {'loss': 0.5815, 'learning_rate': 2.2893197764954003e-05, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.545022189617157, 'eval_accuracy': 0.7289504036908881, 'eval_runtime': 13.3251, 'eval_samples_per_second': 65.065, 'eval_steps_per_second': 8.18, 'epoch': 6.0, 'step': 5202}, {'loss': 0.5765, 'learning_rate': 2.670873072577967e-05, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.5295888185501099, 'eval_accuracy': 0.7497116493656286, 'eval_runtime': 13.312, 'eval_samples_per_second': 65.129, 'eval_steps_per_second': 8.188, 'epoch': 7.0, 'step': 6069}, {'loss': 0.5636, 'learning_rate': 3.0524263686605335e-05, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 0.5180782079696655, 'eval_accuracy': 0.7566320645905421, 'eval_runtime': 13.3107, 'eval_samples_per_second': 65.135, 'eval_steps_per_second': 8.189, 'epoch': 8.0, 'step': 6936}, {'loss': 0.5572, 'learning_rate': 3.4339796647431004e-05, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 0.5167917013168335, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 13.3102, 'eval_samples_per_second': 65.138, 'eval_steps_per_second': 8.189, 'epoch': 9.0, 'step': 7803}, {'loss': 0.5575, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5105111002922058, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 13.3025, 'eval_samples_per_second': 65.176, 'eval_steps_per_second': 8.194, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 3872.0185, 'train_samples_per_second': 8.957, 'train_steps_per_second': 2.239, 'total_flos': 8592021749357280.0, 'train_loss': 0.6129382246780836, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5105111002922058, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 13.1314, 'eval_samples_per_second': 66.025, 'eval_steps_per_second': 8.301, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 25:28, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.743200</td>\n",
       "      <td>0.673790</td>\n",
       "      <td>0.644752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.663900</td>\n",
       "      <td>0.588992</td>\n",
       "      <td>0.710496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.604500</td>\n",
       "      <td>0.532473</td>\n",
       "      <td>0.739331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.510869</td>\n",
       "      <td>0.752018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.559600</td>\n",
       "      <td>0.504713</td>\n",
       "      <td>0.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.559200</td>\n",
       "      <td>0.504481</td>\n",
       "      <td>0.758939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5047129392623901, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.4115, 'eval_samples_per_second': 69.855, 'eval_steps_per_second': 8.782, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 10:14:40,692] Trial 1 finished with values: [0.5047129392623901, 0.7612456747404844] and parameters: {'lr': 7.22642175796173e-05, 'batch': 4, 'accum': 2, 'dropout_rate': 0.8559550689440982, 'weight_decay': 0.00043227475326132285, 'warmup_pct': 0.15462277045804768, 'lora_rank': 28, 'lora_init_scale': 0.015547162542323927, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7432, 'learning_rate': 2.3351049411921112e-05, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6737896800041199, 'eval_accuracy': 0.6447520184544406, 'eval_runtime': 14.0524, 'eval_samples_per_second': 61.698, 'eval_steps_per_second': 7.757, 'epoch': 1.0, 'step': 433}, {'loss': 0.6921, 'learning_rate': 4.6756027344424025e-05, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.6294867396354675, 'eval_accuracy': 0.707035755478662, 'eval_runtime': 12.436, 'eval_samples_per_second': 69.717, 'eval_steps_per_second': 8.765, 'epoch': 2.0, 'step': 867}, {'loss': 0.6639, 'learning_rate': 7.010707675634515e-05, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.588991641998291, 'eval_accuracy': 0.7104959630911188, 'eval_runtime': 12.4859, 'eval_samples_per_second': 69.438, 'eval_steps_per_second': 8.73, 'epoch': 3.0, 'step': 1300}, {'loss': 0.6224, 'learning_rate': 6.274177553066439e-05, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.5548428893089294, 'eval_accuracy': 0.7277970011534025, 'eval_runtime': 12.4225, 'eval_samples_per_second': 69.793, 'eval_steps_per_second': 8.774, 'epoch': 4.0, 'step': 1734}, {'loss': 0.6045, 'learning_rate': 5.227675673067299e-05, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5324729681015015, 'eval_accuracy': 0.7393310265282583, 'eval_runtime': 12.4924, 'eval_samples_per_second': 69.402, 'eval_steps_per_second': 8.725, 'epoch': 5.0, 'step': 2167}, {'loss': 0.5979, 'learning_rate': 4.178756929603957e-05, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.5206310153007507, 'eval_accuracy': 0.7497116493656286, 'eval_runtime': 12.4464, 'eval_samples_per_second': 69.659, 'eval_steps_per_second': 8.758, 'epoch': 6.0, 'step': 2601}, {'loss': 0.5822, 'learning_rate': 3.132255049604817e-05, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.5108690857887268, 'eval_accuracy': 0.7520184544405998, 'eval_runtime': 12.4889, 'eval_samples_per_second': 69.422, 'eval_steps_per_second': 8.728, 'epoch': 7.0, 'step': 3034}, {'loss': 0.5779, 'learning_rate': 2.0833363061414752e-05, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.5071641206741333, 'eval_accuracy': 0.7566320645905421, 'eval_runtime': 12.4413, 'eval_samples_per_second': 69.688, 'eval_steps_per_second': 8.761, 'epoch': 8.0, 'step': 3468}, {'loss': 0.5596, 'learning_rate': 1.0368344261423352e-05, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.5047129392623901, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.4656, 'eval_samples_per_second': 69.552, 'eval_steps_per_second': 8.744, 'epoch': 9.0, 'step': 3901}, {'loss': 0.5592, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5044806003570557, 'eval_accuracy': 0.7589388696655133, 'eval_runtime': 12.4841, 'eval_samples_per_second': 69.448, 'eval_steps_per_second': 8.731, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 1528.6512, 'train_samples_per_second': 22.687, 'train_steps_per_second': 2.833, 'total_flos': 8648105445522240.0, 'train_loss': 0.6203284353912565, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5047129392623901, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.4115, 'eval_samples_per_second': 69.855, 'eval_steps_per_second': 8.782, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 6017027.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 24:29, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.699000</td>\n",
       "      <td>0.649077</td>\n",
       "      <td>0.695502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>0.584898</td>\n",
       "      <td>0.716263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.585200</td>\n",
       "      <td>0.538216</td>\n",
       "      <td>0.731257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.562800</td>\n",
       "      <td>0.501300</td>\n",
       "      <td>0.769319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.485238</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.506200</td>\n",
       "      <td>0.471656</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.487300</td>\n",
       "      <td>0.472879</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>0.495871</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>0.582072</td>\n",
       "      <td>0.769319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.965397923875432: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.48147228360176086, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.228, 'eval_samples_per_second': 70.903, 'eval_steps_per_second': 8.914, 'epoch': 9.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 10:40:06,034] Trial 2 finished with values: [0.48147228360176086, 0.7808535178777394] and parameters: {'lr': 0.0012503640810637153, 'batch': 4, 'accum': 8, 'dropout_rate': 0.7199713439988092, 'weight_decay': 0.00024332594426522476, 'warmup_pct': 0.2775446358093314, 'lora_rank': 4, 'lora_init_scale': 0.07579926522661985, 'lora_scaling_rank': 6}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.699, 'learning_rate': 5.61260684766755e-05, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6490774154663086, 'eval_accuracy': 0.6955017301038062, 'eval_runtime': 13.8488, 'eval_samples_per_second': 62.605, 'eval_steps_per_second': 7.871, 'epoch': 1.0, 'step': 108}, {'loss': 0.6386, 'learning_rate': 0.000112252136953351, 'epoch': 1.99, 'step': 216}, {'eval_loss': 0.584898054599762, 'eval_accuracy': 0.7162629757785467, 'eval_runtime': 12.1198, 'eval_samples_per_second': 71.536, 'eval_steps_per_second': 8.994, 'epoch': 1.99, 'step': 216}, {'loss': 0.5852, 'learning_rate': 0.000168897891249255, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.5382158160209656, 'eval_accuracy': 0.7312572087658593, 'eval_runtime': 12.1553, 'eval_samples_per_second': 71.327, 'eval_steps_per_second': 8.967, 'epoch': 3.0, 'step': 325}, {'loss': 0.5628, 'learning_rate': 0.00022502395972593049, 'epoch': 4.0, 'step': 433}, {'eval_loss': 0.5012996792793274, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 12.1157, 'eval_samples_per_second': 71.56, 'eval_steps_per_second': 8.997, 'epoch': 4.0, 'step': 433}, {'loss': 0.5381, 'learning_rate': 0.00028115002820260597, 'epoch': 4.99, 'step': 541}, {'eval_loss': 0.4852384924888611, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1409, 'eval_samples_per_second': 71.412, 'eval_steps_per_second': 8.978, 'epoch': 4.99, 'step': 541}, {'loss': 0.5062, 'learning_rate': 0.00033779578249851, 'epoch': 6.0, 'step': 650}, {'eval_loss': 0.4716556966304779, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.1229, 'eval_samples_per_second': 71.518, 'eval_steps_per_second': 8.991, 'epoch': 6.0, 'step': 650}, {'loss': 0.4873, 'learning_rate': 0.00039392185097518543, 'epoch': 6.99, 'step': 758}, {'eval_loss': 0.4728793203830719, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1275, 'eval_samples_per_second': 71.49, 'eval_steps_per_second': 8.988, 'epoch': 6.99, 'step': 758}, {'loss': 0.4462, 'learning_rate': 0.0004505676052710894, 'epoch': 8.0, 'step': 867}, {'eval_loss': 0.48147228360176086, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.1409, 'eval_samples_per_second': 71.412, 'eval_steps_per_second': 8.978, 'epoch': 8.0, 'step': 867}, {'loss': 0.4029, 'learning_rate': 0.0005066936737477649, 'epoch': 9.0, 'step': 975}, {'eval_loss': 0.4958708584308624, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.099, 'eval_samples_per_second': 71.659, 'eval_steps_per_second': 9.009, 'epoch': 9.0, 'step': 975}, {'loss': 0.3392, 'learning_rate': 0.0005612606847667551, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.5820724368095398, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 12.1419, 'eval_samples_per_second': 71.406, 'eval_steps_per_second': 8.977, 'epoch': 9.97, 'step': 1080}, {'train_runtime': 1471.2501, 'train_samples_per_second': 23.572, 'train_steps_per_second': 0.734, 'total_flos': 8558826236328960.0, 'train_loss': 0.5210253468266239, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.48147228360176086, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.228, 'eval_samples_per_second': 70.903, 'eval_steps_per_second': 8.914, 'epoch': 9.97, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 8966147.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2601' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2601/4330 15:10 < 10:05, 2.86 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.501384</td>\n",
       "      <td>0.768166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>0.506311</td>\n",
       "      <td>0.783160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.303300</td>\n",
       "      <td>0.907130</td>\n",
       "      <td>0.770473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.987812</td>\n",
       "      <td>0.782007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5063105821609497, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1014, 'eval_samples_per_second': 71.644, 'eval_steps_per_second': 9.007, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 10:56:09,884] Trial 3 finished with values: [0.5063105821609497, 0.7831603229527105] and parameters: {'lr': 0.0008810477725102257, 'batch': 4, 'accum': 2, 'dropout_rate': 0.7094520529165736, 'weight_decay': 2.8132302365672252e-05, 'warmup_pct': 0.025195812845497136, 'lora_rank': 12, 'lora_init_scale': 0.01750033378810108, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.638, 'learning_rate': 0.000834981315533159, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.5013837218284607, 'eval_accuracy': 0.7681660899653979, 'eval_runtime': 13.7977, 'eval_samples_per_second': 62.837, 'eval_steps_per_second': 7.9, 'epoch': 1.0, 'step': 433}, {'loss': 0.5428, 'learning_rate': 0.0007419913512166614, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5009746551513672, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.3529, 'eval_samples_per_second': 70.186, 'eval_steps_per_second': 8.824, 'epoch': 2.0, 'step': 867}, {'loss': 0.4834, 'learning_rate': 0.0006492156494907549, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.5063105821609497, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1207, 'eval_samples_per_second': 71.53, 'eval_steps_per_second': 8.993, 'epoch': 3.0, 'step': 1300}, {'loss': 0.3858, 'learning_rate': 0.0005562256851742573, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.6334637999534607, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1225, 'eval_samples_per_second': 71.52, 'eval_steps_per_second': 8.992, 'epoch': 4.0, 'step': 1734}, {'loss': 0.3033, 'learning_rate': 0.00046344998344835075, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.9071301221847534, 'eval_accuracy': 0.7704728950403691, 'eval_runtime': 12.1196, 'eval_samples_per_second': 71.537, 'eval_steps_per_second': 8.994, 'epoch': 5.0, 'step': 2167}, {'loss': 0.2119, 'learning_rate': 0.0003704600191318532, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.9878118634223938, 'eval_accuracy': 0.7820069204152249, 'eval_runtime': 12.1252, 'eval_samples_per_second': 71.504, 'eval_steps_per_second': 8.99, 'epoch': 6.0, 'step': 2601}, {'train_runtime': 910.6183, 'train_samples_per_second': 38.084, 'train_steps_per_second': 4.755, 'total_flos': 5165645148737568.0, 'train_loss': 0.42746640168350963, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.5063105821609497, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1014, 'eval_samples_per_second': 71.644, 'eval_steps_per_second': 9.007, 'epoch': 6.0, 'step': 2601}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2160' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2160/2160 37:54, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>0.690560</td>\n",
       "      <td>0.525952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.682100</td>\n",
       "      <td>0.672444</td>\n",
       "      <td>0.658593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.661300</td>\n",
       "      <td>0.648331</td>\n",
       "      <td>0.718570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.616800</td>\n",
       "      <td>0.599112</td>\n",
       "      <td>0.719723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.591100</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>0.718570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.569400</td>\n",
       "      <td>0.558757</td>\n",
       "      <td>0.726644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.541700</td>\n",
       "      <td>0.526394</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.520700</td>\n",
       "      <td>0.515346</td>\n",
       "      <td>0.761246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5153459906578064, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.5855, 'eval_samples_per_second': 68.889, 'eval_steps_per_second': 8.661, 'epoch': 9.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 11:34:58,024] Trial 4 finished with values: [0.5153459906578064, 0.7612456747404844] and parameters: {'lr': 2.7429739918683985e-05, 'batch': 2, 'accum': 8, 'dropout_rate': 0.11662725570417348, 'weight_decay': 1.3510283385379407e-05, 'warmup_pct': 0.22556147668738605, 'lora_rank': 28, 'lora_init_scale': 0.00017826421089376304, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6965, 'learning_rate': 1.5149127646217696e-06, 'epoch': 1.0, 'step': 216}, {'eval_loss': 0.6905604004859924, 'eval_accuracy': 0.5259515570934256, 'eval_runtime': 13.8313, 'eval_samples_per_second': 62.684, 'eval_steps_per_second': 7.881, 'epoch': 1.0, 'step': 216}, {'loss': 0.6821, 'learning_rate': 3.0368390142649364e-06, 'epoch': 2.0, 'step': 433}, {'eval_loss': 0.6724444031715393, 'eval_accuracy': 0.6585928489042676, 'eval_runtime': 12.1732, 'eval_samples_per_second': 71.222, 'eval_steps_per_second': 8.954, 'epoch': 2.0, 'step': 433}, {'loss': 0.6613, 'learning_rate': 4.5587652639081025e-06, 'epoch': 3.0, 'step': 650}, {'eval_loss': 0.6483312845230103, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.1933, 'eval_samples_per_second': 71.104, 'eval_steps_per_second': 8.939, 'epoch': 3.0, 'step': 650}, {'loss': 0.6374, 'learning_rate': 6.0806915135512695e-06, 'epoch': 4.0, 'step': 867}, {'eval_loss': 0.6228208541870117, 'eval_accuracy': 0.7162629757785467, 'eval_runtime': 12.2126, 'eval_samples_per_second': 70.992, 'eval_steps_per_second': 8.925, 'epoch': 4.0, 'step': 867}, {'loss': 0.6168, 'learning_rate': 7.595604278173039e-06, 'epoch': 5.0, 'step': 1083}, {'eval_loss': 0.599111795425415, 'eval_accuracy': 0.7197231833910035, 'eval_runtime': 12.2137, 'eval_samples_per_second': 70.986, 'eval_steps_per_second': 8.924, 'epoch': 5.0, 'step': 1083}, {'loss': 0.5911, 'learning_rate': 9.117530527816205e-06, 'epoch': 6.0, 'step': 1300}, {'eval_loss': 0.5779526233673096, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.181, 'eval_samples_per_second': 71.176, 'eval_steps_per_second': 8.948, 'epoch': 6.0, 'step': 1300}, {'loss': 0.5694, 'learning_rate': 1.0639456777459372e-05, 'epoch': 7.0, 'step': 1517}, {'eval_loss': 0.5587568879127502, 'eval_accuracy': 0.726643598615917, 'eval_runtime': 12.1988, 'eval_samples_per_second': 71.073, 'eval_steps_per_second': 8.935, 'epoch': 7.0, 'step': 1517}, {'loss': 0.5515, 'learning_rate': 1.2161383027102539e-05, 'epoch': 8.0, 'step': 1734}, {'eval_loss': 0.5423670411109924, 'eval_accuracy': 0.7393310265282583, 'eval_runtime': 12.2149, 'eval_samples_per_second': 70.979, 'eval_steps_per_second': 8.923, 'epoch': 8.0, 'step': 1734}, {'loss': 0.5417, 'learning_rate': 1.367629579172431e-05, 'epoch': 9.0, 'step': 1950}, {'eval_loss': 0.5263938307762146, 'eval_accuracy': 0.754325259515571, 'eval_runtime': 12.2073, 'eval_samples_per_second': 71.023, 'eval_steps_per_second': 8.929, 'epoch': 9.0, 'step': 1950}, {'loss': 0.5207, 'learning_rate': 1.5149127646217698e-05, 'epoch': 9.97, 'step': 2160}, {'eval_loss': 0.5153459906578064, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.182, 'eval_samples_per_second': 71.171, 'eval_steps_per_second': 8.948, 'epoch': 9.97, 'step': 2160}, {'train_runtime': 2275.2737, 'train_samples_per_second': 15.242, 'train_steps_per_second': 0.949, 'total_flos': 8624667581660160.0, 'train_loss': 0.607126956515842, 'epoch': 9.97, 'step': 2160}, {'eval_loss': 0.5153459906578064, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.5855, 'eval_samples_per_second': 68.889, 'eval_steps_per_second': 8.661, 'epoch': 9.97, 'step': 2160}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 12406787.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 18:12, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.714300</td>\n",
       "      <td>0.695676</td>\n",
       "      <td>0.477509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.709900</td>\n",
       "      <td>0.689695</td>\n",
       "      <td>0.534025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.707400</td>\n",
       "      <td>0.680298</td>\n",
       "      <td>0.621684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.685500</td>\n",
       "      <td>0.656084</td>\n",
       "      <td>0.709343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.643747</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.630438</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.631100</td>\n",
       "      <td>0.605129</td>\n",
       "      <td>0.713956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.621700</td>\n",
       "      <td>0.591674</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5916740894317627, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.2157, 'eval_samples_per_second': 70.974, 'eval_steps_per_second': 8.923, 'epoch': 9.95}\n",
      "History:  [{'loss': 0.7143, 'learning_rate': 3.0207259730167245e-06, 'epoch': 1.0, 'step': 54}, {'eval_loss': 0.6956760883331299, 'eval_accuracy': 0.47750865051903113, 'eval_runtime': 13.8055, 'eval_samples_per_second': 62.801, 'eval_steps_per_second': 7.895, 'epoch': 1.0, 'step': 54}, {'loss': 0.7099, 'learning_rate': 6.041451946033449e-06, 'epoch': 1.99, 'step': 108}, {'eval_loss': 0.6896949410438538, 'eval_accuracy': 0.5340253748558247, 'eval_runtime': 12.1777, 'eval_samples_per_second': 71.196, 'eval_steps_per_second': 8.951, 'epoch': 1.99, 'step': 108}, {'loss': 0.7074, 'learning_rate': 9.062177919050173e-06, 'epoch': 2.99, 'step': 162}, {'eval_loss': 0.6802976131439209, 'eval_accuracy': 0.621683967704729, 'eval_runtime': 12.1358, 'eval_samples_per_second': 71.441, 'eval_steps_per_second': 8.982, 'epoch': 2.99, 'step': 162}, {'loss': 0.685, 'learning_rate': 1.2138843261937579e-05, 'epoch': 4.0, 'step': 217}, {'eval_loss': 0.6684548258781433, 'eval_accuracy': 0.6735870818915801, 'eval_runtime': 12.171, 'eval_samples_per_second': 71.235, 'eval_steps_per_second': 8.956, 'epoch': 4.0, 'step': 217}, {'loss': 0.6855, 'learning_rate': 1.5159569234954302e-05, 'epoch': 5.0, 'step': 271}, {'eval_loss': 0.6560840606689453, 'eval_accuracy': 0.7093425605536332, 'eval_runtime': 12.1428, 'eval_samples_per_second': 71.4, 'eval_steps_per_second': 8.977, 'epoch': 5.0, 'step': 271}, {'loss': 0.677, 'learning_rate': 1.8180295207971026e-05, 'epoch': 5.99, 'step': 325}, {'eval_loss': 0.6437474489212036, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.1764, 'eval_samples_per_second': 71.203, 'eval_steps_per_second': 8.952, 'epoch': 5.99, 'step': 325}, {'loss': 0.6608, 'learning_rate': 2.1201021180987752e-05, 'epoch': 6.99, 'step': 379}, {'eval_loss': 0.6304383873939514, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.1542, 'eval_samples_per_second': 71.333, 'eval_steps_per_second': 8.968, 'epoch': 6.99, 'step': 379}, {'loss': 0.6347, 'learning_rate': 2.4277686523875158e-05, 'epoch': 8.0, 'step': 434}, {'eval_loss': 0.6174824833869934, 'eval_accuracy': 0.7104959630911188, 'eval_runtime': 12.1553, 'eval_samples_per_second': 71.327, 'eval_steps_per_second': 8.967, 'epoch': 8.0, 'step': 434}, {'loss': 0.6311, 'learning_rate': 2.729841249689188e-05, 'epoch': 9.0, 'step': 488}, {'eval_loss': 0.6051294207572937, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 12.1682, 'eval_samples_per_second': 71.251, 'eval_steps_per_second': 8.958, 'epoch': 9.0, 'step': 488}, {'loss': 0.6217, 'learning_rate': 3.0207259730167248e-05, 'epoch': 9.95, 'step': 540}, {'eval_loss': 0.5916740894317627, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.1444, 'eval_samples_per_second': 71.391, 'eval_steps_per_second': 8.975, 'epoch': 9.95, 'step': 540}, {'train_runtime': 1094.7198, 'train_samples_per_second': 31.679, 'train_steps_per_second': 0.493, 'total_flos': 8594913207477744.0, 'train_loss': 0.6728725857204861, 'epoch': 9.95, 'step': 540}, {'eval_loss': 0.5916740894317627, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.2157, 'eval_samples_per_second': 70.974, 'eval_steps_per_second': 8.923, 'epoch': 9.95, 'step': 540}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 11:54:05,690] Trial 5 finished with values: [0.5916740894317627, 0.7174163783160323] and parameters: {'lr': 6.080609504942925e-05, 'batch': 8, 'accum': 8, 'dropout_rate': 0.7463634565392911, 'weight_decay': 2.212635052362363e-05, 'warmup_pct': 0.25097989698030915, 'lora_rank': 20, 'lora_init_scale': 0.005454792883848043, 'lora_scaling_rank': 3}. \n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13389827.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 18:20, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.658595</td>\n",
       "      <td>0.685121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.581600</td>\n",
       "      <td>0.544177</td>\n",
       "      <td>0.739331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.517800</td>\n",
       "      <td>0.484297</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.488600</td>\n",
       "      <td>0.470537</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.469961</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.457400</td>\n",
       "      <td>0.469624</td>\n",
       "      <td>0.777393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46962377429008484, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.1172, 'eval_samples_per_second': 71.551, 'eval_steps_per_second': 8.995, 'epoch': 9.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 12:13:20,168] Trial 6 finished with values: [0.46962377429008484, 0.7773933102652826] and parameters: {'lr': 9.741175165265519e-05, 'batch': 8, 'accum': 4, 'dropout_rate': 0.410982184611112, 'weight_decay': 8.22011375337804e-05, 'warmup_pct': 0.11539407364307791, 'lora_rank': 20, 'lora_init_scale': 0.00016314225042501977, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6899, 'learning_rate': 2.1040938356973522e-05, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6585950255393982, 'eval_accuracy': 0.6851211072664359, 'eval_runtime': 13.818, 'eval_samples_per_second': 62.744, 'eval_steps_per_second': 7.888, 'epoch': 1.0, 'step': 108}, {'loss': 0.6338, 'learning_rate': 4.227670021725235e-05, 'epoch': 2.0, 'step': 217}, {'eval_loss': 0.5963749289512634, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.1438, 'eval_samples_per_second': 71.394, 'eval_steps_per_second': 8.976, 'epoch': 2.0, 'step': 217}, {'loss': 0.5816, 'learning_rate': 6.331763857422588e-05, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.5441765785217285, 'eval_accuracy': 0.7393310265282583, 'eval_runtime': 12.1446, 'eval_samples_per_second': 71.39, 'eval_steps_per_second': 8.975, 'epoch': 3.0, 'step': 325}, {'loss': 0.5334, 'learning_rate': 8.45534004345047e-05, 'epoch': 4.0, 'step': 434}, {'eval_loss': 0.5052882432937622, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1327, 'eval_samples_per_second': 71.459, 'eval_steps_per_second': 8.984, 'epoch': 4.0, 'step': 434}, {'loss': 0.5178, 'learning_rate': 9.035779722263532e-05, 'epoch': 5.0, 'step': 542}, {'eval_loss': 0.48429661989212036, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.1427, 'eval_samples_per_second': 71.401, 'eval_steps_per_second': 8.977, 'epoch': 5.0, 'step': 542}, {'loss': 0.4951, 'learning_rate': 7.205110596377427e-05, 'epoch': 6.0, 'step': 651}, {'eval_loss': 0.47419473528862, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 12.123, 'eval_samples_per_second': 71.517, 'eval_steps_per_second': 8.991, 'epoch': 6.0, 'step': 651}, {'loss': 0.4886, 'learning_rate': 5.391236600086607e-05, 'epoch': 7.0, 'step': 759}, {'eval_loss': 0.4705365300178528, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1475, 'eval_samples_per_second': 71.373, 'eval_steps_per_second': 8.973, 'epoch': 7.0, 'step': 759}, {'loss': 0.4733, 'learning_rate': 3.5605674742005e-05, 'epoch': 8.0, 'step': 868}, {'eval_loss': 0.4685320258140564, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.1215, 'eval_samples_per_second': 71.526, 'eval_steps_per_second': 8.992, 'epoch': 8.0, 'step': 868}, {'loss': 0.4684, 'learning_rate': 1.7466934779096792e-05, 'epoch': 9.0, 'step': 976}, {'eval_loss': 0.46996110677719116, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.1376, 'eval_samples_per_second': 71.431, 'eval_steps_per_second': 8.98, 'epoch': 9.0, 'step': 976}, {'loss': 0.4574, 'learning_rate': 0.0, 'epoch': 9.95, 'step': 1080}, {'eval_loss': 0.46962377429008484, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.1203, 'eval_samples_per_second': 71.533, 'eval_steps_per_second': 8.993, 'epoch': 9.95, 'step': 1080}, {'train_runtime': 1101.6707, 'train_samples_per_second': 31.479, 'train_steps_per_second': 0.98, 'total_flos': 8601836655961584.0, 'train_loss': 0.5342216950875741, 'epoch': 9.95, 'step': 1080}, {'eval_loss': 0.46962377429008484, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.1172, 'eval_samples_per_second': 71.551, 'eval_steps_per_second': 8.995, 'epoch': 9.95, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 20762627.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6936' max='17340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6936/17340 26:50 < 40:16, 4.31 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.356700</td>\n",
       "      <td>0.697409</td>\n",
       "      <td>0.532872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.948600</td>\n",
       "      <td>0.838624</td>\n",
       "      <td>0.532872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.943200</td>\n",
       "      <td>1.661899</td>\n",
       "      <td>0.467128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.856700</td>\n",
       "      <td>0.725009</td>\n",
       "      <td>0.467128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6974089741706848, 'eval_accuracy': 0.532871972318339, 'eval_runtime': 12.1407, 'eval_samples_per_second': 71.413, 'eval_steps_per_second': 8.978, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 12:41:03,518] Trial 7 finished with values: [0.6974089741706848, 0.532871972318339] and parameters: {'lr': 0.003488902870105638, 'batch': 1, 'accum': 2, 'dropout_rate': 0.445921233032751, 'weight_decay': 0.0006951853072945229, 'warmup_pct': 0.0318342806955393, 'lora_rank': 32, 'lora_init_scale': 0.0022330993921392235, 'lora_scaling_rank': 8}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.3567, 'learning_rate': 0.0033535241556336896, 'epoch': 1.0, 'step': 1734}, {'eval_loss': 0.6974089741706848, 'eval_accuracy': 0.532871972318339, 'eval_runtime': 13.8416, 'eval_samples_per_second': 62.637, 'eval_steps_per_second': 7.875, 'epoch': 1.0, 'step': 1734}, {'loss': 0.9486, 'learning_rate': 0.0029809103605632796, 'epoch': 2.0, 'step': 3468}, {'eval_loss': 0.8386238217353821, 'eval_accuracy': 0.532871972318339, 'eval_runtime': 12.1763, 'eval_samples_per_second': 71.204, 'eval_steps_per_second': 8.952, 'epoch': 2.0, 'step': 3468}, {'loss': 0.9432, 'learning_rate': 0.0026082965654928695, 'epoch': 3.0, 'step': 5202}, {'eval_loss': 1.6618987321853638, 'eval_accuracy': 0.4671280276816609, 'eval_runtime': 12.171, 'eval_samples_per_second': 71.235, 'eval_steps_per_second': 8.956, 'epoch': 3.0, 'step': 5202}, {'loss': 0.8567, 'learning_rate': 0.00223568277042246, 'epoch': 4.0, 'step': 6936}, {'eval_loss': 0.7250089645385742, 'eval_accuracy': 0.4671280276816609, 'eval_runtime': 12.1699, 'eval_samples_per_second': 71.241, 'eval_steps_per_second': 8.957, 'epoch': 4.0, 'step': 6936}, {'train_runtime': 1610.6312, 'train_samples_per_second': 21.532, 'train_steps_per_second': 10.766, 'total_flos': 3477146149685952.0, 'train_loss': 1.026306997120999, 'epoch': 4.0, 'step': 6936}, {'eval_loss': 0.6974089741706848, 'eval_accuracy': 0.532871972318339, 'eval_runtime': 12.1407, 'eval_samples_per_second': 71.413, 'eval_steps_per_second': 8.978, 'epoch': 4.0, 'step': 6936}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 18796547.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2170' max='2170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2170/2170 18:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.662600</td>\n",
       "      <td>0.610622</td>\n",
       "      <td>0.716263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.596600</td>\n",
       "      <td>0.566639</td>\n",
       "      <td>0.730104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.562400</td>\n",
       "      <td>0.542956</td>\n",
       "      <td>0.745098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>0.528132</td>\n",
       "      <td>0.752018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.533600</td>\n",
       "      <td>0.518131</td>\n",
       "      <td>0.760092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.527400</td>\n",
       "      <td>0.512817</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.522400</td>\n",
       "      <td>0.506105</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.503390</td>\n",
       "      <td>0.769319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.512900</td>\n",
       "      <td>0.501940</td>\n",
       "      <td>0.770473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.501128</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5011276006698608, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.2766, 'eval_samples_per_second': 70.622, 'eval_steps_per_second': 8.879, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 13:00:41,296] Trial 8 finished with values: [0.5011276006698608, 0.7716262975778547] and parameters: {'lr': 2.7857512832582767e-05, 'batch': 8, 'accum': 2, 'dropout_rate': 0.39189323103060525, 'weight_decay': 0.00016125523015716014, 'warmup_pct': 0.019498689030115708, 'lora_rank': 32, 'lora_init_scale': 0.0012783874660457553, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6626, 'learning_rate': 2.60813626855389e-05, 'epoch': 1.0, 'step': 217}, {'eval_loss': 0.6106218695640564, 'eval_accuracy': 0.7162629757785467, 'eval_runtime': 13.9112, 'eval_samples_per_second': 62.324, 'eval_steps_per_second': 7.835, 'epoch': 1.0, 'step': 217}, {'loss': 0.5966, 'learning_rate': 2.31834334982568e-05, 'epoch': 2.0, 'step': 434}, {'eval_loss': 0.5666386485099792, 'eval_accuracy': 0.7301038062283737, 'eval_runtime': 12.1588, 'eval_samples_per_second': 71.306, 'eval_steps_per_second': 8.965, 'epoch': 2.0, 'step': 434}, {'loss': 0.5624, 'learning_rate': 2.02855043109747e-05, 'epoch': 3.0, 'step': 651}, {'eval_loss': 0.5429564714431763, 'eval_accuracy': 0.7450980392156863, 'eval_runtime': 12.1882, 'eval_samples_per_second': 71.134, 'eval_steps_per_second': 8.943, 'epoch': 3.0, 'step': 651}, {'loss': 0.5407, 'learning_rate': 1.73875751236926e-05, 'epoch': 4.0, 'step': 868}, {'eval_loss': 0.5281320810317993, 'eval_accuracy': 0.7520184544405998, 'eval_runtime': 12.1582, 'eval_samples_per_second': 71.31, 'eval_steps_per_second': 8.965, 'epoch': 4.0, 'step': 868}, {'loss': 0.5336, 'learning_rate': 1.44896459364105e-05, 'epoch': 5.0, 'step': 1085}, {'eval_loss': 0.518130898475647, 'eval_accuracy': 0.7600922722029988, 'eval_runtime': 12.1767, 'eval_samples_per_second': 71.201, 'eval_steps_per_second': 8.952, 'epoch': 5.0, 'step': 1085}, {'loss': 0.5274, 'learning_rate': 1.15917167491284e-05, 'epoch': 6.0, 'step': 1302}, {'eval_loss': 0.5128165483474731, 'eval_accuracy': 0.7577854671280276, 'eval_runtime': 12.1692, 'eval_samples_per_second': 71.245, 'eval_steps_per_second': 8.957, 'epoch': 6.0, 'step': 1302}, {'loss': 0.5224, 'learning_rate': 8.6937875618463e-06, 'epoch': 7.0, 'step': 1519}, {'eval_loss': 0.5061051249504089, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.1617, 'eval_samples_per_second': 71.289, 'eval_steps_per_second': 8.963, 'epoch': 7.0, 'step': 1519}, {'loss': 0.5168, 'learning_rate': 5.7958583745642e-06, 'epoch': 8.0, 'step': 1736}, {'eval_loss': 0.5033898949623108, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 12.1764, 'eval_samples_per_second': 71.203, 'eval_steps_per_second': 8.952, 'epoch': 8.0, 'step': 1736}, {'loss': 0.5129, 'learning_rate': 2.8979291872821e-06, 'epoch': 9.0, 'step': 1953}, {'eval_loss': 0.5019400119781494, 'eval_accuracy': 0.7704728950403691, 'eval_runtime': 12.1639, 'eval_samples_per_second': 71.277, 'eval_steps_per_second': 8.961, 'epoch': 9.0, 'step': 1953}, {'loss': 0.514, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 2170}, {'eval_loss': 0.5011276006698608, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1803, 'eval_samples_per_second': 71.18, 'eval_steps_per_second': 8.949, 'epoch': 10.0, 'step': 2170}, {'train_runtime': 1123.4069, 'train_samples_per_second': 30.87, 'train_steps_per_second': 1.932, 'total_flos': 8678955908717280.0, 'train_loss': 0.5489489049955447, 'epoch': 10.0, 'step': 2170}, {'eval_loss': 0.5011276006698608, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.2766, 'eval_samples_per_second': 70.622, 'eval_steps_per_second': 8.879, 'epoch': 10.0, 'step': 2170}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 9457667.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 38:14, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.690202</td>\n",
       "      <td>0.530565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.665400</td>\n",
       "      <td>0.646689</td>\n",
       "      <td>0.710496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.617300</td>\n",
       "      <td>0.596289</td>\n",
       "      <td>0.718570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.573400</td>\n",
       "      <td>0.560306</td>\n",
       "      <td>0.726644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.547031</td>\n",
       "      <td>0.731257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.555800</td>\n",
       "      <td>0.545329</td>\n",
       "      <td>0.735871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5453286170959473, 'eval_accuracy': 0.7358708189158016, 'eval_runtime': 12.2192, 'eval_samples_per_second': 70.954, 'eval_steps_per_second': 8.92, 'epoch': 9.99}\n",
      "History:  [{'loss': 0.6974, 'learning_rate': 1.7732797878062975e-06, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6902021765708923, 'eval_accuracy': 0.5305651672433679, 'eval_runtime': 13.8106, 'eval_samples_per_second': 62.778, 'eval_steps_per_second': 7.893, 'epoch': 1.0, 'step': 433}, {'loss': 0.6839, 'learning_rate': 3.55065490999552e-06, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.6714340448379517, 'eval_accuracy': 0.6632064590542099, 'eval_runtime': 12.2496, 'eval_samples_per_second': 70.778, 'eval_steps_per_second': 8.898, 'epoch': 2.0, 'step': 867}, {'loss': 0.6654, 'learning_rate': 5.323934697801817e-06, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.6466893553733826, 'eval_accuracy': 0.7104959630911188, 'eval_runtime': 12.1286, 'eval_samples_per_second': 71.484, 'eval_steps_per_second': 8.987, 'epoch': 3.0, 'step': 1300}, {'loss': 0.64, 'learning_rate': 7.10130981999104e-06, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.6207638382911682, 'eval_accuracy': 0.7116493656286044, 'eval_runtime': 12.1194, 'eval_samples_per_second': 71.538, 'eval_steps_per_second': 8.994, 'epoch': 4.0, 'step': 1734}, {'loss': 0.6173, 'learning_rate': 8.874589607797337e-06, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5962885022163391, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.1291, 'eval_samples_per_second': 71.481, 'eval_steps_per_second': 8.987, 'epoch': 5.0, 'step': 2167}, {'loss': 0.5965, 'learning_rate': 1.0105269728140448e-05, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.5751367807388306, 'eval_accuracy': 0.7197231833910035, 'eval_runtime': 12.1694, 'eval_samples_per_second': 71.244, 'eval_steps_per_second': 8.957, 'epoch': 6.0, 'step': 2601}, {'loss': 0.5734, 'learning_rate': 7.574568865049172e-06, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.5603064298629761, 'eval_accuracy': 0.726643598615917, 'eval_runtime': 12.124, 'eval_samples_per_second': 71.511, 'eval_steps_per_second': 8.99, 'epoch': 7.0, 'step': 3034}, {'loss': 0.5601, 'learning_rate': 5.038023427216348e-06, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.5518162846565247, 'eval_accuracy': 0.726643598615917, 'eval_runtime': 12.1218, 'eval_samples_per_second': 71.524, 'eval_steps_per_second': 8.992, 'epoch': 8.0, 'step': 3468}, {'loss': 0.561, 'learning_rate': 2.507322564125073e-06, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.5470306277275085, 'eval_accuracy': 0.7312572087658593, 'eval_runtime': 12.1167, 'eval_samples_per_second': 71.554, 'eval_steps_per_second': 8.996, 'epoch': 9.0, 'step': 3901}, {'loss': 0.5558, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5453286170959473, 'eval_accuracy': 0.7358708189158016, 'eval_runtime': 12.1052, 'eval_samples_per_second': 71.622, 'eval_steps_per_second': 9.004, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 2294.9162, 'train_samples_per_second': 15.112, 'train_steps_per_second': 1.887, 'total_flos': 8602951823096640.0, 'train_loss': 0.6151437455457022, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5453286170959473, 'eval_accuracy': 0.7358708189158016, 'eval_runtime': 12.2192, 'eval_samples_per_second': 70.954, 'eval_steps_per_second': 8.92, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 13:39:51,961] Trial 9 finished with values: [0.5453286170959473, 0.7358708189158016] and parameters: {'lr': 1.0426721338925713e-05, 'batch': 2, 'accum': 4, 'dropout_rate': 0.4748596845801991, 'weight_decay': 0.00015750528343988309, 'warmup_pct': 0.14682840320265267, 'lora_rank': 16, 'lora_init_scale': 0.00010609772427179262, 'lora_scaling_rank': 1}. \n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 7983107.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 24:31, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.671192</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.622122</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.601300</td>\n",
       "      <td>0.577509</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.570600</td>\n",
       "      <td>0.541891</td>\n",
       "      <td>0.741638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.539600</td>\n",
       "      <td>0.513356</td>\n",
       "      <td>0.760092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.511300</td>\n",
       "      <td>0.492808</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.503500</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>0.772780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>0.478434</td>\n",
       "      <td>0.762399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.453900</td>\n",
       "      <td>0.474064</td>\n",
       "      <td>0.772780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47406354546546936, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.0897, 'eval_samples_per_second': 71.714, 'eval_steps_per_second': 9.016, 'epoch': 9.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 14:05:16,910] Trial 10 finished with values: [0.47406354546546936, 0.7727797001153403] and parameters: {'lr': 0.00017217988685369333, 'batch': 4, 'accum': 8, 'dropout_rate': 0.2506796479437915, 'weight_decay': 4.1002548507731495e-05, 'warmup_pct': 0.19855362274271587, 'lora_rank': 8, 'lora_init_scale': 0.08991398196540609, 'lora_scaling_rank': 6}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6914, 'learning_rate': 1.0805013236605973e-05, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6711915135383606, 'eval_accuracy': 0.6470588235294118, 'eval_runtime': 13.7737, 'eval_samples_per_second': 62.946, 'eval_steps_per_second': 7.914, 'epoch': 1.0, 'step': 108}, {'loss': 0.653, 'learning_rate': 2.1610026473211947e-05, 'epoch': 1.99, 'step': 216}, {'eval_loss': 0.6221221685409546, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.1138, 'eval_samples_per_second': 71.571, 'eval_steps_per_second': 8.998, 'epoch': 1.99, 'step': 216}, {'loss': 0.6013, 'learning_rate': 3.251508612867538e-05, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.5775094628334045, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.1136, 'eval_samples_per_second': 71.572, 'eval_steps_per_second': 8.998, 'epoch': 3.0, 'step': 325}, {'loss': 0.5706, 'learning_rate': 4.3320099365281355e-05, 'epoch': 4.0, 'step': 433}, {'eval_loss': 0.5418911576271057, 'eval_accuracy': 0.7416378316032295, 'eval_runtime': 12.1162, 'eval_samples_per_second': 71.557, 'eval_steps_per_second': 8.996, 'epoch': 4.0, 'step': 433}, {'loss': 0.5396, 'learning_rate': 5.412511260188732e-05, 'epoch': 4.99, 'step': 541}, {'eval_loss': 0.5133557319641113, 'eval_accuracy': 0.7600922722029988, 'eval_runtime': 12.1137, 'eval_samples_per_second': 71.572, 'eval_steps_per_second': 8.998, 'epoch': 4.99, 'step': 541}, {'loss': 0.5113, 'learning_rate': 6.503017225735076e-05, 'epoch': 6.0, 'step': 650}, {'eval_loss': 0.4928078353404999, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.11, 'eval_samples_per_second': 71.594, 'eval_steps_per_second': 9.001, 'epoch': 6.0, 'step': 650}, {'loss': 0.5035, 'learning_rate': 7.583518549395674e-05, 'epoch': 6.99, 'step': 758}, {'eval_loss': 0.4836598336696625, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.1198, 'eval_samples_per_second': 71.536, 'eval_steps_per_second': 8.994, 'epoch': 6.99, 'step': 758}, {'loss': 0.4815, 'learning_rate': 8.674024514942017e-05, 'epoch': 8.0, 'step': 867}, {'eval_loss': 0.48582154512405396, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.113, 'eval_samples_per_second': 71.576, 'eval_steps_per_second': 8.999, 'epoch': 8.0, 'step': 867}, {'loss': 0.4726, 'learning_rate': 9.754525838602615e-05, 'epoch': 9.0, 'step': 975}, {'eval_loss': 0.4784338176250458, 'eval_accuracy': 0.76239907727797, 'eval_runtime': 12.1161, 'eval_samples_per_second': 71.558, 'eval_steps_per_second': 8.996, 'epoch': 9.0, 'step': 975}, {'loss': 0.4539, 'learning_rate': 0.00010805013236605973, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.47406354546546936, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.107, 'eval_samples_per_second': 71.611, 'eval_steps_per_second': 9.003, 'epoch': 9.97, 'step': 1080}, {'train_runtime': 1472.3775, 'train_samples_per_second': 23.554, 'train_steps_per_second': 0.734, 'total_flos': 8572687572188160.0, 'train_loss': 0.5480722250761809, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.47406354546546936, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.0897, 'eval_samples_per_second': 71.714, 'eval_steps_per_second': 9.016, 'epoch': 9.97, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 5525507.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 25:13, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.619700</td>\n",
       "      <td>0.513237</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.551200</td>\n",
       "      <td>0.471431</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.441800</td>\n",
       "      <td>0.520613</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.324900</td>\n",
       "      <td>0.789064</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.986994</td>\n",
       "      <td>0.786621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.144500</td>\n",
       "      <td>1.100539</td>\n",
       "      <td>0.790081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.9660893082618713, 'eval_accuracy': 0.7912341407151096, 'eval_runtime': 12.2798, 'eval_samples_per_second': 70.604, 'eval_steps_per_second': 8.876, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 14:31:23,536] Trial 11 finished with values: [0.9660893082618713, 0.7912341407151096] and parameters: {'lr': 0.0017007276558301762, 'batch': 4, 'accum': 2, 'dropout_rate': 0.5912121439542763, 'weight_decay': 1.7695724868609444e-05, 'warmup_pct': 0.08557794125611791, 'lora_rank': 4, 'lora_init_scale': 0.00012360041069115667, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6197, 'learning_rate': 0.0009938125168346373, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.5132373571395874, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 13.8524, 'eval_samples_per_second': 62.589, 'eval_steps_per_second': 7.869, 'epoch': 1.0, 'step': 433}, {'loss': 0.5877, 'learning_rate': 0.0016410197470437169, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.4990178346633911, 'eval_accuracy': 0.7566320645905421, 'eval_runtime': 12.2526, 'eval_samples_per_second': 70.761, 'eval_steps_per_second': 8.896, 'epoch': 2.0, 'step': 867}, {'loss': 0.5512, 'learning_rate': 0.0014358330446267579, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.47143104672431946, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.1192, 'eval_samples_per_second': 71.54, 'eval_steps_per_second': 8.994, 'epoch': 3.0, 'step': 1300}, {'loss': 0.4869, 'learning_rate': 0.0012301724699178426, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.49834349751472473, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.1318, 'eval_samples_per_second': 71.465, 'eval_steps_per_second': 8.985, 'epoch': 4.0, 'step': 1734}, {'loss': 0.4418, 'learning_rate': 0.0010249857675008836, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5206127762794495, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1212, 'eval_samples_per_second': 71.527, 'eval_steps_per_second': 8.992, 'epoch': 5.0, 'step': 2167}, {'loss': 0.359, 'learning_rate': 0.0008193251927919684, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.6332070231437683, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1342, 'eval_samples_per_second': 71.451, 'eval_steps_per_second': 8.983, 'epoch': 6.0, 'step': 2601}, {'loss': 0.3249, 'learning_rate': 0.0006141384903750092, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.7890641093254089, 'eval_accuracy': 0.7647058823529411, 'eval_runtime': 12.1265, 'eval_samples_per_second': 71.497, 'eval_steps_per_second': 8.989, 'epoch': 7.0, 'step': 3034}, {'loss': 0.2392, 'learning_rate': 0.00040847791566609414, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.9660893082618713, 'eval_accuracy': 0.7912341407151096, 'eval_runtime': 12.1243, 'eval_samples_per_second': 71.51, 'eval_steps_per_second': 8.99, 'epoch': 8.0, 'step': 3468}, {'loss': 0.1988, 'learning_rate': 0.00020329121324913501, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.9869940876960754, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.1438, 'eval_samples_per_second': 71.395, 'eval_steps_per_second': 8.976, 'epoch': 9.0, 'step': 3901}, {'loss': 0.1445, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 1.1005394458770752, 'eval_accuracy': 0.790080738177624, 'eval_runtime': 12.1149, 'eval_samples_per_second': 71.565, 'eval_steps_per_second': 8.997, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 1513.3606, 'train_samples_per_second': 22.916, 'train_steps_per_second': 2.861, 'total_flos': 8575164978527040.0, 'train_loss': 0.395638876864321, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.9660893082618713, 'eval_accuracy': 0.7912341407151096, 'eval_runtime': 12.2798, 'eval_samples_per_second': 70.604, 'eval_steps_per_second': 8.876, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 7491587.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 24:51, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.589100</td>\n",
       "      <td>0.495428</td>\n",
       "      <td>0.749712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.499200</td>\n",
       "      <td>0.550767</td>\n",
       "      <td>0.737024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.321600</td>\n",
       "      <td>0.647373</td>\n",
       "      <td>0.792388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>1.296712</td>\n",
       "      <td>0.795848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>1.699357</td>\n",
       "      <td>0.803922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>1.786019</td>\n",
       "      <td>0.806228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 1.6030584573745728, 'eval_accuracy': 0.8073817762399077, 'eval_runtime': 12.1122, 'eval_samples_per_second': 71.581, 'eval_steps_per_second': 8.999, 'epoch': 9.99}\n",
      "History:  [{'loss': 0.5891, 'learning_rate': 0.000600875883008678, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.49542805552482605, 'eval_accuracy': 0.7497116493656286, 'eval_runtime': 13.855, 'eval_samples_per_second': 62.577, 'eval_steps_per_second': 7.867, 'epoch': 1.0, 'step': 433}, {'loss': 0.5318, 'learning_rate': 0.0012031394701351587, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5047907829284668, 'eval_accuracy': 0.7681660899653979, 'eval_runtime': 12.417, 'eval_samples_per_second': 69.824, 'eval_steps_per_second': 8.778, 'epoch': 2.0, 'step': 867}, {'loss': 0.4992, 'learning_rate': 0.0012235628006846489, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.5507667660713196, 'eval_accuracy': 0.7370242214532872, 'eval_runtime': 12.1352, 'eval_samples_per_second': 71.445, 'eval_steps_per_second': 8.982, 'epoch': 3.0, 'step': 1300}, {'loss': 0.4193, 'learning_rate': 0.0010483066107516, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.6031402349472046, 'eval_accuracy': 0.7797001153402537, 'eval_runtime': 12.14, 'eval_samples_per_second': 71.417, 'eval_steps_per_second': 8.979, 'epoch': 4.0, 'step': 1734}, {'loss': 0.3216, 'learning_rate': 0.0008734542369243878, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.6473729610443115, 'eval_accuracy': 0.7923875432525952, 'eval_runtime': 12.1266, 'eval_samples_per_second': 71.496, 'eval_steps_per_second': 8.989, 'epoch': 5.0, 'step': 2167}, {'loss': 0.2183, 'learning_rate': 0.0006981980469913392, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 1.0801066160202026, 'eval_accuracy': 0.7912341407151096, 'eval_runtime': 12.1562, 'eval_samples_per_second': 71.322, 'eval_steps_per_second': 8.967, 'epoch': 6.0, 'step': 2601}, {'loss': 0.1659, 'learning_rate': 0.000523345673164127, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 1.2967115640640259, 'eval_accuracy': 0.7958477508650519, 'eval_runtime': 12.1394, 'eval_samples_per_second': 71.42, 'eval_steps_per_second': 8.979, 'epoch': 7.0, 'step': 3034}, {'loss': 0.0959, 'learning_rate': 0.0003480894832310783, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 1.6030584573745728, 'eval_accuracy': 0.8073817762399077, 'eval_runtime': 12.1497, 'eval_samples_per_second': 71.36, 'eval_steps_per_second': 8.971, 'epoch': 8.0, 'step': 3468}, {'loss': 0.0658, 'learning_rate': 0.00017323710940386612, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 1.6993566751480103, 'eval_accuracy': 0.803921568627451, 'eval_runtime': 12.145, 'eval_samples_per_second': 71.388, 'eval_steps_per_second': 8.975, 'epoch': 9.0, 'step': 3901}, {'loss': 0.0331, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 1.7860190868377686, 'eval_accuracy': 0.8062283737024222, 'eval_runtime': 12.146, 'eval_samples_per_second': 71.382, 'eval_steps_per_second': 8.974, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 1491.9477, 'train_samples_per_second': 23.245, 'train_steps_per_second': 2.902, 'total_flos': 8589058400811840.0, 'train_loss': 0.29425881145732785, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 1.6030584573745728, 'eval_accuracy': 0.8073817762399077, 'eval_runtime': 12.1122, 'eval_samples_per_second': 71.581, 'eval_steps_per_second': 8.999, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 14:57:09,284] Trial 12 finished with values: [1.6030584573745728, 0.8073817762399077] and parameters: {'lr': 0.0013543992189756805, 'batch': 4, 'accum': 2, 'dropout_rate': 0.13587545441638396, 'weight_decay': 5.237543549739713e-05, 'warmup_pct': 0.11257683544453856, 'lora_rank': 12, 'lora_init_scale': 0.0008342401720737065, 'lora_scaling_rank': 1}. \n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 10440707.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 39:04, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.612449</td>\n",
       "      <td>0.712803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>0.492470</td>\n",
       "      <td>0.758939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.512558</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.448700</td>\n",
       "      <td>0.509526</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>0.560017</td>\n",
       "      <td>0.790081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.764132</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5600172281265259, 'eval_accuracy': 0.790080738177624, 'eval_runtime': 12.241, 'eval_samples_per_second': 70.828, 'eval_steps_per_second': 8.905, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 15:37:09,749] Trial 13 finished with values: [0.5600172281265259, 0.790080738177624] and parameters: {'lr': 0.0002961775717294789, 'batch': 2, 'accum': 4, 'dropout_rate': 0.4302902527418263, 'weight_decay': 2.6661703110606258e-05, 'warmup_pct': 0.2310492292719728, 'lora_rank': 16, 'lora_init_scale': 0.022315586481149657, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.67, 'learning_rate': 3.201320233621178e-05, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6124491691589355, 'eval_accuracy': 0.71280276816609, 'eval_runtime': 13.8255, 'eval_samples_per_second': 62.71, 'eval_steps_per_second': 7.884, 'epoch': 1.0, 'step': 433}, {'loss': 0.5819, 'learning_rate': 6.410033816511688e-05, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5307042598724365, 'eval_accuracy': 0.748558246828143, 'eval_runtime': 12.1877, 'eval_samples_per_second': 71.137, 'eval_steps_per_second': 8.943, 'epoch': 2.0, 'step': 867}, {'loss': 0.5337, 'learning_rate': 9.611354050132866e-05, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.49247029423713684, 'eval_accuracy': 0.7589388696655133, 'eval_runtime': 12.1602, 'eval_samples_per_second': 71.298, 'eval_steps_per_second': 8.964, 'epoch': 3.0, 'step': 1300}, {'loss': 0.5048, 'learning_rate': 0.00012820067633023376, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.47576770186424255, 'eval_accuracy': 0.7635524798154556, 'eval_runtime': 12.1524, 'eval_samples_per_second': 71.344, 'eval_steps_per_second': 8.969, 'epoch': 4.0, 'step': 1734}, {'loss': 0.4986, 'learning_rate': 0.00016021387866644554, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5125581622123718, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.1463, 'eval_samples_per_second': 71.38, 'eval_steps_per_second': 8.974, 'epoch': 5.0, 'step': 2167}, {'loss': 0.4784, 'learning_rate': 0.00019230101449535064, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.49828872084617615, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 12.1454, 'eval_samples_per_second': 71.385, 'eval_steps_per_second': 8.975, 'epoch': 6.0, 'step': 2601}, {'loss': 0.4487, 'learning_rate': 0.00022431421683156242, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.5095263123512268, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1632, 'eval_samples_per_second': 71.281, 'eval_steps_per_second': 8.961, 'epoch': 7.0, 'step': 3034}, {'loss': 0.4096, 'learning_rate': 0.0002564013526604675, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.515697181224823, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.1655, 'eval_samples_per_second': 71.267, 'eval_steps_per_second': 8.96, 'epoch': 8.0, 'step': 3468}, {'loss': 0.363, 'learning_rate': 0.00028841455499667933, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.5600172281265259, 'eval_accuracy': 0.790080738177624, 'eval_runtime': 12.1532, 'eval_samples_per_second': 71.339, 'eval_steps_per_second': 8.969, 'epoch': 9.0, 'step': 3901}, {'loss': 0.3028, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.7641316652297974, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1544, 'eval_samples_per_second': 71.332, 'eval_steps_per_second': 8.968, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 2345.3239, 'train_samples_per_second': 14.787, 'train_steps_per_second': 1.846, 'total_flos': 8609898534239040.0, 'train_loss': 0.4793419148575076, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5600172281265259, 'eval_accuracy': 0.790080738177624, 'eval_runtime': 12.241, 'eval_samples_per_second': 70.828, 'eval_steps_per_second': 8.905, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 20762627.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3034' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3034/4330 17:49 < 07:37, 2.83 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.615800</td>\n",
       "      <td>0.510056</td>\n",
       "      <td>0.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.728950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.634300</td>\n",
       "      <td>0.554237</td>\n",
       "      <td>0.686275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.599600</td>\n",
       "      <td>0.626010</td>\n",
       "      <td>0.678201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 6.9988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.9988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5197371244430542, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.228, 'eval_samples_per_second': 70.903, 'eval_steps_per_second': 8.914, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 15:55:54,785] Trial 14 finished with values: [0.5197371244430542, 0.7716262975778547] and parameters: {'lr': 0.0029073895670711004, 'batch': 4, 'accum': 2, 'dropout_rate': 0.5950449403198204, 'weight_decay': 1.4692382946264017e-05, 'warmup_pct': 0.26774223987597806, 'lora_rank': 32, 'lora_init_scale': 0.010004801704867143, 'lora_scaling_rank': 8}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6158, 'learning_rate': 0.0005423953823962889, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.5100557804107666, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 13.8956, 'eval_samples_per_second': 62.394, 'eval_steps_per_second': 7.844, 'epoch': 1.0, 'step': 433}, {'loss': 0.5665, 'learning_rate': 0.0010860434100175113, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5227491855621338, 'eval_accuracy': 0.76239907727797, 'eval_runtime': 12.1795, 'eval_samples_per_second': 71.185, 'eval_steps_per_second': 8.949, 'epoch': 2.0, 'step': 867}, {'loss': 0.5515, 'learning_rate': 0.0016284387924138002, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.5340721607208252, 'eval_accuracy': 0.7289504036908881, 'eval_runtime': 12.1606, 'eval_samples_per_second': 71.296, 'eval_steps_per_second': 8.963, 'epoch': 3.0, 'step': 1300}, {'loss': 0.5251, 'learning_rate': 0.0021720868200350227, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.5197371244430542, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1529, 'eval_samples_per_second': 71.341, 'eval_steps_per_second': 8.969, 'epoch': 4.0, 'step': 1734}, {'loss': 0.6343, 'learning_rate': 0.0027144822024313116, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5542365908622742, 'eval_accuracy': 0.6862745098039216, 'eval_runtime': 12.1877, 'eval_samples_per_second': 71.137, 'eval_steps_per_second': 8.943, 'epoch': 5.0, 'step': 2167}, {'loss': 0.6258, 'learning_rate': 0.002502178477583839, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.6569838523864746, 'eval_accuracy': 0.6678200692041523, 'eval_runtime': 12.1712, 'eval_samples_per_second': 71.234, 'eval_steps_per_second': 8.956, 'epoch': 6.0, 'step': 2601}, {'loss': 0.5996, 'learning_rate': 0.0018755484713410381, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.6260102391242981, 'eval_accuracy': 0.6782006920415224, 'eval_runtime': 12.1757, 'eval_samples_per_second': 71.208, 'eval_steps_per_second': 8.952, 'epoch': 7.0, 'step': 3034}, {'train_runtime': 1070.0698, 'train_samples_per_second': 32.409, 'train_steps_per_second': 4.046, 'total_flos': 6085005761950416.0, 'train_loss': 0.588367263502248, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.5197371244430542, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.228, 'eval_samples_per_second': 70.903, 'eval_steps_per_second': 8.914, 'epoch': 7.0, 'step': 3034}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 40:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.639300</td>\n",
       "      <td>0.511262</td>\n",
       "      <td>0.756632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.594500</td>\n",
       "      <td>0.504704</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.570700</td>\n",
       "      <td>0.567855</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.572300</td>\n",
       "      <td>0.901183</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.574800</td>\n",
       "      <td>0.582358</td>\n",
       "      <td>0.782007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>0.877928</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.400600</td>\n",
       "      <td>0.986768</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>1.248542</td>\n",
       "      <td>0.787774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>1.169265</td>\n",
       "      <td>0.788927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>1.361581</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1692651510238647, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.101, 'eval_samples_per_second': 71.647, 'eval_steps_per_second': 9.008, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 16:36:50,567] Trial 15 finished with values: [1.1692651510238647, 0.7889273356401384] and parameters: {'lr': 0.000972482262056014, 'batch': 2, 'accum': 2, 'dropout_rate': 0.6478358562211909, 'weight_decay': 2.6745850083470124e-05, 'warmup_pct': 0.2285211298578528, 'lora_rank': 24, 'lora_init_scale': 0.00018857623865166026, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6393, 'learning_rate': 0.00021280719868817875, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.5112622976303101, 'eval_accuracy': 0.7566320645905421, 'eval_runtime': 13.8275, 'eval_samples_per_second': 62.701, 'eval_steps_per_second': 7.883, 'epoch': 1.0, 'step': 867}, {'loss': 0.5945, 'learning_rate': 0.0004256143973763575, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.5047042965888977, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.1709, 'eval_samples_per_second': 71.236, 'eval_steps_per_second': 8.956, 'epoch': 2.0, 'step': 1734}, {'loss': 0.5707, 'learning_rate': 0.0006384215960645362, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.5678554773330688, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.2031, 'eval_samples_per_second': 71.047, 'eval_steps_per_second': 8.932, 'epoch': 3.0, 'step': 2601}, {'loss': 0.5723, 'learning_rate': 0.000851228794752715, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.9011834263801575, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1658, 'eval_samples_per_second': 71.265, 'eval_steps_per_second': 8.96, 'epoch': 4.0, 'step': 3468}, {'loss': 0.5748, 'learning_rate': 0.0008954355577767249, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5823583006858826, 'eval_accuracy': 0.7820069204152249, 'eval_runtime': 12.1492, 'eval_samples_per_second': 71.363, 'eval_steps_per_second': 8.972, 'epoch': 5.0, 'step': 4335}, {'loss': 0.5093, 'learning_rate': 0.00071634844622138, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.8779280185699463, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.1434, 'eval_samples_per_second': 71.397, 'eval_steps_per_second': 8.976, 'epoch': 6.0, 'step': 5202}, {'loss': 0.4006, 'learning_rate': 0.0005372613346660349, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.9867682456970215, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.1779, 'eval_samples_per_second': 71.195, 'eval_steps_per_second': 8.951, 'epoch': 7.0, 'step': 6069}, {'loss': 0.3076, 'learning_rate': 0.00035817422311069, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 1.2485424280166626, 'eval_accuracy': 0.7877739331026529, 'eval_runtime': 12.1336, 'eval_samples_per_second': 71.455, 'eval_steps_per_second': 8.983, 'epoch': 8.0, 'step': 6936}, {'loss': 0.2192, 'learning_rate': 0.000179087111555345, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 1.1692651510238647, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.1438, 'eval_samples_per_second': 71.394, 'eval_steps_per_second': 8.976, 'epoch': 9.0, 'step': 7803}, {'loss': 0.1544, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 1.3615809679031372, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1432, 'eval_samples_per_second': 71.398, 'eval_steps_per_second': 8.976, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 2402.9752, 'train_samples_per_second': 14.432, 'train_steps_per_second': 3.608, 'total_flos': 8654614344096480.0, 'train_loss': 0.4542701026010128, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 1.1692651510238647, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.101, 'eval_samples_per_second': 71.647, 'eval_steps_per_second': 9.008, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 20762627.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 25:27, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.669400</td>\n",
       "      <td>0.615327</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.535200</td>\n",
       "      <td>0.514450</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.501300</td>\n",
       "      <td>0.490668</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.486900</td>\n",
       "      <td>0.483202</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.474100</td>\n",
       "      <td>0.481677</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.481871</td>\n",
       "      <td>0.772780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4816770553588867, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1896, 'eval_samples_per_second': 71.126, 'eval_steps_per_second': 8.942, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 17:03:10,645] Trial 16 finished with values: [0.4816770553588867, 0.7716262975778547] and parameters: {'lr': 2.7872807374972613e-05, 'batch': 4, 'accum': 2, 'dropout_rate': 0.1271500923890403, 'weight_decay': 0.00016140349133256677, 'warmup_pct': 0.07067302585418075, 'lora_rank': 32, 'lora_init_scale': 0.04528129489724986, 'lora_scaling_rank': 8}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6694, 'learning_rate': 1.9720466655822126e-05, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6153268218040466, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 13.9041, 'eval_samples_per_second': 62.356, 'eval_steps_per_second': 7.839, 'epoch': 1.0, 'step': 433}, {'loss': 0.5805, 'learning_rate': 2.5961143609341085e-05, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5390207171440125, 'eval_accuracy': 0.7439446366782007, 'eval_runtime': 12.2069, 'eval_samples_per_second': 71.026, 'eval_steps_per_second': 8.929, 'epoch': 2.0, 'step': 867}, {'loss': 0.5352, 'learning_rate': 2.271506356809226e-05, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.5144504308700562, 'eval_accuracy': 0.7577854671280276, 'eval_runtime': 12.1875, 'eval_samples_per_second': 71.138, 'eval_steps_per_second': 8.944, 'epoch': 3.0, 'step': 1300}, {'loss': 0.5158, 'learning_rate': 1.9461486806193896e-05, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.4968010187149048, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1669, 'eval_samples_per_second': 71.259, 'eval_steps_per_second': 8.959, 'epoch': 4.0, 'step': 1734}, {'loss': 0.5013, 'learning_rate': 1.6215406764945067e-05, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.4906676411628723, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.1653, 'eval_samples_per_second': 71.268, 'eval_steps_per_second': 8.96, 'epoch': 5.0, 'step': 2167}, {'loss': 0.4889, 'learning_rate': 1.2961830003046705e-05, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.4857884645462036, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.1719, 'eval_samples_per_second': 71.23, 'eval_steps_per_second': 8.955, 'epoch': 6.0, 'step': 2601}, {'loss': 0.4869, 'learning_rate': 9.715749961797877e-06, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.48320236802101135, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.1521, 'eval_samples_per_second': 71.346, 'eval_steps_per_second': 8.97, 'epoch': 7.0, 'step': 3034}, {'loss': 0.483, 'learning_rate': 6.462173199899514e-06, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.48230740427970886, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.1759, 'eval_samples_per_second': 71.206, 'eval_steps_per_second': 8.952, 'epoch': 8.0, 'step': 3468}, {'loss': 0.4741, 'learning_rate': 3.2160931586506864e-06, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.4816770553588867, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1649, 'eval_samples_per_second': 71.271, 'eval_steps_per_second': 8.96, 'epoch': 9.0, 'step': 3901}, {'loss': 0.4733, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.48187127709388733, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.1953, 'eval_samples_per_second': 71.093, 'eval_steps_per_second': 8.938, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 1527.4825, 'train_samples_per_second': 22.704, 'train_steps_per_second': 2.835, 'total_flos': 8682839001234240.0, 'train_loss': 0.5208771809144053, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.4816770553588867, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1896, 'eval_samples_per_second': 71.126, 'eval_steps_per_second': 8.942, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 1:05:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.673300</td>\n",
       "      <td>0.624790</td>\n",
       "      <td>0.722030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.590400</td>\n",
       "      <td>0.542267</td>\n",
       "      <td>0.734717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.535400</td>\n",
       "      <td>0.515584</td>\n",
       "      <td>0.760092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.518000</td>\n",
       "      <td>0.480431</td>\n",
       "      <td>0.772780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.508400</td>\n",
       "      <td>0.512112</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.494100</td>\n",
       "      <td>0.527156</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>0.540841</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>0.553183</td>\n",
       "      <td>0.780854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.568626</td>\n",
       "      <td>0.779700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.437300</td>\n",
       "      <td>0.607876</td>\n",
       "      <td>0.787774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6078755855560303, 'eval_accuracy': 0.7877739331026529, 'eval_runtime': 12.1316, 'eval_samples_per_second': 71.466, 'eval_steps_per_second': 8.985, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 18:09:08,283] Trial 17 finished with values: [0.6078755855560303, 0.7877739331026529] and parameters: {'lr': 0.00010228861175811826, 'batch': 1, 'accum': 4, 'dropout_rate': 0.15089605117222096, 'weight_decay': 0.0005848959498769158, 'warmup_pct': 0.22688248079209683, 'lora_rank': 24, 'lora_init_scale': 0.00016071693300725813, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6733, 'learning_rate': 1.127150818432747e-05, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.6247900128364563, 'eval_accuracy': 0.7220299884659747, 'eval_runtime': 13.8548, 'eval_samples_per_second': 62.578, 'eval_steps_per_second': 7.867, 'epoch': 1.0, 'step': 867}, {'loss': 0.5904, 'learning_rate': 2.254301636865494e-05, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.5422666668891907, 'eval_accuracy': 0.734717416378316, 'eval_runtime': 12.5055, 'eval_samples_per_second': 69.33, 'eval_steps_per_second': 8.716, 'epoch': 2.0, 'step': 1734}, {'loss': 0.5354, 'learning_rate': 3.3814524552982416e-05, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.5155836939811707, 'eval_accuracy': 0.7600922722029988, 'eval_runtime': 12.178, 'eval_samples_per_second': 71.194, 'eval_steps_per_second': 8.951, 'epoch': 3.0, 'step': 2601}, {'loss': 0.518, 'learning_rate': 4.508603273730988e-05, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.48043128848075867, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.1796, 'eval_samples_per_second': 71.184, 'eval_steps_per_second': 8.949, 'epoch': 4.0, 'step': 3468}, {'loss': 0.5084, 'learning_rate': 5.6357540921637346e-05, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5121115446090698, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.1651, 'eval_samples_per_second': 71.27, 'eval_steps_per_second': 8.96, 'epoch': 5.0, 'step': 4335}, {'loss': 0.4941, 'learning_rate': 6.762904910596483e-05, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.527155876159668, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.1798, 'eval_samples_per_second': 71.183, 'eval_steps_per_second': 8.949, 'epoch': 6.0, 'step': 5202}, {'loss': 0.5001, 'learning_rate': 7.890055729029229e-05, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.5408408045768738, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1812, 'eval_samples_per_second': 71.175, 'eval_steps_per_second': 8.948, 'epoch': 7.0, 'step': 6069}, {'loss': 0.484, 'learning_rate': 9.017206547461976e-05, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 0.5531830787658691, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.1815, 'eval_samples_per_second': 71.174, 'eval_steps_per_second': 8.948, 'epoch': 8.0, 'step': 6936}, {'loss': 0.4674, 'learning_rate': 0.00010144357365894723, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 0.5686255693435669, 'eval_accuracy': 0.7797001153402537, 'eval_runtime': 12.1818, 'eval_samples_per_second': 71.172, 'eval_steps_per_second': 8.948, 'epoch': 9.0, 'step': 7803}, {'loss': 0.4373, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.6078755855560303, 'eval_accuracy': 0.7877739331026529, 'eval_runtime': 12.1713, 'eval_samples_per_second': 71.233, 'eval_steps_per_second': 8.956, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 3903.1989, 'train_samples_per_second': 8.885, 'train_steps_per_second': 2.221, 'total_flos': 8654614344096480.0, 'train_loss': 0.520851862114331, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.6078755855560303, 'eval_accuracy': 0.7877739331026529, 'eval_runtime': 12.1316, 'eval_samples_per_second': 71.466, 'eval_steps_per_second': 8.985, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 8474627.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 24:37, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.780600</td>\n",
       "      <td>0.694232</td>\n",
       "      <td>0.493656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.757900</td>\n",
       "      <td>0.684389</td>\n",
       "      <td>0.597463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.740800</td>\n",
       "      <td>0.670192</td>\n",
       "      <td>0.658593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.739200</td>\n",
       "      <td>0.654492</td>\n",
       "      <td>0.704729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.638543</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.700900</td>\n",
       "      <td>0.623777</td>\n",
       "      <td>0.713956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.703300</td>\n",
       "      <td>0.610851</td>\n",
       "      <td>0.711649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.663600</td>\n",
       "      <td>0.584043</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.571783</td>\n",
       "      <td>0.720877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5717834234237671, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 12.1372, 'eval_samples_per_second': 71.433, 'eval_steps_per_second': 8.981, 'epoch': 9.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 18:34:40,868] Trial 18 finished with values: [0.5717834234237671, 0.720876585928489] and parameters: {'lr': 0.00011458998338605231, 'batch': 4, 'accum': 8, 'dropout_rate': 0.8889810712391235, 'weight_decay': 0.0002104362553864315, 'warmup_pct': 0.17551683751835567, 'lora_rank': 12, 'lora_init_scale': 0.00015938126565652648, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7806, 'learning_rate': 8.136566867648685e-06, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6942320466041565, 'eval_accuracy': 0.4936562860438293, 'eval_runtime': 13.8588, 'eval_samples_per_second': 62.56, 'eval_steps_per_second': 7.865, 'epoch': 1.0, 'step': 108}, {'loss': 0.7579, 'learning_rate': 1.627313373529737e-05, 'epoch': 1.99, 'step': 216}, {'eval_loss': 0.6843894124031067, 'eval_accuracy': 0.5974625144175317, 'eval_runtime': 12.4038, 'eval_samples_per_second': 69.898, 'eval_steps_per_second': 8.788, 'epoch': 1.99, 'step': 216}, {'loss': 0.7408, 'learning_rate': 2.448503918505391e-05, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.6701919436454773, 'eval_accuracy': 0.6585928489042676, 'eval_runtime': 12.167, 'eval_samples_per_second': 71.259, 'eval_steps_per_second': 8.959, 'epoch': 3.0, 'step': 325}, {'loss': 0.7392, 'learning_rate': 3.2621606052702596e-05, 'epoch': 4.0, 'step': 433}, {'eval_loss': 0.6544920206069946, 'eval_accuracy': 0.7047289504036909, 'eval_runtime': 12.1525, 'eval_samples_per_second': 71.343, 'eval_steps_per_second': 8.969, 'epoch': 4.0, 'step': 433}, {'loss': 0.7241, 'learning_rate': 4.075817292035129e-05, 'epoch': 4.99, 'step': 541}, {'eval_loss': 0.638542652130127, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.1735, 'eval_samples_per_second': 71.22, 'eval_steps_per_second': 8.954, 'epoch': 4.99, 'step': 541}, {'loss': 0.7009, 'learning_rate': 4.897007837010782e-05, 'epoch': 6.0, 'step': 650}, {'eval_loss': 0.6237766146659851, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 12.158, 'eval_samples_per_second': 71.311, 'eval_steps_per_second': 8.965, 'epoch': 6.0, 'step': 650}, {'loss': 0.7033, 'learning_rate': 5.710664523775651e-05, 'epoch': 6.99, 'step': 758}, {'eval_loss': 0.6108508110046387, 'eval_accuracy': 0.7116493656286044, 'eval_runtime': 12.1654, 'eval_samples_per_second': 71.268, 'eval_steps_per_second': 8.96, 'epoch': 6.99, 'step': 758}, {'loss': 0.6746, 'learning_rate': 6.531855068751306e-05, 'epoch': 8.0, 'step': 867}, {'eval_loss': 0.5987720489501953, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 12.1691, 'eval_samples_per_second': 71.246, 'eval_steps_per_second': 8.957, 'epoch': 8.0, 'step': 867}, {'loss': 0.6636, 'learning_rate': 7.345511755516175e-05, 'epoch': 9.0, 'step': 975}, {'eval_loss': 0.5840430855751038, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.1386, 'eval_samples_per_second': 71.425, 'eval_steps_per_second': 8.98, 'epoch': 9.0, 'step': 975}, {'loss': 0.645, 'learning_rate': 8.136566867648684e-05, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.5717834234237671, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 12.1538, 'eval_samples_per_second': 71.336, 'eval_steps_per_second': 8.968, 'epoch': 9.97, 'step': 1080}, {'train_runtime': 1478.3012, 'train_samples_per_second': 23.459, 'train_steps_per_second': 0.731, 'total_flos': 8576152906152960.0, 'train_loss': 0.7131701434100116, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.5717834234237671, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 12.1372, 'eval_samples_per_second': 71.433, 'eval_steps_per_second': 8.981, 'epoch': 9.97, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2170' max='2170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2170/2170 18:37, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.681800</td>\n",
       "      <td>0.640165</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.615700</td>\n",
       "      <td>0.565092</td>\n",
       "      <td>0.727797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.555700</td>\n",
       "      <td>0.515241</td>\n",
       "      <td>0.756632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.518800</td>\n",
       "      <td>0.483168</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.478990</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.484600</td>\n",
       "      <td>0.472042</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.478400</td>\n",
       "      <td>0.468585</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.469887</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.449800</td>\n",
       "      <td>0.472126</td>\n",
       "      <td>0.786621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.472196</td>\n",
       "      <td>0.782007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.472126305103302, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.3196, 'eval_samples_per_second': 70.376, 'eval_steps_per_second': 8.848, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 18:54:12,148] Trial 19 finished with values: [0.472126305103302, 0.7866205305651672] and parameters: {'lr': 0.00010175943017273118, 'batch': 8, 'accum': 2, 'dropout_rate': 0.4882243131202929, 'weight_decay': 0.00014993579804161342, 'warmup_pct': 0.18496515086758566, 'lora_rank': 24, 'lora_init_scale': 0.01370043600756871, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6818, 'learning_rate': 2.756778570222555e-05, 'epoch': 1.0, 'step': 217}, {'eval_loss': 0.6401650905609131, 'eval_accuracy': 0.7058823529411765, 'eval_runtime': 13.8461, 'eval_samples_per_second': 62.617, 'eval_steps_per_second': 7.872, 'epoch': 1.0, 'step': 217}, {'loss': 0.6157, 'learning_rate': 5.51355714044511e-05, 'epoch': 2.0, 'step': 434}, {'eval_loss': 0.5650923252105713, 'eval_accuracy': 0.7277970011534025, 'eval_runtime': 12.3136, 'eval_samples_per_second': 70.41, 'eval_steps_per_second': 8.852, 'epoch': 2.0, 'step': 434}, {'loss': 0.5557, 'learning_rate': 8.270335710667665e-05, 'epoch': 3.0, 'step': 651}, {'eval_loss': 0.5152411460876465, 'eval_accuracy': 0.7566320645905421, 'eval_runtime': 12.1375, 'eval_samples_per_second': 71.432, 'eval_steps_per_second': 8.98, 'epoch': 3.0, 'step': 651}, {'loss': 0.5188, 'learning_rate': 9.677923892249525e-05, 'epoch': 4.0, 'step': 868}, {'eval_loss': 0.48316794633865356, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.1648, 'eval_samples_per_second': 71.271, 'eval_steps_per_second': 8.96, 'epoch': 4.0, 'step': 868}, {'loss': 0.508, 'learning_rate': 8.064936576874604e-05, 'epoch': 5.0, 'step': 1085}, {'eval_loss': 0.478990375995636, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.1325, 'eval_samples_per_second': 71.461, 'eval_steps_per_second': 8.984, 'epoch': 5.0, 'step': 1085}, {'loss': 0.4846, 'learning_rate': 6.451949261499683e-05, 'epoch': 6.0, 'step': 1302}, {'eval_loss': 0.4720420837402344, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.1694, 'eval_samples_per_second': 71.245, 'eval_steps_per_second': 8.957, 'epoch': 6.0, 'step': 1302}, {'loss': 0.4784, 'learning_rate': 4.8389619461247624e-05, 'epoch': 7.0, 'step': 1519}, {'eval_loss': 0.4685846269130707, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1325, 'eval_samples_per_second': 71.461, 'eval_steps_per_second': 8.984, 'epoch': 7.0, 'step': 1519}, {'loss': 0.4626, 'learning_rate': 3.2259746307498416e-05, 'epoch': 8.0, 'step': 1736}, {'eval_loss': 0.46988677978515625, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1633, 'eval_samples_per_second': 71.28, 'eval_steps_per_second': 8.961, 'epoch': 8.0, 'step': 1736}, {'loss': 0.4498, 'learning_rate': 1.6129873153749208e-05, 'epoch': 9.0, 'step': 1953}, {'eval_loss': 0.472126305103302, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.1435, 'eval_samples_per_second': 71.396, 'eval_steps_per_second': 8.976, 'epoch': 9.0, 'step': 1953}, {'loss': 0.444, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 2170}, {'eval_loss': 0.472196489572525, 'eval_accuracy': 0.7820069204152249, 'eval_runtime': 12.1796, 'eval_samples_per_second': 71.185, 'eval_steps_per_second': 8.949, 'epoch': 10.0, 'step': 2170}, {'train_runtime': 1118.0872, 'train_samples_per_second': 31.017, 'train_steps_per_second': 1.941, 'total_flos': 8654614344096480.0, 'train_loss': 0.5199425446822347, 'epoch': 10.0, 'step': 2170}, {'eval_loss': 0.472126305103302, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.3196, 'eval_samples_per_second': 70.376, 'eval_steps_per_second': 8.848, 'epoch': 10.0, 'step': 2170}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 1:04:29, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.670400</td>\n",
       "      <td>0.616133</td>\n",
       "      <td>0.720877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.527700</td>\n",
       "      <td>0.498453</td>\n",
       "      <td>0.760092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.485900</td>\n",
       "      <td>0.498460</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.446200</td>\n",
       "      <td>0.491190</td>\n",
       "      <td>0.780854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.517331</td>\n",
       "      <td>0.780854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.512216</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5015458464622498, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.1567, 'eval_samples_per_second': 71.319, 'eval_steps_per_second': 8.966, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 19:59:35,577] Trial 20 finished with values: [0.5015458464622498, 0.7854671280276817] and parameters: {'lr': 9.81833165594484e-05, 'batch': 1, 'accum': 8, 'dropout_rate': 0.14904399426138495, 'weight_decay': 2.1520637807282497e-05, 'warmup_pct': 0.06255151975729772, 'lora_rank': 28, 'lora_init_scale': 0.009225575377661381, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6704, 'learning_rate': 1.9600450009332026e-05, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6161328554153442, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 13.8992, 'eval_samples_per_second': 62.378, 'eval_steps_per_second': 7.842, 'epoch': 1.0, 'step': 433}, {'loss': 0.5825, 'learning_rate': 3.924616664686112e-05, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5331746339797974, 'eval_accuracy': 0.7508650519031141, 'eval_runtime': 12.2728, 'eval_samples_per_second': 70.644, 'eval_steps_per_second': 8.881, 'epoch': 2.0, 'step': 867}, {'loss': 0.5277, 'learning_rate': 5.884661665619314e-05, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.49845337867736816, 'eval_accuracy': 0.7600922722029988, 'eval_runtime': 12.2421, 'eval_samples_per_second': 70.821, 'eval_steps_per_second': 8.904, 'epoch': 3.0, 'step': 1300}, {'loss': 0.5005, 'learning_rate': 7.849233329372224e-05, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.4718185067176819, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.3108, 'eval_samples_per_second': 70.426, 'eval_steps_per_second': 8.854, 'epoch': 4.0, 'step': 1734}, {'loss': 0.4859, 'learning_rate': 9.809278330305426e-05, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.4984603822231293, 'eval_accuracy': 0.7647058823529411, 'eval_runtime': 12.2767, 'eval_samples_per_second': 70.622, 'eval_steps_per_second': 8.879, 'epoch': 5.0, 'step': 2167}, {'loss': 0.4602, 'learning_rate': 7.855574008851748e-05, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.49249815940856934, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.4597, 'eval_samples_per_second': 69.585, 'eval_steps_per_second': 8.748, 'epoch': 6.0, 'step': 2601}, {'loss': 0.4462, 'learning_rate': 5.888272941279275e-05, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.4911901652812958, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.3629, 'eval_samples_per_second': 70.129, 'eval_steps_per_second': 8.817, 'epoch': 7.0, 'step': 3034}, {'loss': 0.4304, 'learning_rate': 3.916428453227419e-05, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.5015458464622498, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.3605, 'eval_samples_per_second': 70.143, 'eval_steps_per_second': 8.818, 'epoch': 8.0, 'step': 3468}, {'loss': 0.4018, 'learning_rate': 1.9491273856549454e-05, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.517330527305603, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.3496, 'eval_samples_per_second': 70.205, 'eval_steps_per_second': 8.826, 'epoch': 9.0, 'step': 3901}, {'loss': 0.3968, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5122155547142029, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.3309, 'eval_samples_per_second': 70.311, 'eval_steps_per_second': 8.84, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 3870.546, 'train_samples_per_second': 8.96, 'train_steps_per_second': 1.119, 'total_flos': 8648105445522240.0, 'train_loss': 0.4903423952450653, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5015458464622498, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.1567, 'eval_samples_per_second': 71.319, 'eval_steps_per_second': 8.966, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 12406787.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='17340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8670/17340 33:26 < 33:27, 4.32 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.718700</td>\n",
       "      <td>0.528246</td>\n",
       "      <td>0.749712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.678100</td>\n",
       "      <td>0.622431</td>\n",
       "      <td>0.786621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.578300</td>\n",
       "      <td>0.856225</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.465600</td>\n",
       "      <td>0.977599</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.333500</td>\n",
       "      <td>1.160793</td>\n",
       "      <td>0.786621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6224311590194702, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.1147, 'eval_samples_per_second': 71.566, 'eval_steps_per_second': 8.997, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 20:34:00,503] Trial 21 finished with values: [0.6224311590194702, 0.7866205305651672] and parameters: {'lr': 0.0005968434843149745, 'batch': 1, 'accum': 2, 'dropout_rate': 0.24140355409911365, 'weight_decay': 2.4682778193751892e-05, 'warmup_pct': 0.02893006659693323, 'lora_rank': 20, 'lora_init_scale': 0.009333935071644909, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7187, 'learning_rate': 0.0005701376884507249, 'epoch': 1.0, 'step': 1734}, {'eval_loss': 0.5282460451126099, 'eval_accuracy': 0.7497116493656286, 'eval_runtime': 14.0258, 'eval_samples_per_second': 61.815, 'eval_steps_per_second': 7.771, 'epoch': 1.0, 'step': 1734}, {'loss': 0.6781, 'learning_rate': 0.0005067890564006444, 'epoch': 2.0, 'step': 3468}, {'eval_loss': 0.6224311590194702, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.354, 'eval_samples_per_second': 70.18, 'eval_steps_per_second': 8.823, 'epoch': 2.0, 'step': 3468}, {'loss': 0.5783, 'learning_rate': 0.0004434404243505638, 'epoch': 3.0, 'step': 5202}, {'eval_loss': 0.8562248349189758, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.3116, 'eval_samples_per_second': 70.422, 'eval_steps_per_second': 8.853, 'epoch': 3.0, 'step': 5202}, {'loss': 0.4656, 'learning_rate': 0.00038009179230048324, 'epoch': 4.0, 'step': 6936}, {'eval_loss': 0.9775992035865784, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.2603, 'eval_samples_per_second': 70.716, 'eval_steps_per_second': 8.89, 'epoch': 4.0, 'step': 6936}, {'loss': 0.3335, 'learning_rate': 0.0003167431602504027, 'epoch': 5.0, 'step': 8670}, {'eval_loss': 1.1607928276062012, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.202, 'eval_samples_per_second': 71.054, 'eval_steps_per_second': 8.933, 'epoch': 5.0, 'step': 8670}, {'train_runtime': 2007.2237, 'train_samples_per_second': 17.278, 'train_steps_per_second': 8.639, 'total_flos': 4316875072925040.0, 'train_loss': 0.5548425307048371, 'epoch': 5.0, 'step': 8670}, {'eval_loss': 0.6224311590194702, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.1147, 'eval_samples_per_second': 71.566, 'eval_steps_per_second': 8.997, 'epoch': 5.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 16338947.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 24:42, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>0.607423</td>\n",
       "      <td>0.713956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>0.533444</td>\n",
       "      <td>0.742791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.561800</td>\n",
       "      <td>0.495114</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.534100</td>\n",
       "      <td>0.478021</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.508200</td>\n",
       "      <td>0.468608</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.486900</td>\n",
       "      <td>0.464343</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.480800</td>\n",
       "      <td>0.471820</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.446400</td>\n",
       "      <td>0.479024</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.433100</td>\n",
       "      <td>0.478897</td>\n",
       "      <td>0.785467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.965397923875432: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.47510308027267456, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.1854, 'eval_samples_per_second': 71.151, 'eval_steps_per_second': 8.945, 'epoch': 9.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 20:59:40,018] Trial 22 finished with values: [0.47510308027267456, 0.7889273356401384] and parameters: {'lr': 0.00027931534083516736, 'batch': 4, 'accum': 8, 'dropout_rate': 0.7764293495201305, 'weight_decay': 0.0005674347244327496, 'warmup_pct': 0.01875664251543504, 'lora_rank': 24, 'lora_init_scale': 0.020967068638031418, 'lora_scaling_rank': 7}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6935, 'learning_rate': 0.0001862102272234449, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6074228882789612, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 13.9421, 'eval_samples_per_second': 62.186, 'eval_steps_per_second': 7.818, 'epoch': 1.0, 'step': 108}, {'loss': 0.6022, 'learning_rate': 0.0002628850266683928, 'epoch': 1.99, 'step': 216}, {'eval_loss': 0.5334439873695374, 'eval_accuracy': 0.7427912341407151, 'eval_runtime': 12.2126, 'eval_samples_per_second': 70.992, 'eval_steps_per_second': 8.925, 'epoch': 1.99, 'step': 216}, {'loss': 0.5618, 'learning_rate': 0.00022972013325768122, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.49511387944221497, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.449, 'eval_samples_per_second': 69.644, 'eval_steps_per_second': 8.756, 'epoch': 3.0, 'step': 325}, {'loss': 0.5341, 'learning_rate': 0.00019685950492413212, 'epoch': 4.0, 'step': 433}, {'eval_loss': 0.478020578622818, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1533, 'eval_samples_per_second': 71.339, 'eval_steps_per_second': 8.969, 'epoch': 4.0, 'step': 433}, {'loss': 0.5082, 'learning_rate': 0.000163998876590583, 'epoch': 4.99, 'step': 541}, {'eval_loss': 0.4686082899570465, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.2176, 'eval_samples_per_second': 70.963, 'eval_steps_per_second': 8.922, 'epoch': 4.99, 'step': 541}, {'loss': 0.4869, 'learning_rate': 0.00013083398317987143, 'epoch': 6.0, 'step': 650}, {'eval_loss': 0.46434250473976135, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1712, 'eval_samples_per_second': 71.234, 'eval_steps_per_second': 8.956, 'epoch': 6.0, 'step': 650}, {'loss': 0.4808, 'learning_rate': 9.797335484632232e-05, 'epoch': 6.99, 'step': 758}, {'eval_loss': 0.4718196988105774, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.2187, 'eval_samples_per_second': 70.957, 'eval_steps_per_second': 8.921, 'epoch': 6.99, 'step': 758}, {'loss': 0.4599, 'learning_rate': 6.480846143561073e-05, 'epoch': 8.0, 'step': 867}, {'eval_loss': 0.47510308027267456, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.1575, 'eval_samples_per_second': 71.314, 'eval_steps_per_second': 8.966, 'epoch': 8.0, 'step': 867}, {'loss': 0.4464, 'learning_rate': 3.1947833102061625e-05, 'epoch': 9.0, 'step': 975}, {'eval_loss': 0.4790240526199341, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.2088, 'eval_samples_per_second': 71.014, 'eval_steps_per_second': 8.928, 'epoch': 9.0, 'step': 975}, {'loss': 0.4331, 'learning_rate': 0.0, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.4788965582847595, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.167, 'eval_samples_per_second': 71.259, 'eval_steps_per_second': 8.959, 'epoch': 9.97, 'step': 1080}, {'train_runtime': 1483.3505, 'train_samples_per_second': 23.38, 'train_steps_per_second': 0.728, 'total_flos': 8631598249589760.0, 'train_loss': 0.5208851284450955, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.47510308027267456, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.1854, 'eval_samples_per_second': 71.151, 'eval_steps_per_second': 8.945, 'epoch': 9.97, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 4050947.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3468' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3468/4330 20:11 < 05:01, 2.86 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.616200</td>\n",
       "      <td>0.513943</td>\n",
       "      <td>0.748558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500300</td>\n",
       "      <td>0.496461</td>\n",
       "      <td>0.770473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.552235</td>\n",
       "      <td>0.779700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>0.698879</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>0.803209</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5522353053092957, 'eval_accuracy': 0.7797001153402537, 'eval_runtime': 12.0795, 'eval_samples_per_second': 71.775, 'eval_steps_per_second': 9.024, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 21:20:45,352] Trial 23 finished with values: [0.5522353053092957, 0.7797001153402537] and parameters: {'lr': 0.0003198497851818602, 'batch': 4, 'accum': 2, 'dropout_rate': 0.311842510839078, 'weight_decay': 0.00044495852902112657, 'warmup_pct': 0.09157933131279024, 'lora_rank': 4, 'lora_init_scale': 0.0349471319445897, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6162, 'learning_rate': 0.000174646856221621, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.5139427185058594, 'eval_accuracy': 0.748558246828143, 'eval_runtime': 13.8051, 'eval_samples_per_second': 62.803, 'eval_steps_per_second': 7.896, 'epoch': 1.0, 'step': 433}, {'loss': 0.5341, 'learning_rate': 0.00031315798871495105, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.4877302050590515, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.2522, 'eval_samples_per_second': 70.763, 'eval_steps_per_second': 8.896, 'epoch': 2.0, 'step': 867}, {'loss': 0.5003, 'learning_rate': 0.000274001936415334, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.4964606761932373, 'eval_accuracy': 0.7704728950403691, 'eval_runtime': 12.1313, 'eval_samples_per_second': 71.468, 'eval_steps_per_second': 8.985, 'epoch': 3.0, 'step': 1300}, {'loss': 0.4499, 'learning_rate': 0.00023475545443373173, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.5118134617805481, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.3054, 'eval_samples_per_second': 70.457, 'eval_steps_per_second': 8.858, 'epoch': 4.0, 'step': 1734}, {'loss': 0.3954, 'learning_rate': 0.00019559940213411469, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5522353053092957, 'eval_accuracy': 0.7797001153402537, 'eval_runtime': 12.097, 'eval_samples_per_second': 71.671, 'eval_steps_per_second': 9.011, 'epoch': 5.0, 'step': 2167}, {'loss': 0.3338, 'learning_rate': 0.00015635292015251238, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.6400648951530457, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1082, 'eval_samples_per_second': 71.604, 'eval_steps_per_second': 9.002, 'epoch': 6.0, 'step': 2601}, {'loss': 0.3036, 'learning_rate': 0.00011719686785289535, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.698879063129425, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.13, 'eval_samples_per_second': 71.476, 'eval_steps_per_second': 8.986, 'epoch': 7.0, 'step': 3034}, {'loss': 0.2598, 'learning_rate': 7.795038587129305e-05, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.8032094836235046, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1548, 'eval_samples_per_second': 71.33, 'eval_steps_per_second': 8.968, 'epoch': 8.0, 'step': 3468}, {'train_runtime': 1211.5033, 'train_samples_per_second': 28.626, 'train_steps_per_second': 3.574, 'total_flos': 6859707933988224.0, 'train_loss': 0.42410826765542214, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.5522353053092957, 'eval_accuracy': 0.7797001153402537, 'eval_runtime': 12.0795, 'eval_samples_per_second': 71.775, 'eval_steps_per_second': 9.024, 'epoch': 8.0, 'step': 3468}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 5525507.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 18:01, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.722500</td>\n",
       "      <td>0.676876</td>\n",
       "      <td>0.626298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.636341</td>\n",
       "      <td>0.712803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.615132</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.644400</td>\n",
       "      <td>0.603991</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.630300</td>\n",
       "      <td>0.599034</td>\n",
       "      <td>0.722030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.633300</td>\n",
       "      <td>0.598271</td>\n",
       "      <td>0.720877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5990336537361145, 'eval_accuracy': 0.7220299884659747, 'eval_runtime': 12.0664, 'eval_samples_per_second': 71.852, 'eval_steps_per_second': 9.033, 'epoch': 9.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 21:39:40,985] Trial 24 finished with values: [0.5990336537361145, 0.7220299884659747] and parameters: {'lr': 2.6341069367238703e-05, 'batch': 8, 'accum': 4, 'dropout_rate': 0.8076835748405067, 'weight_decay': 0.0002452720685722943, 'warmup_pct': 0.022835850984960264, 'lora_rank': 8, 'lora_init_scale': 0.0002155081781119327, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7225, 'learning_rate': 2.607283037164564e-05, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6768763065338135, 'eval_accuracy': 0.6262975778546713, 'eval_runtime': 13.7895, 'eval_samples_per_second': 62.874, 'eval_steps_per_second': 7.905, 'epoch': 1.0, 'step': 108}, {'loss': 0.6935, 'learning_rate': 2.3149025319681262e-05, 'epoch': 2.0, 'step': 217}, {'eval_loss': 0.6531267166137695, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 12.2851, 'eval_samples_per_second': 70.573, 'eval_steps_per_second': 8.873, 'epoch': 2.0, 'step': 217}, {'loss': 0.6875, 'learning_rate': 2.0252044167276192e-05, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.6363407373428345, 'eval_accuracy': 0.71280276816609, 'eval_runtime': 12.1157, 'eval_samples_per_second': 71.56, 'eval_steps_per_second': 8.997, 'epoch': 3.0, 'step': 325}, {'loss': 0.6605, 'learning_rate': 1.7328239115311814e-05, 'epoch': 4.0, 'step': 434}, {'eval_loss': 0.6236370801925659, 'eval_accuracy': 0.7162629757785467, 'eval_runtime': 12.0816, 'eval_samples_per_second': 71.762, 'eval_steps_per_second': 9.022, 'epoch': 4.0, 'step': 434}, {'loss': 0.6638, 'learning_rate': 1.4431257962906744e-05, 'epoch': 5.0, 'step': 542}, {'eval_loss': 0.6151316165924072, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.0803, 'eval_samples_per_second': 71.77, 'eval_steps_per_second': 9.023, 'epoch': 5.0, 'step': 542}, {'loss': 0.6474, 'learning_rate': 1.1507452910942366e-05, 'epoch': 6.0, 'step': 651}, {'eval_loss': 0.6092596650123596, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.0708, 'eval_samples_per_second': 71.826, 'eval_steps_per_second': 9.03, 'epoch': 6.0, 'step': 651}, {'loss': 0.6444, 'learning_rate': 8.610471758537295e-06, 'epoch': 7.0, 'step': 759}, {'eval_loss': 0.6039906740188599, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.0771, 'eval_samples_per_second': 71.789, 'eval_steps_per_second': 9.025, 'epoch': 7.0, 'step': 759}, {'loss': 0.6331, 'learning_rate': 5.686666706572918e-06, 'epoch': 8.0, 'step': 868}, {'eval_loss': 0.6007812023162842, 'eval_accuracy': 0.7197231833910035, 'eval_runtime': 12.1081, 'eval_samples_per_second': 71.605, 'eval_steps_per_second': 9.002, 'epoch': 8.0, 'step': 868}, {'loss': 0.6303, 'learning_rate': 2.7896855541678464e-06, 'epoch': 9.0, 'step': 976}, {'eval_loss': 0.5990336537361145, 'eval_accuracy': 0.7220299884659747, 'eval_runtime': 12.0895, 'eval_samples_per_second': 71.715, 'eval_steps_per_second': 9.016, 'epoch': 9.0, 'step': 976}, {'loss': 0.6333, 'learning_rate': 0.0, 'epoch': 9.95, 'step': 1080}, {'eval_loss': 0.5982711315155029, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 12.0814, 'eval_samples_per_second': 71.763, 'eval_steps_per_second': 9.022, 'epoch': 9.95, 'step': 1080}, {'train_runtime': 1082.4376, 'train_samples_per_second': 32.039, 'train_steps_per_second': 0.998, 'total_flos': 8546449068090864.0, 'train_loss': 0.6617395330358434, 'epoch': 9.95, 'step': 1080}, {'eval_loss': 0.5990336537361145, 'eval_accuracy': 0.7220299884659747, 'eval_runtime': 12.0664, 'eval_samples_per_second': 71.852, 'eval_steps_per_second': 9.033, 'epoch': 9.95, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 17813507.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 40:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.651746</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.582316</td>\n",
       "      <td>0.711649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.539301</td>\n",
       "      <td>0.730104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.531300</td>\n",
       "      <td>0.511163</td>\n",
       "      <td>0.758939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.521700</td>\n",
       "      <td>0.505596</td>\n",
       "      <td>0.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.506600</td>\n",
       "      <td>0.501802</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.499873</td>\n",
       "      <td>0.768166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.502653</td>\n",
       "      <td>0.770473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.490700</td>\n",
       "      <td>0.503599</td>\n",
       "      <td>0.768166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.485200</td>\n",
       "      <td>0.504707</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5047073364257812, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1542, 'eval_samples_per_second': 71.333, 'eval_steps_per_second': 8.968, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.6825, 'learning_rate': 6.412546116415441e-06, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.6517459154129028, 'eval_accuracy': 0.7058823529411765, 'eval_runtime': 13.9151, 'eval_samples_per_second': 62.307, 'eval_steps_per_second': 7.833, 'epoch': 1.0, 'step': 867}, {'loss': 0.6213, 'learning_rate': 1.2825092232830882e-05, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.5823163390159607, 'eval_accuracy': 0.7116493656286044, 'eval_runtime': 12.3779, 'eval_samples_per_second': 70.044, 'eval_steps_per_second': 8.806, 'epoch': 2.0, 'step': 1734}, {'loss': 0.564, 'learning_rate': 1.9237638349246322e-05, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.539301335811615, 'eval_accuracy': 0.7301038062283737, 'eval_runtime': 12.2118, 'eval_samples_per_second': 70.997, 'eval_steps_per_second': 8.926, 'epoch': 3.0, 'step': 2601}, {'loss': 0.5313, 'learning_rate': 2.5650184465661763e-05, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.5111632347106934, 'eval_accuracy': 0.7589388696655133, 'eval_runtime': 12.2821, 'eval_samples_per_second': 70.591, 'eval_steps_per_second': 8.875, 'epoch': 4.0, 'step': 3468}, {'loss': 0.5217, 'learning_rate': 2.7297481706329664e-05, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5055961608886719, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.2069, 'eval_samples_per_second': 71.025, 'eval_steps_per_second': 8.929, 'epoch': 5.0, 'step': 4335}, {'loss': 0.5066, 'learning_rate': 2.183798536506373e-05, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.5018021464347839, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.2112, 'eval_samples_per_second': 71.001, 'eval_steps_per_second': 8.926, 'epoch': 6.0, 'step': 5202}, {'loss': 0.4986, 'learning_rate': 1.63784890237978e-05, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.49987301230430603, 'eval_accuracy': 0.7681660899653979, 'eval_runtime': 12.1828, 'eval_samples_per_second': 71.166, 'eval_steps_per_second': 8.947, 'epoch': 7.0, 'step': 6069}, {'loss': 0.4905, 'learning_rate': 1.0918992682531864e-05, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 0.5026528239250183, 'eval_accuracy': 0.7704728950403691, 'eval_runtime': 12.2054, 'eval_samples_per_second': 71.034, 'eval_steps_per_second': 8.93, 'epoch': 8.0, 'step': 6936}, {'loss': 0.4907, 'learning_rate': 5.459496341265932e-06, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 0.5035994648933411, 'eval_accuracy': 0.7681660899653979, 'eval_runtime': 12.2109, 'eval_samples_per_second': 71.002, 'eval_steps_per_second': 8.926, 'epoch': 9.0, 'step': 7803}, {'loss': 0.4852, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5047073364257812, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1798, 'eval_samples_per_second': 71.183, 'eval_steps_per_second': 8.949, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 2416.4562, 'train_samples_per_second': 14.352, 'train_steps_per_second': 3.588, 'total_flos': 8672001175968480.0, 'train_loss': 0.5392434442469543, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5047073364257812, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1542, 'eval_samples_per_second': 71.333, 'eval_steps_per_second': 8.968, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 22:20:51,531] Trial 25 finished with values: [0.5047073364257812, 0.7716262975778547] and parameters: {'lr': 2.9488836639156127e-05, 'batch': 2, 'accum': 2, 'dropout_rate': 0.2066959589161308, 'weight_decay': 3.152012130710034e-05, 'warmup_pct': 0.2299453124987169, 'lora_rank': 32, 'lora_init_scale': 0.057397598959444816, 'lora_scaling_rank': 2}. \n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 7491587.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 1:03:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.686429</td>\n",
       "      <td>0.566321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.676100</td>\n",
       "      <td>0.659804</td>\n",
       "      <td>0.702422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.648300</td>\n",
       "      <td>0.626751</td>\n",
       "      <td>0.713956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.618900</td>\n",
       "      <td>0.595146</td>\n",
       "      <td>0.718570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>0.567764</td>\n",
       "      <td>0.718570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.562100</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.732411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.546700</td>\n",
       "      <td>0.532136</td>\n",
       "      <td>0.748558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>0.520105</td>\n",
       "      <td>0.755479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.528200</td>\n",
       "      <td>0.512365</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.520800</td>\n",
       "      <td>0.510080</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5100799202919006, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.119, 'eval_samples_per_second': 71.541, 'eval_steps_per_second': 8.994, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 23:24:56,875] Trial 26 finished with values: [0.5100799202919006, 0.7658592848904268] and parameters: {'lr': 1.2950330583920711e-05, 'batch': 1, 'accum': 4, 'dropout_rate': 0.34356337977240714, 'weight_decay': 1.014633767671602e-05, 'warmup_pct': 0.21045539786396336, 'lora_rank': 12, 'lora_init_scale': 0.00021823609442865146, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6958, 'learning_rate': 1.5384950145600515e-06, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.686428964138031, 'eval_accuracy': 0.566320645905421, 'eval_runtime': 13.8646, 'eval_samples_per_second': 62.533, 'eval_steps_per_second': 7.862, 'epoch': 1.0, 'step': 867}, {'loss': 0.6761, 'learning_rate': 3.076990029120103e-06, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.6598038077354431, 'eval_accuracy': 0.7024221453287197, 'eval_runtime': 12.1982, 'eval_samples_per_second': 71.076, 'eval_steps_per_second': 8.936, 'epoch': 2.0, 'step': 1734}, {'loss': 0.6483, 'learning_rate': 4.615485043680155e-06, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.626750648021698, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 12.3187, 'eval_samples_per_second': 70.381, 'eval_steps_per_second': 8.848, 'epoch': 3.0, 'step': 2601}, {'loss': 0.6189, 'learning_rate': 6.153980058240206e-06, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.5951456427574158, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.1795, 'eval_samples_per_second': 71.185, 'eval_steps_per_second': 8.949, 'epoch': 4.0, 'step': 3468}, {'loss': 0.5864, 'learning_rate': 7.692475072800259e-06, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5677642226219177, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.2632, 'eval_samples_per_second': 70.7, 'eval_steps_per_second': 8.888, 'epoch': 5.0, 'step': 4335}, {'loss': 0.5621, 'learning_rate': 9.23097008736031e-06, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.5477780103683472, 'eval_accuracy': 0.7324106113033448, 'eval_runtime': 12.1948, 'eval_samples_per_second': 71.096, 'eval_steps_per_second': 8.938, 'epoch': 6.0, 'step': 5202}, {'loss': 0.5467, 'learning_rate': 1.0769465101920361e-05, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.5321357846260071, 'eval_accuracy': 0.748558246828143, 'eval_runtime': 12.1326, 'eval_samples_per_second': 71.46, 'eval_steps_per_second': 8.984, 'epoch': 7.0, 'step': 6069}, {'loss': 0.5407, 'learning_rate': 1.2307960116480412e-05, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 0.5201047658920288, 'eval_accuracy': 0.7554786620530565, 'eval_runtime': 12.1666, 'eval_samples_per_second': 71.261, 'eval_steps_per_second': 8.959, 'epoch': 8.0, 'step': 6936}, {'loss': 0.5282, 'learning_rate': 8.18362727132599e-06, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 0.5123647451400757, 'eval_accuracy': 0.7647058823529411, 'eval_runtime': 12.1304, 'eval_samples_per_second': 71.473, 'eval_steps_per_second': 8.986, 'epoch': 9.0, 'step': 7803}, {'loss': 0.5208, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5100799202919006, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.1937, 'eval_samples_per_second': 71.102, 'eval_steps_per_second': 8.939, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 3792.025, 'train_samples_per_second': 9.146, 'train_steps_per_second': 2.286, 'total_flos': 8598976482106080.0, 'train_loss': 0.5924025239691465, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5100799202919006, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.119, 'eval_samples_per_second': 71.541, 'eval_steps_per_second': 8.994, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 11915267.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 1:05:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.605400</td>\n",
       "      <td>0.505748</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.561600</td>\n",
       "      <td>0.537317</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.526400</td>\n",
       "      <td>0.565148</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.505900</td>\n",
       "      <td>0.585615</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.568846</td>\n",
       "      <td>0.777393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.428900</td>\n",
       "      <td>0.992668</td>\n",
       "      <td>0.777393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.434100</td>\n",
       "      <td>0.924367</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.330800</td>\n",
       "      <td>1.173546</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>1.277030</td>\n",
       "      <td>0.785467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>1.514849</td>\n",
       "      <td>0.783160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2770304679870605, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.2436, 'eval_samples_per_second': 70.812, 'eval_steps_per_second': 8.903, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-17 00:30:52,410] Trial 27 finished with values: [1.2770304679870605, 0.7854671280276817] and parameters: {'lr': 0.0010324348512860502, 'batch': 1, 'accum': 4, 'dropout_rate': 0.25975794671734587, 'weight_decay': 2.5566039657984235e-05, 'warmup_pct': 0.16846290950398396, 'lora_rank': 16, 'lora_init_scale': 0.00042970877502568024, 'lora_scaling_rank': 6}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6054, 'learning_rate': 0.00015322167341064798, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.5057482719421387, 'eval_accuracy': 0.754325259515571, 'eval_runtime': 13.8605, 'eval_samples_per_second': 62.552, 'eval_steps_per_second': 7.864, 'epoch': 1.0, 'step': 867}, {'loss': 0.5616, 'learning_rate': 0.00030644334682129596, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.5373168587684631, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.2161, 'eval_samples_per_second': 70.972, 'eval_steps_per_second': 8.923, 'epoch': 2.0, 'step': 1734}, {'loss': 0.5264, 'learning_rate': 0.00045966502023194394, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.5651479959487915, 'eval_accuracy': 0.7577854671280276, 'eval_runtime': 12.1883, 'eval_samples_per_second': 71.134, 'eval_steps_per_second': 8.943, 'epoch': 3.0, 'step': 2601}, {'loss': 0.5059, 'learning_rate': 0.0006128866936425919, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.5856146216392517, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.1821, 'eval_samples_per_second': 71.17, 'eval_steps_per_second': 8.948, 'epoch': 4.0, 'step': 3468}, {'loss': 0.4766, 'learning_rate': 0.0007661083670532398, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5688461661338806, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.2101, 'eval_samples_per_second': 71.007, 'eval_steps_per_second': 8.927, 'epoch': 5.0, 'step': 4335}, {'loss': 0.4289, 'learning_rate': 0.0009193300404638879, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.9926683306694031, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.1826, 'eval_samples_per_second': 71.167, 'eval_steps_per_second': 8.947, 'epoch': 6.0, 'step': 5202}, {'loss': 0.4341, 'learning_rate': 0.0009495626054437823, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.9243665337562561, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.2321, 'eval_samples_per_second': 70.879, 'eval_steps_per_second': 8.911, 'epoch': 7.0, 'step': 6069}, {'loss': 0.3308, 'learning_rate': 0.0006330417369625216, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 1.1735460758209229, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.1814, 'eval_samples_per_second': 71.174, 'eval_steps_per_second': 8.948, 'epoch': 8.0, 'step': 6936}, {'loss': 0.223, 'learning_rate': 0.0003165208684812608, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 1.2770304679870605, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.2124, 'eval_samples_per_second': 70.993, 'eval_steps_per_second': 8.925, 'epoch': 9.0, 'step': 7803}, {'loss': 0.1199, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 1.514849066734314, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1658, 'eval_samples_per_second': 71.265, 'eval_steps_per_second': 8.96, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 3902.1759, 'train_samples_per_second': 8.887, 'train_steps_per_second': 2.222, 'total_flos': 8630272779475680.0, 'train_loss': 0.42127388994861503, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 1.2770304679870605, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.2436, 'eval_samples_per_second': 70.812, 'eval_steps_per_second': 8.903, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 3559427.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3034' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3034/4330 43:23 < 18:32, 1.16 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.664900</td>\n",
       "      <td>0.585309</td>\n",
       "      <td>0.709343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.536500</td>\n",
       "      <td>0.502088</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.522103</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.406900</td>\n",
       "      <td>0.603018</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 6.9988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.9988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.493902325630188, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1225, 'eval_samples_per_second': 71.52, 'eval_steps_per_second': 8.992, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-17 01:15:10,354] Trial 28 finished with values: [0.493902325630188, 0.7843137254901961] and parameters: {'lr': 0.0006536702577510741, 'batch': 1, 'accum': 8, 'dropout_rate': 0.6379424072856527, 'weight_decay': 0.00017102693572973834, 'warmup_pct': 0.10222157877969572, 'lora_rank': 4, 'lora_init_scale': 0.00029526840889784614, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6649, 'learning_rate': 7.984181145450355e-05, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.5853091478347778, 'eval_accuracy': 0.7093425605536332, 'eval_runtime': 13.8422, 'eval_samples_per_second': 62.635, 'eval_steps_per_second': 7.874, 'epoch': 1.0, 'step': 433}, {'loss': 0.5711, 'learning_rate': 0.00015986801508326693, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.500209391117096, 'eval_accuracy': 0.76239907727797, 'eval_runtime': 12.359, 'eval_samples_per_second': 70.151, 'eval_steps_per_second': 8.819, 'epoch': 2.0, 'step': 867}, {'loss': 0.5365, 'learning_rate': 0.00023970982653777047, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.5020877718925476, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.2056, 'eval_samples_per_second': 71.033, 'eval_steps_per_second': 8.93, 'epoch': 3.0, 'step': 1300}, {'loss': 0.5074, 'learning_rate': 0.00031973603016653387, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.493902325630188, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1721, 'eval_samples_per_second': 71.229, 'eval_steps_per_second': 8.955, 'epoch': 4.0, 'step': 1734}, {'loss': 0.4947, 'learning_rate': 0.0003995778416210374, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5221025347709656, 'eval_accuracy': 0.7647058823529411, 'eval_runtime': 12.151, 'eval_samples_per_second': 71.352, 'eval_steps_per_second': 8.97, 'epoch': 5.0, 'step': 2167}, {'loss': 0.4447, 'learning_rate': 0.0004796040452498008, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.6286039352416992, 'eval_accuracy': 0.7681660899653979, 'eval_runtime': 12.1579, 'eval_samples_per_second': 71.312, 'eval_steps_per_second': 8.965, 'epoch': 6.0, 'step': 2601}, {'loss': 0.4069, 'learning_rate': 0.0005594458567043044, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.6030178666114807, 'eval_accuracy': 0.7647058823529411, 'eval_runtime': 12.1913, 'eval_samples_per_second': 71.117, 'eval_steps_per_second': 8.941, 'epoch': 7.0, 'step': 3034}, {'train_runtime': 2604.4765, 'train_samples_per_second': 13.316, 'train_steps_per_second': 1.663, 'total_flos': 5999810285777616.0, 'train_loss': 0.518018447181938, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.493902325630188, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1225, 'eval_samples_per_second': 71.52, 'eval_steps_per_second': 8.992, 'epoch': 7.0, 'step': 3034}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 17813507.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 1:04:31, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.692594</td>\n",
       "      <td>0.502884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.672600</td>\n",
       "      <td>0.659977</td>\n",
       "      <td>0.700115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.632400</td>\n",
       "      <td>0.617555</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.593200</td>\n",
       "      <td>0.579617</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.562100</td>\n",
       "      <td>0.548970</td>\n",
       "      <td>0.733564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>0.538559</td>\n",
       "      <td>0.741638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5385587215423584, 'eval_accuracy': 0.7416378316032295, 'eval_runtime': 12.1546, 'eval_samples_per_second': 71.331, 'eval_steps_per_second': 8.968, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-17 02:20:35,965] Trial 29 finished with values: [0.5385587215423584, 0.7416378316032295] and parameters: {'lr': 1.248794881486996e-05, 'batch': 1, 'accum': 8, 'dropout_rate': 0.24568882538347997, 'weight_decay': 0.00044108723597006456, 'warmup_pct': 0.1840727638819394, 'lora_rank': 32, 'lora_init_scale': 0.004927830932678862, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6974, 'learning_rate': 8.47137997311404e-07, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6925938725471497, 'eval_accuracy': 0.5028835063437139, 'eval_runtime': 13.8939, 'eval_samples_per_second': 62.402, 'eval_steps_per_second': 7.845, 'epoch': 1.0, 'step': 433}, {'loss': 0.6858, 'learning_rate': 1.6962324334156755e-06, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.6792370080947876, 'eval_accuracy': 0.6332179930795848, 'eval_runtime': 12.2925, 'eval_samples_per_second': 70.531, 'eval_steps_per_second': 8.867, 'epoch': 2.0, 'step': 867}, {'loss': 0.6726, 'learning_rate': 2.5433704307270797e-06, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.6599773168563843, 'eval_accuracy': 0.7001153402537486, 'eval_runtime': 12.1872, 'eval_samples_per_second': 71.14, 'eval_steps_per_second': 8.944, 'epoch': 3.0, 'step': 1300}, {'loss': 0.6539, 'learning_rate': 3.392464866831351e-06, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.6389437317848206, 'eval_accuracy': 0.7231833910034602, 'eval_runtime': 12.2264, 'eval_samples_per_second': 70.912, 'eval_steps_per_second': 8.915, 'epoch': 4.0, 'step': 1734}, {'loss': 0.6324, 'learning_rate': 4.239602864142755e-06, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.6175552606582642, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.2165, 'eval_samples_per_second': 70.97, 'eval_steps_per_second': 8.922, 'epoch': 5.0, 'step': 2167}, {'loss': 0.6101, 'learning_rate': 5.088697300247026e-06, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.5979918241500854, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.203, 'eval_samples_per_second': 71.048, 'eval_steps_per_second': 8.932, 'epoch': 6.0, 'step': 2601}, {'loss': 0.5932, 'learning_rate': 5.935835297558431e-06, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.5796173810958862, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.2097, 'eval_samples_per_second': 71.009, 'eval_steps_per_second': 8.927, 'epoch': 7.0, 'step': 3034}, {'loss': 0.578, 'learning_rate': 6.784929733662702e-06, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.5640504360198975, 'eval_accuracy': 0.7243367935409458, 'eval_runtime': 12.1916, 'eval_samples_per_second': 71.115, 'eval_steps_per_second': 8.941, 'epoch': 8.0, 'step': 3468}, {'loss': 0.5621, 'learning_rate': 7.632067730974105e-06, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.548969566822052, 'eval_accuracy': 0.7335640138408305, 'eval_runtime': 12.2063, 'eval_samples_per_second': 71.029, 'eval_steps_per_second': 8.93, 'epoch': 9.0, 'step': 3901}, {'loss': 0.5515, 'learning_rate': 8.471379973114041e-06, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5385587215423584, 'eval_accuracy': 0.7416378316032295, 'eval_runtime': 12.1803, 'eval_samples_per_second': 71.18, 'eval_steps_per_second': 8.949, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 3871.9168, 'train_samples_per_second': 8.957, 'train_steps_per_second': 1.118, 'total_flos': 8661998867807040.0, 'train_loss': 0.6237618743685046, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5385587215423584, 'eval_accuracy': 0.7416378316032295, 'eval_runtime': 12.1546, 'eval_samples_per_second': 71.331, 'eval_steps_per_second': 8.968, 'epoch': 9.99, 'step': 4330}]\n",
      "Loss: 0.46962377429008484, Accuracy: 0.7773933102652826\n",
      "Loss: 0.9660893082618713, Accuracy: 0.7912341407151096\n",
      "Loss: 1.6030584573745728, Accuracy: 0.8073817762399077\n",
      "Loss: 0.5600172281265259, Accuracy: 0.790080738177624\n",
      "Loss: 0.472126305103302, Accuracy: 0.7866205305651672\n",
      "Loss: 0.47510308027267456, Accuracy: 0.7889273356401384\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Set the seed for reproducibility in each trial\n",
    "    # seed = trial.suggest_int('seed', 0, 10000)\n",
    "    # set_seeds(seed)\n",
    "    \n",
    "    # Hyperparameters to be optimized\n",
    "    # Updated to use suggest_float with log=True for loguniform distribution\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    batch = trial.suggest_categorical('batch', [1, 2, 4, 8])\n",
    "    accum = trial.suggest_categorical('accum', [2, 4, 8])\n",
    "    # Updated to use suggest_float for uniform distribution\n",
    "    dropout = trial.suggest_float('dropout_rate', 0.1, 0.9)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    warmup_pct = trial.suggest_float(\"warmup_pct\", 0.01, 0.3)  # Warmup percentage between 1% and 30%\n",
    "    lora_rank = trial.suggest_int('lora_rank', 4, 32, step=4)\n",
    "    lora_init_scale = trial.suggest_float('lora_init_scale', 1e-4, 1e-1, log=True)\n",
    "    lora_scaling_rank = trial.suggest_int('lora_scaling_rank', 1, 8)\n",
    "\n",
    "\n",
    "    # Training and evaluation\n",
    "    tokenizer, model, history = train_per_protein(\n",
    "        train_dataset=train_set, \n",
    "        valid_dataset=valid_set, \n",
    "        num_labels=2, \n",
    "        batch=batch, \n",
    "        accum=accum, \n",
    "        epochs=10,  # Fewer epochs for the trial runs\n",
    "        lr=lr,\n",
    "        dropout=dropout,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_pct=warmup_pct,\n",
    "        lora_rank=lora_rank,\n",
    "        lora_init_scale=lora_init_scale,\n",
    "        lora_scaling_rank=lora_scaling_rank,\n",
    "        # seed=seed\n",
    "    )\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    # torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"History: \", history)\n",
    "    \n",
    "    # Extract the last validation accuracy from the history\n",
    "    val_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry][-1]\n",
    "    val_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry][-1]\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "directions=['minimize', 'maximize']  # Set the direction to maximize the validation accuracy, can also be 'minimize'\n",
    "study = optuna.create_study(directions=directions,\n",
    "                            storage=\"sqlite:///finetuned_model_D_and_P_balance_dataset.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"finetuned_model_D_and_P_balance_dataset\")\n",
    "study.optimize(objective, n_trials=30)  # Adjust the number of trials based on your computational resources\n",
    "\n",
    "# Analyzing results\n",
    "pareto_front = study.best_trials  # Get the Pareto front (best non-dominated solutions)\n",
    "for trial in pareto_front:\n",
    "    print(f\"Loss: {trial.values[0]}, Accuracy: {trial.values[1]}\")  # Note the negation of accuracy\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# print(\"  Value: \", study.best_trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in study.best_trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a28d3c1-8e24-4437-a1d9-dda9cefccfd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:37.168731Z",
     "iopub.status.busy": "2024-04-05T14:04:37.168220Z",
     "iopub.status.idle": "2024-04-05T14:04:38.081706Z",
     "shell.execute_reply": "2024-04-05T14:04:38.080275Z",
     "shell.execute_reply.started": "2024-04-05T14:04:37.168675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Truncate the longer list to the size of the shorter one\n",
    "min_length = min(len(loss), len(val_loss))\n",
    "loss = loss[:min_length]\n",
    "val_loss = val_loss[:min_length]\n",
    "\n",
    "# Get spearman (for regression) or accuracy value (for classification)\n",
    "if [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x] != []:\n",
    "    metric = [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x]\n",
    "else:\n",
    "    metric = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n",
    "\n",
    "epochs = [x['epoch'] for x in history if 'loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "line1 = ax1.plot(epochs, loss, label='train_loss')\n",
    "line2 = ax1.plot(epochs, val_loss, label='validation_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "#line3 = ax2.plot(epochs, metric, color='red', label='validation_metric')\n",
    "ax2.set_ylabel('Metric')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Add grid lines\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 \n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History for fine-tuning\")\n",
    "plt.savefig(f\"../Plots/Without_3rdline_Training_History_new.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccb1bbda-d70e-4b4c-a8d4-24600495171a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:38.083526Z",
     "iopub.status.busy": "2024-04-05T14:04:38.083162Z",
     "iopub.status.idle": "2024-04-05T14:04:38.092729Z",
     "shell.execute_reply": "2024-04-05T14:04:38.091278Z",
     "shell.execute_reply.started": "2024-04-05T14:04:38.083490Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "def load_model(filepath, num_labels=2):\n",
    "# Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "    # load a new model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=0.4882243131202929, lora_rank=24, lora_init_scale=0.01370043600756871, lora_scaling_rank=5)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98e915-c8a8-433a-870a-c6dcaf191e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:38.095733Z",
     "iopub.status.busy": "2024-04-05T14:04:38.095313Z",
     "iopub.status.idle": "2024-04-05T14:05:24.016922Z",
     "shell.execute_reply": "2024-04-05T14:05:24.014560Z",
     "shell.execute_reply.started": "2024-04-05T14:04:38.095698Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def save_model(model, filepath):\n",
    "#     torch.save(model.state_dict(), filepath)\n",
    "\n",
    "# save_model(model, \"../finetuned_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa9b15",
   "metadata": {},
   "source": [
    "{'lr': 0.00010175943017273118, 'batch': 8, 'accum': 2, 'dropout_rate': 0.4882243131202929, 'weight_decay': 0.00014993579804161342, 'warmup_pct': 0.18496515086758566, 'lora_rank': 24, 'lora_init_scale': 0.01370043600756871, 'lora_scaling_rank': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c97fa52-3aea-42e8-b72f-c4bb84808576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:05:24.020589Z",
     "iopub.status.busy": "2024-04-05T14:05:24.019788Z",
     "iopub.status.idle": "2024-04-05T14:08:10.428922Z",
     "shell.execute_reply": "2024-04-05T14:08:10.426805Z",
     "shell.execute_reply.started": "2024-04-05T14:05:24.020524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_D_and_P_balance_dataset.pth\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c20e75-5f40-4ca1-9579-5df49b738fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:10.432313Z",
     "iopub.status.busy": "2024-04-05T14:08:10.431835Z",
     "iopub.status.idle": "2024-04-05T14:08:19.838631Z",
     "shell.execute_reply": "2024-04-05T14:08:19.836988Z",
     "shell.execute_reply.started": "2024-04-05T14:08:10.432274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have identical weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a62aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = from_pretrained(\"model_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50b8a403-e7c5-4912-9c7a-f404c060c32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.841225Z",
     "iopub.status.busy": "2024-04-05T14:08:19.840752Z",
     "iopub.status.idle": "2024-04-05T14:08:19.864579Z",
     "shell.execute_reply": "2024-04-05T14:08:19.862993Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.841173Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WUI4|HDAC7_HUMAN%342%358</td>\n",
       "      <td>ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|Q13950|RUNX2_HUMAN%416%432</td>\n",
       "      <td>THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q15796|SMAD2_HUMAN%229%245</td>\n",
       "      <td>DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%416%432</td>\n",
       "      <td>TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2798%2814</td>\n",
       "      <td>MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0   sp|Q8WUI4|HDAC7_HUMAN%342%358  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
       "1   sp|Q13950|RUNX2_HUMAN%416%432  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
       "2   sp|Q15796|SMAD2_HUMAN%229%245  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
       "3    sp|P05787|K2C8_HUMAN%416%432  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2798%2814  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "    \n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_Y.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2d18716-fd26-49fe-9ba4-b84c936a364c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.867076Z",
     "iopub.status.busy": "2024-04-05T14:08:19.866598Z",
     "iopub.status.idle": "2024-04-05T14:08:19.887853Z",
     "shell.execute_reply": "2024-04-05T14:08:19.886215Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.867024Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sequence  label\n",
      "0  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
      "1  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
      "2  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
      "3  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
      "4  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1\n"
     ]
    }
   ],
   "source": [
    "my_test=df[[\"sequence\", \"label\"]]\n",
    "\n",
    "print(my_test.head(5))\n",
    "\n",
    "'''\n",
    "my_test[\"sequence\"]=my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "my_test['sequence']=my_test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "'''\n",
    "\n",
    "#Using .loc ensures that you are modifying the original DataFrame rather than a view of it, which helps avoid the SettingWithCopyWarning.\n",
    "# Replace characters in the \"sequence\" column\n",
    "my_test.loc[:, \"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Convert each sequence to a space-separated string\n",
    "my_test.loc[:, 'sequence'] = my_test.apply(lambda row: \" \".join(row[\"sequence\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eee8fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = sequence.split()\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "my_test['middle_char'] = my_test['sequence'].apply(get_middle_char)\n",
    "\n",
    "# Split the DataFrame\n",
    "my_test_S = my_test[my_test['middle_char'] == 'S'].drop(columns=['middle_char'])\n",
    "my_test_T = my_test[my_test['middle_char'] == 'T'].drop(columns=['middle_char'])\n",
    "my_test_Y = my_test[my_test['middle_char'] == 'Y'].drop(columns=['middle_char'])\n",
    "my_test_ST = my_test[my_test['middle_char'].isin(['S', 'T'])].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcd9ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0dff151-a667-4717-af18-401818bc4c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.889951Z",
     "iopub.status.busy": "2024-04-05T14:08:19.889601Z",
     "iopub.status.idle": "2024-04-05T14:08:22.641629Z",
     "shell.execute_reply": "2024-04-05T14:08:22.639919Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.889916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.784465 |      0.769231 |             1 |       0.88 |  0.956731 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[20  6]\n",
      " [ 0 24]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ce2f51a-887c-4684-82b9-22ea5fffd334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:22.647264Z",
     "iopub.status.busy": "2024-04-05T14:08:22.646121Z",
     "iopub.status.idle": "2024-04-05T14:08:23.557189Z",
     "shell.execute_reply": "2024-04-05T14:08:23.555594Z",
     "shell.execute_reply.started": "2024-04-05T14:08:22.647207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['0', '1']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"../Plots/Confusion_matrix_for_dephos_new.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07603226",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5e0d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [00:04<00:00,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.627874 |      0.808036 |       0.81982 |   0.813901 |  0.883687 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[181  43]\n",
      " [ 40 182]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5528dc-6e06-456d-920f-8f05055d0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, n_neighbors=5, min_dist=0.01, metric='euclidean'):\n",
    "    umap_model = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric\n",
    "    )\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    df = pd.DataFrame({\n",
    "        \"UMAP1\": embeddings[:, 0],\n",
    "        \"UMAP2\": embeddings[:, 1],\n",
    "        \"Label\": labels\n",
    "    })\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = sns.scatterplot(\n",
    "        x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9\n",
    "    )\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.legend(title='Label', bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_ST.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "    embeddings = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch = sequences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "            embeddings.extend(hidden_states[:, 0, :])\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(sequences) // batch_size + 1}\")\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7718f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = list(sequence)\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "valid_df = df\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "valid_df['middle_char'] = valid_df['sequence'].apply(get_middle_char)\n",
    "\n",
    "valid_df = valid_df[valid_df['middle_char'] == 'T'].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a162964f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sp|Q9GZM8|NDEL1_HUMAN%203%219</td>\n",
       "      <td>CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>sp|Q8N163|CCAR2_HUMAN%438%454</td>\n",
       "      <td>EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>sp|P10636-8|TAU_HUMAN%196%212</td>\n",
       "      <td>GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>sp|Q02241|KIF23_HUMAN%434%450</td>\n",
       "      <td>QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sp|Q04206|TF65_HUMAN%419%435</td>\n",
       "      <td>QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>sp|Q76N33|STALP_MOUSE%326%342</td>\n",
       "      <td>ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>sp|P49790|NU153_HUMAN%1098%1114</td>\n",
       "      <td>FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>sp|Q8NFC6|BD1L1_HUMAN%2789%2805</td>\n",
       "      <td>DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>sp|Q5T6F2|UBAP2_HUMAN%514%530</td>\n",
       "      <td>SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>sp|Q9H040|SPRTN_HUMAN%265%281</td>\n",
       "      <td>NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name                           sequence  label\n",
       "180    sp|Q9GZM8|NDEL1_HUMAN%203%219  CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI      1\n",
       "181    sp|Q8N163|CCAR2_HUMAN%438%454  EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA      1\n",
       "182    sp|P10636-8|TAU_HUMAN%196%212  GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV      1\n",
       "183    sp|Q02241|KIF23_HUMAN%434%450  QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE      1\n",
       "184     sp|Q04206|TF65_HUMAN%419%435  QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG      1\n",
       "..                               ...                                ...    ...\n",
       "441    sp|Q76N33|STALP_MOUSE%326%342  ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS      0\n",
       "442  sp|P49790|NU153_HUMAN%1098%1114  FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ      0\n",
       "443  sp|Q8NFC6|BD1L1_HUMAN%2789%2805  DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL      0\n",
       "444    sp|Q5T6F2|UBAP2_HUMAN%514%530  SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS      0\n",
       "445    sp|Q9H040|SPRTN_HUMAN%265%281  NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN      0\n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a44d9187-1ac5-4e36-89a0-8f827a7f0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 3559427.0\n",
      "\n",
      "Processed batch 1/3\n",
      "Processed batch 2/3\n",
      "Processed batch 3/3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_df = my_valid\n",
    "\n",
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_ST.pth\",num_labels=2)\n",
    "\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "valid_sequences = list(valid_df['sequence'])\n",
    "valid_embeddings = get_embeddings(model_reload, tokenizer, valid_sequences)\n",
    "\n",
    "umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "\n",
    "labels = list(valid_df['label'])\n",
    "\n",
    "plot_umap(umap_embeddings, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f029bcf-42ef-4476-b575-3c14adb71b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da0e6c-e921-493b-9304-8ba9aad07d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2319a5",
   "metadata": {},
   "source": [
    "This notebook will implement changing lora settings and separate dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1959ca-a3c9-46d8-8519-064c38f52007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:48:44.051741Z",
     "iopub.status.busy": "2024-04-05T12:48:44.050047Z",
     "iopub.status.idle": "2024-04-05T12:52:49.260801Z",
     "shell.execute_reply": "2024-04-05T12:52:49.259100Z",
     "shell.execute_reply.started": "2024-04-05T12:48:44.051657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torch==2.1.1 torchaudio torchvision tqdm==4.66.1 accelerate==0.24.1 biopython==1.81 numpy==1.26.2 pandas==2.1.3 \\\n",
    "# transformers==4.35.2 datasets==2.15.0 scikit-learn==1.3.2 umap-learn==0.5.5 sentencepiece==0.1.99 seaborn==0.13.0 scipy==1.11.4 \\\n",
    "# matplotlib==3.8.2 evaluate==0.4.1 deepspeed==0.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060d0bba-32ad-4dc9-b1b8-d1124da1336c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a377270-2995-4da1-a673-5369769a6279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:52:49.264011Z",
     "iopub.status.busy": "2024-04-05T12:52:49.263502Z",
     "iopub.status.idle": "2024-04-05T12:53:29.491461Z",
     "shell.execute_reply": "2024-04-05T12:53:29.490156Z",
     "shell.execute_reply.started": "2024-04-05T12:52:49.263956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "# from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "# from transformers import ESMTokenizer, ESMForSequenceClassification\n",
    "import esm\n",
    "\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install umap-learn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0148ff8f-80eb-4bbd-aac7-fe1f371da27a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.508233Z",
     "iopub.status.busy": "2024-04-05T12:53:29.507801Z",
     "iopub.status.idle": "2024-04-05T12:53:29.536614Z",
     "shell.execute_reply": "2024-04-05T12:53:29.514877Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.508197Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.1.1+cu121\n",
      "Cuda version:  12.1\n",
      "Numpy version:  1.26.4\n",
      "Pandas version:  2.2.2\n",
      "Transformers version:  4.35.2\n",
      "Datasets version:  2.19.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96bd9396-a81c-4d87-a722-0d2020627dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.538488Z",
     "iopub.status.busy": "2024-04-05T12:53:29.538089Z",
     "iopub.status.idle": "2024-04-05T12:53:29.768968Z",
     "shell.execute_reply": "2024-04-05T12:53:29.767620Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.538452Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|P24928|RPB1_HUMAN%1775%1791</td>\n",
       "      <td>NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%58%74</td>\n",
       "      <td>SGMGGITAVTVNQSLLSPLVLEVDPNIQAVRTQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q14832|GRM3_HUMAN%829%845</td>\n",
       "      <td>QPQKNVVTHRLHLNRFSVSGTGTTYSQSSASTY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P01106|MYC_HUMAN%46%62</td>\n",
       "      <td>SEDIWKKFELLPTPPLSPSRRSGLCSPSYVAVT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2792%2808</td>\n",
       "      <td>TREGDSMALYNRTRRISQTSQVSVDAAHGYSPR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0  sp|P24928|RPB1_HUMAN%1775%1791  NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS      1\n",
       "1      sp|P05787|K2C8_HUMAN%58%74  SGMGGITAVTVNQSLLSPLVLEVDPNIQAVRTQ      1\n",
       "2    sp|Q14832|GRM3_HUMAN%829%845  QPQKNVVTHRLHLNRFSVSGTGTTYSQSSASTY      1\n",
       "3       sp|P01106|MYC_HUMAN%46%62  SEDIWKKFELLPTPPLSPSRRSGLCSPSYVAVT      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2792%2808  TREGDSMALYNRTRRISQTSQVSVDAAHGYSPR      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/train_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/train_Pos_Neg_Y.fasta'\n",
    "\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b784f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to get the middle character\n",
    "# def get_middle_char(sequence):\n",
    "#     chars = list(sequence)\n",
    "#     middle_index = len(chars) // 2\n",
    "#     return chars[middle_index]\n",
    "\n",
    "# # Apply the function to get the middle characters\n",
    "# df['middle_char'] = df['sequence'].apply(get_middle_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a68724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to count 'S', 'T', 'Y' in a sequence\n",
    "# def count_chars(sequence, char):\n",
    "#     return sequence.count(char)\n",
    "\n",
    "# # Count the occurrences of 'S', 'T', and 'Y' in the sequences\n",
    "# df['count_S'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'S'))\n",
    "# df['count_T'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'T'))\n",
    "# df['count_Y'] = df['middle_char'].apply(lambda seq: count_chars(seq, 'Y'))\n",
    "\n",
    "# # Sum the counts to get the total occurrences in the DataFrame\n",
    "# total_S = df['count_S'].sum()\n",
    "# total_T = df['count_T'].sum()\n",
    "# total_Y = df['count_Y'].sum()\n",
    "\n",
    "# print(f\"Total number of 'S': {total_S}\")\n",
    "# print(f\"Total number of 'T': {total_T}\")\n",
    "# print(f\"Total number of 'Y': {total_Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9c28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group by label and sum the counts\n",
    "# grouped_counts = df.groupby('label')[['count_S', 'count_T', 'count_Y']].sum().reset_index()\n",
    "\n",
    "# # Display the grouped counts\n",
    "# print(grouped_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c189b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate the DataFrame by middle character\n",
    "# df_S = df[df['middle_char'] == 'S']\n",
    "# df_T = df[df['middle_char'] == 'T']\n",
    "# df_Y = df[df['middle_char'] == 'Y']\n",
    "\n",
    "# # Separate each subset by label\n",
    "# df_S_0 = df_S[df_S['label'] == 0]\n",
    "# df_S_1 = df_S[df_S['label'] == 1]\n",
    "# df_T_0 = df_T[df_T['label'] == 0]\n",
    "# df_T_1 = df_T[df_T['label'] == 1]\n",
    "# df_Y_0 = df_Y[df_Y['label'] == 0]\n",
    "# df_Y_1 = df_Y[df_Y['label'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "333000b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "# # Desired number of samples per group\n",
    "# n_samples_S = 500\n",
    "# n_sampple_T = 300\n",
    "# n_sampple_Y = 200\n",
    "# # Perform stratified sampling\n",
    "# df_S_0_resampled = resample(df_S_0, replace=False, n_samples=n_samples_S, random_state=42)\n",
    "# df_S_1_resampled = resample(df_S_1, replace=False, n_samples=n_samples_S, random_state=42)\n",
    "# df_T_0_resampled = resample(df_T_0, replace=True, n_samples=n_sampple_T, random_state=42)\n",
    "# df_T_1_resampled = resample(df_T_1, replace=True, n_samples=n_sampple_T, random_state=42)\n",
    "# df_Y_0_resampled = resample(df_Y_0, replace=True, n_samples=n_sampple_Y, random_state=42)\n",
    "# df_Y_1_resampled = resample(df_Y_1, replace=True, n_samples=n_sampple_Y, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31710914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine the resampled subsets\n",
    "# balanced_df = pd.concat([\n",
    "#     df_S_0_resampled, df_S_1_resampled,\n",
    "#     df_T_0_resampled, df_T_1_resampled,\n",
    "#     df_Y_0_resampled, df_Y_1_resampled\n",
    "# ])\n",
    "\n",
    "# # Shuffle the combined DataFrame\n",
    "# balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# print(\"Balanced DataFrame:\")\n",
    "# print(balanced_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46617eaa-de6d-4d12-82cb-08ec66b4f56a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.771322Z",
     "iopub.status.busy": "2024-04-05T12:53:29.770859Z",
     "iopub.status.idle": "2024-04-05T12:53:29.786558Z",
     "shell.execute_reply": "2024-04-05T12:53:29.785263Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.771275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the dataset into training and validation sets\n",
    "# my_train, my_valid = train_test_split(\n",
    "#     balanced_df, \n",
    "#     test_size=0.2, \n",
    "#     random_state=42, \n",
    "#     stratify=balanced_df[['label', 'middle_char']]\n",
    "# )\n",
    "\n",
    "# my_train=my_train[[\"sequence\", \"label\"]]\n",
    "# my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# # Print the first 5 rows of the training set\n",
    "# print(\"Training Set:\")\n",
    "# print(my_train.shape)\n",
    "\n",
    "# # Print the first 5 rows of the validation set\n",
    "# print(\"\\nValidation Set:\")\n",
    "# print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76760f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "(1584, 2)\n",
      "\n",
      "Validation Set:\n",
      "(396, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "my_train, my_valid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "my_train=my_train[[\"sequence\", \"label\"]]\n",
    "my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the training set\n",
    "print(\"Training Set:\")\n",
    "print(my_train.shape)\n",
    "\n",
    "# Print the first 5 rows of the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a424877b-787c-44fe-bf87-33346ffd3be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.789138Z",
     "iopub.status.busy": "2024-04-05T12:53:29.788675Z",
     "iopub.status.idle": "2024-04-05T12:53:29.816779Z",
     "shell.execute_reply": "2024-04-05T12:53:29.815341Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.789094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifies an existing transformer and introduce the LoRA layers\n",
    "\n",
    "class LoRAConfig:\n",
    "    def __init__(self, lora_rank=4, lora_init_scale=0.01, lora_scaling_rank=1):\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_init_scale = lora_init_scale\n",
    "        self.lora_modules = \".*SelfAttention|.*EncDecAttention\"\n",
    "        self.lora_layers = \"q|k|v|o\"\n",
    "        self.trainable_param_names = \".*layer_norm.*|.*lora_[ab].*\"\n",
    "        self.lora_scaling_rank = lora_scaling_rank\n",
    "        # lora_modules and lora_layers are specified with regular expressions\n",
    "        # see https://www.w3schools.com/python/python_regex.asp for reference\n",
    "        \n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, scaling_rank, init_scale):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.rank = rank\n",
    "        self.scaling_rank = scaling_rank\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        if self.rank > 0:\n",
    "            self.lora_a = nn.Parameter(torch.randn(rank, linear_layer.in_features) * init_scale)\n",
    "            if init_scale < 0:\n",
    "                self.lora_b = nn.Parameter(torch.randn(linear_layer.out_features, rank) * init_scale)\n",
    "            else:\n",
    "                self.lora_b = nn.Parameter(torch.zeros(linear_layer.out_features, rank))\n",
    "        if self.scaling_rank:\n",
    "            self.multi_lora_a = nn.Parameter(\n",
    "                torch.ones(self.scaling_rank, linear_layer.in_features)\n",
    "                + torch.randn(self.scaling_rank, linear_layer.in_features) * init_scale\n",
    "            )\n",
    "            if init_scale < 0:\n",
    "                self.multi_lora_b = nn.Parameter(\n",
    "                    torch.ones(linear_layer.out_features, self.scaling_rank)\n",
    "                    + torch.randn(linear_layer.out_features, self.scaling_rank) * init_scale\n",
    "                )\n",
    "            else:\n",
    "                self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, self.scaling_rank))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.scaling_rank == 1 and self.rank == 0:\n",
    "            # parsimonious implementation for ia3 and lora scaling\n",
    "            if self.multi_lora_a.requires_grad:\n",
    "                hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n",
    "            else:\n",
    "                hidden = F.linear(input, self.weight, self.bias)\n",
    "            if self.multi_lora_b.requires_grad:\n",
    "                hidden = hidden * self.multi_lora_b.flatten()\n",
    "            return hidden\n",
    "        else:\n",
    "            # general implementation for lora (adding and scaling)\n",
    "            weight = self.weight\n",
    "            if self.scaling_rank:\n",
    "                weight = weight * torch.matmul(self.multi_lora_b, self.multi_lora_a) / self.scaling_rank\n",
    "            if self.rank:\n",
    "                weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n",
    "            return F.linear(input, weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, rank={}, scaling_rank={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.rank, self.scaling_rank\n",
    "        )\n",
    "\n",
    "\n",
    "def modify_with_lora(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.lora_modules, m_name):\n",
    "            for c_name, layer in dict(module.named_children()).items():\n",
    "                if re.fullmatch(config.lora_layers, c_name):\n",
    "                    assert isinstance(\n",
    "                        layer, nn.Linear\n",
    "                    ), f\"LoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        c_name,\n",
    "                        LoRALinear(layer, config.lora_rank, config.lora_scaling_rank, config.lora_init_scale),\n",
    "                    )\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e79b323-4677-4723-a5fd-a60dc13a3b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.819433Z",
     "iopub.status.busy": "2024-04-05T12:53:29.818965Z",
     "iopub.status.idle": "2024-04-05T12:53:29.845976Z",
     "shell.execute_reply": "2024-04-05T12:53:29.844438Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.819335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.7, num_labels=2):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class T5EncoderClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, class_config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "        \n",
    "        # Trainable emphasis factor\n",
    "        self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        seq_length = hidden_states.size(1)\n",
    "        middle_idx = seq_length // 2\n",
    "        middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "        # Apply trainable emphasis factor\n",
    "        emphasized_middle_embedding = middle_embedding * self.emphasis_factor\n",
    "\n",
    "        # Combine with the average embedding\n",
    "        average_embedding = torch.mean(hidden_states, dim=1)\n",
    "        combined_embedding = emphasized_middle_embedding + average_embedding\n",
    "\n",
    "        x = self.dropout(combined_embedding)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.out_proj(x)\n",
    "        return logits\n",
    "\n",
    "    # def forward(self, hidden_states):\n",
    "\n",
    "    #     hidden_states =  torch.mean(hidden_states,dim=1)  # avg embedding\n",
    "\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.dense(hidden_states)\n",
    "    #     hidden_states = torch.tanh(hidden_states)\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.out_proj(hidden_states)\n",
    "    #     return hidden_states\n",
    "    \n",
    "    # def forward(self, hidden_states):\n",
    "    #     # Original sequence length and middle index\n",
    "    #     seq_length = hidden_states.size(1)\n",
    "    #     middle_idx = seq_length // 2\n",
    "\n",
    "    #     # Extract the middle embedding vector\n",
    "    #     middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "    #     # Amplify the influence of the middle embedding\n",
    "    #     amplified_middle_embedding = middle_embedding * 2\n",
    "\n",
    "    #     # Combine with average to retain context\n",
    "    #     average_embedding = torch.mean(hidden_states, dim=1)\n",
    "    #     combined_embedding = 0.5 * amplified_middle_embedding + 0.5 * average_embedding\n",
    "\n",
    "    #     # Classification layers\n",
    "    #     x = self.dropout(combined_embedding)\n",
    "    #     x = self.dense(x)\n",
    "    #     x = torch.tanh(x)\n",
    "    #     x = self.dropout(x)\n",
    "    #     logits = self.out_proj(x)\n",
    "    #     return logits\n",
    "\n",
    "\n",
    "# class T5EncoderForSimpleSequenceClassification(T5PreTrainedModel):\n",
    "\n",
    "#     def __init__(self, config: T5Config, class_config):\n",
    "#         super().__init__(config)\n",
    "#         self.num_labels = class_config.num_labels\n",
    "#         self.config = config\n",
    "\n",
    "#         self.shared = nn.Embedding(config.vocab_size, config.d_model)\n",
    "\n",
    "#         encoder_config = copy.deepcopy(config)\n",
    "#         encoder_config.use_cache = False\n",
    "#         encoder_config.is_encoder_decoder = False\n",
    "#         self.encoder = T5Stack(encoder_config, self.shared)\n",
    "\n",
    "#         self.dropout = nn.Dropout(class_config.dropout_rate) \n",
    "#         self.classifier = T5EncoderClassificationHead(config, class_config)\n",
    "\n",
    "#         # Initialize weights and apply final processing\n",
    "#         self.post_init()\n",
    "\n",
    "#         # Model parallel\n",
    "#         self.model_parallel = False\n",
    "#         self.device_map = None\n",
    "\n",
    "#     def parallelize(self, device_map=None):\n",
    "#         self.device_map = (\n",
    "#             get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
    "#             if device_map is None\n",
    "#             else device_map\n",
    "#         )\n",
    "#         assert_device_map(self.device_map, len(self.encoder.block))\n",
    "#         self.encoder.parallelize(self.device_map)\n",
    "#         self.classifier = self.classifier.to(self.encoder.first_device)\n",
    "#         self.model_parallel = True\n",
    "\n",
    "#     def deparallelize(self):\n",
    "#         self.encoder.deparallelize()\n",
    "#         self.encoder = self.encoder.to(\"cpu\")\n",
    "#         self.model_parallel = False\n",
    "#         self.device_map = None\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#     def get_input_embeddings(self):\n",
    "#         return self.shared\n",
    "\n",
    "#     def set_input_embeddings(self, new_embeddings):\n",
    "#         self.shared = new_embeddings\n",
    "#         self.encoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "#     def get_encoder(self):\n",
    "#         return self.encoder\n",
    "\n",
    "#     def _prune_heads(self, heads_to_prune):\n",
    "#         \"\"\"\n",
    "#         Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "#         class PreTrainedModel\n",
    "#         \"\"\"\n",
    "#         for layer, heads in heads_to_prune.items():\n",
    "#             self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         input_ids=None,\n",
    "#         attention_mask=None,\n",
    "#         head_mask=None,\n",
    "#         inputs_embeds=None,\n",
    "#         labels=None,\n",
    "#         output_attentions=None,\n",
    "#         output_hidden_states=None,\n",
    "#         return_dict=None,\n",
    "#     ):\n",
    "#         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "#         outputs = self.encoder(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             inputs_embeds=inputs_embeds,\n",
    "#             head_mask=head_mask,\n",
    "#             output_attentions=output_attentions,\n",
    "#             output_hidden_states=True,\n",
    "#             return_dict=return_dict,\n",
    "#         )\n",
    "\n",
    "#         hidden_states = outputs[0]\n",
    "#         logits = self.classifier(hidden_states)\n",
    "\n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             if self.config.problem_type is None:\n",
    "#                 if self.num_labels == 1:\n",
    "#                     self.config.problem_type = \"regression\"\n",
    "#                 elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "#                     self.config.problem_type = \"single_label_classification\"\n",
    "#                 else:\n",
    "#                     self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "#             if self.config.problem_type == \"regression\":\n",
    "#                 loss_fct = MSELoss()\n",
    "#                 if self.num_labels == 1:\n",
    "#                     loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "#                 else:\n",
    "#                     loss = loss_fct(logits, labels)\n",
    "#             elif self.config.problem_type == \"single_label_classification\":\n",
    "#                 loss_fct = CrossEntropyLoss()\n",
    "#                 loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "#             elif self.config.problem_type == \"multi_label_classification\":\n",
    "#                 loss_fct = BCEWithLogitsLoss()\n",
    "#                 loss = loss_fct(logits, labels)\n",
    "#         if not return_dict:\n",
    "#             output = (logits,) + outputs[1:]\n",
    "#             return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "#         return SequenceClassifierOutput(\n",
    "#             loss=loss,\n",
    "#             logits=logits,\n",
    "#             hidden_states=outputs.hidden_states,\n",
    "#             attentions=outputs.attentions,\n",
    "#         )\n",
    "        \n",
    "# import esm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class ESMEncoderForSimpleSequenceClassification(nn.Module):\n",
    "    def __init__(self, esm_model, class_config):\n",
    "        super().__init__()\n",
    "        self.esm_model = esm_model\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        \n",
    "        # Get the dimension of the embeddings\n",
    "        embed_dim = esm_model.args.embed_dim\n",
    "        self.classifier = nn.Linear(embed_dim, class_config.num_labels)\n",
    "\n",
    "        # Trainable emphasis factor\n",
    "        self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        # Get the hidden states from the ESM model\n",
    "        outputs = self.esm_model(input_ids, repr_layers=[33])\n",
    "        hidden_states = outputs[\"representations\"][33]\n",
    "\n",
    "        # Emphasize the middle token representation\n",
    "        seq_length = hidden_states.size(1)\n",
    "        middle_idx = seq_length // 2\n",
    "        middle_embedding = hidden_states[:, middle_idx, :]\n",
    "        emphasized_middle_embedding = middle_embedding * self.emphasis_factor\n",
    "\n",
    "        # Combine with average embedding\n",
    "        average_embedding = torch.mean(hidden_states, dim=1)\n",
    "        combined_embedding = emphasized_middle_embedding + average_embedding\n",
    "\n",
    "        x = self.dropout(combined_embedding)\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=hidden_states,\n",
    "            attentions=None,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "# # Load ESM model\n",
    "# esm_model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "\n",
    "# # Initialize class configuration\n",
    "# class_config = ClassConfig(dropout=0.7, num_labels=2)\n",
    "\n",
    "# # Initialize the model with ESM encoder\n",
    "# model = ESMEncoderForSimpleSequenceClassification(esm_model, class_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71394626-6f8b-4ca5-80f3-c697e4320bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.848217Z",
     "iopub.status.busy": "2024-04-05T12:53:29.847782Z",
     "iopub.status.idle": "2024-04-05T12:53:29.859841Z",
     "shell.execute_reply": "2024-04-05T12:53:29.858398Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.848182Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def PT5_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "#     # Load PT5 and tokenizer\n",
    "#     model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "#     tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", do_lower_case=False, force_download=True) \n",
    "    \n",
    "#     # Create new Classifier model with PT5 dimensions\n",
    "#     class_config=ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "#     class_model=T5EncoderForSimpleSequenceClassification(model.config,class_config)\n",
    "    \n",
    "#     # Set encoder and embedding weights to checkpoint weights\n",
    "#     class_model.shared=model.shared\n",
    "#     class_model.encoder=model.encoder    \n",
    "    \n",
    "#     # Delete the checkpoint model\n",
    "#     model=class_model\n",
    "#     del class_model\n",
    "    \n",
    "#     # Print number of trainable parameters\n",
    "#     model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "#     params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "#     print(\"ProtT5_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "#     # Add model modification lora\n",
    "#     config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "#     # Add LoRA layers\n",
    "#     model = modify_with_lora(model, config)\n",
    "    \n",
    "#     # Freeze Embeddings and Encoder (except LoRA)\n",
    "#     for (param_name, param) in model.shared.named_parameters():\n",
    "#                 param.requires_grad = False\n",
    "#     for (param_name, param) in model.encoder.named_parameters():\n",
    "#                 param.requires_grad = False       \n",
    "\n",
    "#     for (param_name, param) in model.named_parameters():\n",
    "#             if re.fullmatch(config.trainable_param_names, param_name):\n",
    "#                 param.requires_grad = True\n",
    "\n",
    "#     # Print trainable Parameter          \n",
    "#     model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "#     params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "#     print(\"ProtT5_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "#     return model, tokenizer\n",
    "\n",
    "# import esm\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "def ESM_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "    # Load ESM model and alphabet\n",
    "    esm_model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    \n",
    "    # Define class configuration\n",
    "    class_config = ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "    \n",
    "    # Create new classifier model with ESM dimensions\n",
    "    class_model = ESMEncoderForSimpleSequenceClassification(esm_model, class_config)\n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, class_model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ESM_Classfier\\nTrainable Parameter: \" + str(params))\n",
    "    \n",
    "    # Add model modification LoRA\n",
    "    config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "    # Add LoRA layers\n",
    "    class_model = modify_with_lora(class_model, config)\n",
    "    \n",
    "    # Freeze Embeddings and Encoder (except LoRA)\n",
    "    for param_name, param in class_model.esm_model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param_name, param in class_model.named_parameters():\n",
    "        if re.fullmatch(config.trainable_param_names, param_name):\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, class_model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ESM_LoRA_Classfier\\nTrainable Parameter: \" + str(params) + \"\\n\")\n",
    "    \n",
    "    return class_model, batch_converter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c4d56b2-c9ca-460d-b977-a1e4ae1e9568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.864172Z",
     "iopub.status.busy": "2024-04-05T12:53:29.863760Z",
     "iopub.status.idle": "2024-04-05T12:53:29.873119Z",
     "shell.execute_reply": "2024-04-05T12:53:29.871609Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.864135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4550fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    \"\"\"Custom early stopping callback that can monitor loss or accuracy.\"\"\"\n",
    "    \n",
    "    def __init__(self, metric_name='eval_loss', early_stopping_patience=3, minimize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric_name (str): Metric to monitor, default 'eval_loss'.\n",
    "            early_stopping_patience (int): Number of checks with no improvement after which training will be stopped.\n",
    "            minimize (bool): Set to True if the metric should be minimized, False if it should be maximized.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_counter = 0\n",
    "        self.minimize = minimize\n",
    "        self.best_metric = float('inf') if minimize else float('-inf')\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        current_metric = kwargs['metrics'][self.metric_name]\n",
    "        \n",
    "        if (self.minimize and current_metric < self.best_metric) or (not self.minimize and current_metric > self.best_metric):\n",
    "            self.best_metric = current_metric\n",
    "            self.early_stopping_counter = 0\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "        \n",
    "        if self.early_stopping_counter >= self.early_stopping_patience:\n",
    "            control.should_training_stop = True\n",
    "            print(f'Stopping early! No improvement in {self.metric_name} for {self.early_stopping_patience} evaluation steps.')\n",
    "\n",
    "\n",
    "class MultiObjectiveEarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        # Extract current validation loss and accuracy\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "\n",
    "        # Check if current loss and accuracy improved significantly\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            # Update best scores and reset wait time\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            # If no improvement, increment the wait counter\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                # If wait exceeds the patience, stop training\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "class MultiObjectiveEarlyStoppingAndSaveCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001, output_dir='./model_output', filename='finetuned_model'):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "        self.output_dir = output_dir\n",
    "        self.filename = filename\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "        model = kwargs['model']\n",
    "\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "            # Save the model as the best so far\n",
    "            self.save_finetuned_parameters(model, os.path.join(self.output_dir, self.filename))\n",
    "            print(f\"Saved improved model to {self.output_dir}/{self.filename}\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "    def save_finetuned_parameters(self, model, filepath):\n",
    "        # Create a dictionary to hold the non-frozen parameters\n",
    "        non_frozen_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "        # Save only the finetuned parameters \n",
    "        torch.save(non_frozen_params, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ea2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['HF_HOME'] = '/home/ubuntu/data/hai/huggingface_cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb8bb11-79b0-4936-9099-f9f8ef97e105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.875565Z",
     "iopub.status.busy": "2024-04-05T12:53:29.875038Z",
     "iopub.status.idle": "2024-04-05T12:53:30.214710Z",
     "shell.execute_reply": "2024-04-05T12:53:30.213349Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.875495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# #!pip install seaborn\n",
    "# import seaborn as sns\n",
    "# import gc\n",
    "\n",
    "# # Set random seeds for reproducibility of your trainings run\n",
    "# def set_seeds(s):\n",
    "#     torch.manual_seed(s)\n",
    "#     np.random.seed(s)\n",
    "#     random.seed(s)\n",
    "#     set_seed(s)\n",
    "\n",
    "# def apply_umap(embeddings, n_components=2, min_dist=0.01):\n",
    "#     umap_model = umap.UMAP(n_components=n_components)\n",
    "#     umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "#     return umap_embeddings\n",
    "\n",
    "# def plot_umap(embeddings, labels):\n",
    "#     data = {\"UMAP1\": embeddings[:, 0], \"UMAP2\": embeddings[:, 1], \"Label\": labels}\n",
    "#     df = pd.DataFrame(data)\n",
    "    \n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.scatterplot(x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9)\n",
    "#     plt.title(\"UMAP Visualization of Embeddings\")\n",
    "#     plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_new.pdf\")\n",
    "#     plt.show()\n",
    "    \n",
    "# # Main training fuction\n",
    "# def train_per_protein(\n",
    "#         train_dataset,         #training data\n",
    "#         valid_dataset,         #validation data      \n",
    "#         weight_decay,\n",
    "#         warmup_pct,\n",
    "#         num_labels= 2,    #1 for regression, >1 for classification\n",
    "    \n",
    "#         # effective training batch size is batch * accum\n",
    "#         # we recommend an effective batch size of 8 \n",
    "#         batch= 4,         #for training\n",
    "#         accum= 2,         #gradient accumulation\n",
    "    \n",
    "#         val_batch = 16,   #batch size for evaluation\n",
    "#         epochs=1,       #training epochs\n",
    "#         lr= 3e-4,         #recommended learning rate\n",
    "#         seed= 42,         #random seed\n",
    "#         deepspeed=False,  #if gpu is large enough disable deepspeed for training speedup\n",
    "#         gpu= 1,\n",
    "#         dropout=0.5, #dropout rate\n",
    "#          #L2 weight regularization\n",
    "#         lora_rank=4,      #lora rank\n",
    "#         lora_init_scale=0.01, #lora scaling rank\n",
    "#         lora_scaling_rank=1,       #lora a\n",
    "#         ):         #gpu selection (1 for first gpu)\n",
    "\n",
    "#     # Set gpu device\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "#     # Set all random seeds\n",
    "#     set_seeds(seed)\n",
    "    \n",
    "#     # load model\n",
    "#     model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=dropout, lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "\n",
    "#     # Huggingface Trainer arguments\n",
    "#     total_steps = epochs * len(train_dataset) // batch\n",
    "#     warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "#     # Define TrainingArguments\n",
    "#     args = TrainingArguments(\n",
    "#         output_dir='./results',              # where to save the model\n",
    "#         evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "#         logging_strategy='epoch',\n",
    "#         save_strategy='no',\n",
    "#         learning_rate=lr,                    # initial learning rate\n",
    "#         per_device_train_batch_size=batch,   # batch size per device\n",
    "#         gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "#         num_train_epochs=epochs,             # number of epochs to train\n",
    "#         weight_decay=weight_decay,           # L2 weight regularization\n",
    "#         warmup_steps=warmup_steps,           # 10% of total steps\n",
    "#         load_best_model_at_end=False,         # load the best model at the end of training\n",
    "#         seed=seed,                           # random seed\n",
    "#         push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "#         logging_dir='./logs',\n",
    "#     )\n",
    "#     # metric_for_best_model='eval_loss|accuracy'\n",
    "\n",
    "#     # Metric definition for validation data\n",
    "#     def compute_metrics(eval_pred):\n",
    "#         predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "#         # Check if predictions have the expected shape\n",
    "#         if isinstance(predictions, tuple):\n",
    "#             predictions = predictions[0]\n",
    "#         if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "#             predictions = np.argmax(predictions, axis=1)\n",
    "#         # Now, compute the metric (e.g., accuracy)\n",
    "#         accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "#         # Return the metric(s) as a dictionary\n",
    "#         return {\"accuracy\": accuracy}\n",
    "    \n",
    "#     # For minimizing loss\n",
    "#     early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "#     # For maximizing accuracy\n",
    "#     early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "#     # Trainer          \n",
    "#     trainer = Trainer(\n",
    "#         model,\n",
    "#         args,\n",
    "#         train_dataset=train_dataset,\n",
    "#         eval_dataset=valid_dataset,\n",
    "#         tokenizer=tokenizer,\n",
    "#         compute_metrics=compute_metrics,\n",
    "#         callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "#             early_stopping_patience=3,\n",
    "#             min_delta=0.001,\n",
    "#             output_dir='./model_output',\n",
    "#             filename='finetuned_model_all_bfd.pth'\n",
    "#         )],\n",
    "#     )    \n",
    "\n",
    "#     def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "#         embeddings = []\n",
    "#         model = model.to(device)\n",
    "#         model.eval()\n",
    "    \n",
    "#         # Iterate over the sequences in batches\n",
    "#         for i in range(0, len(sequences), batch_size):\n",
    "#             # Extract a batch of sequences\n",
    "#             batch = sequences[i:i + batch_size]\n",
    "    \n",
    "#             # Tokenize the batch using the specified tokenizer and convert to PyTorch tensors\n",
    "#             inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "#             with torch.no_grad():\n",
    "#                 # Forward pass through the model to obtain outputs\n",
    "#                 outputs = model(**inputs)\n",
    "    \n",
    "#             # Extract hidden states from the second-to-last layer (penultimate layer)\n",
    "#             hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "    \n",
    "#             # Take the embeddings from the second-to-last layer\n",
    "#             embeddings_from_layer = hidden_states[:, 0, :]\n",
    "    \n",
    "#             # Extend the list with the generated embeddings\n",
    "#             embeddings.extend(embeddings_from_layer)\n",
    "    \n",
    "#             print(f\"Batch {i // batch_size + 1}, Second-to-Last Layer Embeddings Shape: {embeddings_from_layer.shape}\")\n",
    "    \n",
    "#         return np.array(embeddings)\n",
    "\n",
    "        \n",
    "#     # Train model\n",
    "#     trainer.train()\n",
    "\n",
    "#     # Get the best model\n",
    "#     # model = trainer.model\n",
    "#     # Ensure the best model is loaded\n",
    "#     best_model_path = os.path.join('./model_output', 'finetuned_model_all_bfd.pth')\n",
    "#     if os.path.exists(best_model_path):\n",
    "#         state_dict = torch.load(best_model_path)\n",
    "#         model.load_state_dict(state_dict, strict=False)\n",
    "#         print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "#     # Evaluate the best model\n",
    "#     eval_results = trainer.evaluate()\n",
    "#     print(eval_results)\n",
    "    \n",
    "#     # Print the current learning rate\n",
    "#     # current_lr = trainer.optimizer.param_groups[0]['lr']\n",
    "#     # print(f\"Current learning rate: {current_lr}\")\n",
    "    \n",
    "#     # valid_sequences = list(valid_dataset['sequence'])\n",
    "#     # valid_embeddings = get_embeddings(model, tokenizer, valid_sequences)\n",
    "\n",
    "#     # # Apply UMAP for dimensionality reduction\n",
    "#     # umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "#     # # Plot UMAP embeddings\n",
    "#     # labels = list(valid_dataset['label'])\n",
    "#     # plot_umap(umap_embeddings, labels)\n",
    "    \n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "\n",
    "#     return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aa2bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, min_dist=0.01):\n",
    "    umap_model = umap.UMAP(n_components=n_components)\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    data = {\"UMAP1\": embeddings[:, 0], \"UMAP2\": embeddings[:, 1], \"Label\": labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9)\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_new.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "def ESM_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "    # Load ESM model and alphabet\n",
    "    esm_model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    \n",
    "    # Define class configuration\n",
    "    class_config = ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "    \n",
    "    # Create new classifier model with ESM dimensions\n",
    "    class_model = ESMEncoderForSimpleSequenceClassification(esm_model, class_config)\n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, class_model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ESM_Classfier\\nTrainable Parameter: \" + str(params))\n",
    "    \n",
    "    # Add model modification LoRA\n",
    "    config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "    # Add LoRA layers\n",
    "    class_model = modify_with_lora(class_model, config)\n",
    "    \n",
    "    # Freeze Embeddings and Encoder (except LoRA)\n",
    "    for param_name, param in class_model.esm_model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param_name, param in class_model.named_parameters():\n",
    "        if re.fullmatch(config.trainable_param_names, param_name):\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, class_model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ESM_LoRA_Classfier\\nTrainable Parameter: \" + str(params) + \"\\n\")\n",
    "    \n",
    "    return class_model, batch_converter\n",
    "\n",
    "\n",
    "\n",
    "# Main training function\n",
    "def train_per_protein(\n",
    "        train_dataset,         # training data\n",
    "        valid_dataset,         # validation data\n",
    "        weight_decay,\n",
    "        warmup_pct,\n",
    "        num_labels=2,    # 1 for regression, >1 for classification\n",
    "        batch=4,         # for training\n",
    "        accum=2,         # gradient accumulation\n",
    "        val_batch=16,   # batch size for evaluation\n",
    "        epochs=1,       # training epochs\n",
    "        lr=3e-4,         # recommended learning rate\n",
    "        seed=42,         # random seed\n",
    "        deepspeed=False,  # if GPU is large enough, disable deepspeed for training speedup\n",
    "        gpu=1,\n",
    "        dropout=0.5,     # dropout rate\n",
    "        lora_rank=4,     # LoRA rank\n",
    "        lora_init_scale=0.01, # LoRA scaling rank\n",
    "        lora_scaling_rank=1,  # LoRA a\n",
    "        ):\n",
    "    \n",
    "    # Set GPU device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # Load model\n",
    "    model, batch_converter = ESM_classification_model(num_labels=num_labels, dropout=dropout, lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    total_steps = epochs * len(train_dataset) // batch\n",
    "    warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "    # Define TrainingArguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir='./results',              # where to save the model\n",
    "        evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "        logging_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        learning_rate=lr,                    # initial learning rate\n",
    "        per_device_train_batch_size=batch,   # batch size per device\n",
    "        gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "        num_train_epochs=epochs,             # number of epochs to train\n",
    "        weight_decay=weight_decay,           # L2 weight regularization\n",
    "        warmup_steps=warmup_steps,           # 10% of total steps\n",
    "        load_best_model_at_end=False,        # load the best model at the end of training\n",
    "        seed=seed,                           # random seed\n",
    "        push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "        logging_dir='./logs',\n",
    "    )\n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        # Check if predictions have the expected shape\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "        # Now, compute the metric (e.g., accuracy)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        # Return the metric(s) as a dictionary\n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    # For minimizing loss\n",
    "    # early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "    # # For maximizing accuracy\n",
    "    # early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=None,  # ESM model doesn't use a HuggingFace tokenizer\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "            early_stopping_patience=3,\n",
    "            min_delta=0.001,\n",
    "            output_dir='./model_output',\n",
    "            filename='finetuned_model_all_esm_no_lora.pth'\n",
    "        )],    )    \n",
    "\n",
    "    def get_embeddings(model, sequences, batch_size=32, device=\"cuda\"):\n",
    "        embeddings = []\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "    \n",
    "        # Iterate over the sequences in batches\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            # Extract a batch of sequences\n",
    "            batch = sequences[i:i + batch_size]\n",
    "    \n",
    "            # Convert sequences to tokens using batch_converter\n",
    "            batch_labels, batch_strs, batch_tokens = batch_converter(batch)\n",
    "            batch_tokens = batch_tokens.to(device)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                # Forward pass through the model to obtain outputs\n",
    "                outputs = model(batch_tokens)\n",
    "    \n",
    "            # Extract hidden states from the penultimate layer\n",
    "            hidden_states = outputs[\"logits\"].detach().cpu().numpy()\n",
    "    \n",
    "            # Take the embeddings from the second-to-last layer\n",
    "            embeddings_from_layer = hidden_states[:, 0, :]\n",
    "    \n",
    "            # Extend the list with the generated embeddings\n",
    "            embeddings.extend(embeddings_from_layer)\n",
    "    \n",
    "            print(f\"Batch {i // batch_size + 1}, Second-to-Last Layer Embeddings Shape: {embeddings_from_layer.shape}\")\n",
    "    \n",
    "        return np.array(embeddings)\n",
    "\n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    # Get the best model\n",
    "    best_model_path = os.path.join('./model_output', 'finetuned_model_all_esm_no_lora.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        state_dict = torch.load(best_model_path)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "    # Evaluate the best model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(eval_results)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return None, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "248cf4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "import esm\n",
    "\n",
    "# Function to create dataset\n",
    "def create_dataset(sequences, labels, batch_converter):\n",
    "    # Use the batch_converter to tokenize sequences\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(list(zip(labels, sequences)))\n",
    "    \n",
    "    # Create a dataset from the tokenized sequences\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"input_ids\": batch_tokens.tolist(),\n",
    "        \"labels\": labels\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "# Initialize the ESM model and batch_converter\n",
    "esm_model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "# Assume train_df and valid_df are your training and validation DataFrames\n",
    "train_df = my_train\n",
    "valid_df = my_valid\n",
    "\n",
    "# Preprocess inputs\n",
    "# Replace uncommon AAs with \"X\"\n",
    "train_df[\"sequence\"] = train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]), \"X\", regex=True)\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Create Datasets\n",
    "train_set = create_dataset(list(train_df['sequence']), list(train_df['label']), batch_converter)\n",
    "valid_set = create_dataset(list(valid_df['sequence']), list(valid_df['label']), batch_converter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b300952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# # Dataset creation\n",
    "# def create_dataset(tokenizer,seqs,labels):\n",
    "#     tokenized = tokenizer(seqs, max_length=1024, padding=True, truncation=True)\n",
    "#     dataset = Dataset.from_dict(tokenized)\n",
    "#     dataset = dataset.add_column(\"labels\", labels)\n",
    "\n",
    "#     return dataset\n",
    "\n",
    "# # Initialize the tokenizer\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", do_lower_case=False) \n",
    "\n",
    "# train_df = my_train\n",
    "# valid_df = my_valid\n",
    "\n",
    "# # Preprocess inputs\n",
    "# # Replace uncommon AAs with \"X\"\n",
    "# train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "# valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "# # Add spaces between each amino acid for PT5 to correctly use them\n",
    "# train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "# valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "# # Create Datasets\n",
    "# train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']))\n",
    "# valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f20a2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm all_dephos_noLORA_esm.sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcbe5f",
   "metadata": {},
   "source": [
    "lr 0.0007818596894056708\n",
    "\n",
    "batch 4\n",
    "\n",
    "accum 4\n",
    "\n",
    "dropout_rate 0.4540649581660329\n",
    "\n",
    "weight_decay 1.0585189745148587e-05\n",
    "\n",
    "warmup_pct 0.01886939819712101\n",
    "\n",
    "lora_rank 8\n",
    "\n",
    "lora_init_scale 0.01054546478690803\n",
    "\n",
    "lora_scaling_rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a57f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca1393b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 495/1980 02:14 < 06:46, 3.65 it/s, Epoch 5/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.779700</td>\n",
       "      <td>0.591919</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.539400</td>\n",
       "      <td>0.499246</td>\n",
       "      <td>0.782828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.441200</td>\n",
       "      <td>0.543619</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.574022</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.361500</td>\n",
       "      <td>0.679763</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_bfd.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_bfd.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_bfd.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.49924570322036743, 'eval_accuracy': 0.7828282828282829, 'eval_runtime': 2.3796, 'eval_samples_per_second': 166.413, 'eval_steps_per_second': 21.012, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# Assume train_set and valid_set are already created datasets\n",
    "\n",
    "_, model, history = train_per_protein(\n",
    "    train_set, \n",
    "    valid_set, \n",
    "    weight_decay=1.0585189745148587e-05, \n",
    "    warmup_pct=0.01886939819712101, \n",
    "    num_labels=2, \n",
    "    batch=4, \n",
    "    accum=4, \n",
    "    epochs=20, \n",
    "    seed=42, \n",
    "    lr=0.0007818596894056708, \n",
    "    dropout=0.4540649581660329, \n",
    "    lora_rank=8, \n",
    "    lora_init_scale=0.01054546478690803, \n",
    "    lora_scaling_rank=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ebf90f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:20:09,149] A new study created in RDB with name: all_dephos_noLORA_esm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 02:12, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.927400</td>\n",
       "      <td>0.687018</td>\n",
       "      <td>0.550505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.545700</td>\n",
       "      <td>0.524538</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.371100</td>\n",
       "      <td>0.603142</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5418418049812317, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 2.4059, 'eval_samples_per_second': 164.596, 'eval_steps_per_second': 20.782, 'epoch': 4.95}\n",
      "History:  [{'loss': 0.9274, 'learning_rate': 0.00018438559140728238, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.687017560005188, 'eval_accuracy': 0.5505050505050505, 'eval_runtime': 2.4182, 'eval_samples_per_second': 163.76, 'eval_steps_per_second': 20.677, 'epoch': 0.99, 'step': 49}, {'loss': 0.7015, 'learning_rate': 0.0003725341540677746, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.597595751285553, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3702, 'eval_samples_per_second': 167.073, 'eval_steps_per_second': 21.095, 'epoch': 2.0, 'step': 99}, {'loss': 0.5457, 'learning_rate': 0.000556919745475057, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.5245376229286194, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3734, 'eval_samples_per_second': 166.85, 'eval_steps_per_second': 21.067, 'epoch': 2.99, 'step': 148}, {'loss': 0.4651, 'learning_rate': 0.0007450683081355492, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5418418049812317, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 2.3807, 'eval_samples_per_second': 166.337, 'eval_steps_per_second': 21.002, 'epoch': 4.0, 'step': 198}, {'loss': 0.3711, 'learning_rate': 0.0009219279570364119, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.603142499923706, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3755, 'eval_samples_per_second': 166.705, 'eval_steps_per_second': 21.049, 'epoch': 4.95, 'step': 245}, {'train_runtime': 138.7624, 'train_samples_per_second': 57.076, 'train_steps_per_second': 1.766, 'total_flos': 0.0, 'train_loss': 0.6038853080905213, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5418418049812317, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 2.4059, 'eval_samples_per_second': 164.596, 'eval_steps_per_second': 20.782, 'epoch': 4.95, 'step': 245}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:22:45,677] Trial 0 finished with values: [0.5418418049812317, 0.7676767676767676] and parameters: {'lr': 0.0009482687558088808, 'batch': 4, 'accum': 8, 'dropout_rate': 0.5078646795206229, 'weight_decay': 1.8639783574929038e-05, 'warmup_pct': 0.12735869517439577}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.173800</td>\n",
       "      <td>0.741324</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.893900</td>\n",
       "      <td>0.670730</td>\n",
       "      <td>0.628788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.657900</td>\n",
       "      <td>0.610819</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.602100</td>\n",
       "      <td>0.558128</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.538400</td>\n",
       "      <td>0.552919</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5529186725616455, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3835, 'eval_samples_per_second': 166.142, 'eval_steps_per_second': 20.978, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:26:42,770] Trial 1 finished with values: [0.5529186725616455, 0.7323232323232324] and parameters: {'lr': 0.00020346991265926905, 'batch': 2, 'accum': 4, 'dropout_rate': 0.8024822715089562, 'weight_decay': 6.623901780297333e-05, 'warmup_pct': 0.18582702970746992}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1738, 'learning_rate': 5.481230300208881e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.7413235306739807, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4075, 'eval_samples_per_second': 164.485, 'eval_steps_per_second': 20.768, 'epoch': 1.0, 'step': 198}, {'loss': 0.8939, 'learning_rate': 0.00010962460600417762, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6707295179367065, 'eval_accuracy': 0.6287878787878788, 'eval_runtime': 2.3761, 'eval_samples_per_second': 166.663, 'eval_steps_per_second': 21.043, 'epoch': 2.0, 'step': 396}, {'loss': 0.6579, 'learning_rate': 0.00016443690900626643, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6108192801475525, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.3904, 'eval_samples_per_second': 165.665, 'eval_steps_per_second': 20.917, 'epoch': 3.0, 'step': 594}, {'loss': 0.6021, 'learning_rate': 0.00015798840277072657, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.558128297328949, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 2.38, 'eval_samples_per_second': 166.388, 'eval_steps_per_second': 21.009, 'epoch': 4.0, 'step': 792}, {'loss': 0.5384, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5529186725616455, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3806, 'eval_samples_per_second': 166.343, 'eval_steps_per_second': 21.003, 'epoch': 5.0, 'step': 990}, {'train_runtime': 221.5267, 'train_samples_per_second': 35.752, 'train_steps_per_second': 4.469, 'total_flos': 0.0, 'train_loss': 0.773244954118825, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5529186725616455, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3835, 'eval_samples_per_second': 166.142, 'eval_steps_per_second': 20.978, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 02:13, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.107700</td>\n",
       "      <td>0.681419</td>\n",
       "      <td>0.510101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.584200</td>\n",
       "      <td>0.530773</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.562814</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5364523530006409, 'eval_accuracy': 0.7651515151515151, 'eval_runtime': 2.3841, 'eval_samples_per_second': 166.1, 'eval_steps_per_second': 20.972, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:29:11,929] Trial 2 finished with values: [0.5364523530006409, 0.7651515151515151] and parameters: {'lr': 0.0026434035671698895, 'batch': 4, 'accum': 8, 'dropout_rate': 0.8426275228259498, 'weight_decay': 1.2229560673027971e-05, 'warmup_pct': 0.16819141556956405}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1077, 'learning_rate': 0.0003889692936676414, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.6814190745353699, 'eval_accuracy': 0.51010101010101, 'eval_runtime': 2.4249, 'eval_samples_per_second': 163.305, 'eval_steps_per_second': 20.619, 'epoch': 0.99, 'step': 49}, {'loss': 0.7024, 'learning_rate': 0.0007858767361856429, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.5926249623298645, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 2.3819, 'eval_samples_per_second': 166.256, 'eval_steps_per_second': 20.992, 'epoch': 2.0, 'step': 99}, {'loss': 0.5842, 'learning_rate': 0.0011748460298532841, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.530772864818573, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3904, 'eval_samples_per_second': 165.666, 'eval_steps_per_second': 20.917, 'epoch': 2.99, 'step': 148}, {'loss': 0.5174, 'learning_rate': 0.0015717534723712857, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5364523530006409, 'eval_accuracy': 0.7651515151515151, 'eval_runtime': 2.3849, 'eval_samples_per_second': 166.042, 'eval_steps_per_second': 20.965, 'epoch': 4.0, 'step': 198}, {'loss': 0.521, 'learning_rate': 0.0019448464683382068, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5628144145011902, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 2.3921, 'eval_samples_per_second': 165.542, 'eval_steps_per_second': 20.902, 'epoch': 4.95, 'step': 245}, {'train_runtime': 133.636, 'train_samples_per_second': 59.265, 'train_steps_per_second': 1.833, 'total_flos': 0.0, 'train_loss': 0.6872501840396803, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5364523530006409, 'eval_accuracy': 0.7651515151515151, 'eval_runtime': 2.3841, 'eval_samples_per_second': 166.1, 'eval_steps_per_second': 20.972, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 01:45, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.899700</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.758400</td>\n",
       "      <td>0.698231</td>\n",
       "      <td>0.510101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.709200</td>\n",
       "      <td>0.682154</td>\n",
       "      <td>0.578283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6821537017822266, 'eval_accuracy': 0.5782828282828283, 'eval_runtime': 2.3916, 'eval_samples_per_second': 165.576, 'eval_steps_per_second': 20.906, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:31:13,041] Trial 3 finished with values: [0.6821537017822266, 0.5782828282828283] and parameters: {'lr': 2.518578485581676e-05, 'batch': 8, 'accum': 4, 'dropout_rate': 0.19985392099174062, 'weight_decay': 0.00011316018821785159, 'warmup_pct': 0.1446328441050829}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8997, 'learning_rate': 8.630094111433714e-06, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.8257953524589539, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4296, 'eval_samples_per_second': 162.992, 'eval_steps_per_second': 20.58, 'epoch': 0.99, 'step': 49}, {'loss': 0.8192, 'learning_rate': 1.7436312592488526e-05, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.7467978000640869, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3977, 'eval_samples_per_second': 165.16, 'eval_steps_per_second': 20.853, 'epoch': 2.0, 'step': 99}, {'loss': 0.7584, 'learning_rate': 2.3951187558962995e-05, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.6982306241989136, 'eval_accuracy': 0.51010101010101, 'eval_runtime': 2.3891, 'eval_samples_per_second': 165.755, 'eval_steps_per_second': 20.929, 'epoch': 2.99, 'step': 148}, {'loss': 0.7099, 'learning_rate': 1.1605214590425368e-05, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.6859604120254517, 'eval_accuracy': 0.5707070707070707, 'eval_runtime': 2.3895, 'eval_samples_per_second': 165.725, 'eval_steps_per_second': 20.925, 'epoch': 4.0, 'step': 198}, {'loss': 0.7092, 'learning_rate': 0.0, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.6821537017822266, 'eval_accuracy': 0.5782828282828283, 'eval_runtime': 2.3905, 'eval_samples_per_second': 165.654, 'eval_steps_per_second': 20.916, 'epoch': 4.95, 'step': 245}, {'train_runtime': 106.2455, 'train_samples_per_second': 74.544, 'train_steps_per_second': 2.306, 'total_flos': 0.0, 'train_loss': 0.7797327314104353, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.6821537017822266, 'eval_accuracy': 0.5782828282828283, 'eval_runtime': 2.3916, 'eval_samples_per_second': 165.576, 'eval_steps_per_second': 20.906, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 01:45, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.889800</td>\n",
       "      <td>0.713298</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.606449</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.507400</td>\n",
       "      <td>0.557675</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5580357909202576, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.854, 'eval_steps_per_second': 20.941, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:33:14,355] Trial 4 finished with values: [0.5580357909202576, 0.7424242424242424] and parameters: {'lr': 0.0002875349579388252, 'batch': 8, 'accum': 4, 'dropout_rate': 0.3664426861971811, 'weight_decay': 0.00020215322767494295, 'warmup_pct': 0.23074007626616083}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8898, 'learning_rate': 6.179479359211594e-05, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.7132983803749084, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4337, 'eval_samples_per_second': 162.714, 'eval_steps_per_second': 20.545, 'epoch': 0.99, 'step': 49}, {'loss': 0.7282, 'learning_rate': 0.0001248507054208057, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.6611166000366211, 'eval_accuracy': 0.6464646464646465, 'eval_runtime': 2.3866, 'eval_samples_per_second': 165.93, 'eval_steps_per_second': 20.951, 'epoch': 2.0, 'step': 99}, {'loss': 0.6575, 'learning_rate': 0.00018664549901292163, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.6064490675926208, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.704, 'eval_steps_per_second': 20.922, 'epoch': 2.99, 'step': 148}, {'loss': 0.5653, 'learning_rate': 0.0002497014108416114, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5580357909202576, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3842, 'eval_samples_per_second': 166.094, 'eval_steps_per_second': 20.971, 'epoch': 4.0, 'step': 198}, {'loss': 0.5074, 'learning_rate': 0.0, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.557675302028656, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3956, 'eval_samples_per_second': 165.305, 'eval_steps_per_second': 20.872, 'epoch': 4.95, 'step': 245}, {'train_runtime': 106.2247, 'train_samples_per_second': 74.559, 'train_steps_per_second': 2.306, 'total_flos': 0.0, 'train_loss': 0.6707716338488521, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5580357909202576, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.854, 'eval_steps_per_second': 20.941, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 01:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.852900</td>\n",
       "      <td>0.579916</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.756900</td>\n",
       "      <td>0.638819</td>\n",
       "      <td>0.648990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>0.529092</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>0.525879</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.483700</td>\n",
       "      <td>0.505793</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5057934522628784, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.4316, 'eval_samples_per_second': 162.856, 'eval_steps_per_second': 20.563, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:35:17,555] Trial 5 finished with values: [0.5057934522628784, 0.7575757575757576] and parameters: {'lr': 0.003683776838729286, 'batch': 8, 'accum': 2, 'dropout_rate': 0.8544569159968521, 'weight_decay': 0.0008196064718702577, 'warmup_pct': 0.16858374448371116}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8529, 'learning_rate': 0.0021969512471939714, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5799157023429871, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.4211, 'eval_samples_per_second': 163.561, 'eval_steps_per_second': 20.652, 'epoch': 1.0, 'step': 99}, {'loss': 0.7569, 'learning_rate': 0.003325476355934948, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6388189792633057, 'eval_accuracy': 0.648989898989899, 'eval_runtime': 2.3914, 'eval_samples_per_second': 165.594, 'eval_steps_per_second': 20.908, 'epoch': 2.0, 'step': 198}, {'loss': 0.6454, 'learning_rate': 0.0022169842372899654, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5290923118591309, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3924, 'eval_samples_per_second': 165.527, 'eval_steps_per_second': 20.9, 'epoch': 3.0, 'step': 297}, {'loss': 0.5753, 'learning_rate': 0.0011084921186449827, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5258785486221313, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3839, 'eval_samples_per_second': 166.117, 'eval_steps_per_second': 20.974, 'epoch': 4.0, 'step': 396}, {'loss': 0.4837, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5057934522628784, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3864, 'eval_samples_per_second': 165.943, 'eval_steps_per_second': 20.952, 'epoch': 5.0, 'step': 495}, {'train_runtime': 108.7426, 'train_samples_per_second': 72.833, 'train_steps_per_second': 4.552, 'total_flos': 0.0, 'train_loss': 0.662842683117799, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5057934522628784, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.4316, 'eval_samples_per_second': 162.856, 'eval_steps_per_second': 20.563, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 07:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.873900</td>\n",
       "      <td>0.689848</td>\n",
       "      <td>0.512626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.681700</td>\n",
       "      <td>0.603372</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.620700</td>\n",
       "      <td>0.719639</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.609500</td>\n",
       "      <td>0.926983</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.490300</td>\n",
       "      <td>1.004702</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9269832968711853, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.4199, 'eval_samples_per_second': 163.643, 'eval_steps_per_second': 20.662, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:42:33,508] Trial 6 finished with values: [0.9269832968711853, 0.7626262626262627] and parameters: {'lr': 0.00011729822597402431, 'batch': 1, 'accum': 2, 'dropout_rate': 0.4258356729985485, 'weight_decay': 9.833347839805573e-05, 'warmup_pct': 0.24803655575167158}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8739, 'learning_rate': 4.7301524934535266e-05, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.6898477077484131, 'eval_accuracy': 0.5126262626262627, 'eval_runtime': 2.4271, 'eval_samples_per_second': 163.158, 'eval_steps_per_second': 20.601, 'epoch': 1.0, 'step': 792}, {'loss': 0.6817, 'learning_rate': 9.460304986907053e-05, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6033724546432495, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.3894, 'eval_samples_per_second': 165.731, 'eval_steps_per_second': 20.926, 'epoch': 2.0, 'step': 1584}, {'loss': 0.6207, 'learning_rate': 9.308636770684094e-05, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.7196387648582458, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.3956, 'eval_samples_per_second': 165.306, 'eval_steps_per_second': 20.872, 'epoch': 3.0, 'step': 2376}, {'loss': 0.6095, 'learning_rate': 4.654318385342047e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.9269832968711853, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.4029, 'eval_samples_per_second': 164.802, 'eval_steps_per_second': 20.808, 'epoch': 4.0, 'step': 3168}, {'loss': 0.4903, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 1.0047019720077515, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.3938, 'eval_samples_per_second': 165.425, 'eval_steps_per_second': 20.887, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 421.0479, 'train_samples_per_second': 18.81, 'train_steps_per_second': 9.405, 'total_flos': 0.0, 'train_loss': 0.655224863688151, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.9269832968711853, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.4199, 'eval_samples_per_second': 163.643, 'eval_steps_per_second': 20.662, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.621017</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.588400</td>\n",
       "      <td>0.532839</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.494800</td>\n",
       "      <td>0.585483</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.438400</td>\n",
       "      <td>0.587613</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>0.624830</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5328385829925537, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3856, 'eval_samples_per_second': 165.993, 'eval_steps_per_second': 20.959, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:49:31,965] Trial 7 finished with values: [0.5328385829925537, 0.7525252525252525] and parameters: {'lr': 0.00014284290340818136, 'batch': 1, 'accum': 4, 'dropout_rate': 0.2080290627140376, 'weight_decay': 1.0061476346999425e-05, 'warmup_pct': 0.050016076647387546}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.748, 'learning_rate': 0.00014284290340818136, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6210168600082397, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.4276, 'eval_samples_per_second': 163.127, 'eval_steps_per_second': 20.597, 'epoch': 1.0, 'step': 396}, {'loss': 0.5884, 'learning_rate': 0.00010713217755613602, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.5328385829925537, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.382, 'eval_samples_per_second': 166.249, 'eval_steps_per_second': 20.991, 'epoch': 2.0, 'step': 792}, {'loss': 0.4948, 'learning_rate': 7.142145170409068e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.5854828357696533, 'eval_accuracy': 0.75, 'eval_runtime': 2.3836, 'eval_samples_per_second': 166.136, 'eval_steps_per_second': 20.977, 'epoch': 3.0, 'step': 1188}, {'loss': 0.4384, 'learning_rate': 3.571072585204534e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.5876127481460571, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3806, 'eval_samples_per_second': 166.347, 'eval_steps_per_second': 21.003, 'epoch': 4.0, 'step': 1584}, {'loss': 0.3871, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6248298287391663, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.388, 'eval_samples_per_second': 165.827, 'eval_steps_per_second': 20.938, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 404.077, 'train_samples_per_second': 19.6, 'train_steps_per_second': 4.9, 'total_flos': 0.0, 'train_loss': 0.5313586302477904, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5328385829925537, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3856, 'eval_samples_per_second': 165.993, 'eval_steps_per_second': 20.959, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 03:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.682200</td>\n",
       "      <td>0.777573</td>\n",
       "      <td>0.641414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.856800</td>\n",
       "      <td>0.711236</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.796200</td>\n",
       "      <td>0.632068</td>\n",
       "      <td>0.648990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.682200</td>\n",
       "      <td>0.636386</td>\n",
       "      <td>0.633838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.656300</td>\n",
       "      <td>0.619669</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6196690201759338, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 2.3834, 'eval_samples_per_second': 166.151, 'eval_steps_per_second': 20.979, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:53:30,642] Trial 8 finished with values: [0.6196690201759338, 0.6666666666666666] and parameters: {'lr': 0.003910077966096533, 'batch': 2, 'accum': 2, 'dropout_rate': 0.4566814361858127, 'weight_decay': 1.4128809232463443e-05, 'warmup_pct': 0.27746533877747237}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6822, 'learning_rate': 0.0014101920533462907, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.7775726318359375, 'eval_accuracy': 0.6414141414141414, 'eval_runtime': 2.4325, 'eval_samples_per_second': 162.795, 'eval_steps_per_second': 20.555, 'epoch': 1.0, 'step': 396}, {'loss': 0.8568, 'learning_rate': 0.0028203841066925814, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.7112364172935486, 'eval_accuracy': 0.5454545454545454, 'eval_runtime': 2.3862, 'eval_samples_per_second': 165.954, 'eval_steps_per_second': 20.954, 'epoch': 2.0, 'step': 792}, {'loss': 0.7962, 'learning_rate': 0.0035110904185356624, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6320679187774658, 'eval_accuracy': 0.648989898989899, 'eval_runtime': 2.418, 'eval_samples_per_second': 163.775, 'eval_steps_per_second': 20.679, 'epoch': 3.0, 'step': 1188}, {'loss': 0.6822, 'learning_rate': 0.0017555452092678312, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6363855600357056, 'eval_accuracy': 0.6338383838383839, 'eval_runtime': 2.3935, 'eval_samples_per_second': 165.446, 'eval_steps_per_second': 20.89, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6563, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6196690201759338, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 2.381, 'eval_samples_per_second': 166.317, 'eval_steps_per_second': 21.0, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 225.13, 'train_samples_per_second': 35.18, 'train_steps_per_second': 8.795, 'total_flos': 0.0, 'train_loss': 0.7347416116733744, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6196690201759338, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 2.3834, 'eval_samples_per_second': 166.151, 'eval_steps_per_second': 20.979, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 02:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.912900</td>\n",
       "      <td>0.644872</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.652600</td>\n",
       "      <td>0.584996</td>\n",
       "      <td>0.669192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.735200</td>\n",
       "      <td>0.632706</td>\n",
       "      <td>0.621212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.805800</td>\n",
       "      <td>0.749453</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.743700</td>\n",
       "      <td>0.667185</td>\n",
       "      <td>0.623737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5849964618682861, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.4052, 'eval_samples_per_second': 164.64, 'eval_steps_per_second': 20.788, 'epoch': 5.0}\n",
      "History:  [{'loss': 0.9129, 'learning_rate': 0.001174499487343238, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6448724269866943, 'eval_accuracy': 0.6111111111111112, 'eval_runtime': 2.4075, 'eval_samples_per_second': 164.489, 'eval_steps_per_second': 20.769, 'epoch': 1.0, 'step': 99}, {'loss': 0.6526, 'learning_rate': 0.002348998974686476, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5849964618682861, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.3942, 'eval_samples_per_second': 165.401, 'eval_steps_per_second': 20.884, 'epoch': 2.0, 'step': 198}, {'loss': 0.7352, 'learning_rate': 0.0035234984620297143, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6327064037322998, 'eval_accuracy': 0.6212121212121212, 'eval_runtime': 2.3825, 'eval_samples_per_second': 166.214, 'eval_steps_per_second': 20.987, 'epoch': 3.0, 'step': 297}, {'loss': 0.8058, 'learning_rate': 0.004697997949372952, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.7494533061981201, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3939, 'eval_samples_per_second': 165.419, 'eval_steps_per_second': 20.886, 'epoch': 4.0, 'step': 396}, {'loss': 0.7437, 'learning_rate': 0.00587249743671619, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6671847105026245, 'eval_accuracy': 0.6237373737373737, 'eval_runtime': 2.3895, 'eval_samples_per_second': 165.724, 'eval_steps_per_second': 20.925, 'epoch': 5.0, 'step': 495}, {'train_runtime': 135.7941, 'train_samples_per_second': 58.324, 'train_steps_per_second': 3.645, 'total_flos': 0.0, 'train_loss': 0.7700656158755524, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5849964618682861, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.4052, 'eval_samples_per_second': 164.64, 'eval_steps_per_second': 20.788, 'epoch': 5.0, 'step': 495}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:56:00,046] Trial 9 finished with values: [0.5849964618682861, 0.6691919191919192] and parameters: {'lr': 0.005896224699086761, 'batch': 4, 'accum': 4, 'dropout_rate': 0.8862820877124913, 'weight_decay': 0.0006003361529211938, 'warmup_pct': 0.2512517467249306}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.952200</td>\n",
       "      <td>0.791058</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>0.710215</td>\n",
       "      <td>0.507576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.754700</td>\n",
       "      <td>0.677306</td>\n",
       "      <td>0.598485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.705900</td>\n",
       "      <td>0.653359</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.650600</td>\n",
       "      <td>0.623763</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6237630844116211, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.3895, 'eval_samples_per_second': 165.725, 'eval_steps_per_second': 20.925, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 07:59:36,931] Trial 10 finished with values: [0.6237630844116211, 0.696969696969697] and parameters: {'lr': 5.516531302657079e-05, 'batch': 2, 'accum': 4, 'dropout_rate': 0.414472537281629, 'weight_decay': 0.0001800718182568339, 'warmup_pct': 0.2844097486281415}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9522, 'learning_rate': 9.700472450498239e-06, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.7910580039024353, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4198, 'eval_samples_per_second': 163.652, 'eval_steps_per_second': 20.663, 'epoch': 1.0, 'step': 198}, {'loss': 0.8586, 'learning_rate': 1.9400944900996477e-05, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.7102145552635193, 'eval_accuracy': 0.5075757575757576, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.707, 'eval_steps_per_second': 20.923, 'epoch': 2.0, 'step': 396}, {'loss': 0.7547, 'learning_rate': 2.9101417351494714e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6773055791854858, 'eval_accuracy': 0.5984848484848485, 'eval_runtime': 2.3863, 'eval_samples_per_second': 165.946, 'eval_steps_per_second': 20.953, 'epoch': 3.0, 'step': 594}, {'loss': 0.7059, 'learning_rate': 3.8801889801992955e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6533587574958801, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.3868, 'eval_samples_per_second': 165.912, 'eval_steps_per_second': 20.948, 'epoch': 4.0, 'step': 792}, {'loss': 0.6506, 'learning_rate': 4.8502362252491185e-05, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6237630844116211, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.3872, 'eval_samples_per_second': 165.887, 'eval_steps_per_second': 20.945, 'epoch': 5.0, 'step': 990}, {'train_runtime': 203.9651, 'train_samples_per_second': 38.83, 'train_steps_per_second': 4.854, 'total_flos': 0.0, 'train_loss': 0.7843821670069839, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6237630844116211, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.3895, 'eval_samples_per_second': 165.725, 'eval_steps_per_second': 20.925, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.044500</td>\n",
       "      <td>0.771205</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.944400</td>\n",
       "      <td>0.725594</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.872400</td>\n",
       "      <td>0.706890</td>\n",
       "      <td>0.510101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.845100</td>\n",
       "      <td>0.697865</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>0.696176</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.696176290512085, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.3921, 'eval_samples_per_second': 165.545, 'eval_steps_per_second': 20.902, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:06:34,479] Trial 11 finished with values: [0.696176290512085, 0.494949494949495] and parameters: {'lr': 1.5161287217324154e-05, 'batch': 1, 'accum': 4, 'dropout_rate': 0.6869693757314441, 'weight_decay': 4.6202065573283256e-05, 'warmup_pct': 0.011122516351375924}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.0445, 'learning_rate': 1.2693170693573712e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.7712050676345825, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4345, 'eval_samples_per_second': 162.662, 'eval_steps_per_second': 20.538, 'epoch': 1.0, 'step': 396}, {'loss': 0.9444, 'learning_rate': 9.519878020180282e-06, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.7255935072898865, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.4103, 'eval_samples_per_second': 164.294, 'eval_steps_per_second': 20.744, 'epoch': 2.0, 'step': 792}, {'loss': 0.8724, 'learning_rate': 6.346585346786856e-06, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.7068900465965271, 'eval_accuracy': 0.51010101010101, 'eval_runtime': 2.3921, 'eval_samples_per_second': 165.547, 'eval_steps_per_second': 20.902, 'epoch': 3.0, 'step': 1188}, {'loss': 0.8451, 'learning_rate': 3.173292673393428e-06, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6978647112846375, 'eval_accuracy': 0.5, 'eval_runtime': 2.3986, 'eval_samples_per_second': 165.095, 'eval_steps_per_second': 20.845, 'epoch': 4.0, 'step': 1584}, {'loss': 0.8196, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.696176290512085, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.3922, 'eval_samples_per_second': 165.539, 'eval_steps_per_second': 20.901, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 404.5741, 'train_samples_per_second': 19.576, 'train_steps_per_second': 4.894, 'total_flos': 0.0, 'train_loss': 0.9052121094983033, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.696176290512085, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.3921, 'eval_samples_per_second': 165.545, 'eval_steps_per_second': 20.902, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 01:45, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.107600</td>\n",
       "      <td>0.806899</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.884400</td>\n",
       "      <td>0.681660</td>\n",
       "      <td>0.578283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.671400</td>\n",
       "      <td>0.618720</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6187196969985962, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3913, 'eval_samples_per_second': 165.603, 'eval_steps_per_second': 20.909, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:08:33,450] Trial 12 finished with values: [0.6187196969985962, 0.6843434343434344] and parameters: {'lr': 0.0001553677171170621, 'batch': 8, 'accum': 4, 'dropout_rate': 0.6649420762960857, 'weight_decay': 0.0005871919830213267, 'warmup_pct': 0.29181631422148985}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1076, 'learning_rate': 2.643409075950015e-05, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.8068992495536804, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4329, 'eval_samples_per_second': 162.766, 'eval_steps_per_second': 20.551, 'epoch': 0.99, 'step': 49}, {'loss': 0.971, 'learning_rate': 5.34076527589901e-05, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.7159594297409058, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3935, 'eval_samples_per_second': 165.449, 'eval_steps_per_second': 20.89, 'epoch': 2.0, 'step': 99}, {'loss': 0.8844, 'learning_rate': 7.984174351849025e-05, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.6816595792770386, 'eval_accuracy': 0.5782828282828283, 'eval_runtime': 2.3953, 'eval_samples_per_second': 165.324, 'eval_steps_per_second': 20.874, 'epoch': 2.99, 'step': 148}, {'loss': 0.7706, 'learning_rate': 0.0001068153055179802, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.654568612575531, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 2.3964, 'eval_samples_per_second': 165.247, 'eval_steps_per_second': 20.865, 'epoch': 4.0, 'step': 198}, {'loss': 0.6714, 'learning_rate': 0.00013217045379750075, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.6187196969985962, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3933, 'eval_samples_per_second': 165.464, 'eval_steps_per_second': 20.892, 'epoch': 4.95, 'step': 245}, {'train_runtime': 105.9383, 'train_samples_per_second': 74.761, 'train_steps_per_second': 2.313, 'total_flos': 0.0, 'train_loss': 0.8826063740010164, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.6187196969985962, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3913, 'eval_samples_per_second': 165.603, 'eval_steps_per_second': 20.909, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.016300</td>\n",
       "      <td>0.844733</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.022400</td>\n",
       "      <td>0.805217</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.911700</td>\n",
       "      <td>0.754899</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.876700</td>\n",
       "      <td>0.719694</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.815900</td>\n",
       "      <td>0.694454</td>\n",
       "      <td>0.525253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6944543123245239, 'eval_accuracy': 0.5252525252525253, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.707, 'eval_steps_per_second': 20.923, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:12:13,418] Trial 13 finished with values: [0.6944543123245239, 0.5252525252525253] and parameters: {'lr': 1.641922650378061e-05, 'batch': 2, 'accum': 4, 'dropout_rate': 0.5629384783921074, 'weight_decay': 0.0006709278573715538, 'warmup_pct': 0.29932157431017997}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.0163, 'learning_rate': 2.743465694302583e-06, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.8447333574295044, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4163, 'eval_samples_per_second': 163.889, 'eval_steps_per_second': 20.693, 'epoch': 1.0, 'step': 198}, {'loss': 1.0224, 'learning_rate': 5.486931388605166e-06, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.8052170276641846, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3901, 'eval_samples_per_second': 165.684, 'eval_steps_per_second': 20.92, 'epoch': 2.0, 'step': 396}, {'loss': 0.9117, 'learning_rate': 8.230397082907748e-06, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.7548986673355103, 'eval_accuracy': 0.5, 'eval_runtime': 2.3888, 'eval_samples_per_second': 165.777, 'eval_steps_per_second': 20.931, 'epoch': 3.0, 'step': 594}, {'loss': 0.8767, 'learning_rate': 1.0973862777210332e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.7196941375732422, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3892, 'eval_samples_per_second': 165.743, 'eval_steps_per_second': 20.927, 'epoch': 4.0, 'step': 792}, {'loss': 0.8159, 'learning_rate': 1.3717328471512914e-05, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6944543123245239, 'eval_accuracy': 0.5252525252525253, 'eval_runtime': 2.3938, 'eval_samples_per_second': 165.425, 'eval_steps_per_second': 20.887, 'epoch': 5.0, 'step': 990}, {'train_runtime': 207.0557, 'train_samples_per_second': 38.251, 'train_steps_per_second': 4.781, 'total_flos': 0.0, 'train_loss': 0.9286225444138653, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6944543123245239, 'eval_accuracy': 0.5252525252525253, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.707, 'eval_steps_per_second': 20.923, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.886400</td>\n",
       "      <td>0.722275</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.750300</td>\n",
       "      <td>0.670945</td>\n",
       "      <td>0.631313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.624039</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.583500</td>\n",
       "      <td>0.579914</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.553799</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5537992119789124, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3891, 'eval_samples_per_second': 165.751, 'eval_steps_per_second': 20.928, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:15:51,941] Trial 14 finished with values: [0.5537992119789124, 0.7474747474747475] and parameters: {'lr': 0.00014801925216937834, 'batch': 2, 'accum': 4, 'dropout_rate': 0.3262524723241616, 'weight_decay': 0.00026633364694670817, 'warmup_pct': 0.2830421730372154}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8864, 'learning_rate': 2.6167689222800816e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.7222745418548584, 'eval_accuracy': 0.5, 'eval_runtime': 2.4144, 'eval_samples_per_second': 164.015, 'eval_steps_per_second': 20.709, 'epoch': 1.0, 'step': 198}, {'loss': 0.7503, 'learning_rate': 5.233537844560163e-05, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6709448099136353, 'eval_accuracy': 0.6313131313131313, 'eval_runtime': 2.3909, 'eval_samples_per_second': 165.626, 'eval_steps_per_second': 20.912, 'epoch': 2.0, 'step': 396}, {'loss': 0.666, 'learning_rate': 7.850306766840243e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6240392327308655, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 2.3879, 'eval_samples_per_second': 165.833, 'eval_steps_per_second': 20.939, 'epoch': 3.0, 'step': 594}, {'loss': 0.5835, 'learning_rate': 0.00010467075689120326, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.579914391040802, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3911, 'eval_samples_per_second': 165.617, 'eval_steps_per_second': 20.911, 'epoch': 4.0, 'step': 792}, {'loss': 0.512, 'learning_rate': 0.00013083844611400407, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5537992119789124, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3934, 'eval_samples_per_second': 165.456, 'eval_steps_per_second': 20.891, 'epoch': 5.0, 'step': 990}, {'train_runtime': 205.7383, 'train_samples_per_second': 38.496, 'train_steps_per_second': 4.812, 'total_flos': 0.0, 'train_loss': 0.6796426021691525, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5537992119789124, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3891, 'eval_samples_per_second': 165.751, 'eval_steps_per_second': 20.928, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3168' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3168/3960 05:11 < 01:18, 10.15 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.819300</td>\n",
       "      <td>0.688358</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.844700</td>\n",
       "      <td>0.712889</td>\n",
       "      <td>0.542929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.698107</td>\n",
       "      <td>0.603535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.793200</td>\n",
       "      <td>0.718250</td>\n",
       "      <td>0.626263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6883583664894104, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.41, 'eval_samples_per_second': 164.317, 'eval_steps_per_second': 20.747, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:21:17,284] Trial 15 finished with values: [0.6883583664894104, 0.73989898989899] and parameters: {'lr': 0.0004070581758902677, 'batch': 1, 'accum': 2, 'dropout_rate': 0.6919509179899231, 'weight_decay': 0.0008700949623805471, 'warmup_pct': 0.08312650415278516}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8193, 'learning_rate': 0.000390539158455593, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.6883583664894104, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.4133, 'eval_samples_per_second': 164.091, 'eval_steps_per_second': 20.719, 'epoch': 1.0, 'step': 792}, {'loss': 0.8447, 'learning_rate': 0.00029290436884169474, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.712888777256012, 'eval_accuracy': 0.5429292929292929, 'eval_runtime': 2.3847, 'eval_samples_per_second': 166.061, 'eval_steps_per_second': 20.967, 'epoch': 2.0, 'step': 1584}, {'loss': 0.8455, 'learning_rate': 0.0001952695792277965, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.6981070041656494, 'eval_accuracy': 0.6035353535353535, 'eval_runtime': 2.3874, 'eval_samples_per_second': 165.872, 'eval_steps_per_second': 20.943, 'epoch': 3.0, 'step': 2376}, {'loss': 0.7932, 'learning_rate': 9.763478961389825e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.7182499766349792, 'eval_accuracy': 0.6262626262626263, 'eval_runtime': 2.3873, 'eval_samples_per_second': 165.875, 'eval_steps_per_second': 20.944, 'epoch': 4.0, 'step': 3168}, {'train_runtime': 312.0977, 'train_samples_per_second': 25.377, 'train_steps_per_second': 12.688, 'total_flos': 0.0, 'train_loss': 0.8256481440380367, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.6883583664894104, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.41, 'eval_samples_per_second': 164.317, 'eval_steps_per_second': 20.747, 'epoch': 4.0, 'step': 3168}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 01:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.665971</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.628845</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.611600</td>\n",
       "      <td>0.605876</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.581600</td>\n",
       "      <td>0.592482</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.567600</td>\n",
       "      <td>0.589215</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5892154574394226, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3896, 'eval_samples_per_second': 165.716, 'eval_steps_per_second': 20.924, 'epoch': 5.0}\n",
      "History:  [{'loss': 0.776, 'learning_rate': 7.854133758871339e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6659711599349976, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 2.4203, 'eval_samples_per_second': 163.614, 'eval_steps_per_second': 20.658, 'epoch': 1.0, 'step': 99}, {'loss': 0.6566, 'learning_rate': 5.8906003191535044e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6288451552391052, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 2.394, 'eval_samples_per_second': 165.415, 'eval_steps_per_second': 20.886, 'epoch': 2.0, 'step': 198}, {'loss': 0.6116, 'learning_rate': 3.9270668794356696e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6058759689331055, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.765, 'eval_steps_per_second': 20.93, 'epoch': 3.0, 'step': 297}, {'loss': 0.5816, 'learning_rate': 1.9635334397178348e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5924818515777588, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3888, 'eval_samples_per_second': 165.775, 'eval_steps_per_second': 20.931, 'epoch': 4.0, 'step': 396}, {'loss': 0.5676, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5892154574394226, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3904, 'eval_samples_per_second': 165.659, 'eval_steps_per_second': 20.917, 'epoch': 5.0, 'step': 495}, {'train_runtime': 108.4167, 'train_samples_per_second': 73.052, 'train_steps_per_second': 4.566, 'total_flos': 0.0, 'train_loss': 0.6386761752041903, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5892154574394226, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3896, 'eval_samples_per_second': 165.716, 'eval_steps_per_second': 20.924, 'epoch': 5.0, 'step': 495}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:23:19,347] Trial 16 finished with values: [0.5892154574394226, 0.7247474747474747] and parameters: {'lr': 8.984653012042214e-05, 'batch': 8, 'accum': 2, 'dropout_rate': 0.25101912396801973, 'weight_decay': 1.3342189991436294e-05, 'warmup_pct': 0.04274672598515941}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 02:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.244500</td>\n",
       "      <td>0.827484</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.165900</td>\n",
       "      <td>0.757761</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.966500</td>\n",
       "      <td>0.701968</td>\n",
       "      <td>0.505051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.906300</td>\n",
       "      <td>0.680464</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.674852</td>\n",
       "      <td>0.570707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6748523712158203, 'eval_accuracy': 0.5707070707070707, 'eval_runtime': 2.393, 'eval_samples_per_second': 165.482, 'eval_steps_per_second': 20.894, 'epoch': 5.0}\n",
      "History:  [{'loss': 1.2445, 'learning_rate': 2.7454215413086574e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.8274837732315063, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4188, 'eval_samples_per_second': 163.721, 'eval_steps_per_second': 20.672, 'epoch': 1.0, 'step': 99}, {'loss': 1.1659, 'learning_rate': 5.490843082617315e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.7577607035636902, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3927, 'eval_samples_per_second': 165.505, 'eval_steps_per_second': 20.897, 'epoch': 2.0, 'step': 198}, {'loss': 0.9665, 'learning_rate': 5.0439139944973005e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.7019678950309753, 'eval_accuracy': 0.5050505050505051, 'eval_runtime': 2.393, 'eval_samples_per_second': 165.486, 'eval_steps_per_second': 20.895, 'epoch': 3.0, 'step': 297}, {'loss': 0.9063, 'learning_rate': 2.5219569972486503e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6804643273353577, 'eval_accuracy': 0.5277777777777778, 'eval_runtime': 2.392, 'eval_samples_per_second': 165.554, 'eval_steps_per_second': 20.903, 'epoch': 4.0, 'step': 396}, {'loss': 0.7995, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6748523712158203, 'eval_accuracy': 0.5707070707070707, 'eval_runtime': 2.3914, 'eval_samples_per_second': 165.594, 'eval_steps_per_second': 20.908, 'epoch': 5.0, 'step': 495}, {'train_runtime': 135.8752, 'train_samples_per_second': 58.289, 'train_steps_per_second': 3.643, 'total_flos': 0.0, 'train_loss': 1.0165360730103772, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6748523712158203, 'eval_accuracy': 0.5707070707070707, 'eval_runtime': 2.393, 'eval_samples_per_second': 165.482, 'eval_steps_per_second': 20.894, 'epoch': 5.0, 'step': 495}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:25:48,407] Trial 17 finished with values: [0.6748523712158203, 0.5707070707070707] and parameters: {'lr': 6.572372780708604e-05, 'batch': 4, 'accum': 4, 'dropout_rate': 0.8674299723072716, 'weight_decay': 4.914237989883984e-05, 'warmup_pct': 0.11993192038787218}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 01:42, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.002500</td>\n",
       "      <td>0.616271</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.605300</td>\n",
       "      <td>0.592472</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.547100</td>\n",
       "      <td>0.548549</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.454800</td>\n",
       "      <td>0.523607</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5236071944236755, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 2.3939, 'eval_samples_per_second': 165.417, 'eval_steps_per_second': 20.886, 'epoch': 4.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:27:44,561] Trial 18 finished with values: [0.5236071944236755, 0.7727272727272727] and parameters: {'lr': 0.0026672988265693475, 'batch': 8, 'accum': 8, 'dropout_rate': 0.8733284354227296, 'weight_decay': 3.9315367129718254e-05, 'warmup_pct': 0.02183159453601221}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.0025, 'learning_rate': 0.0025864715894005795, 'epoch': 0.97, 'step': 24}, {'eval_loss': 0.6162707805633545, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.4209, 'eval_samples_per_second': 163.573, 'eval_steps_per_second': 20.653, 'epoch': 0.97, 'step': 24}, {'loss': 0.6053, 'learning_rate': 0.001912911279660845, 'epoch': 1.98, 'step': 49}, {'eval_loss': 0.5924715995788574, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 2.3927, 'eval_samples_per_second': 165.504, 'eval_steps_per_second': 20.897, 'epoch': 1.98, 'step': 49}, {'loss': 0.5471, 'learning_rate': 0.001239350969921111, 'epoch': 2.99, 'step': 74}, {'eval_loss': 0.5485493540763855, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.3924, 'eval_samples_per_second': 165.526, 'eval_steps_per_second': 20.9, 'epoch': 2.99, 'step': 74}, {'loss': 0.5045, 'learning_rate': 0.0005657906601813767, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.5229614973068237, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.394, 'eval_samples_per_second': 165.416, 'eval_steps_per_second': 20.886, 'epoch': 4.0, 'step': 99}, {'loss': 0.4548, 'learning_rate': 0.0, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.5236071944236755, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 2.3956, 'eval_samples_per_second': 165.303, 'eval_steps_per_second': 20.872, 'epoch': 4.85, 'step': 120}, {'train_runtime': 103.2749, 'train_samples_per_second': 76.689, 'train_steps_per_second': 1.162, 'total_flos': 0.0, 'train_loss': 0.6252596378326416, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.5236071944236755, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 2.3939, 'eval_samples_per_second': 165.417, 'eval_steps_per_second': 20.886, 'epoch': 4.85, 'step': 120}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [792/990 01:50 < 00:27, 7.12 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.744300</td>\n",
       "      <td>0.598257</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.625200</td>\n",
       "      <td>0.825413</td>\n",
       "      <td>0.558081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>0.740966</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>0.691402</td>\n",
       "      <td>0.530303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5982569456100464, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.4109, 'eval_samples_per_second': 164.251, 'eval_steps_per_second': 20.739, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:29:48,723] Trial 19 finished with values: [0.5982569456100464, 0.7297979797979798] and parameters: {'lr': 0.002569825038535863, 'batch': 4, 'accum': 2, 'dropout_rate': 0.5699238501030862, 'weight_decay': 2.4010257447838972e-05, 'warmup_pct': 0.2721995720664585}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7443, 'learning_rate': 0.0009457720402046484, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.5982569456100464, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.4189, 'eval_samples_per_second': 163.713, 'eval_steps_per_second': 20.671, 'epoch': 1.0, 'step': 198}, {'loss': 0.6252, 'learning_rate': 0.0018915440804092968, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.8254131078720093, 'eval_accuracy': 0.5580808080808081, 'eval_runtime': 2.3931, 'eval_samples_per_second': 165.473, 'eval_steps_per_second': 20.893, 'epoch': 2.0, 'step': 396}, {'loss': 0.719, 'learning_rate': 0.0022514396355314196, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.7409662008285522, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3906, 'eval_samples_per_second': 165.651, 'eval_steps_per_second': 20.916, 'epoch': 3.0, 'step': 594}, {'loss': 0.8169, 'learning_rate': 0.0011257198177657098, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6914022564888, 'eval_accuracy': 0.5303030303030303, 'eval_runtime': 2.3962, 'eval_samples_per_second': 165.259, 'eval_steps_per_second': 20.866, 'epoch': 4.0, 'step': 792}, {'train_runtime': 111.0393, 'train_samples_per_second': 71.326, 'train_steps_per_second': 8.916, 'total_flos': 0.0, 'train_loss': 0.7263791248051807, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5982569456100464, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.4109, 'eval_samples_per_second': 164.251, 'eval_steps_per_second': 20.739, 'epoch': 4.0, 'step': 792}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 01:45, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.334800</td>\n",
       "      <td>0.858793</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.247600</td>\n",
       "      <td>0.840597</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.151300</td>\n",
       "      <td>0.810494</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8104940056800842, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3999, 'eval_samples_per_second': 165.006, 'eval_steps_per_second': 20.834, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:31:48,523] Trial 20 finished with values: [0.8104940056800842, 0.5025252525252525] and parameters: {'lr': 1.2189588358500046e-05, 'batch': 8, 'accum': 4, 'dropout_rate': 0.8758210481564984, 'weight_decay': 3.848107675780158e-05, 'warmup_pct': 0.2516035614156951}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.3348, 'learning_rate': 2.3987543356084427e-06, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.8587928414344788, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4184, 'eval_samples_per_second': 163.748, 'eval_steps_per_second': 20.675, 'epoch': 0.99, 'step': 49}, {'loss': 1.3023, 'learning_rate': 4.8464628413313435e-06, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.852384090423584, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3944, 'eval_samples_per_second': 165.386, 'eval_steps_per_second': 20.882, 'epoch': 2.0, 'step': 99}, {'loss': 1.2476, 'learning_rate': 7.245217176939786e-06, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.840596616268158, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3965, 'eval_samples_per_second': 165.243, 'eval_steps_per_second': 20.864, 'epoch': 2.99, 'step': 148}, {'loss': 1.2931, 'learning_rate': 9.692925682662687e-06, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.8249016404151917, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4005, 'eval_samples_per_second': 164.963, 'eval_steps_per_second': 20.829, 'epoch': 4.0, 'step': 198}, {'loss': 1.1513, 'learning_rate': 1.1993771678042213e-05, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.8104940056800842, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4088, 'eval_samples_per_second': 164.399, 'eval_steps_per_second': 20.757, 'epoch': 4.95, 'step': 245}, {'train_runtime': 106.0171, 'train_samples_per_second': 74.705, 'train_steps_per_second': 2.311, 'total_flos': 0.0, 'train_loss': 1.267014826560507, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.8104940056800842, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3999, 'eval_samples_per_second': 165.006, 'eval_steps_per_second': 20.834, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.736400</td>\n",
       "      <td>0.582916</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.568100</td>\n",
       "      <td>0.655644</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.615600</td>\n",
       "      <td>0.607699</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.681759</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.282600</td>\n",
       "      <td>0.866818</td>\n",
       "      <td>0.782828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8668177723884583, 'eval_accuracy': 0.7828282828282829, 'eval_runtime': 2.3837, 'eval_samples_per_second': 166.13, 'eval_steps_per_second': 20.976, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:38:21,100] Trial 21 finished with values: [0.8668177723884583, 0.7828282828282829] and parameters: {'lr': 0.0009587249250726995, 'batch': 1, 'accum': 4, 'dropout_rate': 0.4299005231848295, 'weight_decay': 0.000772527565350219, 'warmup_pct': 0.1357739304622294}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7364, 'learning_rate': 0.0003531675072825944, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.5829162001609802, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.4165, 'eval_samples_per_second': 163.871, 'eval_steps_per_second': 20.691, 'epoch': 1.0, 'step': 396}, {'loss': 0.5681, 'learning_rate': 0.0007063350145651888, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6556439399719238, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3902, 'eval_samples_per_second': 165.676, 'eval_steps_per_second': 20.919, 'epoch': 2.0, 'step': 792}, {'loss': 0.6156, 'learning_rate': 0.0008390167300083736, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6076991558074951, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3874, 'eval_samples_per_second': 165.871, 'eval_steps_per_second': 20.943, 'epoch': 3.0, 'step': 1188}, {'loss': 0.497, 'learning_rate': 0.0004195083650041868, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6817594766616821, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 2.3852, 'eval_samples_per_second': 166.021, 'eval_steps_per_second': 20.962, 'epoch': 4.0, 'step': 1584}, {'loss': 0.2826, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.8668177723884583, 'eval_accuracy': 0.7828282828282829, 'eval_runtime': 2.3862, 'eval_samples_per_second': 165.953, 'eval_steps_per_second': 20.954, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 379.293, 'train_samples_per_second': 20.881, 'train_steps_per_second': 5.22, 'total_flos': 0.0, 'train_loss': 0.5399322240039556, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.8668177723884583, 'eval_accuracy': 0.7828282828282829, 'eval_runtime': 2.3837, 'eval_samples_per_second': 166.13, 'eval_steps_per_second': 20.976, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 06:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.872400</td>\n",
       "      <td>0.673584</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.666600</td>\n",
       "      <td>0.589990</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.548600</td>\n",
       "      <td>0.552797</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.472200</td>\n",
       "      <td>0.592174</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.552198</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5521978139877319, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3899, 'eval_samples_per_second': 165.696, 'eval_steps_per_second': 20.921, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:44:48,014] Trial 22 finished with values: [0.5521978139877319, 0.7626262626262627] and parameters: {'lr': 0.0006203254061465803, 'batch': 1, 'accum': 8, 'dropout_rate': 0.4914183485282615, 'weight_decay': 1.929220868189138e-05, 'warmup_pct': 0.165492291809389}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8724, 'learning_rate': 9.375910718856709e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6735835075378418, 'eval_accuracy': 0.6136363636363636, 'eval_runtime': 2.4146, 'eval_samples_per_second': 164.001, 'eval_steps_per_second': 20.707, 'epoch': 1.0, 'step': 198}, {'loss': 0.6666, 'learning_rate': 0.00018751821437713417, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.5899902582168579, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.3814, 'eval_samples_per_second': 166.289, 'eval_steps_per_second': 20.996, 'epoch': 2.0, 'step': 396}, {'loss': 0.5486, 'learning_rate': 0.0002812773215657013, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.5527967810630798, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3827, 'eval_samples_per_second': 166.197, 'eval_steps_per_second': 20.984, 'epoch': 3.0, 'step': 594}, {'loss': 0.4722, 'learning_rate': 0.00037503642875426834, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5921738147735596, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3852, 'eval_samples_per_second': 166.027, 'eval_steps_per_second': 20.963, 'epoch': 4.0, 'step': 792}, {'loss': 0.41, 'learning_rate': 0.0004687955359428355, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5521978139877319, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3905, 'eval_samples_per_second': 165.658, 'eval_steps_per_second': 20.916, 'epoch': 5.0, 'step': 990}, {'train_runtime': 372.5096, 'train_samples_per_second': 21.261, 'train_steps_per_second': 2.658, 'total_flos': 0.0, 'train_loss': 0.593943301114169, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5521978139877319, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3899, 'eval_samples_per_second': 165.696, 'eval_steps_per_second': 20.921, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>0.820679</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.172600</td>\n",
       "      <td>0.756077</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.933200</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>0.512626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.768100</td>\n",
       "      <td>0.669820</td>\n",
       "      <td>0.595960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.718900</td>\n",
       "      <td>0.661294</td>\n",
       "      <td>0.661616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6612944006919861, 'eval_accuracy': 0.6616161616161617, 'eval_runtime': 2.387, 'eval_samples_per_second': 165.901, 'eval_steps_per_second': 20.947, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:48:27,788] Trial 23 finished with values: [0.6612944006919861, 0.6616161616161617] and parameters: {'lr': 4.802901317428113e-05, 'batch': 2, 'accum': 4, 'dropout_rate': 0.8068915561008349, 'weight_decay': 0.0003953655187374692, 'warmup_pct': 0.16886484835207982}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.22, 'learning_rate': 1.4236144623514466e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.8206791877746582, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4123, 'eval_samples_per_second': 164.159, 'eval_steps_per_second': 20.727, 'epoch': 1.0, 'step': 198}, {'loss': 1.1726, 'learning_rate': 2.847228924702893e-05, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.7560766935348511, 'eval_accuracy': 0.5, 'eval_runtime': 2.3825, 'eval_samples_per_second': 166.213, 'eval_steps_per_second': 20.986, 'epoch': 2.0, 'step': 396}, {'loss': 0.9332, 'learning_rate': 4.270843387054339e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.693000078201294, 'eval_accuracy': 0.5126262626262627, 'eval_runtime': 2.3839, 'eval_samples_per_second': 166.117, 'eval_steps_per_second': 20.974, 'epoch': 3.0, 'step': 594}, {'loss': 0.7681, 'learning_rate': 2.9533368349402683e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6698200702667236, 'eval_accuracy': 0.5959595959595959, 'eval_runtime': 2.384, 'eval_samples_per_second': 166.109, 'eval_steps_per_second': 20.973, 'epoch': 4.0, 'step': 792}, {'loss': 0.7189, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6612944006919861, 'eval_accuracy': 0.6616161616161617, 'eval_runtime': 2.3866, 'eval_samples_per_second': 165.925, 'eval_steps_per_second': 20.95, 'epoch': 5.0, 'step': 990}, {'train_runtime': 204.8696, 'train_samples_per_second': 38.659, 'train_steps_per_second': 4.832, 'total_flos': 0.0, 'train_loss': 0.962557074036261, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6612944006919861, 'eval_accuracy': 0.6616161616161617, 'eval_runtime': 2.387, 'eval_samples_per_second': 165.901, 'eval_steps_per_second': 20.947, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.023100</td>\n",
       "      <td>0.845368</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.039700</td>\n",
       "      <td>0.807897</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.924400</td>\n",
       "      <td>0.757921</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.876900</td>\n",
       "      <td>0.722822</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.827800</td>\n",
       "      <td>0.696134</td>\n",
       "      <td>0.512626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6961343288421631, 'eval_accuracy': 0.5126262626262627, 'eval_runtime': 2.3896, 'eval_samples_per_second': 165.719, 'eval_steps_per_second': 20.924, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:52:05,151] Trial 24 finished with values: [0.6961343288421631, 0.5126262626262627] and parameters: {'lr': 1.4913891214856663e-05, 'batch': 2, 'accum': 4, 'dropout_rate': 0.5802023030868284, 'weight_decay': 0.00013126168284436653, 'warmup_pct': 0.2691221301103538}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.0231, 'learning_rate': 2.772723437128281e-06, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.8453680276870728, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4134, 'eval_samples_per_second': 164.085, 'eval_steps_per_second': 20.718, 'epoch': 1.0, 'step': 198}, {'loss': 1.0397, 'learning_rate': 5.545446874256562e-06, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.8078972697257996, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.851, 'eval_steps_per_second': 20.941, 'epoch': 2.0, 'step': 396}, {'loss': 0.9244, 'learning_rate': 8.318170311384843e-06, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.7579206824302673, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3853, 'eval_samples_per_second': 166.013, 'eval_steps_per_second': 20.961, 'epoch': 3.0, 'step': 594}, {'loss': 0.8769, 'learning_rate': 1.1090893748513124e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.7228221893310547, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3911, 'eval_samples_per_second': 165.615, 'eval_steps_per_second': 20.911, 'epoch': 4.0, 'step': 792}, {'loss': 0.8278, 'learning_rate': 1.3863617185641404e-05, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6961343288421631, 'eval_accuracy': 0.5126262626262627, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.701, 'eval_steps_per_second': 20.922, 'epoch': 5.0, 'step': 990}, {'train_runtime': 204.4119, 'train_samples_per_second': 38.745, 'train_steps_per_second': 4.843, 'total_flos': 0.0, 'train_loss': 0.9383691652856692, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6961343288421631, 'eval_accuracy': 0.5126262626262627, 'eval_runtime': 2.3896, 'eval_samples_per_second': 165.719, 'eval_steps_per_second': 20.924, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 06:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.072000</td>\n",
       "      <td>0.697583</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.086000</td>\n",
       "      <td>0.685604</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.717400</td>\n",
       "      <td>0.657559</td>\n",
       "      <td>0.593434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.697900</td>\n",
       "      <td>0.647926</td>\n",
       "      <td>0.643939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.641300</td>\n",
       "      <td>0.624784</td>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6247836947441101, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.4071, 'eval_samples_per_second': 164.512, 'eval_steps_per_second': 20.772, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 08:58:48,079] Trial 25 finished with values: [0.6247836947441101, 0.6717171717171717] and parameters: {'lr': 0.0038400108952085796, 'batch': 1, 'accum': 2, 'dropout_rate': 0.8636687067835267, 'weight_decay': 1.0436939463804888e-05, 'warmup_pct': 0.2393737645166039}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.072, 'learning_rate': 0.0016049016511900766, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.6975829601287842, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.415, 'eval_samples_per_second': 163.974, 'eval_steps_per_second': 20.704, 'epoch': 1.0, 'step': 792}, {'loss': 1.086, 'learning_rate': 0.0032098033023801533, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6856037378311157, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.389, 'eval_samples_per_second': 165.759, 'eval_steps_per_second': 20.929, 'epoch': 2.0, 'step': 1584}, {'loss': 0.7174, 'learning_rate': 0.002945557994193893, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.6575586199760437, 'eval_accuracy': 0.5934343434343434, 'eval_runtime': 2.3893, 'eval_samples_per_second': 165.737, 'eval_steps_per_second': 20.926, 'epoch': 3.0, 'step': 2376}, {'loss': 0.6979, 'learning_rate': 0.0014727789970969466, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.647925853729248, 'eval_accuracy': 0.6439393939393939, 'eval_runtime': 2.3905, 'eval_samples_per_second': 165.657, 'eval_steps_per_second': 20.916, 'epoch': 4.0, 'step': 3168}, {'loss': 0.6413, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.6247836947441101, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.4051, 'eval_samples_per_second': 164.648, 'eval_steps_per_second': 20.789, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 390.0066, 'train_samples_per_second': 20.307, 'train_steps_per_second': 10.154, 'total_flos': 0.0, 'train_loss': 0.8429130323005445, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.6247836947441101, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.4071, 'eval_samples_per_second': 164.512, 'eval_steps_per_second': 20.772, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.879500</td>\n",
       "      <td>0.736174</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.864600</td>\n",
       "      <td>0.700281</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>0.664083</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.666100</td>\n",
       "      <td>0.658877</td>\n",
       "      <td>0.603535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.629100</td>\n",
       "      <td>0.638182</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6381819248199463, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.3896, 'eval_samples_per_second': 165.72, 'eval_steps_per_second': 20.924, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 09:02:54,484] Trial 26 finished with values: [0.6381819248199463, 0.6515151515151515] and parameters: {'lr': 0.009325851256274033, 'batch': 2, 'accum': 4, 'dropout_rate': 0.7817839633295772, 'weight_decay': 1.916679117428816e-05, 'warmup_pct': 0.18526858085368333}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8795, 'learning_rate': 0.002519124895964882, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.7361736297607422, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.4294, 'eval_samples_per_second': 163.005, 'eval_steps_per_second': 20.581, 'epoch': 1.0, 'step': 198}, {'loss': 0.8646, 'learning_rate': 0.005038249791929764, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.7002807259559631, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3833, 'eval_samples_per_second': 166.157, 'eval_steps_per_second': 20.979, 'epoch': 2.0, 'step': 396}, {'loss': 0.6917, 'learning_rate': 0.007557374687894646, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6640831828117371, 'eval_accuracy': 0.6136363636363636, 'eval_runtime': 2.3866, 'eval_samples_per_second': 165.929, 'eval_steps_per_second': 20.951, 'epoch': 3.0, 'step': 594}, {'loss': 0.6661, 'learning_rate': 0.0071848970768181265, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6588773727416992, 'eval_accuracy': 0.6035353535353535, 'eval_runtime': 2.3867, 'eval_samples_per_second': 165.92, 'eval_steps_per_second': 20.95, 'epoch': 4.0, 'step': 792}, {'loss': 0.6291, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6381819248199463, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.3884, 'eval_samples_per_second': 165.803, 'eval_steps_per_second': 20.935, 'epoch': 5.0, 'step': 990}, {'train_runtime': 232.9386, 'train_samples_per_second': 34.0, 'train_steps_per_second': 4.25, 'total_flos': 0.0, 'train_loss': 0.7461896029385653, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6381819248199463, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.3896, 'eval_samples_per_second': 165.72, 'eval_steps_per_second': 20.924, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 02:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.827200</td>\n",
       "      <td>0.690490</td>\n",
       "      <td>0.535354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>0.638232</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.617900</td>\n",
       "      <td>0.610338</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.583100</td>\n",
       "      <td>0.599181</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.560800</td>\n",
       "      <td>0.596152</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.59615159034729, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.3976, 'eval_samples_per_second': 165.165, 'eval_steps_per_second': 20.854, 'epoch': 5.0}\n",
      "History:  [{'loss': 0.8272, 'learning_rate': 4.9984060039122695e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6904897689819336, 'eval_accuracy': 0.5353535353535354, 'eval_runtime': 2.4138, 'eval_samples_per_second': 164.055, 'eval_steps_per_second': 20.714, 'epoch': 1.0, 'step': 198}, {'loss': 0.6904, 'learning_rate': 5.594609771369211e-05, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6382315158843994, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 2.3871, 'eval_samples_per_second': 165.891, 'eval_steps_per_second': 20.946, 'epoch': 2.0, 'step': 396}, {'loss': 0.6179, 'learning_rate': 3.729739847579474e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6103383302688599, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.766, 'eval_steps_per_second': 20.93, 'epoch': 3.0, 'step': 594}, {'loss': 0.5831, 'learning_rate': 1.864869923789737e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5991809964179993, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.4079, 'eval_samples_per_second': 164.456, 'eval_steps_per_second': 20.765, 'epoch': 4.0, 'step': 792}, {'loss': 0.5608, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.59615159034729, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.3872, 'eval_samples_per_second': 165.887, 'eval_steps_per_second': 20.945, 'epoch': 5.0, 'step': 990}, {'train_runtime': 139.58, 'train_samples_per_second': 56.742, 'train_steps_per_second': 7.093, 'total_flos': 0.0, 'train_loss': 0.6558650084216185, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.59615159034729, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.3976, 'eval_samples_per_second': 165.165, 'eval_steps_per_second': 20.854, 'epoch': 5.0, 'step': 990}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 09:05:27,354] Trial 27 finished with values: [0.59615159034729, 0.7045454545454546] and parameters: {'lr': 6.790763712385861e-05, 'batch': 4, 'accum': 2, 'dropout_rate': 0.24516907554969097, 'weight_decay': 0.00015398127614702297, 'warmup_pct': 0.1360060971031842}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 07:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.964200</td>\n",
       "      <td>0.690225</td>\n",
       "      <td>0.532828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.699700</td>\n",
       "      <td>0.611454</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.569100</td>\n",
       "      <td>0.553783</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.495500</td>\n",
       "      <td>0.520669</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.561059</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5206692814826965, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 2.4232, 'eval_samples_per_second': 163.42, 'eval_steps_per_second': 20.634, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 09:12:55,055] Trial 28 finished with values: [0.5206692814826965, 0.7727272727272727] and parameters: {'lr': 0.00038839967736054487, 'batch': 1, 'accum': 8, 'dropout_rate': 0.649352271980414, 'weight_decay': 9.32396849985729e-05, 'warmup_pct': 0.10367367343032101}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9642, 'learning_rate': 9.367008053275016e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6902250647544861, 'eval_accuracy': 0.5328282828282829, 'eval_runtime': 2.4267, 'eval_samples_per_second': 163.183, 'eval_steps_per_second': 20.604, 'epoch': 1.0, 'step': 198}, {'loss': 0.6997, 'learning_rate': 0.00018734016106550033, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6114543080329895, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3883, 'eval_samples_per_second': 165.806, 'eval_steps_per_second': 20.935, 'epoch': 2.0, 'step': 396}, {'loss': 0.5691, 'learning_rate': 0.0002810102415982505, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.55378258228302, 'eval_accuracy': 0.75, 'eval_runtime': 2.3919, 'eval_samples_per_second': 165.561, 'eval_steps_per_second': 20.904, 'epoch': 3.0, 'step': 594}, {'loss': 0.4955, 'learning_rate': 0.00037468032213100065, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5206692814826965, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 2.4044, 'eval_samples_per_second': 164.701, 'eval_steps_per_second': 20.796, 'epoch': 4.0, 'step': 792}, {'loss': 0.42, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5610591769218445, 'eval_accuracy': 0.75, 'eval_runtime': 2.4018, 'eval_samples_per_second': 164.877, 'eval_steps_per_second': 20.818, 'epoch': 5.0, 'step': 990}, {'train_runtime': 432.7936, 'train_samples_per_second': 18.3, 'train_steps_per_second': 2.287, 'total_flos': 0.0, 'train_loss': 0.6296863209117542, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5206692814826965, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 2.4232, 'eval_samples_per_second': 163.42, 'eval_steps_per_second': 20.634, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 06:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.784200</td>\n",
       "      <td>0.667446</td>\n",
       "      <td>0.623737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.649100</td>\n",
       "      <td>0.611455</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.620900</td>\n",
       "      <td>0.752090</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>0.909959</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.506700</td>\n",
       "      <td>1.011838</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9099588394165039, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3869, 'eval_samples_per_second': 165.909, 'eval_steps_per_second': 20.948, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 09:20:04,823] Trial 29 finished with values: [0.9099588394165039, 0.7525252525252525] and parameters: {'lr': 0.00010508616553926973, 'batch': 1, 'accum': 2, 'dropout_rate': 0.17332454412617376, 'weight_decay': 3.948957000697015e-05, 'warmup_pct': 0.27589559193148167}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7842, 'learning_rate': 3.809072911080166e-05, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.6674464344978333, 'eval_accuracy': 0.6237373737373737, 'eval_runtime': 2.4195, 'eval_samples_per_second': 163.671, 'eval_steps_per_second': 20.665, 'epoch': 1.0, 'step': 792}, {'loss': 0.6491, 'learning_rate': 7.618145822160332e-05, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6114546060562134, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.3897, 'eval_samples_per_second': 165.71, 'eval_steps_per_second': 20.923, 'epoch': 2.0, 'step': 1584}, {'loss': 0.6209, 'learning_rate': 9.377830209250888e-05, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.7520896792411804, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3844, 'eval_samples_per_second': 166.078, 'eval_steps_per_second': 20.969, 'epoch': 3.0, 'step': 2376}, {'loss': 0.6038, 'learning_rate': 4.688915104625444e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.9099588394165039, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3842, 'eval_samples_per_second': 166.093, 'eval_steps_per_second': 20.971, 'epoch': 4.0, 'step': 3168}, {'loss': 0.5067, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 1.0118378400802612, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3891, 'eval_samples_per_second': 165.754, 'eval_steps_per_second': 20.929, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 415.8124, 'train_samples_per_second': 19.047, 'train_steps_per_second': 9.524, 'total_flos': 0.0, 'train_loss': 0.6329342081089212, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.9099588394165039, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3869, 'eval_samples_per_second': 165.909, 'eval_steps_per_second': 20.948, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 06:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.299000</td>\n",
       "      <td>0.749083</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.935300</td>\n",
       "      <td>0.651807</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.703400</td>\n",
       "      <td>0.593868</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.640700</td>\n",
       "      <td>0.576243</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.635200</td>\n",
       "      <td>0.578014</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5780142545700073, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 2.3848, 'eval_samples_per_second': 166.053, 'eval_steps_per_second': 20.966, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 09:26:49,286] Trial 30 finished with values: [0.5780142545700073, 0.7348484848484849] and parameters: {'lr': 0.00010953690417324806, 'batch': 1, 'accum': 2, 'dropout_rate': 0.8919256282834808, 'weight_decay': 3.937879437736638e-05, 'warmup_pct': 0.2826997173226675}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.299, 'learning_rate': 3.876373016318698e-05, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.749083399772644, 'eval_accuracy': 0.5, 'eval_runtime': 2.4102, 'eval_samples_per_second': 164.299, 'eval_steps_per_second': 20.745, 'epoch': 1.0, 'step': 792}, {'loss': 0.9353, 'learning_rate': 7.752746032637396e-05, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6518072485923767, 'eval_accuracy': 0.6590909090909091, 'eval_runtime': 2.38, 'eval_samples_per_second': 166.388, 'eval_steps_per_second': 21.009, 'epoch': 2.0, 'step': 1584}, {'loss': 0.7034, 'learning_rate': 0.00010075868537190762, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.5938675403594971, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.3812, 'eval_samples_per_second': 166.302, 'eval_steps_per_second': 20.998, 'epoch': 3.0, 'step': 2376}, {'loss': 0.6407, 'learning_rate': 5.037934268595381e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.5762431621551514, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3834, 'eval_samples_per_second': 166.151, 'eval_steps_per_second': 20.979, 'epoch': 4.0, 'step': 3168}, {'loss': 0.6352, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.5780142545700073, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 2.3851, 'eval_samples_per_second': 166.029, 'eval_steps_per_second': 20.963, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 390.0015, 'train_samples_per_second': 20.308, 'train_steps_per_second': 10.154, 'total_flos': 0.0, 'train_loss': 0.842711331145932, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.5780142545700073, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 2.3848, 'eval_samples_per_second': 166.053, 'eval_steps_per_second': 20.966, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.303100</td>\n",
       "      <td>0.820102</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.138800</td>\n",
       "      <td>0.738983</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.677922</td>\n",
       "      <td>0.550505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.722800</td>\n",
       "      <td>0.643965</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.613567</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6135666370391846, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3843, 'eval_samples_per_second': 166.087, 'eval_steps_per_second': 20.971, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 09:33:55,064] Trial 31 finished with values: [0.6135666370391846, 0.6994949494949495] and parameters: {'lr': 7.658771591659248e-05, 'batch': 1, 'accum': 4, 'dropout_rate': 0.8504336918837415, 'weight_decay': 0.000425063071863535, 'warmup_pct': 0.2542436182993035}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.3031, 'learning_rate': 1.5066435918018192e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.8201023936271667, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4292, 'eval_samples_per_second': 163.014, 'eval_steps_per_second': 20.583, 'epoch': 1.0, 'step': 396}, {'loss': 1.1388, 'learning_rate': 3.0132871836036384e-05, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.7389826774597168, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4011, 'eval_samples_per_second': 164.921, 'eval_steps_per_second': 20.823, 'epoch': 2.0, 'step': 792}, {'loss': 0.9075, 'learning_rate': 4.519930775405458e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6779218912124634, 'eval_accuracy': 0.5505050505050505, 'eval_runtime': 2.4009, 'eval_samples_per_second': 164.938, 'eval_steps_per_second': 20.825, 'epoch': 3.0, 'step': 1188}, {'loss': 0.7228, 'learning_rate': 6.026574367207277e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6439650058746338, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.3914, 'eval_samples_per_second': 165.594, 'eval_steps_per_second': 20.908, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6638, 'learning_rate': 7.533217959009096e-05, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6135666370391846, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3901, 'eval_samples_per_second': 165.685, 'eval_steps_per_second': 20.92, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 412.7298, 'train_samples_per_second': 19.189, 'train_steps_per_second': 4.797, 'total_flos': 0.0, 'train_loss': 0.9471950954861111, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6135666370391846, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3843, 'eval_samples_per_second': 166.087, 'eval_steps_per_second': 20.971, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.866800</td>\n",
       "      <td>0.661461</td>\n",
       "      <td>0.648990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.669700</td>\n",
       "      <td>0.620201</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.600473</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.593695</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.592172</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5921721458435059, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.706, 'eval_steps_per_second': 20.922, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 09:40:31,239] Trial 32 finished with values: [0.5921721458435059, 0.7121212121212122] and parameters: {'lr': 7.26659640267162e-05, 'batch': 1, 'accum': 4, 'dropout_rate': 0.6083826257681657, 'weight_decay': 0.000461406326249639, 'warmup_pct': 0.015346277863747627}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8668, 'learning_rate': 6.191656106418422e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6614605188369751, 'eval_accuracy': 0.648989898989899, 'eval_runtime': 2.4166, 'eval_samples_per_second': 163.864, 'eval_steps_per_second': 20.69, 'epoch': 1.0, 'step': 396}, {'loss': 0.6697, 'learning_rate': 4.6437420798138165e-05, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6202008724212646, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.3922, 'eval_samples_per_second': 165.54, 'eval_steps_per_second': 20.901, 'epoch': 2.0, 'step': 792}, {'loss': 0.599, 'learning_rate': 3.095828053209211e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6004733443260193, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.3917, 'eval_samples_per_second': 165.573, 'eval_steps_per_second': 20.906, 'epoch': 3.0, 'step': 1188}, {'loss': 0.561, 'learning_rate': 1.5479140266046054e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.5936954617500305, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.767, 'eval_steps_per_second': 20.93, 'epoch': 4.0, 'step': 1584}, {'loss': 0.5475, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5921721458435059, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3958, 'eval_samples_per_second': 165.288, 'eval_steps_per_second': 20.87, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 383.028, 'train_samples_per_second': 20.677, 'train_steps_per_second': 5.169, 'total_flos': 0.0, 'train_loss': 0.6487858011264994, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5921721458435059, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.706, 'eval_steps_per_second': 20.922, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [792/990 01:51 < 00:27, 7.11 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.641800</td>\n",
       "      <td>0.560520</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.719177</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.700100</td>\n",
       "      <td>0.681407</td>\n",
       "      <td>0.595960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.656300</td>\n",
       "      <td>0.687448</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5605202317237854, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.4003, 'eval_samples_per_second': 164.979, 'eval_steps_per_second': 20.831, 'epoch': 4.0}\n",
      "History:  [{'loss': 0.6418, 'learning_rate': 0.0014817597878028284, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.5605202317237854, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.4184, 'eval_samples_per_second': 163.746, 'eval_steps_per_second': 20.675, 'epoch': 1.0, 'step': 198}, {'loss': 0.805, 'learning_rate': 0.002963519575605657, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.7191766500473022, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3955, 'eval_samples_per_second': 165.307, 'eval_steps_per_second': 20.872, 'epoch': 2.0, 'step': 396}, {'loss': 0.7001, 'learning_rate': 0.0022662208519337373, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6814067959785461, 'eval_accuracy': 0.5959595959595959, 'eval_runtime': 2.3954, 'eval_samples_per_second': 165.318, 'eval_steps_per_second': 20.874, 'epoch': 3.0, 'step': 594}, {'loss': 0.6563, 'learning_rate': 0.0011331104259668687, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6874482035636902, 'eval_accuracy': 0.5833333333333334, 'eval_runtime': 2.3858, 'eval_samples_per_second': 165.985, 'eval_steps_per_second': 20.958, 'epoch': 4.0, 'step': 792}, {'train_runtime': 111.2386, 'train_samples_per_second': 71.198, 'train_steps_per_second': 8.9, 'total_flos': 0.0, 'train_loss': 0.7007824868866892, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5605202317237854, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.4003, 'eval_samples_per_second': 164.979, 'eval_steps_per_second': 20.831, 'epoch': 4.0, 'step': 792}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 09:42:36,053] Trial 33 finished with values: [0.5605202317237854, 0.7045454545454546] and parameters: {'lr': 0.0032104795402394613, 'batch': 4, 'accum': 2, 'dropout_rate': 0.1698095821173462, 'weight_decay': 8.63707205968112e-05, 'warmup_pct': 0.21692105224696948}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 06:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.866100</td>\n",
       "      <td>0.718028</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.725300</td>\n",
       "      <td>0.647088</td>\n",
       "      <td>0.664141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.639400</td>\n",
       "      <td>0.621776</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.608700</td>\n",
       "      <td>0.617040</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.591200</td>\n",
       "      <td>0.617236</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.617039680480957, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.4032, 'eval_samples_per_second': 164.782, 'eval_steps_per_second': 20.806, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 09:49:37,708] Trial 34 finished with values: [0.617039680480957, 0.6742424242424242] and parameters: {'lr': 2.679707266037432e-05, 'batch': 1, 'accum': 2, 'dropout_rate': 0.27554322956952126, 'weight_decay': 0.00018917751354183602, 'warmup_pct': 0.1518123966189644}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8661, 'learning_rate': 1.765664022214348e-05, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.7180280685424805, 'eval_accuracy': 0.5, 'eval_runtime': 2.4099, 'eval_samples_per_second': 164.321, 'eval_steps_per_second': 20.748, 'epoch': 1.0, 'step': 792}, {'loss': 0.7253, 'learning_rate': 2.308551292278803e-05, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6470881104469299, 'eval_accuracy': 0.6641414141414141, 'eval_runtime': 2.3921, 'eval_samples_per_second': 165.543, 'eval_steps_per_second': 20.902, 'epoch': 2.0, 'step': 1584}, {'loss': 0.6394, 'learning_rate': 1.5390341948525353e-05, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.6217760443687439, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3855, 'eval_samples_per_second': 166.002, 'eval_steps_per_second': 20.96, 'epoch': 3.0, 'step': 2376}, {'loss': 0.6087, 'learning_rate': 7.695170974262676e-06, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.617039680480957, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.3918, 'eval_samples_per_second': 165.567, 'eval_steps_per_second': 20.905, 'epoch': 4.0, 'step': 3168}, {'loss': 0.5912, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.6172360777854919, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 2.3829, 'eval_samples_per_second': 166.187, 'eval_steps_per_second': 20.983, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 405.2494, 'train_samples_per_second': 19.544, 'train_steps_per_second': 9.772, 'total_flos': 0.0, 'train_loss': 0.6861174689398871, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.617039680480957, 'eval_accuracy': 0.6742424242424242, 'eval_runtime': 2.4032, 'eval_samples_per_second': 164.782, 'eval_steps_per_second': 20.806, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.726200</td>\n",
       "      <td>0.553996</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.529684</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.468300</td>\n",
       "      <td>0.695949</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>0.874103</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>1.049700</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5296838879585266, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.412, 'eval_samples_per_second': 164.181, 'eval_steps_per_second': 20.73, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 09:56:13,350] Trial 35 finished with values: [0.5296838879585266, 0.7702020202020202] and parameters: {'lr': 0.0002824571363563599, 'batch': 1, 'accum': 4, 'dropout_rate': 0.40860348691591963, 'weight_decay': 2.046648307343997e-05, 'warmup_pct': 0.03546683549151491}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7262, 'learning_rate': 0.0002631835905814554, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.5539957284927368, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.4191, 'eval_samples_per_second': 163.695, 'eval_steps_per_second': 20.669, 'epoch': 1.0, 'step': 396}, {'loss': 0.538, 'learning_rate': 0.00019738769293609152, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.5296838879585266, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.391, 'eval_samples_per_second': 165.624, 'eval_steps_per_second': 20.912, 'epoch': 2.0, 'step': 792}, {'loss': 0.4683, 'learning_rate': 0.0001315917952907277, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.695948600769043, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.388, 'eval_samples_per_second': 165.829, 'eval_steps_per_second': 20.938, 'epoch': 3.0, 'step': 1188}, {'loss': 0.3857, 'learning_rate': 6.579589764536385e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.8741032481193542, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3849, 'eval_samples_per_second': 166.045, 'eval_steps_per_second': 20.965, 'epoch': 4.0, 'step': 1584}, {'loss': 0.281, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 1.049700379371643, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 2.3894, 'eval_samples_per_second': 165.732, 'eval_steps_per_second': 20.926, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 382.0264, 'train_samples_per_second': 20.732, 'train_steps_per_second': 5.183, 'total_flos': 0.0, 'train_loss': 0.47981566997489544, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5296838879585266, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.412, 'eval_samples_per_second': 164.181, 'eval_steps_per_second': 20.73, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 03:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.917900</td>\n",
       "      <td>0.848811</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.896200</td>\n",
       "      <td>0.813292</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.839200</td>\n",
       "      <td>0.765536</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.798800</td>\n",
       "      <td>0.726502</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.756200</td>\n",
       "      <td>0.702043</td>\n",
       "      <td>0.507576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7020426988601685, 'eval_accuracy': 0.5075757575757576, 'eval_runtime': 2.3849, 'eval_samples_per_second': 166.047, 'eval_steps_per_second': 20.966, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:00:04,248] Trial 36 finished with values: [0.7020426988601685, 0.5075757575757576] and parameters: {'lr': 1.7756993352618404e-05, 'batch': 2, 'accum': 8, 'dropout_rate': 0.23745555780304617, 'weight_decay': 0.0002018795716742958, 'warmup_pct': 0.23392665338279803}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9179, 'learning_rate': 1.8984258551935443e-06, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.8488109707832336, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4234, 'eval_samples_per_second': 163.404, 'eval_steps_per_second': 20.632, 'epoch': 1.0, 'step': 99}, {'loss': 0.8962, 'learning_rate': 3.7968517103870885e-06, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.813292384147644, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3969, 'eval_samples_per_second': 165.214, 'eval_steps_per_second': 20.86, 'epoch': 2.0, 'step': 198}, {'loss': 0.8392, 'learning_rate': 5.695277565580633e-06, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.765535831451416, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3885, 'eval_samples_per_second': 165.794, 'eval_steps_per_second': 20.934, 'epoch': 3.0, 'step': 297}, {'loss': 0.7988, 'learning_rate': 7.593703420774177e-06, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.7265022993087769, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.702, 'eval_steps_per_second': 20.922, 'epoch': 4.0, 'step': 396}, {'loss': 0.7562, 'learning_rate': 9.492129275967721e-06, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.7020426988601685, 'eval_accuracy': 0.5075757575757576, 'eval_runtime': 2.3915, 'eval_samples_per_second': 165.587, 'eval_steps_per_second': 20.907, 'epoch': 5.0, 'step': 495}, {'train_runtime': 217.1292, 'train_samples_per_second': 36.476, 'train_steps_per_second': 2.28, 'total_flos': 0.0, 'train_loss': 0.8416653719815341, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.7020426988601685, 'eval_accuracy': 0.5075757575757576, 'eval_runtime': 2.3849, 'eval_samples_per_second': 166.047, 'eval_steps_per_second': 20.966, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.694858</td>\n",
       "      <td>0.525253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.735100</td>\n",
       "      <td>0.668894</td>\n",
       "      <td>0.628788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.652009</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.663000</td>\n",
       "      <td>0.642438</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.638622</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6386221051216125, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3939, 'eval_samples_per_second': 165.422, 'eval_steps_per_second': 20.887, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:03:42,827] Trial 37 finished with values: [0.6386221051216125, 0.6843434343434344] and parameters: {'lr': 3.80544899085794e-05, 'batch': 2, 'accum': 4, 'dropout_rate': 0.3751279886367357, 'weight_decay': 0.00036385204796382677, 'warmup_pct': 0.03832529177795859}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.872, 'learning_rate': 3.592271276233002e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6948582530021667, 'eval_accuracy': 0.5252525252525253, 'eval_runtime': 2.4118, 'eval_samples_per_second': 164.19, 'eval_steps_per_second': 20.731, 'epoch': 1.0, 'step': 198}, {'loss': 0.7351, 'learning_rate': 2.6942034571747514e-05, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6688941121101379, 'eval_accuracy': 0.6287878787878788, 'eval_runtime': 2.3837, 'eval_samples_per_second': 166.127, 'eval_steps_per_second': 20.976, 'epoch': 2.0, 'step': 396}, {'loss': 0.6791, 'learning_rate': 1.796135638116501e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6520088911056519, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 2.3852, 'eval_samples_per_second': 166.022, 'eval_steps_per_second': 20.962, 'epoch': 3.0, 'step': 594}, {'loss': 0.663, 'learning_rate': 8.980678190582505e-06, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6424376964569092, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.3807, 'eval_samples_per_second': 166.341, 'eval_steps_per_second': 21.003, 'epoch': 4.0, 'step': 792}, {'loss': 0.6442, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6386221051216125, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3891, 'eval_samples_per_second': 165.754, 'eval_steps_per_second': 20.929, 'epoch': 5.0, 'step': 990}, {'train_runtime': 205.53, 'train_samples_per_second': 38.535, 'train_steps_per_second': 4.817, 'total_flos': 0.0, 'train_loss': 0.718683863167811, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6386221051216125, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3939, 'eval_samples_per_second': 165.422, 'eval_steps_per_second': 20.887, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 01:45, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.834700</td>\n",
       "      <td>0.587699</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.487600</td>\n",
       "      <td>0.560249</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.259900</td>\n",
       "      <td>0.672841</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 4.94949494949495: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.94949494949495: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5067949891090393, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3819, 'eval_samples_per_second': 166.253, 'eval_steps_per_second': 20.991, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:05:43,966] Trial 38 finished with values: [0.5067949891090393, 0.7626262626262627] and parameters: {'lr': 0.0018068803483599837, 'batch': 8, 'accum': 4, 'dropout_rate': 0.5979807623208674, 'weight_decay': 0.00017005349314421525, 'warmup_pct': 0.10195415599861549}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8347, 'learning_rate': 0.000885371370696392, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.587698757648468, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.4163, 'eval_samples_per_second': 163.888, 'eval_steps_per_second': 20.693, 'epoch': 0.99, 'step': 49}, {'loss': 0.5388, 'learning_rate': 0.0017888115448763838, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.5067949891090393, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3875, 'eval_samples_per_second': 165.864, 'eval_steps_per_second': 20.942, 'epoch': 2.0, 'step': 99}, {'loss': 0.4876, 'learning_rate': 0.0012087406468339202, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.5602486729621887, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3904, 'eval_samples_per_second': 165.666, 'eval_steps_per_second': 20.917, 'epoch': 2.99, 'step': 148}, {'loss': 0.3872, 'learning_rate': 0.0005856784577442705, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5727141499519348, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3961, 'eval_samples_per_second': 165.268, 'eval_steps_per_second': 20.867, 'epoch': 4.0, 'step': 198}, {'loss': 0.2599, 'learning_rate': 0.0, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.6728408336639404, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3861, 'eval_samples_per_second': 165.962, 'eval_steps_per_second': 20.955, 'epoch': 4.95, 'step': 245}, {'train_runtime': 106.1768, 'train_samples_per_second': 74.593, 'train_steps_per_second': 2.307, 'total_flos': 0.0, 'train_loss': 0.5032968092937858, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5067949891090393, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3819, 'eval_samples_per_second': 166.253, 'eval_steps_per_second': 20.991, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 06:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.852443</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.968400</td>\n",
       "      <td>0.831016</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.914800</td>\n",
       "      <td>0.796309</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.887800</td>\n",
       "      <td>0.762945</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.846500</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7355124950408936, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.3933, 'eval_samples_per_second': 165.463, 'eval_steps_per_second': 20.892, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:12:18,936] Trial 39 finished with values: [0.7355124950408936, 0.494949494949495] and parameters: {'lr': 1.1156524126443455e-05, 'batch': 1, 'accum': 8, 'dropout_rate': 0.41084253933498416, 'weight_decay': 9.342404068439992e-05, 'warmup_pct': 0.2767645877268916}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.971, 'learning_rate': 1.0082116736813345e-06, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.8524428606033325, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4298, 'eval_samples_per_second': 162.976, 'eval_steps_per_second': 20.578, 'epoch': 1.0, 'step': 198}, {'loss': 0.9684, 'learning_rate': 2.016423347362669e-06, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.8310161828994751, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3918, 'eval_samples_per_second': 165.569, 'eval_steps_per_second': 20.905, 'epoch': 2.0, 'step': 396}, {'loss': 0.9148, 'learning_rate': 3.024635021044004e-06, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.7963090538978577, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3966, 'eval_samples_per_second': 165.236, 'eval_steps_per_second': 20.863, 'epoch': 3.0, 'step': 594}, {'loss': 0.8878, 'learning_rate': 4.032846694725338e-06, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.7629454731941223, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3895, 'eval_samples_per_second': 165.728, 'eval_steps_per_second': 20.925, 'epoch': 4.0, 'step': 792}, {'loss': 0.8465, 'learning_rate': 5.041058368406673e-06, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.7355124950408936, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.3974, 'eval_samples_per_second': 165.181, 'eval_steps_per_second': 20.856, 'epoch': 5.0, 'step': 990}, {'train_runtime': 379.8848, 'train_samples_per_second': 20.848, 'train_steps_per_second': 2.606, 'total_flos': 0.0, 'train_loss': 0.9177036323932686, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.7355124950408936, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.3933, 'eval_samples_per_second': 165.463, 'eval_steps_per_second': 20.892, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 07:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.699200</td>\n",
       "      <td>0.873478</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.716400</td>\n",
       "      <td>0.796415</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.559400</td>\n",
       "      <td>1.131321</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.300800</td>\n",
       "      <td>1.484260</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161200</td>\n",
       "      <td>1.650381</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.7964152097702026, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.855, 'eval_steps_per_second': 20.941, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:19:33,775] Trial 40 finished with values: [0.7964152097702026, 0.7550505050505051] and parameters: {'lr': 0.0003515993874277286, 'batch': 1, 'accum': 2, 'dropout_rate': 0.19990359292384527, 'weight_decay': 1.025491247337864e-05, 'warmup_pct': 0.04490513731930811}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6992, 'learning_rate': 0.0003089783243747695, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.8734777569770813, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.4096, 'eval_samples_per_second': 164.341, 'eval_steps_per_second': 20.75, 'epoch': 1.0, 'step': 792}, {'loss': 0.7164, 'learning_rate': 0.00023173374328107715, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.7964152097702026, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.386, 'eval_samples_per_second': 165.969, 'eval_steps_per_second': 20.956, 'epoch': 2.0, 'step': 1584}, {'loss': 0.5594, 'learning_rate': 0.00015448916218738476, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 1.1313209533691406, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 2.3911, 'eval_samples_per_second': 165.617, 'eval_steps_per_second': 20.911, 'epoch': 3.0, 'step': 2376}, {'loss': 0.3008, 'learning_rate': 7.724458109369238e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 1.4842603206634521, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.4098, 'eval_samples_per_second': 164.329, 'eval_steps_per_second': 20.749, 'epoch': 4.0, 'step': 3168}, {'loss': 0.1612, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 1.6503806114196777, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3849, 'eval_samples_per_second': 166.048, 'eval_steps_per_second': 20.966, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 421.0741, 'train_samples_per_second': 18.809, 'train_steps_per_second': 9.405, 'total_flos': 0.0, 'train_loss': 0.48737581041124134, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.7964152097702026, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.855, 'eval_steps_per_second': 20.941, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 03:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.907200</td>\n",
       "      <td>0.684496</td>\n",
       "      <td>0.558081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.729400</td>\n",
       "      <td>0.651901</td>\n",
       "      <td>0.669192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.642200</td>\n",
       "      <td>0.628356</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.614200</td>\n",
       "      <td>0.615531</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.601100</td>\n",
       "      <td>0.611745</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.61174476146698, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.3854, 'eval_samples_per_second': 166.009, 'eval_steps_per_second': 20.961, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:23:14,975] Trial 41 finished with values: [0.61174476146698, 0.696969696969697] and parameters: {'lr': 4.8546005199523706e-05, 'batch': 2, 'accum': 2, 'dropout_rate': 0.585085744378257, 'weight_decay': 0.0006245575727189024, 'warmup_pct': 0.04815402138232326}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9072, 'learning_rate': 4.2959146500584104e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6844964623451233, 'eval_accuracy': 0.5580808080808081, 'eval_runtime': 2.4105, 'eval_samples_per_second': 164.281, 'eval_steps_per_second': 20.743, 'epoch': 1.0, 'step': 396}, {'loss': 0.7294, 'learning_rate': 3.2219359875438075e-05, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6519007682800293, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.3867, 'eval_samples_per_second': 165.92, 'eval_steps_per_second': 20.949, 'epoch': 2.0, 'step': 792}, {'loss': 0.6422, 'learning_rate': 2.1479573250292052e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6283562183380127, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.3878, 'eval_samples_per_second': 165.844, 'eval_steps_per_second': 20.94, 'epoch': 3.0, 'step': 1188}, {'loss': 0.6142, 'learning_rate': 1.0739786625146026e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6155305504798889, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.3907, 'eval_samples_per_second': 165.642, 'eval_steps_per_second': 20.914, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6011, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.61174476146698, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.3847, 'eval_samples_per_second': 166.061, 'eval_steps_per_second': 20.967, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 208.2458, 'train_samples_per_second': 38.032, 'train_steps_per_second': 9.508, 'total_flos': 0.0, 'train_loss': 0.6988053215874566, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.61174476146698, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.3854, 'eval_samples_per_second': 166.009, 'eval_steps_per_second': 20.961, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 01:42, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.958900</td>\n",
       "      <td>0.857359</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.904300</td>\n",
       "      <td>0.845808</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.900900</td>\n",
       "      <td>0.827231</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.856900</td>\n",
       "      <td>0.781803</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7818031907081604, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3912, 'eval_samples_per_second': 165.607, 'eval_steps_per_second': 20.91, 'epoch': 4.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:25:10,867] Trial 42 finished with values: [0.7818031907081604, 0.5025252525252525] and parameters: {'lr': 1.2978023446158652e-05, 'batch': 8, 'accum': 8, 'dropout_rate': 0.3418067299353618, 'weight_decay': 0.0009454773401976414, 'warmup_pct': 0.18854480478628555}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9589, 'learning_rate': 1.674583670472084e-06, 'epoch': 0.97, 'step': 24}, {'eval_loss': 0.8573592901229858, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4172, 'eval_samples_per_second': 163.825, 'eval_steps_per_second': 20.685, 'epoch': 0.97, 'step': 24}, {'loss': 0.9043, 'learning_rate': 3.4189416605471713e-06, 'epoch': 1.98, 'step': 49}, {'eval_loss': 0.8458082675933838, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3866, 'eval_samples_per_second': 165.929, 'eval_steps_per_second': 20.951, 'epoch': 1.98, 'step': 49}, {'loss': 0.9009, 'learning_rate': 5.163299650622259e-06, 'epoch': 2.99, 'step': 74}, {'eval_loss': 0.8272308707237244, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3869, 'eval_samples_per_second': 165.903, 'eval_steps_per_second': 20.947, 'epoch': 2.99, 'step': 74}, {'loss': 0.8983, 'learning_rate': 6.907657640697347e-06, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.8043270111083984, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.859, 'eval_steps_per_second': 20.942, 'epoch': 4.0, 'step': 99}, {'loss': 0.8569, 'learning_rate': 8.37291835236042e-06, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.7818031907081604, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3871, 'eval_samples_per_second': 165.89, 'eval_steps_per_second': 20.946, 'epoch': 4.85, 'step': 120}, {'train_runtime': 103.0984, 'train_samples_per_second': 76.82, 'train_steps_per_second': 1.164, 'total_flos': 0.0, 'train_loss': 0.9049846172332764, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.7818031907081604, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3912, 'eval_samples_per_second': 165.607, 'eval_steps_per_second': 20.91, 'epoch': 4.85, 'step': 120}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 01:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.687800</td>\n",
       "      <td>0.537106</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.525200</td>\n",
       "      <td>0.514591</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.514900</td>\n",
       "      <td>0.522601</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>0.533750</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.246800</td>\n",
       "      <td>0.721420</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.51459139585495, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3884, 'eval_samples_per_second': 165.799, 'eval_steps_per_second': 20.934, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:27:11,997] Trial 43 finished with values: [0.51459139585495, 0.76010101010101] and parameters: {'lr': 0.002365442206851229, 'batch': 8, 'accum': 2, 'dropout_rate': 0.13946774290845135, 'weight_decay': 2.395969539853002e-05, 'warmup_pct': 0.2978091638164422}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6878, 'learning_rate': 0.0007965264574090873, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5371056795120239, 'eval_accuracy': 0.75, 'eval_runtime': 2.4224, 'eval_samples_per_second': 163.476, 'eval_steps_per_second': 20.641, 'epoch': 1.0, 'step': 99}, {'loss': 0.5252, 'learning_rate': 0.0015930529148181745, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.51459139585495, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3872, 'eval_samples_per_second': 165.882, 'eval_steps_per_second': 20.945, 'epoch': 2.0, 'step': 198}, {'loss': 0.5149, 'learning_rate': 0.0023301370992862853, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5226012468338013, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3883, 'eval_samples_per_second': 165.805, 'eval_steps_per_second': 20.935, 'epoch': 3.0, 'step': 297}, {'loss': 0.4444, 'learning_rate': 0.0011650685496431426, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5337502956390381, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3871, 'eval_samples_per_second': 165.894, 'eval_steps_per_second': 20.946, 'epoch': 4.0, 'step': 396}, {'loss': 0.2468, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.7214198112487793, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3904, 'eval_samples_per_second': 165.662, 'eval_steps_per_second': 20.917, 'epoch': 5.0, 'step': 495}, {'train_runtime': 108.3611, 'train_samples_per_second': 73.089, 'train_steps_per_second': 4.568, 'total_flos': 0.0, 'train_loss': 0.48382805718315974, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.51459139585495, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3884, 'eval_samples_per_second': 165.799, 'eval_steps_per_second': 20.934, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 01:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>0.865350</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.718200</td>\n",
       "      <td>0.648357</td>\n",
       "      <td>0.641414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>0.634963</td>\n",
       "      <td>0.654040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.623100</td>\n",
       "      <td>0.613648</td>\n",
       "      <td>0.669192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.580800</td>\n",
       "      <td>0.620457</td>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6204569935798645, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.3851, 'eval_samples_per_second': 166.032, 'eval_steps_per_second': 20.964, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:29:13,054] Trial 44 finished with values: [0.6204569935798645, 0.6717171717171717] and parameters: {'lr': 0.0029278781735402313, 'batch': 8, 'accum': 2, 'dropout_rate': 0.11227653995921667, 'weight_decay': 4.348775957087923e-05, 'warmup_pct': 0.030591292130942818}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.757, 'learning_rate': 0.002493418831660068, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.8653499484062195, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.4129, 'eval_samples_per_second': 164.119, 'eval_steps_per_second': 20.722, 'epoch': 1.0, 'step': 99}, {'loss': 0.7182, 'learning_rate': 0.001870064123745051, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6483569145202637, 'eval_accuracy': 0.6414141414141414, 'eval_runtime': 2.3884, 'eval_samples_per_second': 165.802, 'eval_steps_per_second': 20.935, 'epoch': 2.0, 'step': 198}, {'loss': 0.6891, 'learning_rate': 0.001246709415830034, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6349627375602722, 'eval_accuracy': 0.6540404040404041, 'eval_runtime': 2.3927, 'eval_samples_per_second': 165.503, 'eval_steps_per_second': 20.897, 'epoch': 3.0, 'step': 297}, {'loss': 0.6231, 'learning_rate': 0.000623354707915017, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6136478781700134, 'eval_accuracy': 0.6691919191919192, 'eval_runtime': 2.3884, 'eval_samples_per_second': 165.805, 'eval_steps_per_second': 20.935, 'epoch': 4.0, 'step': 396}, {'loss': 0.5808, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6204569935798645, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.3852, 'eval_samples_per_second': 166.025, 'eval_steps_per_second': 20.963, 'epoch': 5.0, 'step': 495}, {'train_runtime': 108.2865, 'train_samples_per_second': 73.139, 'train_steps_per_second': 4.571, 'total_flos': 0.0, 'train_loss': 0.6736357563673848, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6204569935798645, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.3851, 'eval_samples_per_second': 166.032, 'eval_steps_per_second': 20.964, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 01:42, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.781800</td>\n",
       "      <td>0.613698</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.531067</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.521400</td>\n",
       "      <td>0.541233</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>0.539576</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5395762324333191, 'eval_accuracy': 0.7777777777777778, 'eval_runtime': 2.3886, 'eval_samples_per_second': 165.785, 'eval_steps_per_second': 20.932, 'epoch': 4.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:31:09,545] Trial 45 finished with values: [0.5395762324333191, 0.7777777777777778] and parameters: {'lr': 0.004271458706450745, 'batch': 8, 'accum': 8, 'dropout_rate': 0.3247078606693055, 'weight_decay': 8.735724698578458e-05, 'warmup_pct': 0.08710666707762078}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7818, 'learning_rate': 0.0011920349878467194, 'epoch': 0.97, 'step': 24}, {'eval_loss': 0.6136980652809143, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 2.413, 'eval_samples_per_second': 164.113, 'eval_steps_per_second': 20.721, 'epoch': 0.97, 'step': 24}, {'loss': 0.5152, 'learning_rate': 0.002433738100187052, 'epoch': 1.98, 'step': 49}, {'eval_loss': 0.5310665965080261, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.393, 'eval_samples_per_second': 165.486, 'eval_steps_per_second': 20.895, 'epoch': 1.98, 'step': 49}, {'loss': 0.5214, 'learning_rate': 0.003675441212527385, 'epoch': 2.99, 'step': 74}, {'eval_loss': 0.5412330031394958, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3919, 'eval_samples_per_second': 165.556, 'eval_steps_per_second': 20.904, 'epoch': 2.99, 'step': 74}, {'loss': 0.4806, 'learning_rate': 0.00263825390692546, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.5270955562591553, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3897, 'eval_samples_per_second': 165.714, 'eval_steps_per_second': 20.924, 'epoch': 4.0, 'step': 99}, {'loss': 0.3809, 'learning_rate': 0.0, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.5395762324333191, 'eval_accuracy': 0.7777777777777778, 'eval_runtime': 2.3906, 'eval_samples_per_second': 165.652, 'eval_steps_per_second': 20.916, 'epoch': 4.85, 'step': 120}, {'train_runtime': 103.4331, 'train_samples_per_second': 76.571, 'train_steps_per_second': 1.16, 'total_flos': 0.0, 'train_loss': 0.5390915830930074, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.5395762324333191, 'eval_accuracy': 0.7777777777777778, 'eval_runtime': 2.3886, 'eval_samples_per_second': 165.785, 'eval_steps_per_second': 20.932, 'epoch': 4.85, 'step': 120}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 02:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.187900</td>\n",
       "      <td>0.835073</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.156800</td>\n",
       "      <td>0.782080</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.984400</td>\n",
       "      <td>0.724079</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.944800</td>\n",
       "      <td>0.687995</td>\n",
       "      <td>0.520202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.815300</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6782655119895935, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 2.3907, 'eval_samples_per_second': 165.644, 'eval_steps_per_second': 20.915, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:33:38,313] Trial 46 finished with values: [0.6782655119895935, 0.5757575757575758] and parameters: {'lr': 4.7584540614298015e-05, 'batch': 4, 'accum': 4, 'dropout_rate': 0.7917224101346604, 'weight_decay': 2.074689872583201e-05, 'warmup_pct': 0.1875991394591483}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1879, 'learning_rate': 1.2697761511632084e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.8350731730461121, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4198, 'eval_samples_per_second': 163.653, 'eval_steps_per_second': 20.663, 'epoch': 1.0, 'step': 99}, {'loss': 1.1568, 'learning_rate': 2.5395523023264167e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.7820799946784973, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3886, 'eval_samples_per_second': 165.788, 'eval_steps_per_second': 20.933, 'epoch': 2.0, 'step': 198}, {'loss': 0.9844, 'learning_rate': 3.809328453489625e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.724079430103302, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.769, 'eval_steps_per_second': 20.93, 'epoch': 3.0, 'step': 297}, {'loss': 0.9448, 'learning_rate': 3.799088323238309e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6879951357841492, 'eval_accuracy': 0.5202020202020202, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.768, 'eval_steps_per_second': 20.93, 'epoch': 4.0, 'step': 396}, {'loss': 0.8153, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6782655119895935, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 2.3938, 'eval_samples_per_second': 165.429, 'eval_steps_per_second': 20.887, 'epoch': 5.0, 'step': 495}, {'train_runtime': 135.9104, 'train_samples_per_second': 58.274, 'train_steps_per_second': 3.642, 'total_flos': 0.0, 'train_loss': 1.017836800006905, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6782655119895935, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 2.3907, 'eval_samples_per_second': 165.644, 'eval_steps_per_second': 20.915, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [792/990 03:04 < 00:46, 4.28 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.640900</td>\n",
       "      <td>0.541982</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.597600</td>\n",
       "      <td>1.056609</td>\n",
       "      <td>0.512626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.712400</td>\n",
       "      <td>0.650702</td>\n",
       "      <td>0.588384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.749300</td>\n",
       "      <td>0.823776</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5419823527336121, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3885, 'eval_samples_per_second': 165.794, 'eval_steps_per_second': 20.934, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:36:55,976] Trial 47 finished with values: [0.5419823527336121, 0.7575757575757576] and parameters: {'lr': 0.0073241945475088594, 'batch': 2, 'accum': 4, 'dropout_rate': 0.12144555734283058, 'weight_decay': 0.00012767251690941857, 'warmup_pct': 0.2625335736059853}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6409, 'learning_rate': 0.0013957560350401868, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.5419823527336121, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.4187, 'eval_samples_per_second': 163.727, 'eval_steps_per_second': 20.673, 'epoch': 1.0, 'step': 198}, {'loss': 0.5976, 'learning_rate': 0.0027915120700803737, 'epoch': 2.0, 'step': 396}, {'eval_loss': 1.0566085577011108, 'eval_accuracy': 0.5126262626262627, 'eval_runtime': 2.384, 'eval_samples_per_second': 166.109, 'eval_steps_per_second': 20.973, 'epoch': 2.0, 'step': 396}, {'loss': 0.7124, 'learning_rate': 0.004187268105120561, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6507023572921753, 'eval_accuracy': 0.5883838383838383, 'eval_runtime': 2.3891, 'eval_samples_per_second': 165.75, 'eval_steps_per_second': 20.928, 'epoch': 3.0, 'step': 594}, {'loss': 0.7493, 'learning_rate': 0.005583024140160747, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.8237764239311218, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3869, 'eval_samples_per_second': 165.908, 'eval_steps_per_second': 20.948, 'epoch': 4.0, 'step': 792}, {'train_runtime': 184.8724, 'train_samples_per_second': 42.84, 'train_steps_per_second': 5.355, 'total_flos': 0.0, 'train_loss': 0.6750353514546096, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5419823527336121, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3885, 'eval_samples_per_second': 165.794, 'eval_steps_per_second': 20.934, 'epoch': 4.0, 'step': 792}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 02:12, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.723300</td>\n",
       "      <td>0.571900</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.524958</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.622054</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.94949494949495: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5249578952789307, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.3908, 'eval_samples_per_second': 165.636, 'eval_steps_per_second': 20.914, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:39:22,071] Trial 48 finished with values: [0.5249578952789307, 0.7702020202020202] and parameters: {'lr': 0.0012567998518264842, 'batch': 4, 'accum': 8, 'dropout_rate': 0.2598202682685361, 'weight_decay': 6.274182292518844e-05, 'warmup_pct': 0.033162752522080945}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7233, 'learning_rate': 0.0009474337344538112, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.5718998908996582, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.4136, 'eval_samples_per_second': 164.072, 'eval_steps_per_second': 20.716, 'epoch': 0.99, 'step': 49}, {'loss': 0.5224, 'learning_rate': 0.0010194043242592594, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.5403844714164734, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3879, 'eval_samples_per_second': 165.837, 'eval_steps_per_second': 20.939, 'epoch': 2.0, 'step': 99}, {'loss': 0.4625, 'learning_rate': 0.0006772754757064942, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.5249578952789307, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.396, 'eval_samples_per_second': 165.278, 'eval_steps_per_second': 20.868, 'epoch': 2.99, 'step': 148}, {'loss': 0.3767, 'learning_rate': 0.0003281644057546931, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5403060913085938, 'eval_accuracy': 0.7651515151515151, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.705, 'eval_steps_per_second': 20.922, 'epoch': 4.0, 'step': 198}, {'loss': 0.2685, 'learning_rate': 0.0, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.6220536828041077, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3917, 'eval_samples_per_second': 165.573, 'eval_steps_per_second': 20.906, 'epoch': 4.95, 'step': 245}, {'train_runtime': 133.1769, 'train_samples_per_second': 59.47, 'train_steps_per_second': 1.84, 'total_flos': 0.0, 'train_loss': 0.4721866140560228, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5249578952789307, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.3908, 'eval_samples_per_second': 165.636, 'eval_steps_per_second': 20.914, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 02:12, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.174900</td>\n",
       "      <td>0.795756</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.671074</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.628500</td>\n",
       "      <td>0.584980</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5849803686141968, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.389, 'eval_samples_per_second': 165.76, 'eval_steps_per_second': 20.929, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:41:48,480] Trial 49 finished with values: [0.5849803686141968, 0.7323232323232324] and parameters: {'lr': 0.0004263309149756276, 'batch': 4, 'accum': 8, 'dropout_rate': 0.7775540702544163, 'weight_decay': 0.00015089331615034942, 'warmup_pct': 0.2231134504954486}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1749, 'learning_rate': 4.737010166395862e-05, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.795756459236145, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4131, 'eval_samples_per_second': 164.101, 'eval_steps_per_second': 20.72, 'epoch': 0.99, 'step': 49}, {'loss': 1.0564, 'learning_rate': 9.570694009656946e-05, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.7157796025276184, 'eval_accuracy': 0.5, 'eval_runtime': 2.4016, 'eval_samples_per_second': 164.89, 'eval_steps_per_second': 20.819, 'epoch': 2.0, 'step': 99}, {'loss': 0.858, 'learning_rate': 0.00014307704176052809, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.6710740923881531, 'eval_accuracy': 0.5833333333333334, 'eval_runtime': 2.4044, 'eval_samples_per_second': 164.696, 'eval_steps_per_second': 20.795, 'epoch': 2.99, 'step': 148}, {'loss': 0.7055, 'learning_rate': 0.00019141388019313892, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.637302815914154, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.3981, 'eval_samples_per_second': 165.13, 'eval_steps_per_second': 20.85, 'epoch': 4.0, 'step': 198}, {'loss': 0.6285, 'learning_rate': 0.00023685050831979312, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5849803686141968, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3985, 'eval_samples_per_second': 165.102, 'eval_steps_per_second': 20.846, 'epoch': 4.95, 'step': 245}, {'train_runtime': 133.3769, 'train_samples_per_second': 59.381, 'train_steps_per_second': 1.837, 'total_flos': 0.0, 'train_loss': 0.8867212412308674, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5849803686141968, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.389, 'eval_samples_per_second': 165.76, 'eval_steps_per_second': 20.929, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3168' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3168/3960 05:36 < 01:24, 9.40 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.771439</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.915612</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.992300</td>\n",
       "      <td>1.971605</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.872800</td>\n",
       "      <td>1.010981</td>\n",
       "      <td>0.603535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.7714393734931946, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3862, 'eval_samples_per_second': 165.952, 'eval_steps_per_second': 20.953, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:47:38,339] Trial 50 finished with values: [0.7714393734931946, 0.7424242424242424] and parameters: {'lr': 0.002365442206851229, 'batch': 1, 'accum': 2, 'dropout_rate': 0.13946774290845135, 'weight_decay': 1.0476388755032381e-05, 'warmup_pct': 0.2978091638164422}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.715, 'learning_rate': 0.0007944996725301838, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.7714393734931946, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.4199, 'eval_samples_per_second': 163.643, 'eval_steps_per_second': 20.662, 'epoch': 1.0, 'step': 792}, {'loss': 0.881, 'learning_rate': 0.0015889993450603677, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.9156123995780945, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.3896, 'eval_samples_per_second': 165.716, 'eval_steps_per_second': 20.924, 'epoch': 2.0, 'step': 1584}, {'loss': 0.9923, 'learning_rate': 0.002338864204527058, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 1.9716054201126099, 'eval_accuracy': 0.5, 'eval_runtime': 2.3887, 'eval_samples_per_second': 165.783, 'eval_steps_per_second': 20.932, 'epoch': 3.0, 'step': 2376}, {'loss': 0.8728, 'learning_rate': 0.001169432102263529, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 1.0109812021255493, 'eval_accuracy': 0.6035353535353535, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.852, 'eval_steps_per_second': 20.941, 'epoch': 4.0, 'step': 3168}, {'train_runtime': 337.0101, 'train_samples_per_second': 23.501, 'train_steps_per_second': 11.75, 'total_flos': 0.0, 'train_loss': 0.8652375924466836, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.7714393734931946, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3862, 'eval_samples_per_second': 165.952, 'eval_steps_per_second': 20.953, 'epoch': 4.0, 'step': 3168}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 06:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.733700</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.835600</td>\n",
       "      <td>0.668126</td>\n",
       "      <td>0.593434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.735200</td>\n",
       "      <td>0.639525</td>\n",
       "      <td>0.595960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.656200</td>\n",
       "      <td>0.596771</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.564900</td>\n",
       "      <td>0.581684</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5816836357116699, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.3986, 'eval_samples_per_second': 165.093, 'eval_steps_per_second': 20.845, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:54:07,371] Trial 51 finished with values: [0.5816836357116699, 0.6919191919191919] and parameters: {'lr': 0.0026672988265693475, 'batch': 1, 'accum': 8, 'dropout_rate': 0.3820783788748944, 'weight_decay': 3.9315367129718254e-05, 'warmup_pct': 0.050016076647387546}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7337, 'learning_rate': 0.0013336494132846737, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.7094586491584778, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.4212, 'eval_samples_per_second': 163.558, 'eval_steps_per_second': 20.651, 'epoch': 1.0, 'step': 198}, {'loss': 0.8356, 'learning_rate': 0.0026672988265693475, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6681264042854309, 'eval_accuracy': 0.5934343434343434, 'eval_runtime': 2.3915, 'eval_samples_per_second': 165.589, 'eval_steps_per_second': 20.908, 'epoch': 2.0, 'step': 396}, {'loss': 0.7352, 'learning_rate': 0.0017781992177128983, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6395246982574463, 'eval_accuracy': 0.5959595959595959, 'eval_runtime': 2.3885, 'eval_samples_per_second': 165.797, 'eval_steps_per_second': 20.934, 'epoch': 3.0, 'step': 594}, {'loss': 0.6562, 'learning_rate': 0.0008890996088564492, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5967714786529541, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 2.394, 'eval_samples_per_second': 165.417, 'eval_steps_per_second': 20.886, 'epoch': 4.0, 'step': 792}, {'loss': 0.5649, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5816836357116699, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.3972, 'eval_samples_per_second': 165.193, 'eval_steps_per_second': 20.858, 'epoch': 5.0, 'step': 990}, {'train_runtime': 376.1446, 'train_samples_per_second': 21.056, 'train_steps_per_second': 2.632, 'total_flos': 0.0, 'train_loss': 0.705116256559738, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5816836357116699, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.3986, 'eval_samples_per_second': 165.093, 'eval_steps_per_second': 20.845, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1584' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1584/1980 05:39 < 01:25, 4.66 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.948300</td>\n",
       "      <td>0.605394</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.687300</td>\n",
       "      <td>0.703200</td>\n",
       "      <td>0.641414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.758700</td>\n",
       "      <td>0.635529</td>\n",
       "      <td>0.643939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>0.668918</td>\n",
       "      <td>0.618687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6053940653800964, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.421, 'eval_samples_per_second': 163.566, 'eval_steps_per_second': 20.652, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:00:00,611] Trial 52 finished with values: [0.6053940653800964, 0.702020202020202] and parameters: {'lr': 0.002569825038535863, 'batch': 1, 'accum': 4, 'dropout_rate': 0.8504336918837415, 'weight_decay': 0.0009417287430392066, 'warmup_pct': 0.2542436182993035}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9483, 'learning_rate': 0.0005055393518431206, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6053940653800964, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.4328, 'eval_samples_per_second': 162.777, 'eval_steps_per_second': 20.553, 'epoch': 1.0, 'step': 396}, {'loss': 0.6873, 'learning_rate': 0.0010110787036862411, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.7032001614570618, 'eval_accuracy': 0.6414141414141414, 'eval_runtime': 2.4045, 'eval_samples_per_second': 164.692, 'eval_steps_per_second': 20.794, 'epoch': 2.0, 'step': 792}, {'loss': 0.7587, 'learning_rate': 0.0015166180555293617, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6355291604995728, 'eval_accuracy': 0.6439393939393939, 'eval_runtime': 2.4104, 'eval_samples_per_second': 164.286, 'eval_steps_per_second': 20.743, 'epoch': 3.0, 'step': 1188}, {'loss': 0.8296, 'learning_rate': 0.0020221574073724822, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6689184904098511, 'eval_accuracy': 0.6186868686868687, 'eval_runtime': 2.4013, 'eval_samples_per_second': 164.908, 'eval_steps_per_second': 20.822, 'epoch': 4.0, 'step': 1584}, {'train_runtime': 339.9081, 'train_samples_per_second': 23.3, 'train_steps_per_second': 5.825, 'total_flos': 0.0, 'train_loss': 0.8059880420415089, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6053940653800964, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.421, 'eval_samples_per_second': 163.566, 'eval_steps_per_second': 20.652, 'epoch': 4.0, 'step': 1584}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 02:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.187900</td>\n",
       "      <td>0.835073</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.156800</td>\n",
       "      <td>0.782080</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.984400</td>\n",
       "      <td>0.724079</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.944800</td>\n",
       "      <td>0.687995</td>\n",
       "      <td>0.520202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.815300</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6782655119895935, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 2.394, 'eval_samples_per_second': 165.413, 'eval_steps_per_second': 20.886, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:02:32,471] Trial 53 finished with values: [0.6782655119895935, 0.5757575757575758] and parameters: {'lr': 4.7584540614298015e-05, 'batch': 4, 'accum': 4, 'dropout_rate': 0.7917224101346604, 'weight_decay': 2.074689872583201e-05, 'warmup_pct': 0.1875991394591483}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1879, 'learning_rate': 1.2697761511632084e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.8350731730461121, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4267, 'eval_samples_per_second': 163.182, 'eval_steps_per_second': 20.604, 'epoch': 1.0, 'step': 99}, {'loss': 1.1568, 'learning_rate': 2.5395523023264167e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.7820799946784973, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4033, 'eval_samples_per_second': 164.775, 'eval_steps_per_second': 20.805, 'epoch': 2.0, 'step': 198}, {'loss': 0.9844, 'learning_rate': 3.809328453489625e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.724079430103302, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.4022, 'eval_samples_per_second': 164.847, 'eval_steps_per_second': 20.814, 'epoch': 3.0, 'step': 297}, {'loss': 0.9448, 'learning_rate': 3.799088323238309e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6879951357841492, 'eval_accuracy': 0.5202020202020202, 'eval_runtime': 2.4006, 'eval_samples_per_second': 164.957, 'eval_steps_per_second': 20.828, 'epoch': 4.0, 'step': 396}, {'loss': 0.8153, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6782655119895935, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 2.3916, 'eval_samples_per_second': 165.582, 'eval_steps_per_second': 20.907, 'epoch': 5.0, 'step': 495}, {'train_runtime': 138.7876, 'train_samples_per_second': 57.066, 'train_steps_per_second': 3.567, 'total_flos': 0.0, 'train_loss': 1.017836800006905, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6782655119895935, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 2.394, 'eval_samples_per_second': 165.413, 'eval_steps_per_second': 20.886, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.808800</td>\n",
       "      <td>0.636077</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.612400</td>\n",
       "      <td>0.551794</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.525900</td>\n",
       "      <td>0.673734</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.612813</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.460400</td>\n",
       "      <td>0.886126</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6128132939338684, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3909, 'eval_samples_per_second': 165.628, 'eval_steps_per_second': 20.913, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:09:16,564] Trial 54 finished with values: [0.6128132939338684, 0.7525252525252525] and parameters: {'lr': 0.0006203254061465803, 'batch': 1, 'accum': 4, 'dropout_rate': 0.4258356729985485, 'weight_decay': 1.929220868189138e-05, 'warmup_pct': 0.24803655575167158}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8088, 'learning_rate': 0.00012507579472201925, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6360770463943481, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.4168, 'eval_samples_per_second': 163.852, 'eval_steps_per_second': 20.688, 'epoch': 1.0, 'step': 396}, {'loss': 0.6124, 'learning_rate': 0.0002501515894440385, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.5517943501472473, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3958, 'eval_samples_per_second': 165.291, 'eval_steps_per_second': 20.87, 'epoch': 2.0, 'step': 792}, {'loss': 0.5259, 'learning_rate': 0.00037522738416605775, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.673734188079834, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.3878, 'eval_samples_per_second': 165.844, 'eval_steps_per_second': 20.94, 'epoch': 3.0, 'step': 1188}, {'loss': 0.512, 'learning_rate': 0.000500303178888077, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6128132939338684, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3905, 'eval_samples_per_second': 165.656, 'eval_steps_per_second': 20.916, 'epoch': 4.0, 'step': 1584}, {'loss': 0.4604, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.8861257433891296, 'eval_accuracy': 0.75, 'eval_runtime': 2.3875, 'eval_samples_per_second': 165.867, 'eval_steps_per_second': 20.943, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 391.0803, 'train_samples_per_second': 20.252, 'train_steps_per_second': 5.063, 'total_flos': 0.0, 'train_loss': 0.5839062700367937, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6128132939338684, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3909, 'eval_samples_per_second': 165.628, 'eval_steps_per_second': 20.913, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 03:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.036700</td>\n",
       "      <td>0.766380</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.936300</td>\n",
       "      <td>0.688060</td>\n",
       "      <td>0.560606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.723100</td>\n",
       "      <td>0.649008</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.642100</td>\n",
       "      <td>0.604169</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.570300</td>\n",
       "      <td>0.560700</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5607003569602966, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3874, 'eval_samples_per_second': 165.873, 'eval_steps_per_second': 20.944, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:13:02,549] Trial 55 finished with values: [0.5607003569602966, 0.7626262626262627] and parameters: {'lr': 0.00038839967736054487, 'batch': 2, 'accum': 8, 'dropout_rate': 0.649352271980414, 'weight_decay': 0.00026633364694670817, 'warmup_pct': 0.2830421730372154}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.0367, 'learning_rate': 3.433175719526245e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.766379714012146, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4153, 'eval_samples_per_second': 163.957, 'eval_steps_per_second': 20.702, 'epoch': 1.0, 'step': 99}, {'loss': 0.9363, 'learning_rate': 6.86635143905249e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6880601048469543, 'eval_accuracy': 0.5606060606060606, 'eval_runtime': 2.3878, 'eval_samples_per_second': 165.843, 'eval_steps_per_second': 20.94, 'epoch': 2.0, 'step': 198}, {'loss': 0.7231, 'learning_rate': 0.00010299527158578735, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6490083932876587, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.3888, 'eval_samples_per_second': 165.775, 'eval_steps_per_second': 20.931, 'epoch': 3.0, 'step': 297}, {'loss': 0.6421, 'learning_rate': 0.0001373270287810498, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6041688919067383, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.3885, 'eval_samples_per_second': 165.795, 'eval_steps_per_second': 20.934, 'epoch': 4.0, 'step': 396}, {'loss': 0.5703, 'learning_rate': 0.00017165878597631223, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5607003569602966, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.856, 'eval_steps_per_second': 20.941, 'epoch': 5.0, 'step': 495}, {'train_runtime': 212.8555, 'train_samples_per_second': 37.208, 'train_steps_per_second': 2.326, 'total_flos': 0.0, 'train_loss': 0.7816955489341659, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5607003569602966, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3874, 'eval_samples_per_second': 165.873, 'eval_steps_per_second': 20.944, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 01:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.787400</td>\n",
       "      <td>0.666512</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>0.631293</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.615400</td>\n",
       "      <td>0.608501</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.598637</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.569900</td>\n",
       "      <td>0.595553</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.595553457736969, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.4061, 'eval_samples_per_second': 164.581, 'eval_steps_per_second': 20.78, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:15:03,817] Trial 56 finished with values: [0.595553457736969, 0.7121212121212122] and parameters: {'lr': 8.984653012042214e-05, 'batch': 8, 'accum': 2, 'dropout_rate': 0.3015776221661395, 'weight_decay': 1.3342189991436294e-05, 'warmup_pct': 0.04274672598515941}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7874, 'learning_rate': 7.854133758871339e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6665120124816895, 'eval_accuracy': 0.6388888888888888, 'eval_runtime': 2.4126, 'eval_samples_per_second': 164.139, 'eval_steps_per_second': 20.725, 'epoch': 1.0, 'step': 99}, {'loss': 0.657, 'learning_rate': 5.8906003191535044e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.631292998790741, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 2.3904, 'eval_samples_per_second': 165.665, 'eval_steps_per_second': 20.917, 'epoch': 2.0, 'step': 198}, {'loss': 0.6154, 'learning_rate': 3.9270668794356696e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6085007190704346, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3883, 'eval_samples_per_second': 165.809, 'eval_steps_per_second': 20.935, 'epoch': 3.0, 'step': 297}, {'loss': 0.5875, 'learning_rate': 1.9635334397178348e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5986365675926208, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3879, 'eval_samples_per_second': 165.837, 'eval_steps_per_second': 20.939, 'epoch': 4.0, 'step': 396}, {'loss': 0.5699, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.595553457736969, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.3901, 'eval_samples_per_second': 165.684, 'eval_steps_per_second': 20.92, 'epoch': 5.0, 'step': 495}, {'train_runtime': 108.3104, 'train_samples_per_second': 73.123, 'train_steps_per_second': 4.57, 'total_flos': 0.0, 'train_loss': 0.6434400308011758, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.595553457736969, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.4061, 'eval_samples_per_second': 164.581, 'eval_steps_per_second': 20.78, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.761700</td>\n",
       "      <td>0.830339</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.776200</td>\n",
       "      <td>0.825108</td>\n",
       "      <td>0.550505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>0.648036</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.742900</td>\n",
       "      <td>0.700040</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.704400</td>\n",
       "      <td>0.637869</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6378688812255859, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 2.3968, 'eval_samples_per_second': 165.223, 'eval_steps_per_second': 20.861, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:21:35,491] Trial 57 finished with values: [0.6378688812255859, 0.6565656565656566] and parameters: {'lr': 0.0031966991695355986, 'batch': 1, 'accum': 4, 'dropout_rate': 0.2598202682685361, 'weight_decay': 1.0061476346999425e-05, 'warmup_pct': 0.033162752522080945}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7617, 'learning_rate': 0.0029473640771504003, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.8303390741348267, 'eval_accuracy': 0.5227272727272727, 'eval_runtime': 2.4191, 'eval_samples_per_second': 163.7, 'eval_steps_per_second': 20.669, 'epoch': 1.0, 'step': 396}, {'loss': 0.7762, 'learning_rate': 0.0022105230578628003, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.8251082301139832, 'eval_accuracy': 0.5505050505050505, 'eval_runtime': 2.3946, 'eval_samples_per_second': 165.372, 'eval_steps_per_second': 20.88, 'epoch': 2.0, 'step': 792}, {'loss': 0.683, 'learning_rate': 0.0014736820385752001, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6480360627174377, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 2.3967, 'eval_samples_per_second': 165.23, 'eval_steps_per_second': 20.862, 'epoch': 3.0, 'step': 1188}, {'loss': 0.7429, 'learning_rate': 0.0007368410192876001, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.7000398635864258, 'eval_accuracy': 0.5227272727272727, 'eval_runtime': 2.3966, 'eval_samples_per_second': 165.235, 'eval_steps_per_second': 20.863, 'epoch': 4.0, 'step': 1584}, {'loss': 0.7044, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6378688812255859, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.764, 'eval_steps_per_second': 20.93, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 378.6694, 'train_samples_per_second': 20.915, 'train_steps_per_second': 5.229, 'total_flos': 0.0, 'train_loss': 0.7336423469312263, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6378688812255859, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 2.3968, 'eval_samples_per_second': 165.223, 'eval_steps_per_second': 20.861, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 01:45, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.907800</td>\n",
       "      <td>0.849437</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.842600</td>\n",
       "      <td>0.771612</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.750800</td>\n",
       "      <td>0.703232</td>\n",
       "      <td>0.505051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7032321095466614, 'eval_accuracy': 0.5050505050505051, 'eval_runtime': 2.3839, 'eval_samples_per_second': 166.111, 'eval_steps_per_second': 20.974, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:23:35,184] Trial 58 finished with values: [0.7032321095466614, 0.5050505050505051] and parameters: {'lr': 1.641922650378061e-05, 'batch': 8, 'accum': 4, 'dropout_rate': 0.19985392099174062, 'weight_decay': 0.00010661757333894475, 'warmup_pct': 0.29932157431017997}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9078, 'learning_rate': 2.7180476306934115e-06, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.8494365811347961, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4338, 'eval_samples_per_second': 162.708, 'eval_steps_per_second': 20.544, 'epoch': 0.99, 'step': 49}, {'loss': 0.8675, 'learning_rate': 5.4915656211968934e-06, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.8164802193641663, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3937, 'eval_samples_per_second': 165.431, 'eval_steps_per_second': 20.888, 'epoch': 2.0, 'step': 99}, {'loss': 0.8426, 'learning_rate': 8.209613251890305e-06, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.7716119885444641, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3885, 'eval_samples_per_second': 165.796, 'eval_steps_per_second': 20.934, 'epoch': 2.99, 'step': 148}, {'loss': 0.7803, 'learning_rate': 1.0983131242393787e-05, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.7296586632728577, 'eval_accuracy': 0.5, 'eval_runtime': 2.3905, 'eval_samples_per_second': 165.653, 'eval_steps_per_second': 20.916, 'epoch': 4.0, 'step': 198}, {'loss': 0.7508, 'learning_rate': 1.3590238153467059e-05, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.7032321095466614, 'eval_accuracy': 0.5050505050505051, 'eval_runtime': 2.3852, 'eval_samples_per_second': 166.022, 'eval_steps_per_second': 20.962, 'epoch': 4.95, 'step': 245}, {'train_runtime': 106.2878, 'train_samples_per_second': 74.515, 'train_steps_per_second': 2.305, 'total_flos': 0.0, 'train_loss': 0.8303959437779018, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.7032321095466614, 'eval_accuracy': 0.5050505050505051, 'eval_runtime': 2.3839, 'eval_samples_per_second': 166.111, 'eval_steps_per_second': 20.974, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 07:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.718400</td>\n",
       "      <td>0.764721</td>\n",
       "      <td>0.633838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.724700</td>\n",
       "      <td>0.677969</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.630700</td>\n",
       "      <td>0.743591</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.523600</td>\n",
       "      <td>0.624934</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.376300</td>\n",
       "      <td>0.726347</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7263472080230713, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3886, 'eval_samples_per_second': 165.784, 'eval_steps_per_second': 20.932, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:31:19,218] Trial 59 finished with values: [0.7263472080230713, 0.76010101010101] and parameters: {'lr': 0.0018068803483599837, 'batch': 1, 'accum': 4, 'dropout_rate': 0.5979807623208674, 'weight_decay': 0.00017005349314421525, 'warmup_pct': 0.06522799302200422}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7184, 'learning_rate': 0.0013866756161832433, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.7647212147712708, 'eval_accuracy': 0.6338383838383839, 'eval_runtime': 2.425, 'eval_samples_per_second': 163.301, 'eval_steps_per_second': 20.619, 'epoch': 1.0, 'step': 396}, {'loss': 0.7247, 'learning_rate': 0.0014662389712101508, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6779686808586121, 'eval_accuracy': 0.6590909090909091, 'eval_runtime': 2.3982, 'eval_samples_per_second': 165.121, 'eval_steps_per_second': 20.849, 'epoch': 2.0, 'step': 792}, {'loss': 0.6307, 'learning_rate': 0.000977492647473434, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.743590772151947, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 2.3972, 'eval_samples_per_second': 165.195, 'eval_steps_per_second': 20.858, 'epoch': 3.0, 'step': 1188}, {'loss': 0.5236, 'learning_rate': 0.000488746323736717, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.624933660030365, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3928, 'eval_samples_per_second': 165.495, 'eval_steps_per_second': 20.896, 'epoch': 4.0, 'step': 1584}, {'loss': 0.3763, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.7263472080230713, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.4006, 'eval_samples_per_second': 164.958, 'eval_steps_per_second': 20.828, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 448.9412, 'train_samples_per_second': 17.642, 'train_steps_per_second': 4.41, 'total_flos': 0.0, 'train_loss': 0.5947405188974708, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.7263472080230713, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3886, 'eval_samples_per_second': 165.784, 'eval_steps_per_second': 20.932, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 02:13, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.938800</td>\n",
       "      <td>0.617667</td>\n",
       "      <td>0.654040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.602900</td>\n",
       "      <td>0.551196</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.425900</td>\n",
       "      <td>0.537498</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.537498414516449, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.856, 'eval_steps_per_second': 20.941, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:33:48,425] Trial 60 finished with values: [0.537498414516449, 0.7702020202020202] and parameters: {'lr': 0.0026434035671698895, 'batch': 4, 'accum': 8, 'dropout_rate': 0.8426275228259498, 'weight_decay': 3.9315367129718254e-05, 'warmup_pct': 0.04821520592534925}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9388, 'learning_rate': 0.001363439734645522, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.6176669001579285, 'eval_accuracy': 0.6540404040404041, 'eval_runtime': 2.4176, 'eval_samples_per_second': 163.796, 'eval_steps_per_second': 20.681, 'epoch': 0.99, 'step': 49}, {'loss': 0.6154, 'learning_rate': 0.0025729128053786927, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.5525764226913452, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3969, 'eval_samples_per_second': 165.212, 'eval_steps_per_second': 20.86, 'epoch': 2.0, 'step': 99}, {'loss': 0.6029, 'learning_rate': 0.0017094009734365285, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.5511964559555054, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3945, 'eval_samples_per_second': 165.38, 'eval_steps_per_second': 20.881, 'epoch': 2.99, 'step': 148}, {'loss': 0.507, 'learning_rate': 0.0008282664510465655, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5349843502044678, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3954, 'eval_samples_per_second': 165.318, 'eval_steps_per_second': 20.874, 'epoch': 4.0, 'step': 198}, {'loss': 0.4259, 'learning_rate': 0.0, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.537498414516449, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.3863, 'eval_samples_per_second': 165.947, 'eval_steps_per_second': 20.953, 'epoch': 4.95, 'step': 245}, {'train_runtime': 134.0531, 'train_samples_per_second': 59.081, 'train_steps_per_second': 1.828, 'total_flos': 0.0, 'train_loss': 0.6191111350546078, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.537498414516449, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.856, 'eval_steps_per_second': 20.941, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 01:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.710700</td>\n",
       "      <td>0.553873</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.681400</td>\n",
       "      <td>0.590810</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.534000</td>\n",
       "      <td>0.556587</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.437900</td>\n",
       "      <td>0.536582</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.268900</td>\n",
       "      <td>0.639541</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5365818738937378, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.4044, 'eval_samples_per_second': 164.7, 'eval_steps_per_second': 20.795, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:35:50,535] Trial 61 finished with values: [0.5365818738937378, 0.7626262626262627] and parameters: {'lr': 0.004271458706450745, 'batch': 8, 'accum': 2, 'dropout_rate': 0.2693979054790823, 'weight_decay': 0.000461406326249639, 'warmup_pct': 0.08710666707762078}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7107, 'learning_rate': 0.0041356910703043885, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5538727045059204, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 2.4128, 'eval_samples_per_second': 164.126, 'eval_steps_per_second': 20.723, 'epoch': 1.0, 'step': 99}, {'loss': 0.6814, 'learning_rate': 0.003101768302728291, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5908099412918091, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3927, 'eval_samples_per_second': 165.504, 'eval_steps_per_second': 20.897, 'epoch': 2.0, 'step': 198}, {'loss': 0.534, 'learning_rate': 0.0020678455351521943, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5565866231918335, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3938, 'eval_samples_per_second': 165.428, 'eval_steps_per_second': 20.887, 'epoch': 3.0, 'step': 297}, {'loss': 0.4379, 'learning_rate': 0.0010339227675760971, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5365818738937378, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.397, 'eval_samples_per_second': 165.205, 'eval_steps_per_second': 20.859, 'epoch': 4.0, 'step': 396}, {'loss': 0.2689, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6395409107208252, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3868, 'eval_samples_per_second': 165.915, 'eval_steps_per_second': 20.949, 'epoch': 5.0, 'step': 495}, {'train_runtime': 108.4758, 'train_samples_per_second': 73.012, 'train_steps_per_second': 4.563, 'total_flos': 0.0, 'train_loss': 0.5265814540362117, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5365818738937378, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.4044, 'eval_samples_per_second': 164.7, 'eval_steps_per_second': 20.795, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 01:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.687800</td>\n",
       "      <td>0.537106</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.525200</td>\n",
       "      <td>0.514591</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.514900</td>\n",
       "      <td>0.522601</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>0.533750</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.246800</td>\n",
       "      <td>0.721420</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.51459139585495, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.853, 'eval_steps_per_second': 20.941, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:37:52,105] Trial 62 finished with values: [0.51459139585495, 0.76010101010101] and parameters: {'lr': 0.002365442206851229, 'batch': 8, 'accum': 2, 'dropout_rate': 0.13946774290845135, 'weight_decay': 2.395969539853002e-05, 'warmup_pct': 0.2978091638164422}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6878, 'learning_rate': 0.0007965264574090873, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5371056795120239, 'eval_accuracy': 0.75, 'eval_runtime': 2.4182, 'eval_samples_per_second': 163.756, 'eval_steps_per_second': 20.676, 'epoch': 1.0, 'step': 99}, {'loss': 0.5252, 'learning_rate': 0.0015930529148181745, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.51459139585495, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3945, 'eval_samples_per_second': 165.376, 'eval_steps_per_second': 20.881, 'epoch': 2.0, 'step': 198}, {'loss': 0.5149, 'learning_rate': 0.0023301370992862853, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5226012468338013, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3935, 'eval_samples_per_second': 165.447, 'eval_steps_per_second': 20.89, 'epoch': 3.0, 'step': 297}, {'loss': 0.4444, 'learning_rate': 0.0011650685496431426, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5337502956390381, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3935, 'eval_samples_per_second': 165.449, 'eval_steps_per_second': 20.89, 'epoch': 4.0, 'step': 396}, {'loss': 0.2468, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.7214198112487793, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.701, 'eval_steps_per_second': 20.922, 'epoch': 5.0, 'step': 495}, {'train_runtime': 108.4872, 'train_samples_per_second': 73.004, 'train_steps_per_second': 4.563, 'total_flos': 0.0, 'train_loss': 0.48382805718315974, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.51459139585495, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.853, 'eval_steps_per_second': 20.941, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 02:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.187900</td>\n",
       "      <td>0.835073</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.156800</td>\n",
       "      <td>0.782080</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.984400</td>\n",
       "      <td>0.724079</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.944800</td>\n",
       "      <td>0.687995</td>\n",
       "      <td>0.520202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.815300</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6782655119895935, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 2.3948, 'eval_samples_per_second': 165.359, 'eval_steps_per_second': 20.879, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:40:21,356] Trial 63 finished with values: [0.6782655119895935, 0.5757575757575758] and parameters: {'lr': 4.7584540614298015e-05, 'batch': 4, 'accum': 4, 'dropout_rate': 0.7917224101346604, 'weight_decay': 2.074689872583201e-05, 'warmup_pct': 0.1875991394591483}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1879, 'learning_rate': 1.2697761511632084e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.8350731730461121, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4195, 'eval_samples_per_second': 163.672, 'eval_steps_per_second': 20.666, 'epoch': 1.0, 'step': 99}, {'loss': 1.1568, 'learning_rate': 2.5395523023264167e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.7820799946784973, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3927, 'eval_samples_per_second': 165.506, 'eval_steps_per_second': 20.897, 'epoch': 2.0, 'step': 198}, {'loss': 0.9844, 'learning_rate': 3.809328453489625e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.724079430103302, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.392, 'eval_samples_per_second': 165.551, 'eval_steps_per_second': 20.903, 'epoch': 3.0, 'step': 297}, {'loss': 0.9448, 'learning_rate': 3.799088323238309e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6879951357841492, 'eval_accuracy': 0.5202020202020202, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.853, 'eval_steps_per_second': 20.941, 'epoch': 4.0, 'step': 396}, {'loss': 0.8153, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6782655119895935, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 2.3918, 'eval_samples_per_second': 165.567, 'eval_steps_per_second': 20.905, 'epoch': 5.0, 'step': 495}, {'train_runtime': 136.2296, 'train_samples_per_second': 58.137, 'train_steps_per_second': 3.634, 'total_flos': 0.0, 'train_loss': 1.017836800006905, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6782655119895935, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 2.3948, 'eval_samples_per_second': 165.359, 'eval_steps_per_second': 20.879, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 02:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.843500</td>\n",
       "      <td>0.696911</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.706100</td>\n",
       "      <td>0.643985</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.613500</td>\n",
       "      <td>0.585732</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.542600</td>\n",
       "      <td>0.545591</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.461400</td>\n",
       "      <td>0.568857</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5688570737838745, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3919, 'eval_samples_per_second': 165.557, 'eval_steps_per_second': 20.904, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:42:50,555] Trial 64 finished with values: [0.5688570737838745, 0.7525252525252525] and parameters: {'lr': 0.0002824571363563599, 'batch': 4, 'accum': 4, 'dropout_rate': 0.27697220460719785, 'weight_decay': 0.0006003361529211938, 'warmup_pct': 0.2512517467249306}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8435, 'learning_rate': 5.626409758406365e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6969113349914551, 'eval_accuracy': 0.5277777777777778, 'eval_runtime': 2.4147, 'eval_samples_per_second': 163.993, 'eval_steps_per_second': 20.706, 'epoch': 1.0, 'step': 99}, {'loss': 0.7061, 'learning_rate': 0.0001125281951681273, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6439846158027649, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.3892, 'eval_samples_per_second': 165.746, 'eval_steps_per_second': 20.928, 'epoch': 2.0, 'step': 198}, {'loss': 0.6135, 'learning_rate': 0.00016879229275219094, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5857318043708801, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.3866, 'eval_samples_per_second': 165.929, 'eval_steps_per_second': 20.951, 'epoch': 3.0, 'step': 297}, {'loss': 0.5426, 'learning_rate': 0.0002250563903362546, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5455908179283142, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3883, 'eval_samples_per_second': 165.811, 'eval_steps_per_second': 20.936, 'epoch': 4.0, 'step': 396}, {'loss': 0.4614, 'learning_rate': 0.00028132048792031824, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5688570737838745, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3897, 'eval_samples_per_second': 165.711, 'eval_steps_per_second': 20.923, 'epoch': 5.0, 'step': 495}, {'train_runtime': 136.0575, 'train_samples_per_second': 58.211, 'train_steps_per_second': 3.638, 'total_flos': 0.0, 'train_loss': 0.633436253094914, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5688570737838745, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3919, 'eval_samples_per_second': 165.557, 'eval_steps_per_second': 20.904, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.106900</td>\n",
       "      <td>0.687496</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693300</td>\n",
       "      <td>0.578617</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.595099</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>0.603357</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.482800</td>\n",
       "      <td>0.659550</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6595501899719238, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.4048, 'eval_samples_per_second': 164.672, 'eval_steps_per_second': 20.792, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:49:28,462] Trial 65 finished with values: [0.6595501899719238, 0.7702020202020202] and parameters: {'lr': 0.00034057822098307983, 'batch': 1, 'accum': 4, 'dropout_rate': 0.8257234374248439, 'weight_decay': 3.937879437736638e-05, 'warmup_pct': 0.1446328441050829}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1069, 'learning_rate': 0.00011778949826139703, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6874961256980896, 'eval_accuracy': 0.5151515151515151, 'eval_runtime': 2.4192, 'eval_samples_per_second': 163.692, 'eval_steps_per_second': 20.668, 'epoch': 1.0, 'step': 396}, {'loss': 0.6933, 'learning_rate': 0.00023557899652279407, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.5786169171333313, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3844, 'eval_samples_per_second': 166.08, 'eval_steps_per_second': 20.97, 'epoch': 2.0, 'step': 792}, {'loss': 0.585, 'learning_rate': 0.0003230394622977236, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.5950989127159119, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.3898, 'eval_samples_per_second': 165.707, 'eval_steps_per_second': 20.923, 'epoch': 3.0, 'step': 1188}, {'loss': 0.5287, 'learning_rate': 0.0001615197311488618, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6033565998077393, 'eval_accuracy': 0.7651515151515151, 'eval_runtime': 2.391, 'eval_samples_per_second': 165.618, 'eval_steps_per_second': 20.911, 'epoch': 4.0, 'step': 1584}, {'loss': 0.4828, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6595501899719238, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.4109, 'eval_samples_per_second': 164.257, 'eval_steps_per_second': 20.74, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 384.5, 'train_samples_per_second': 20.598, 'train_steps_per_second': 5.15, 'total_flos': 0.0, 'train_loss': 0.6793220597084122, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6595501899719238, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 2.4048, 'eval_samples_per_second': 164.672, 'eval_steps_per_second': 20.792, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 03:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.745800</td>\n",
       "      <td>0.568057</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.690682</td>\n",
       "      <td>0.553030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.626700</td>\n",
       "      <td>0.630539</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.583800</td>\n",
       "      <td>0.601324</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.545800</td>\n",
       "      <td>0.598439</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6013241410255432, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.4018, 'eval_samples_per_second': 164.874, 'eval_steps_per_second': 20.817, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 11:53:25,567] Trial 66 finished with values: [0.6013241410255432, 0.6994949494949495] and parameters: {'lr': 0.005582158628882097, 'batch': 2, 'accum': 2, 'dropout_rate': 0.4566814361858127, 'weight_decay': 3.937879437736638e-05, 'warmup_pct': 0.15153288640300333}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7458, 'learning_rate': 0.0036842246950621843, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.5680567622184753, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.4189, 'eval_samples_per_second': 163.708, 'eval_steps_per_second': 20.67, 'epoch': 1.0, 'step': 396}, {'loss': 0.8641, 'learning_rate': 0.00480551047182024, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6906824707984924, 'eval_accuracy': 0.553030303030303, 'eval_runtime': 2.387, 'eval_samples_per_second': 165.902, 'eval_steps_per_second': 20.947, 'epoch': 2.0, 'step': 792}, {'loss': 0.6267, 'learning_rate': 0.00320367364788016, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6305390000343323, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 2.3868, 'eval_samples_per_second': 165.912, 'eval_steps_per_second': 20.948, 'epoch': 3.0, 'step': 1188}, {'loss': 0.5838, 'learning_rate': 0.00160183682394008, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6013241410255432, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3891, 'eval_samples_per_second': 165.751, 'eval_steps_per_second': 20.928, 'epoch': 4.0, 'step': 1584}, {'loss': 0.5458, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5984389781951904, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 2.3893, 'eval_samples_per_second': 165.736, 'eval_steps_per_second': 20.926, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 223.3312, 'train_samples_per_second': 35.463, 'train_steps_per_second': 8.866, 'total_flos': 0.0, 'train_loss': 0.6732163169167259, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6013241410255432, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.4018, 'eval_samples_per_second': 164.874, 'eval_steps_per_second': 20.817, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 06:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.801400</td>\n",
       "      <td>0.652643</td>\n",
       "      <td>0.631313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.653200</td>\n",
       "      <td>0.718913</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.692600</td>\n",
       "      <td>0.768233</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.596400</td>\n",
       "      <td>1.087463</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.421800</td>\n",
       "      <td>1.201199</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0874632596969604, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.4104, 'eval_samples_per_second': 164.288, 'eval_steps_per_second': 20.743, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:00:40,698] Trial 67 finished with values: [1.0874632596969604, 0.7449494949494949] and parameters: {'lr': 0.0001513570514600591, 'batch': 1, 'accum': 2, 'dropout_rate': 0.2598202682685361, 'weight_decay': 3.948957000697015e-05, 'warmup_pct': 0.27589559193148167}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8014, 'learning_rate': 5.486260171916101e-05, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.6526431441307068, 'eval_accuracy': 0.6313131313131313, 'eval_runtime': 2.4132, 'eval_samples_per_second': 164.1, 'eval_steps_per_second': 20.72, 'epoch': 1.0, 'step': 792}, {'loss': 0.6532, 'learning_rate': 0.00010972520343832203, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.7189130783081055, 'eval_accuracy': 0.696969696969697, 'eval_runtime': 2.3912, 'eval_samples_per_second': 165.61, 'eval_steps_per_second': 20.91, 'epoch': 2.0, 'step': 1584}, {'loss': 0.6926, 'learning_rate': 0.00013507018000717387, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.7682331800460815, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3876, 'eval_samples_per_second': 165.855, 'eval_steps_per_second': 20.941, 'epoch': 3.0, 'step': 2376}, {'loss': 0.5964, 'learning_rate': 6.753509000358694e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 1.0874632596969604, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.3864, 'eval_samples_per_second': 165.94, 'eval_steps_per_second': 20.952, 'epoch': 4.0, 'step': 3168}, {'loss': 0.4218, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 1.2011988162994385, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.764, 'eval_steps_per_second': 20.93, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 418.5225, 'train_samples_per_second': 18.924, 'train_steps_per_second': 9.462, 'total_flos': 0.0, 'train_loss': 0.633090556751598, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 1.0874632596969604, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.4104, 'eval_samples_per_second': 164.288, 'eval_steps_per_second': 20.743, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 01:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.126900</td>\n",
       "      <td>0.814252</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.019500</td>\n",
       "      <td>0.737662</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.930400</td>\n",
       "      <td>0.708011</td>\n",
       "      <td>0.507576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.888900</td>\n",
       "      <td>0.697441</td>\n",
       "      <td>0.505051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.829800</td>\n",
       "      <td>0.694865</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:02:43,037] Trial 68 finished with values: [0.694865345954895, 0.5025252525252525] and parameters: {'lr': 2.679707266037432e-05, 'batch': 8, 'accum': 2, 'dropout_rate': 0.6995636171551254, 'weight_decay': 0.00018917751354183602, 'warmup_pct': 0.1518123966189644}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.694865345954895, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3987, 'eval_samples_per_second': 165.093, 'eval_steps_per_second': 20.845, 'epoch': 5.0}\n",
      "History:  [{'loss': 1.1269, 'learning_rate': 1.768606795584705e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.8142519593238831, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4183, 'eval_samples_per_second': 163.749, 'eval_steps_per_second': 20.675, 'epoch': 1.0, 'step': 99}, {'loss': 1.0195, 'learning_rate': 2.3068784290235285e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.7376619577407837, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3967, 'eval_samples_per_second': 165.224, 'eval_steps_per_second': 20.862, 'epoch': 2.0, 'step': 198}, {'loss': 0.9304, 'learning_rate': 1.5379189526823522e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.7080110311508179, 'eval_accuracy': 0.5075757575757576, 'eval_runtime': 2.3944, 'eval_samples_per_second': 165.385, 'eval_steps_per_second': 20.882, 'epoch': 3.0, 'step': 297}, {'loss': 0.8889, 'learning_rate': 7.689594763411761e-06, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.697441041469574, 'eval_accuracy': 0.5050505050505051, 'eval_runtime': 2.3932, 'eval_samples_per_second': 165.467, 'eval_steps_per_second': 20.892, 'epoch': 4.0, 'step': 396}, {'loss': 0.8298, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.694865345954895, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3909, 'eval_samples_per_second': 165.626, 'eval_steps_per_second': 20.912, 'epoch': 5.0, 'step': 495}, {'train_runtime': 108.8228, 'train_samples_per_second': 72.779, 'train_steps_per_second': 4.549, 'total_flos': 0.0, 'train_loss': 0.959106753570865, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.694865345954895, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3987, 'eval_samples_per_second': 165.093, 'eval_steps_per_second': 20.845, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [792/990 02:59 < 00:45, 4.40 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.920500</td>\n",
       "      <td>0.585736</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.691620</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.907400</td>\n",
       "      <td>0.713814</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.724900</td>\n",
       "      <td>0.645172</td>\n",
       "      <td>0.623737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5857363343238831, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.3981, 'eval_samples_per_second': 165.128, 'eval_steps_per_second': 20.849, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:05:55,877] Trial 69 finished with values: [0.5857363343238831, 0.7045454545454546] and parameters: {'lr': 0.005896224699086761, 'batch': 2, 'accum': 4, 'dropout_rate': 0.8862820877124913, 'weight_decay': 0.00012767251690941857, 'warmup_pct': 0.2625335736059853}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9205, 'learning_rate': 0.0011236308858702394, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.5857363343238831, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.4198, 'eval_samples_per_second': 163.653, 'eval_steps_per_second': 20.663, 'epoch': 1.0, 'step': 198}, {'loss': 0.858, 'learning_rate': 0.0022472617717404788, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.691619873046875, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.394, 'eval_samples_per_second': 165.411, 'eval_steps_per_second': 20.885, 'epoch': 2.0, 'step': 396}, {'loss': 0.9074, 'learning_rate': 0.003370892657610718, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.7138144969940186, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3945, 'eval_samples_per_second': 165.382, 'eval_steps_per_second': 20.882, 'epoch': 3.0, 'step': 594}, {'loss': 0.7249, 'learning_rate': 0.0044945235434809576, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6451724171638489, 'eval_accuracy': 0.6237373737373737, 'eval_runtime': 2.3932, 'eval_samples_per_second': 165.471, 'eval_steps_per_second': 20.893, 'epoch': 4.0, 'step': 792}, {'train_runtime': 179.8739, 'train_samples_per_second': 44.031, 'train_steps_per_second': 5.504, 'total_flos': 0.0, 'train_loss': 0.8527171587703204, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5857363343238831, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.3981, 'eval_samples_per_second': 165.128, 'eval_steps_per_second': 20.849, 'epoch': 4.0, 'step': 792}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 06:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.859100</td>\n",
       "      <td>0.672005</td>\n",
       "      <td>0.623737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.636724</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.628900</td>\n",
       "      <td>0.613436</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.594400</td>\n",
       "      <td>0.601472</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.574400</td>\n",
       "      <td>0.598281</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5982812643051147, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3871, 'eval_samples_per_second': 165.894, 'eval_steps_per_second': 20.946, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:13:00,108] Trial 70 finished with values: [0.5982812643051147, 0.702020202020202] and parameters: {'lr': 7.26659640267162e-05, 'batch': 1, 'accum': 8, 'dropout_rate': 0.4914183485282615, 'weight_decay': 0.000461406326249639, 'warmup_pct': 0.015346277863747627}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8591, 'learning_rate': 6.622720772055147e-05, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.6720045208930969, 'eval_accuracy': 0.6237373737373737, 'eval_runtime': 2.4265, 'eval_samples_per_second': 163.198, 'eval_steps_per_second': 20.606, 'epoch': 1.0, 'step': 198}, {'loss': 0.6942, 'learning_rate': 4.9670405790413604e-05, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6367241144180298, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.3967, 'eval_samples_per_second': 165.225, 'eval_steps_per_second': 20.862, 'epoch': 2.0, 'step': 396}, {'loss': 0.6289, 'learning_rate': 3.3113603860275734e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6134358644485474, 'eval_accuracy': 0.6944444444444444, 'eval_runtime': 2.3916, 'eval_samples_per_second': 165.579, 'eval_steps_per_second': 20.906, 'epoch': 3.0, 'step': 594}, {'loss': 0.5944, 'learning_rate': 1.6556801930137867e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6014719009399414, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3925, 'eval_samples_per_second': 165.52, 'eval_steps_per_second': 20.899, 'epoch': 4.0, 'step': 792}, {'loss': 0.5744, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5982812643051147, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3878, 'eval_samples_per_second': 165.846, 'eval_steps_per_second': 20.94, 'epoch': 5.0, 'step': 990}, {'train_runtime': 411.2789, 'train_samples_per_second': 19.257, 'train_steps_per_second': 2.407, 'total_flos': 0.0, 'train_loss': 0.6701980976143269, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.5982812643051147, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.3871, 'eval_samples_per_second': 165.894, 'eval_steps_per_second': 20.946, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 01:45, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.648534</td>\n",
       "      <td>0.654040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.545800</td>\n",
       "      <td>0.535810</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.473000</td>\n",
       "      <td>0.527226</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5277373790740967, 'eval_accuracy': 0.75, 'eval_runtime': 2.3893, 'eval_samples_per_second': 165.738, 'eval_steps_per_second': 20.927, 'epoch': 4.95}\n",
      "History:  [{'loss': 0.8092, 'learning_rate': 0.0002636266605992693, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.6485338807106018, 'eval_accuracy': 0.6540404040404041, 'eval_runtime': 2.4163, 'eval_samples_per_second': 163.884, 'eval_steps_per_second': 20.692, 'epoch': 0.99, 'step': 49}, {'loss': 0.614, 'learning_rate': 0.0001963749614668026, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.569968581199646, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3878, 'eval_samples_per_second': 165.841, 'eval_steps_per_second': 20.94, 'epoch': 2.0, 'step': 99}, {'loss': 0.5458, 'learning_rate': 0.0001304682963169853, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.5358095765113831, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.39, 'eval_samples_per_second': 165.687, 'eval_steps_per_second': 20.92, 'epoch': 2.99, 'step': 148}, {'loss': 0.4887, 'learning_rate': 6.321659718451865e-05, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5277373790740967, 'eval_accuracy': 0.75, 'eval_runtime': 2.3959, 'eval_samples_per_second': 165.282, 'eval_steps_per_second': 20.869, 'epoch': 4.0, 'step': 198}, {'loss': 0.473, 'learning_rate': 0.0, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5272261500358582, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3945, 'eval_samples_per_second': 165.382, 'eval_steps_per_second': 20.882, 'epoch': 4.95, 'step': 245}, {'train_runtime': 105.9089, 'train_samples_per_second': 74.781, 'train_steps_per_second': 2.313, 'total_flos': 0.0, 'train_loss': 0.5867709335015745, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5277373790740967, 'eval_accuracy': 0.75, 'eval_runtime': 2.3893, 'eval_samples_per_second': 165.738, 'eval_steps_per_second': 20.927, 'epoch': 4.95, 'step': 245}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:14:59,063] Trial 71 finished with values: [0.5277373790740967, 0.75] and parameters: {'lr': 0.0002824571363563599, 'batch': 8, 'accum': 4, 'dropout_rate': 0.40860348691591963, 'weight_decay': 0.00020215322767494295, 'warmup_pct': 0.03546683549151491}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 02:13, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.001400</td>\n",
       "      <td>0.767128</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.764100</td>\n",
       "      <td>0.665854</td>\n",
       "      <td>0.621212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.615400</td>\n",
       "      <td>0.585638</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5856384634971619, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.4025, 'eval_samples_per_second': 164.827, 'eval_steps_per_second': 20.812, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:17:25,773] Trial 72 finished with values: [0.5856384634971619, 0.7045454545454546] and parameters: {'lr': 0.0002875349579388252, 'batch': 4, 'accum': 8, 'dropout_rate': 0.5020485174234813, 'weight_decay': 0.00029430992372702226, 'warmup_pct': 0.21692105224696948}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.0014, 'learning_rate': 3.284198820280288e-05, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.7671276926994324, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4266, 'eval_samples_per_second': 163.192, 'eval_steps_per_second': 20.605, 'epoch': 0.99, 'step': 49}, {'loss': 0.8638, 'learning_rate': 6.635422106280582e-05, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.6909763813018799, 'eval_accuracy': 0.5580808080808081, 'eval_runtime': 2.3963, 'eval_samples_per_second': 165.258, 'eval_steps_per_second': 20.866, 'epoch': 2.0, 'step': 99}, {'loss': 0.7641, 'learning_rate': 9.919620926560868e-05, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.6658544540405273, 'eval_accuracy': 0.6212121212121212, 'eval_runtime': 2.4009, 'eval_samples_per_second': 164.936, 'eval_steps_per_second': 20.825, 'epoch': 2.99, 'step': 148}, {'loss': 0.6839, 'learning_rate': 0.00013270844212561164, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.6288798451423645, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 2.3953, 'eval_samples_per_second': 165.322, 'eval_steps_per_second': 20.874, 'epoch': 4.0, 'step': 198}, {'loss': 0.6154, 'learning_rate': 0.0001642099410140144, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5856384634971619, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.4009, 'eval_samples_per_second': 164.937, 'eval_steps_per_second': 20.825, 'epoch': 4.95, 'step': 245}, {'train_runtime': 133.7435, 'train_samples_per_second': 59.218, 'train_steps_per_second': 1.832, 'total_flos': 0.0, 'train_loss': 0.7870201266541773, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5856384634971619, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.4025, 'eval_samples_per_second': 164.827, 'eval_steps_per_second': 20.812, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 03:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>0.680150</td>\n",
       "      <td>0.643939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>0.602460</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.820100</td>\n",
       "      <td>0.895746</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.820900</td>\n",
       "      <td>0.736849</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.684200</td>\n",
       "      <td>0.649655</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6024600863456726, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.4176, 'eval_samples_per_second': 163.797, 'eval_steps_per_second': 20.681, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:21:26,376] Trial 73 finished with values: [0.6024600863456726, 0.7196969696969697] and parameters: {'lr': 0.0032104795402394613, 'batch': 2, 'accum': 2, 'dropout_rate': 0.4566814361858127, 'weight_decay': 8.63707205968112e-05, 'warmup_pct': 0.27746533877747237}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6764, 'learning_rate': 0.001157877866971609, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.6801504492759705, 'eval_accuracy': 0.6439393939393939, 'eval_runtime': 2.4129, 'eval_samples_per_second': 164.116, 'eval_steps_per_second': 20.722, 'epoch': 1.0, 'step': 396}, {'loss': 0.661, 'learning_rate': 0.002315755733943218, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6024600863456726, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3942, 'eval_samples_per_second': 165.4, 'eval_steps_per_second': 20.884, 'epoch': 2.0, 'step': 792}, {'loss': 0.8201, 'learning_rate': 0.002882879587153802, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.8957464694976807, 'eval_accuracy': 0.5, 'eval_runtime': 2.3949, 'eval_samples_per_second': 165.355, 'eval_steps_per_second': 20.878, 'epoch': 3.0, 'step': 1188}, {'loss': 0.8209, 'learning_rate': 0.001441439793576901, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.7368489503860474, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.4033, 'eval_samples_per_second': 164.771, 'eval_steps_per_second': 20.804, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6842, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6496546864509583, 'eval_accuracy': 0.6111111111111112, 'eval_runtime': 2.3953, 'eval_samples_per_second': 165.325, 'eval_steps_per_second': 20.874, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 227.6607, 'train_samples_per_second': 34.789, 'train_steps_per_second': 8.697, 'total_flos': 0.0, 'train_loss': 0.7325396605212279, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6024600863456726, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.4176, 'eval_samples_per_second': 163.797, 'eval_steps_per_second': 20.681, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 07:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.869700</td>\n",
       "      <td>0.759846</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.756200</td>\n",
       "      <td>0.689813</td>\n",
       "      <td>0.553030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.685700</td>\n",
       "      <td>0.660156</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.663200</td>\n",
       "      <td>0.639400</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.634500</td>\n",
       "      <td>0.634016</td>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6340162754058838, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.3893, 'eval_samples_per_second': 165.738, 'eval_steps_per_second': 20.927, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:28:59,231] Trial 74 finished with values: [0.6340162754058838, 0.6717171717171717] and parameters: {'lr': 2.518578485581676e-05, 'batch': 1, 'accum': 4, 'dropout_rate': 0.19985392099174062, 'weight_decay': 4.6202065573283256e-05, 'warmup_pct': 0.1446328441050829}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8697, 'learning_rate': 8.710542185941866e-06, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.7598456144332886, 'eval_accuracy': 0.5, 'eval_runtime': 2.4191, 'eval_samples_per_second': 163.699, 'eval_steps_per_second': 20.669, 'epoch': 1.0, 'step': 396}, {'loss': 0.7562, 'learning_rate': 1.742108437188373e-05, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6898133754730225, 'eval_accuracy': 0.553030303030303, 'eval_runtime': 2.3919, 'eval_samples_per_second': 165.56, 'eval_steps_per_second': 20.904, 'epoch': 2.0, 'step': 792}, {'loss': 0.6857, 'learning_rate': 2.388879234228368e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6601564288139343, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.3808, 'eval_samples_per_second': 166.333, 'eval_steps_per_second': 21.002, 'epoch': 3.0, 'step': 1188}, {'loss': 0.6632, 'learning_rate': 1.194439617114184e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6394004225730896, 'eval_accuracy': 0.6666666666666666, 'eval_runtime': 2.4026, 'eval_samples_per_second': 164.82, 'eval_steps_per_second': 20.811, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6345, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6340162754058838, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.3985, 'eval_samples_per_second': 165.103, 'eval_steps_per_second': 20.846, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 439.7684, 'train_samples_per_second': 18.009, 'train_steps_per_second': 4.502, 'total_flos': 0.0, 'train_loss': 0.7218531984271426, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.6340162754058838, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.3893, 'eval_samples_per_second': 165.738, 'eval_steps_per_second': 20.927, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [792/990 05:06 < 01:16, 2.58 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.556945</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.565900</td>\n",
       "      <td>0.612946</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.540300</td>\n",
       "      <td>0.632090</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.632026</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5569446682929993, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.4149, 'eval_samples_per_second': 163.982, 'eval_steps_per_second': 20.705, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:34:21,960] Trial 75 finished with values: [0.5569446682929993, 0.73989898989899] and parameters: {'lr': 0.0026434035671698895, 'batch': 1, 'accum': 8, 'dropout_rate': 0.4914183485282615, 'weight_decay': 1.2229560673027971e-05, 'warmup_pct': 0.12414205931416358}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.745, 'learning_rate': 0.000532445479450293, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.5569446682929993, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.4197, 'eval_samples_per_second': 163.659, 'eval_steps_per_second': 20.664, 'epoch': 1.0, 'step': 198}, {'loss': 0.5659, 'learning_rate': 0.001064890958900586, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6129462718963623, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 2.3881, 'eval_samples_per_second': 165.82, 'eval_steps_per_second': 20.937, 'epoch': 2.0, 'step': 396}, {'loss': 0.5403, 'learning_rate': 0.0015973364383508794, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6320897936820984, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3931, 'eval_samples_per_second': 165.479, 'eval_steps_per_second': 20.894, 'epoch': 3.0, 'step': 594}, {'loss': 0.548, 'learning_rate': 0.002129781917801172, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6320257186889648, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3881, 'eval_samples_per_second': 165.821, 'eval_steps_per_second': 20.937, 'epoch': 4.0, 'step': 792}, {'train_runtime': 306.832, 'train_samples_per_second': 25.812, 'train_steps_per_second': 3.227, 'total_flos': 0.0, 'train_loss': 0.5997906405516346, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5569446682929993, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.4149, 'eval_samples_per_second': 163.982, 'eval_steps_per_second': 20.705, 'epoch': 4.0, 'step': 792}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='396' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [396/495 01:48 < 00:27, 3.64 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.731900</td>\n",
       "      <td>0.565026</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.658300</td>\n",
       "      <td>0.754339</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.715100</td>\n",
       "      <td>0.703743</td>\n",
       "      <td>0.512626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.728200</td>\n",
       "      <td>0.640684</td>\n",
       "      <td>0.631313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5650255084037781, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.4133, 'eval_samples_per_second': 164.092, 'eval_steps_per_second': 20.719, 'epoch': 4.0}\n",
      "History:  [{'loss': 0.7319, 'learning_rate': 0.0007858767361856429, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5650255084037781, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.4112, 'eval_samples_per_second': 164.232, 'eval_steps_per_second': 20.736, 'epoch': 1.0, 'step': 99}, {'loss': 0.6583, 'learning_rate': 0.0015717534723712857, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.7543394565582275, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3913, 'eval_samples_per_second': 165.597, 'eval_steps_per_second': 20.909, 'epoch': 2.0, 'step': 198}, {'loss': 0.7151, 'learning_rate': 0.0023576302085569286, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.703742504119873, 'eval_accuracy': 0.5126262626262627, 'eval_runtime': 2.3852, 'eval_samples_per_second': 166.022, 'eval_steps_per_second': 20.962, 'epoch': 3.0, 'step': 297}, {'loss': 0.7282, 'learning_rate': 0.001615413291048266, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6406844258308411, 'eval_accuracy': 0.6313131313131313, 'eval_runtime': 2.3888, 'eval_samples_per_second': 165.776, 'eval_steps_per_second': 20.931, 'epoch': 4.0, 'step': 396}, {'train_runtime': 108.4436, 'train_samples_per_second': 73.033, 'train_steps_per_second': 4.565, 'total_flos': 0.0, 'train_loss': 0.7083794179588857, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5650255084037781, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.4133, 'eval_samples_per_second': 164.092, 'eval_steps_per_second': 20.719, 'epoch': 4.0, 'step': 396}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:36:24,085] Trial 76 finished with values: [0.5650255084037781, 0.7247474747474747] and parameters: {'lr': 0.0026434035671698895, 'batch': 4, 'accum': 4, 'dropout_rate': 0.3751279886367357, 'weight_decay': 0.00036385204796382677, 'warmup_pct': 0.16819141556956405}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 01:42, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>0.773938</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.838000</td>\n",
       "      <td>0.692180</td>\n",
       "      <td>0.547980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.787300</td>\n",
       "      <td>0.673846</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.718100</td>\n",
       "      <td>0.661777</td>\n",
       "      <td>0.641414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6617767810821533, 'eval_accuracy': 0.6414141414141414, 'eval_runtime': 2.3939, 'eval_samples_per_second': 165.418, 'eval_steps_per_second': 20.886, 'epoch': 4.85}\n",
      "History:  [{'loss': 0.9958, 'learning_rate': 5.134087435452693e-05, 'epoch': 0.97, 'step': 24}, {'eval_loss': 0.7739377021789551, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4172, 'eval_samples_per_second': 163.826, 'eval_steps_per_second': 20.685, 'epoch': 0.97, 'step': 24}, {'loss': 0.838, 'learning_rate': 8.178337998140989e-05, 'epoch': 1.98, 'step': 49}, {'eval_loss': 0.6921796798706055, 'eval_accuracy': 0.547979797979798, 'eval_runtime': 2.3905, 'eval_samples_per_second': 165.655, 'eval_steps_per_second': 20.916, 'epoch': 1.98, 'step': 49}, {'loss': 0.7873, 'learning_rate': 5.2986415199223314e-05, 'epoch': 2.99, 'step': 74}, {'eval_loss': 0.6738455295562744, 'eval_accuracy': 0.6136363636363636, 'eval_runtime': 2.3894, 'eval_samples_per_second': 165.731, 'eval_steps_per_second': 20.926, 'epoch': 2.99, 'step': 74}, {'loss': 0.7542, 'learning_rate': 2.418945041703673e-05, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.6647374033927917, 'eval_accuracy': 0.6338383838383839, 'eval_runtime': 2.3906, 'eval_samples_per_second': 165.648, 'eval_steps_per_second': 20.915, 'epoch': 4.0, 'step': 99}, {'loss': 0.7181, 'learning_rate': 0.0, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.6617767810821533, 'eval_accuracy': 0.6414141414141414, 'eval_runtime': 2.3892, 'eval_samples_per_second': 165.744, 'eval_steps_per_second': 20.927, 'epoch': 4.85, 'step': 120}, {'train_runtime': 103.2814, 'train_samples_per_second': 76.684, 'train_steps_per_second': 1.162, 'total_flos': 0.0, 'train_loss': 0.8205471674601237, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.6617767810821533, 'eval_accuracy': 0.6414141414141414, 'eval_runtime': 2.3939, 'eval_samples_per_second': 165.418, 'eval_steps_per_second': 20.886, 'epoch': 4.85, 'step': 120}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:38:20,441] Trial 77 finished with values: [0.6617767810821533, 0.6414141414141414] and parameters: {'lr': 8.984653012042214e-05, 'batch': 8, 'accum': 8, 'dropout_rate': 0.5078646795206229, 'weight_decay': 1.8639783574929038e-05, 'warmup_pct': 0.04274672598515941}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 06:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.748400</td>\n",
       "      <td>0.969425</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.880900</td>\n",
       "      <td>0.593473</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.959900</td>\n",
       "      <td>1.110976</td>\n",
       "      <td>0.505051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.774800</td>\n",
       "      <td>0.683095</td>\n",
       "      <td>0.648990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.664400</td>\n",
       "      <td>0.649066</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5934728384017944, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.4161, 'eval_samples_per_second': 163.897, 'eval_steps_per_second': 20.694, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:45:01,892] Trial 78 finished with values: [0.5934728384017944, 0.7196969696969697] and parameters: {'lr': 0.002569825038535863, 'batch': 1, 'accum': 2, 'dropout_rate': 0.2080290627140376, 'weight_decay': 2.4010257447838972e-05, 'warmup_pct': 0.2721995720664585}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7484, 'learning_rate': 0.0009444554201950828, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.9694250822067261, 'eval_accuracy': 0.702020202020202, 'eval_runtime': 2.4124, 'eval_samples_per_second': 164.152, 'eval_steps_per_second': 20.726, 'epoch': 1.0, 'step': 792}, {'loss': 0.8809, 'learning_rate': 0.0018889108403901656, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.5934728384017944, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3888, 'eval_samples_per_second': 165.775, 'eval_steps_per_second': 20.931, 'epoch': 2.0, 'step': 1584}, {'loss': 0.9599, 'learning_rate': 0.0022551816404658208, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 1.1109764575958252, 'eval_accuracy': 0.5050505050505051, 'eval_runtime': 2.3945, 'eval_samples_per_second': 165.382, 'eval_steps_per_second': 20.882, 'epoch': 3.0, 'step': 2376}, {'loss': 0.7748, 'learning_rate': 0.0011275908202329104, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.68309485912323, 'eval_accuracy': 0.648989898989899, 'eval_runtime': 2.3936, 'eval_samples_per_second': 165.439, 'eval_steps_per_second': 20.889, 'epoch': 4.0, 'step': 3168}, {'loss': 0.6644, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.6490663290023804, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3863, 'eval_samples_per_second': 165.95, 'eval_steps_per_second': 20.953, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 388.5535, 'train_samples_per_second': 20.383, 'train_steps_per_second': 10.192, 'total_flos': 0.0, 'train_loss': 0.8056834057123974, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.5934728384017944, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.4161, 'eval_samples_per_second': 163.897, 'eval_steps_per_second': 20.694, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 03:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.985800</td>\n",
       "      <td>0.822356</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.943400</td>\n",
       "      <td>0.746128</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>0.696418</td>\n",
       "      <td>0.517677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.774100</td>\n",
       "      <td>0.675899</td>\n",
       "      <td>0.601010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.721400</td>\n",
       "      <td>0.656694</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6566935181617737, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.4033, 'eval_samples_per_second': 164.773, 'eval_steps_per_second': 20.805, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:48:46,634] Trial 79 finished with values: [0.6566935181617737, 0.6515151515151515] and parameters: {'lr': 5.516531302657079e-05, 'batch': 2, 'accum': 8, 'dropout_rate': 0.4914183485282615, 'weight_decay': 1.929220868189138e-05, 'warmup_pct': 0.165492291809389}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9858, 'learning_rate': 8.33796334294734e-06, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.8223559260368347, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4126, 'eval_samples_per_second': 164.141, 'eval_steps_per_second': 20.725, 'epoch': 1.0, 'step': 99}, {'loss': 0.9434, 'learning_rate': 1.667592668589468e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.7461276054382324, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3901, 'eval_samples_per_second': 165.682, 'eval_steps_per_second': 20.919, 'epoch': 2.0, 'step': 198}, {'loss': 0.821, 'learning_rate': 2.501389002884202e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6964176297187805, 'eval_accuracy': 0.5176767676767676, 'eval_runtime': 2.3883, 'eval_samples_per_second': 165.805, 'eval_steps_per_second': 20.935, 'epoch': 3.0, 'step': 297}, {'loss': 0.7741, 'learning_rate': 3.335185337178936e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6758991479873657, 'eval_accuracy': 0.601010101010101, 'eval_runtime': 2.4022, 'eval_samples_per_second': 164.849, 'eval_steps_per_second': 20.814, 'epoch': 4.0, 'step': 396}, {'loss': 0.7214, 'learning_rate': 4.1689816714736707e-05, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6566935181617737, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.4065, 'eval_samples_per_second': 164.551, 'eval_steps_per_second': 20.777, 'epoch': 5.0, 'step': 495}, {'train_runtime': 211.7311, 'train_samples_per_second': 37.406, 'train_steps_per_second': 2.338, 'total_flos': 0.0, 'train_loss': 0.849150100862137, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.6566935181617737, 'eval_accuracy': 0.6515151515151515, 'eval_runtime': 2.4033, 'eval_samples_per_second': 164.773, 'eval_steps_per_second': 20.805, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 06:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.881500</td>\n",
       "      <td>0.697453</td>\n",
       "      <td>0.505051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.696200</td>\n",
       "      <td>0.608881</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.718807</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.657800</td>\n",
       "      <td>0.934953</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>1.040399</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.7188068628311157, 'eval_accuracy': 0.75, 'eval_runtime': 2.4192, 'eval_samples_per_second': 163.691, 'eval_steps_per_second': 20.668, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:55:38,038] Trial 80 finished with values: [0.7188068628311157, 0.75] and parameters: {'lr': 0.00011729822597402431, 'batch': 1, 'accum': 2, 'dropout_rate': 0.4258356729985485, 'weight_decay': 3.937879437736638e-05, 'warmup_pct': 0.2826997173226675}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8815, 'learning_rate': 4.151036415166544e-05, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.6974533796310425, 'eval_accuracy': 0.5050505050505051, 'eval_runtime': 2.4147, 'eval_samples_per_second': 163.997, 'eval_steps_per_second': 20.707, 'epoch': 1.0, 'step': 792}, {'loss': 0.6962, 'learning_rate': 8.302072830333088e-05, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6088811755180359, 'eval_accuracy': 0.6843434343434344, 'eval_runtime': 2.3862, 'eval_samples_per_second': 165.956, 'eval_steps_per_second': 20.954, 'epoch': 2.0, 'step': 1584}, {'loss': 0.631, 'learning_rate': 0.00010789801971129762, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.7188068628311157, 'eval_accuracy': 0.75, 'eval_runtime': 2.3849, 'eval_samples_per_second': 166.048, 'eval_steps_per_second': 20.966, 'epoch': 3.0, 'step': 2376}, {'loss': 0.6578, 'learning_rate': 5.394900985564881e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.9349528551101685, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.3856, 'eval_samples_per_second': 165.997, 'eval_steps_per_second': 20.959, 'epoch': 4.0, 'step': 3168}, {'loss': 0.517, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 1.0403989553451538, 'eval_accuracy': 0.75, 'eval_runtime': 2.4031, 'eval_samples_per_second': 164.785, 'eval_steps_per_second': 20.806, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 397.641, 'train_samples_per_second': 19.917, 'train_steps_per_second': 9.959, 'total_flos': 0.0, 'train_loss': 0.6767077590479995, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.7188068628311157, 'eval_accuracy': 0.75, 'eval_runtime': 2.4192, 'eval_samples_per_second': 163.691, 'eval_steps_per_second': 20.668, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 01:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.894500</td>\n",
       "      <td>0.604016</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.554838</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.630300</td>\n",
       "      <td>0.548573</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.567900</td>\n",
       "      <td>0.547377</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.559454</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5594543814659119, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3882, 'eval_samples_per_second': 165.815, 'eval_steps_per_second': 20.936, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 12:57:39,333] Trial 81 finished with values: [0.5594543814659119, 0.7626262626262627] and parameters: {'lr': 0.0026672988265693475, 'batch': 8, 'accum': 2, 'dropout_rate': 0.8733284354227296, 'weight_decay': 3.9315367129718254e-05, 'warmup_pct': 0.1518123966189644}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8945, 'learning_rate': 0.0017604172255357693, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.6040161848068237, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 2.4099, 'eval_samples_per_second': 164.325, 'eval_steps_per_second': 20.748, 'epoch': 1.0, 'step': 99}, {'loss': 0.7241, 'learning_rate': 0.0022961963811336124, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5548384785652161, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 2.3862, 'eval_samples_per_second': 165.953, 'eval_steps_per_second': 20.954, 'epoch': 2.0, 'step': 198}, {'loss': 0.6303, 'learning_rate': 0.0015307975874224082, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5485728979110718, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3873, 'eval_samples_per_second': 165.877, 'eval_steps_per_second': 20.944, 'epoch': 3.0, 'step': 297}, {'loss': 0.5679, 'learning_rate': 0.0007653987937112041, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5473769307136536, 'eval_accuracy': 0.75, 'eval_runtime': 2.3917, 'eval_samples_per_second': 165.575, 'eval_steps_per_second': 20.906, 'epoch': 4.0, 'step': 396}, {'loss': 0.4766, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5594543814659119, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3946, 'eval_samples_per_second': 165.375, 'eval_steps_per_second': 20.881, 'epoch': 5.0, 'step': 495}, {'train_runtime': 108.2889, 'train_samples_per_second': 73.138, 'train_steps_per_second': 4.571, 'total_flos': 0.0, 'train_loss': 0.6586956139766809, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5594543814659119, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 2.3882, 'eval_samples_per_second': 165.815, 'eval_steps_per_second': 20.936, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 06:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.717040</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>0.623413</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.612900</td>\n",
       "      <td>0.657132</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.615400</td>\n",
       "      <td>0.836060</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.591500</td>\n",
       "      <td>0.902455</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9024547338485718, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.3881, 'eval_samples_per_second': 165.82, 'eval_steps_per_second': 20.937, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:04:19,144] Trial 82 finished with values: [0.9024547338485718, 0.7297979797979798] and parameters: {'lr': 7.658771591659248e-05, 'batch': 1, 'accum': 2, 'dropout_rate': 0.4258356729985485, 'weight_decay': 0.000425063071863535, 'warmup_pct': 0.2542436182993035}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.899, 'learning_rate': 3.0132871836036384e-05, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.7170403003692627, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.4305, 'eval_samples_per_second': 162.928, 'eval_steps_per_second': 20.572, 'epoch': 1.0, 'step': 792}, {'loss': 0.734, 'learning_rate': 6.026574367207277e-05, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6234132647514343, 'eval_accuracy': 0.6590909090909091, 'eval_runtime': 2.3882, 'eval_samples_per_second': 165.814, 'eval_steps_per_second': 20.936, 'epoch': 2.0, 'step': 1584}, {'loss': 0.6129, 'learning_rate': 6.230865023722778e-05, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.6571318507194519, 'eval_accuracy': 0.7146464646464646, 'eval_runtime': 2.3939, 'eval_samples_per_second': 165.422, 'eval_steps_per_second': 20.887, 'epoch': 3.0, 'step': 2376}, {'loss': 0.6154, 'learning_rate': 3.115432511861389e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.8360595107078552, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 2.3857, 'eval_samples_per_second': 165.991, 'eval_steps_per_second': 20.959, 'epoch': 4.0, 'step': 3168}, {'loss': 0.5915, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.9024547338485718, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.3879, 'eval_samples_per_second': 165.835, 'eval_steps_per_second': 20.939, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 386.8444, 'train_samples_per_second': 20.473, 'train_steps_per_second': 10.237, 'total_flos': 0.0, 'train_loss': 0.6905713707509668, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.9024547338485718, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.3881, 'eval_samples_per_second': 165.82, 'eval_steps_per_second': 20.937, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 01:42, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.856700</td>\n",
       "      <td>0.665525</td>\n",
       "      <td>0.628788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.621000</td>\n",
       "      <td>0.544578</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.612300</td>\n",
       "      <td>0.652993</td>\n",
       "      <td>0.646465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.751259</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5317743420600891, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.4144, 'eval_samples_per_second': 164.013, 'eval_steps_per_second': 20.709, 'epoch': 4.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:06:15,717] Trial 83 finished with values: [0.5317743420600891, 0.7525252525252525] and parameters: {'lr': 0.0031768567832676656, 'batch': 8, 'accum': 8, 'dropout_rate': 0.41050804616493186, 'weight_decay': 1.929220868189138e-05, 'warmup_pct': 0.16858374448371116}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8567, 'learning_rate': 0.00045930459517122877, 'epoch': 0.97, 'step': 24}, {'eval_loss': 0.6655254364013672, 'eval_accuracy': 0.6287878787878788, 'eval_runtime': 2.4098, 'eval_samples_per_second': 164.332, 'eval_steps_per_second': 20.749, 'epoch': 0.97, 'step': 24}, {'loss': 0.621, 'learning_rate': 0.0009377468818079254, 'epoch': 1.98, 'step': 49}, {'eval_loss': 0.5445778965950012, 'eval_accuracy': 0.75, 'eval_runtime': 2.3859, 'eval_samples_per_second': 165.975, 'eval_steps_per_second': 20.956, 'epoch': 1.98, 'step': 49}, {'loss': 0.6123, 'learning_rate': 0.001416189168444622, 'epoch': 2.99, 'step': 74}, {'eval_loss': 0.6529932022094727, 'eval_accuracy': 0.6464646464646465, 'eval_runtime': 2.3869, 'eval_samples_per_second': 165.907, 'eval_steps_per_second': 20.948, 'epoch': 2.99, 'step': 74}, {'loss': 0.4842, 'learning_rate': 0.0018946314550813185, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.5317743420600891, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3827, 'eval_samples_per_second': 166.199, 'eval_steps_per_second': 20.985, 'epoch': 4.0, 'step': 99}, {'loss': 0.463, 'learning_rate': 0.0022965229758561438, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.7512587904930115, 'eval_accuracy': 0.6868686868686869, 'eval_runtime': 2.3809, 'eval_samples_per_second': 166.322, 'eval_steps_per_second': 21.0, 'epoch': 4.85, 'step': 120}, {'train_runtime': 103.2402, 'train_samples_per_second': 76.714, 'train_steps_per_second': 1.162, 'total_flos': 0.0, 'train_loss': 0.6101959705352783, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.5317743420600891, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.4144, 'eval_samples_per_second': 164.013, 'eval_steps_per_second': 20.709, 'epoch': 4.85, 'step': 120}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.103300</td>\n",
       "      <td>0.716314</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.744600</td>\n",
       "      <td>0.622599</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.607900</td>\n",
       "      <td>0.560146</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.537900</td>\n",
       "      <td>0.581937</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.595073</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5950727462768555, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3848, 'eval_samples_per_second': 166.049, 'eval_steps_per_second': 20.966, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:12:49,474] Trial 84 finished with values: [0.5950727462768555, 0.7474747474747475] and parameters: {'lr': 0.00020346991265926905, 'batch': 1, 'accum': 4, 'dropout_rate': 0.8024822715089562, 'weight_decay': 6.623901780297333e-05, 'warmup_pct': 0.1357739304622294}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1033, 'learning_rate': 7.495263759355399e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.7163143157958984, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.4187, 'eval_samples_per_second': 163.725, 'eval_steps_per_second': 20.672, 'epoch': 1.0, 'step': 396}, {'loss': 0.7446, 'learning_rate': 0.00014990527518710797, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.6225994825363159, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.389, 'eval_samples_per_second': 165.757, 'eval_steps_per_second': 20.929, 'epoch': 2.0, 'step': 792}, {'loss': 0.6079, 'learning_rate': 0.000178064277155957, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.5601456761360168, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3923, 'eval_samples_per_second': 165.534, 'eval_steps_per_second': 20.901, 'epoch': 3.0, 'step': 1188}, {'loss': 0.5379, 'learning_rate': 8.90321385779785e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.5819365382194519, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3823, 'eval_samples_per_second': 166.225, 'eval_steps_per_second': 20.988, 'epoch': 4.0, 'step': 1584}, {'loss': 0.4986, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5950727462768555, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3816, 'eval_samples_per_second': 166.272, 'eval_steps_per_second': 20.994, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 378.9144, 'train_samples_per_second': 20.902, 'train_steps_per_second': 5.225, 'total_flos': 0.0, 'train_loss': 0.6984569819286616, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.5950727462768555, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3848, 'eval_samples_per_second': 166.049, 'eval_steps_per_second': 20.966, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 03:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.940500</td>\n",
       "      <td>0.804315</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.858200</td>\n",
       "      <td>0.721058</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.758200</td>\n",
       "      <td>0.684082</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.721000</td>\n",
       "      <td>0.661567</td>\n",
       "      <td>0.661616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.635088</td>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6350882053375244, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.392, 'eval_samples_per_second': 165.555, 'eval_steps_per_second': 20.903, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:16:27,061] Trial 85 finished with values: [0.6350882053375244, 0.6717171717171717] and parameters: {'lr': 3.80544899085794e-05, 'batch': 2, 'accum': 4, 'dropout_rate': 0.3751279886367357, 'weight_decay': 0.0006003361529211938, 'warmup_pct': 0.2512517467249306}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9405, 'learning_rate': 7.580270625652637e-06, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.8043151497840881, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.41, 'eval_samples_per_second': 164.313, 'eval_steps_per_second': 20.747, 'epoch': 1.0, 'step': 198}, {'loss': 0.8582, 'learning_rate': 1.5160541251305274e-05, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.7210575938224792, 'eval_accuracy': 0.5, 'eval_runtime': 2.3862, 'eval_samples_per_second': 165.956, 'eval_steps_per_second': 20.954, 'epoch': 2.0, 'step': 396}, {'loss': 0.7582, 'learning_rate': 2.2740811876957914e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6840822696685791, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 2.4, 'eval_samples_per_second': 165.002, 'eval_steps_per_second': 20.834, 'epoch': 3.0, 'step': 594}, {'loss': 0.721, 'learning_rate': 3.0321082502610548e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.661567211151123, 'eval_accuracy': 0.6616161616161617, 'eval_runtime': 2.3847, 'eval_samples_per_second': 166.058, 'eval_steps_per_second': 20.967, 'epoch': 4.0, 'step': 792}, {'loss': 0.668, 'learning_rate': 3.7901353128263185e-05, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6350882053375244, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.3866, 'eval_samples_per_second': 165.926, 'eval_steps_per_second': 20.95, 'epoch': 5.0, 'step': 990}, {'train_runtime': 204.0995, 'train_samples_per_second': 38.805, 'train_steps_per_second': 4.851, 'total_flos': 0.0, 'train_loss': 0.7891851714163115, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6350882053375244, 'eval_accuracy': 0.6717171717171717, 'eval_runtime': 2.392, 'eval_samples_per_second': 165.555, 'eval_steps_per_second': 20.903, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 01:42, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.884900</td>\n",
       "      <td>0.686972</td>\n",
       "      <td>0.563131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.583002</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.534900</td>\n",
       "      <td>0.559788</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>0.583972</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5570338368415833, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3885, 'eval_samples_per_second': 165.795, 'eval_steps_per_second': 20.934, 'epoch': 4.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:18:23,097] Trial 86 finished with values: [0.5570338368415833, 0.7525252525252525] and parameters: {'lr': 0.002365442206851229, 'batch': 8, 'accum': 8, 'dropout_rate': 0.43640771283730995, 'weight_decay': 2.395969539853002e-05, 'warmup_pct': 0.1747023296052651}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8849, 'learning_rate': 0.0003300617032815668, 'epoch': 0.97, 'step': 24}, {'eval_loss': 0.6869724988937378, 'eval_accuracy': 0.5631313131313131, 'eval_runtime': 2.4155, 'eval_samples_per_second': 163.941, 'eval_steps_per_second': 20.7, 'epoch': 0.97, 'step': 24}, {'loss': 0.655, 'learning_rate': 0.000673875977533199, 'epoch': 1.98, 'step': 49}, {'eval_loss': 0.5830024480819702, 'eval_accuracy': 0.7171717171717171, 'eval_runtime': 2.386, 'eval_samples_per_second': 165.97, 'eval_steps_per_second': 20.956, 'epoch': 1.98, 'step': 49}, {'loss': 0.5349, 'learning_rate': 0.001017690251784831, 'epoch': 2.99, 'step': 74}, {'eval_loss': 0.5597878098487854, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3892, 'eval_samples_per_second': 165.745, 'eval_steps_per_second': 20.927, 'epoch': 2.99, 'step': 74}, {'loss': 0.4523, 'learning_rate': 0.0013615045260364632, 'epoch': 4.0, 'step': 99}, {'eval_loss': 0.5570338368415833, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3894, 'eval_samples_per_second': 165.733, 'eval_steps_per_second': 20.926, 'epoch': 4.0, 'step': 99}, {'loss': 0.3699, 'learning_rate': 0.0016503085164078343, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.5839719176292419, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.3861, 'eval_samples_per_second': 165.963, 'eval_steps_per_second': 20.955, 'epoch': 4.85, 'step': 120}, {'train_runtime': 103.1351, 'train_samples_per_second': 76.792, 'train_steps_per_second': 1.164, 'total_flos': 0.0, 'train_loss': 0.5838346083958944, 'epoch': 4.85, 'step': 120}, {'eval_loss': 0.5570338368415833, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3885, 'eval_samples_per_second': 165.795, 'eval_steps_per_second': 20.934, 'epoch': 4.85, 'step': 120}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 03:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.888400</td>\n",
       "      <td>0.585190</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.703700</td>\n",
       "      <td>0.555389</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.566800</td>\n",
       "      <td>0.546476</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.513300</td>\n",
       "      <td>0.552242</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.420300</td>\n",
       "      <td>0.531237</td>\n",
       "      <td>0.785354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5312367677688599, 'eval_accuracy': 0.7853535353535354, 'eval_runtime': 2.3821, 'eval_samples_per_second': 166.237, 'eval_steps_per_second': 20.99, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:21:59,624] Trial 87 finished with values: [0.5312367677688599, 0.7853535353535354] and parameters: {'lr': 0.0026672988265693475, 'batch': 2, 'accum': 8, 'dropout_rate': 0.8733284354227296, 'weight_decay': 3.9315367129718254e-05, 'warmup_pct': 0.02183159453601221}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8884, 'learning_rate': 0.0025825191572651876, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5851897597312927, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 2.4091, 'eval_samples_per_second': 164.374, 'eval_steps_per_second': 20.754, 'epoch': 1.0, 'step': 99}, {'loss': 0.7037, 'learning_rate': 0.0019368893679488903, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5553891062736511, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3843, 'eval_samples_per_second': 166.088, 'eval_steps_per_second': 20.971, 'epoch': 2.0, 'step': 198}, {'loss': 0.5668, 'learning_rate': 0.0012912595786325938, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5464757084846497, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3845, 'eval_samples_per_second': 166.07, 'eval_steps_per_second': 20.968, 'epoch': 3.0, 'step': 297}, {'loss': 0.5133, 'learning_rate': 0.0006456297893162969, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5522419810295105, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.3832, 'eval_samples_per_second': 166.165, 'eval_steps_per_second': 20.98, 'epoch': 4.0, 'step': 396}, {'loss': 0.4203, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5312367677688599, 'eval_accuracy': 0.7853535353535354, 'eval_runtime': 2.386, 'eval_samples_per_second': 165.966, 'eval_steps_per_second': 20.955, 'epoch': 5.0, 'step': 495}, {'train_runtime': 203.6968, 'train_samples_per_second': 38.881, 'train_steps_per_second': 2.43, 'total_flos': 0.0, 'train_loss': 0.6184854141389481, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5312367677688599, 'eval_accuracy': 0.7853535353535354, 'eval_runtime': 2.3821, 'eval_samples_per_second': 166.237, 'eval_steps_per_second': 20.99, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 06:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.821448</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.752421</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>0.702203</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.785200</td>\n",
       "      <td>0.681352</td>\n",
       "      <td>0.565657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.729700</td>\n",
       "      <td>0.663298</td>\n",
       "      <td>0.633838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6632978916168213, 'eval_accuracy': 0.6338383838383839, 'eval_runtime': 2.3986, 'eval_samples_per_second': 165.098, 'eval_steps_per_second': 20.846, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:28:25,380] Trial 88 finished with values: [0.6632978916168213, 0.6338383838383839] and parameters: {'lr': 3.599124408357784e-05, 'batch': 1, 'accum': 8, 'dropout_rate': 0.4914183485282615, 'weight_decay': 1.776351643505484e-05, 'warmup_pct': 0.165492291809389}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.9875, 'learning_rate': 5.439897960723979e-06, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.8214476704597473, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4175, 'eval_samples_per_second': 163.803, 'eval_steps_per_second': 20.682, 'epoch': 1.0, 'step': 198}, {'loss': 0.927, 'learning_rate': 1.0879795921447958e-05, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.7524209022521973, 'eval_accuracy': 0.5, 'eval_runtime': 2.3851, 'eval_samples_per_second': 166.033, 'eval_steps_per_second': 20.964, 'epoch': 2.0, 'step': 396}, {'loss': 0.8325, 'learning_rate': 1.6319693882171936e-05, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.7022033333778381, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.3884, 'eval_samples_per_second': 165.803, 'eval_steps_per_second': 20.935, 'epoch': 3.0, 'step': 594}, {'loss': 0.7852, 'learning_rate': 2.1759591842895916e-05, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.6813516616821289, 'eval_accuracy': 0.5656565656565656, 'eval_runtime': 2.3881, 'eval_samples_per_second': 165.825, 'eval_steps_per_second': 20.938, 'epoch': 4.0, 'step': 792}, {'loss': 0.7297, 'learning_rate': 2.7199489803619896e-05, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6632978916168213, 'eval_accuracy': 0.6338383838383839, 'eval_runtime': 2.3864, 'eval_samples_per_second': 165.94, 'eval_steps_per_second': 20.952, 'epoch': 5.0, 'step': 990}, {'train_runtime': 372.8023, 'train_samples_per_second': 21.245, 'train_steps_per_second': 2.656, 'total_flos': 0.0, 'train_loss': 0.8523904203164457, 'epoch': 5.0, 'step': 990}, {'eval_loss': 0.6632978916168213, 'eval_accuracy': 0.6338383838383839, 'eval_runtime': 2.3986, 'eval_samples_per_second': 165.098, 'eval_steps_per_second': 20.846, 'epoch': 5.0, 'step': 990}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 06:46, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.178100</td>\n",
       "      <td>0.707464</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.763300</td>\n",
       "      <td>0.632484</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.659800</td>\n",
       "      <td>0.607462</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.610900</td>\n",
       "      <td>0.604041</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.609400</td>\n",
       "      <td>0.602451</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6024513840675354, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.3952, 'eval_samples_per_second': 165.333, 'eval_steps_per_second': 20.875, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:35:25,303] Trial 89 finished with values: [0.6024513840675354, 0.7095959595959596] and parameters: {'lr': 7.658771591659248e-05, 'batch': 1, 'accum': 2, 'dropout_rate': 0.8504336918837415, 'weight_decay': 9.32396849985729e-05, 'warmup_pct': 0.10938556977378296}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1781, 'learning_rate': 7.004326905997834e-05, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.7074642181396484, 'eval_accuracy': 0.5, 'eval_runtime': 2.4064, 'eval_samples_per_second': 164.563, 'eval_steps_per_second': 20.778, 'epoch': 1.0, 'step': 792}, {'loss': 0.7633, 'learning_rate': 5.881461312793269e-05, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6324842572212219, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 2.3786, 'eval_samples_per_second': 166.485, 'eval_steps_per_second': 21.021, 'epoch': 2.0, 'step': 1584}, {'loss': 0.6598, 'learning_rate': 3.920974208528845e-05, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.6074618697166443, 'eval_accuracy': 0.6893939393939394, 'eval_runtime': 2.397, 'eval_samples_per_second': 165.203, 'eval_steps_per_second': 20.859, 'epoch': 3.0, 'step': 2376}, {'loss': 0.6109, 'learning_rate': 1.9604871042644226e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.6040414571762085, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.413, 'eval_samples_per_second': 164.111, 'eval_steps_per_second': 20.721, 'epoch': 4.0, 'step': 3168}, {'loss': 0.6094, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.6024513840675354, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.3847, 'eval_samples_per_second': 166.058, 'eval_steps_per_second': 20.967, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 406.9529, 'train_samples_per_second': 19.462, 'train_steps_per_second': 9.731, 'total_flos': 0.0, 'train_loss': 0.7642861183243569, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.6024513840675354, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.3952, 'eval_samples_per_second': 165.333, 'eval_steps_per_second': 20.875, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 01:45, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.664769</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.589400</td>\n",
       "      <td>0.576980</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.523500</td>\n",
       "      <td>0.563235</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5632351040840149, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3852, 'eval_samples_per_second': 166.027, 'eval_steps_per_second': 20.963, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:37:24,036] Trial 90 finished with values: [0.5632351040840149, 0.7474747474747475] and parameters: {'lr': 0.00019117103709685623, 'batch': 8, 'accum': 4, 'dropout_rate': 0.3751279886367357, 'weight_decay': 0.00038674227562305154, 'warmup_pct': 0.03832529177795859}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.822, 'learning_rate': 0.00018014193880280682, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.6647688746452332, 'eval_accuracy': 0.6363636363636364, 'eval_runtime': 2.413, 'eval_samples_per_second': 164.112, 'eval_steps_per_second': 20.721, 'epoch': 0.99, 'step': 49}, {'loss': 0.6541, 'learning_rate': 0.000134187362577601, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.6129583120346069, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.3878, 'eval_samples_per_second': 165.844, 'eval_steps_per_second': 20.94, 'epoch': 2.0, 'step': 99}, {'loss': 0.5894, 'learning_rate': 8.91518778768993e-05, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.5769804120063782, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 2.3886, 'eval_samples_per_second': 165.79, 'eval_steps_per_second': 20.933, 'epoch': 2.99, 'step': 148}, {'loss': 0.5378, 'learning_rate': 4.319730165169348e-05, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5652543306350708, 'eval_accuracy': 0.75, 'eval_runtime': 2.3883, 'eval_samples_per_second': 165.808, 'eval_steps_per_second': 20.935, 'epoch': 4.0, 'step': 198}, {'loss': 0.5235, 'learning_rate': 0.0, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5632351040840149, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3859, 'eval_samples_per_second': 165.978, 'eval_steps_per_second': 20.957, 'epoch': 4.95, 'step': 245}, {'train_runtime': 105.8545, 'train_samples_per_second': 74.82, 'train_steps_per_second': 2.314, 'total_flos': 0.0, 'train_loss': 0.6259386646504305, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5632351040840149, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 2.3852, 'eval_samples_per_second': 166.027, 'eval_steps_per_second': 20.963, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 02:12, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.769500</td>\n",
       "      <td>0.636519</td>\n",
       "      <td>0.631313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.482300</td>\n",
       "      <td>0.590774</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.398900</td>\n",
       "      <td>0.589137</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 4.94949494949495: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.94949494949495: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.517328143119812, 'eval_accuracy': 0.7803030303030303, 'eval_runtime': 2.3952, 'eval_samples_per_second': 165.332, 'eval_steps_per_second': 20.875, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:39:49,935] Trial 91 finished with values: [0.517328143119812, 0.7803030303030303] and parameters: {'lr': 0.0029363178896559855, 'batch': 4, 'accum': 8, 'dropout_rate': 0.2598202682685361, 'weight_decay': 1.2229560673027971e-05, 'warmup_pct': 0.16819141556956405}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7695, 'learning_rate': 0.00043207080058000984, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.6365190148353577, 'eval_accuracy': 0.6313131313131313, 'eval_runtime': 2.4125, 'eval_samples_per_second': 164.146, 'eval_steps_per_second': 20.726, 'epoch': 0.99, 'step': 49}, {'loss': 0.556, 'learning_rate': 0.0008729593726004281, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.517328143119812, 'eval_accuracy': 0.7803030303030303, 'eval_runtime': 2.3889, 'eval_samples_per_second': 165.769, 'eval_steps_per_second': 20.93, 'epoch': 2.0, 'step': 99}, {'loss': 0.4823, 'learning_rate': 0.0013050301731804379, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.5907742381095886, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3909, 'eval_samples_per_second': 165.629, 'eval_steps_per_second': 20.913, 'epoch': 2.99, 'step': 148}, {'loss': 0.4932, 'learning_rate': 0.0017459187452008563, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.5555099844932556, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 2.3907, 'eval_samples_per_second': 165.643, 'eval_steps_per_second': 20.915, 'epoch': 4.0, 'step': 198}, {'loss': 0.3989, 'learning_rate': 0.0021603540029000493, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5891373157501221, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 2.3996, 'eval_samples_per_second': 165.03, 'eval_steps_per_second': 20.837, 'epoch': 4.95, 'step': 245}, {'train_runtime': 133.0958, 'train_samples_per_second': 59.506, 'train_steps_per_second': 1.841, 'total_flos': 0.0, 'train_loss': 0.5410207631636639, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.517328143119812, 'eval_accuracy': 0.7803030303030303, 'eval_runtime': 2.3952, 'eval_samples_per_second': 165.332, 'eval_steps_per_second': 20.875, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 01:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.687800</td>\n",
       "      <td>0.537106</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.525200</td>\n",
       "      <td>0.514591</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.514900</td>\n",
       "      <td>0.522601</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>0.533750</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.246800</td>\n",
       "      <td>0.721420</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.51459139585495, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.4055, 'eval_samples_per_second': 164.619, 'eval_steps_per_second': 20.785, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:41:51,096] Trial 92 finished with values: [0.51459139585495, 0.76010101010101] and parameters: {'lr': 0.002365442206851229, 'batch': 8, 'accum': 2, 'dropout_rate': 0.13946774290845135, 'weight_decay': 2.395969539853002e-05, 'warmup_pct': 0.2978091638164422}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6878, 'learning_rate': 0.0007965264574090873, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.5371056795120239, 'eval_accuracy': 0.75, 'eval_runtime': 2.4099, 'eval_samples_per_second': 164.325, 'eval_steps_per_second': 20.748, 'epoch': 1.0, 'step': 99}, {'loss': 0.5252, 'learning_rate': 0.0015930529148181745, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.51459139585495, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.3866, 'eval_samples_per_second': 165.929, 'eval_steps_per_second': 20.951, 'epoch': 2.0, 'step': 198}, {'loss': 0.5149, 'learning_rate': 0.0023301370992862853, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5226012468338013, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3952, 'eval_samples_per_second': 165.331, 'eval_steps_per_second': 20.875, 'epoch': 3.0, 'step': 297}, {'loss': 0.4444, 'learning_rate': 0.0011650685496431426, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5337502956390381, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3982, 'eval_samples_per_second': 165.122, 'eval_steps_per_second': 20.849, 'epoch': 4.0, 'step': 396}, {'loss': 0.2468, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.7214198112487793, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3874, 'eval_samples_per_second': 165.869, 'eval_steps_per_second': 20.943, 'epoch': 5.0, 'step': 495}, {'train_runtime': 108.2997, 'train_samples_per_second': 73.13, 'train_steps_per_second': 4.571, 'total_flos': 0.0, 'train_loss': 0.48382805718315974, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.51459139585495, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 2.4055, 'eval_samples_per_second': 164.619, 'eval_steps_per_second': 20.785, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 02:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.751000</td>\n",
       "      <td>0.570764</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.593600</td>\n",
       "      <td>0.526309</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.658700</td>\n",
       "      <td>1.869029</td>\n",
       "      <td>0.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.807400</td>\n",
       "      <td>0.613751</td>\n",
       "      <td>0.641414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>0.610873</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5263094305992126, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.4111, 'eval_samples_per_second': 164.24, 'eval_steps_per_second': 20.737, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:44:19,629] Trial 93 finished with values: [0.5263094305992126, 0.7525252525252525] and parameters: {'lr': 0.005896224699086761, 'batch': 4, 'accum': 4, 'dropout_rate': 0.5954855633405799, 'weight_decay': 1.287953295719676e-05, 'warmup_pct': 0.23074007626616083}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.751, 'learning_rate': 0.00128010141493331, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.570763885974884, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 2.4125, 'eval_samples_per_second': 164.144, 'eval_steps_per_second': 20.725, 'epoch': 1.0, 'step': 99}, {'loss': 0.5936, 'learning_rate': 0.00256020282986662, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.5263094305992126, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3813, 'eval_samples_per_second': 166.293, 'eval_steps_per_second': 20.997, 'epoch': 2.0, 'step': 198}, {'loss': 0.6587, 'learning_rate': 0.0038403042447999296, 'epoch': 3.0, 'step': 297}, {'eval_loss': 1.86902916431427, 'eval_accuracy': 0.494949494949495, 'eval_runtime': 2.3873, 'eval_samples_per_second': 165.881, 'eval_steps_per_second': 20.945, 'epoch': 3.0, 'step': 297}, {'loss': 0.8074, 'learning_rate': 0.00512040565973324, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6137506365776062, 'eval_accuracy': 0.6414141414141414, 'eval_runtime': 2.3856, 'eval_samples_per_second': 165.998, 'eval_steps_per_second': 20.959, 'epoch': 4.0, 'step': 396}, {'loss': 0.7363, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.610872745513916, 'eval_accuracy': 0.6590909090909091, 'eval_runtime': 2.3917, 'eval_samples_per_second': 165.575, 'eval_steps_per_second': 20.906, 'epoch': 5.0, 'step': 495}, {'train_runtime': 135.7495, 'train_samples_per_second': 58.343, 'train_steps_per_second': 3.646, 'total_flos': 0.0, 'train_loss': 0.7094039300475458, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5263094305992126, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.4111, 'eval_samples_per_second': 164.24, 'eval_steps_per_second': 20.737, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.303100</td>\n",
       "      <td>0.820102</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.138800</td>\n",
       "      <td>0.738983</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.677922</td>\n",
       "      <td>0.550505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.722800</td>\n",
       "      <td>0.643965</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.613566</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.613565981388092, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.39, 'eval_samples_per_second': 165.687, 'eval_steps_per_second': 20.92, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:50:54,792] Trial 94 finished with values: [0.613565981388092, 0.6994949494949495] and parameters: {'lr': 7.658771591659248e-05, 'batch': 1, 'accum': 4, 'dropout_rate': 0.8504336918837415, 'weight_decay': 0.00012767251690941857, 'warmup_pct': 0.2542436182993035}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.3031, 'learning_rate': 1.5066435918018192e-05, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.8201023936271667, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4219, 'eval_samples_per_second': 163.507, 'eval_steps_per_second': 20.645, 'epoch': 1.0, 'step': 396}, {'loss': 1.1388, 'learning_rate': 3.0132871836036384e-05, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.7389826774597168, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3918, 'eval_samples_per_second': 165.566, 'eval_steps_per_second': 20.905, 'epoch': 2.0, 'step': 792}, {'loss': 0.9075, 'learning_rate': 4.519930775405458e-05, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6779218912124634, 'eval_accuracy': 0.5505050505050505, 'eval_runtime': 2.3875, 'eval_samples_per_second': 165.863, 'eval_steps_per_second': 20.942, 'epoch': 3.0, 'step': 1188}, {'loss': 0.7228, 'learning_rate': 6.026574367207277e-05, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6439650058746338, 'eval_accuracy': 0.6767676767676768, 'eval_runtime': 2.3949, 'eval_samples_per_second': 165.354, 'eval_steps_per_second': 20.878, 'epoch': 4.0, 'step': 1584}, {'loss': 0.6638, 'learning_rate': 7.533217959009096e-05, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.613565981388092, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.3897, 'eval_samples_per_second': 165.711, 'eval_steps_per_second': 20.923, 'epoch': 5.0, 'step': 1980}, {'train_runtime': 382.2415, 'train_samples_per_second': 20.72, 'train_steps_per_second': 5.18, 'total_flos': 0.0, 'train_loss': 0.9471951108990293, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.613565981388092, 'eval_accuracy': 0.6994949494949495, 'eval_runtime': 2.39, 'eval_samples_per_second': 165.687, 'eval_steps_per_second': 20.92, 'epoch': 5.0, 'step': 1980}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 01:45, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.103000</td>\n",
       "      <td>0.793368</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.844500</td>\n",
       "      <td>0.669553</td>\n",
       "      <td>0.618687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.618100</td>\n",
       "      <td>0.588536</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5885359048843384, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.3899, 'eval_samples_per_second': 165.695, 'eval_steps_per_second': 20.921, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:52:53,607] Trial 95 finished with values: [0.5885359048843384, 0.7297979797979798] and parameters: {'lr': 0.0001553677171170621, 'batch': 8, 'accum': 4, 'dropout_rate': 0.6649420762960857, 'weight_decay': 0.0007356117866234412, 'warmup_pct': 0.2231134504954486}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.103, 'learning_rate': 3.460462790334565e-05, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.793368399143219, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4233, 'eval_samples_per_second': 163.412, 'eval_steps_per_second': 20.633, 'epoch': 0.99, 'step': 49}, {'loss': 0.9485, 'learning_rate': 6.991547270267796e-05, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.7008920311927795, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.3865, 'eval_samples_per_second': 165.932, 'eval_steps_per_second': 20.951, 'epoch': 2.0, 'step': 99}, {'loss': 0.8445, 'learning_rate': 0.0001045201006060236, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.6695532202720642, 'eval_accuracy': 0.6186868686868687, 'eval_runtime': 2.3873, 'eval_samples_per_second': 165.877, 'eval_steps_per_second': 20.944, 'epoch': 2.99, 'step': 148}, {'loss': 0.7135, 'learning_rate': 0.0001398309454053559, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.6309468746185303, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 2.392, 'eval_samples_per_second': 165.55, 'eval_steps_per_second': 20.903, 'epoch': 4.0, 'step': 198}, {'loss': 0.6181, 'learning_rate': 0.0, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5885359048843384, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.391, 'eval_samples_per_second': 165.621, 'eval_steps_per_second': 20.912, 'epoch': 4.95, 'step': 245}, {'train_runtime': 105.863, 'train_samples_per_second': 74.814, 'train_steps_per_second': 2.314, 'total_flos': 0.0, 'train_loss': 0.847239147886938, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.5885359048843384, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 2.3899, 'eval_samples_per_second': 165.695, 'eval_steps_per_second': 20.921, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 02:12, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.747800</td>\n",
       "      <td>0.640351</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.721200</td>\n",
       "      <td>0.722399</td>\n",
       "      <td>0.507576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.650500</td>\n",
       "      <td>0.643569</td>\n",
       "      <td>0.628788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6355234980583191, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 2.4026, 'eval_samples_per_second': 164.824, 'eval_steps_per_second': 20.811, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 13:55:19,530] Trial 96 finished with values: [0.6355234980583191, 0.6565656565656566] and parameters: {'lr': 0.0032104795402394613, 'batch': 4, 'accum': 8, 'dropout_rate': 0.444269514628686, 'weight_decay': 8.63707205968112e-05, 'warmup_pct': 0.013966979007142126}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7478, 'learning_rate': 0.002886486192141901, 'epoch': 0.99, 'step': 49}, {'eval_loss': 0.6403513550758362, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 2.4171, 'eval_samples_per_second': 163.831, 'eval_steps_per_second': 20.686, 'epoch': 0.99, 'step': 49}, {'loss': 0.9465, 'learning_rate': 0.002150137673738355, 'epoch': 2.0, 'step': 99}, {'eval_loss': 0.6938738822937012, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.3842, 'eval_samples_per_second': 166.094, 'eval_steps_per_second': 20.972, 'epoch': 2.0, 'step': 99}, {'loss': 0.7212, 'learning_rate': 0.0014285161257028796, 'epoch': 2.99, 'step': 148}, {'eval_loss': 0.7223994731903076, 'eval_accuracy': 0.5075757575757576, 'eval_runtime': 2.3884, 'eval_samples_per_second': 165.803, 'eval_steps_per_second': 20.935, 'epoch': 2.99, 'step': 148}, {'loss': 0.6797, 'learning_rate': 0.0006921676072993335, 'epoch': 4.0, 'step': 198}, {'eval_loss': 0.6355234980583191, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 2.3857, 'eval_samples_per_second': 165.988, 'eval_steps_per_second': 20.958, 'epoch': 4.0, 'step': 198}, {'loss': 0.6505, 'learning_rate': 0.0, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.6435688138008118, 'eval_accuracy': 0.6287878787878788, 'eval_runtime': 2.3878, 'eval_samples_per_second': 165.845, 'eval_steps_per_second': 20.94, 'epoch': 4.95, 'step': 245}, {'train_runtime': 133.0467, 'train_samples_per_second': 59.528, 'train_steps_per_second': 1.841, 'total_flos': 0.0, 'train_loss': 0.7504735129220145, 'epoch': 4.95, 'step': 245}, {'eval_loss': 0.6355234980583191, 'eval_accuracy': 0.6565656565656566, 'eval_runtime': 2.4026, 'eval_samples_per_second': 164.824, 'eval_steps_per_second': 20.811, 'epoch': 4.95, 'step': 245}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 06:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.784200</td>\n",
       "      <td>0.667446</td>\n",
       "      <td>0.623737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.649100</td>\n",
       "      <td>0.611455</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.620900</td>\n",
       "      <td>0.752090</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>0.909959</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.506700</td>\n",
       "      <td>1.011838</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9099588394165039, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.402, 'eval_samples_per_second': 164.863, 'eval_steps_per_second': 20.816, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 14:01:59,809] Trial 97 finished with values: [0.9099588394165039, 0.7525252525252525] and parameters: {'lr': 0.00010508616553926973, 'batch': 1, 'accum': 2, 'dropout_rate': 0.17332454412617376, 'weight_decay': 3.948957000697015e-05, 'warmup_pct': 0.27589559193148167}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7842, 'learning_rate': 3.809072911080166e-05, 'epoch': 1.0, 'step': 792}, {'eval_loss': 0.6674464344978333, 'eval_accuracy': 0.6237373737373737, 'eval_runtime': 2.4109, 'eval_samples_per_second': 164.255, 'eval_steps_per_second': 20.739, 'epoch': 1.0, 'step': 792}, {'loss': 0.6491, 'learning_rate': 7.618145822160332e-05, 'epoch': 2.0, 'step': 1584}, {'eval_loss': 0.6114546060562134, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.3844, 'eval_samples_per_second': 166.077, 'eval_steps_per_second': 20.969, 'epoch': 2.0, 'step': 1584}, {'loss': 0.6209, 'learning_rate': 9.377830209250888e-05, 'epoch': 3.0, 'step': 2376}, {'eval_loss': 0.7520896792411804, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 2.3812, 'eval_samples_per_second': 166.304, 'eval_steps_per_second': 20.998, 'epoch': 3.0, 'step': 2376}, {'loss': 0.6038, 'learning_rate': 4.688915104625444e-05, 'epoch': 4.0, 'step': 3168}, {'eval_loss': 0.9099588394165039, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.3832, 'eval_samples_per_second': 166.164, 'eval_steps_per_second': 20.98, 'epoch': 4.0, 'step': 3168}, {'loss': 0.5067, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 1.0118378400802612, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.85, 'eval_steps_per_second': 20.941, 'epoch': 5.0, 'step': 3960}, {'train_runtime': 387.3921, 'train_samples_per_second': 20.444, 'train_steps_per_second': 10.222, 'total_flos': 0.0, 'train_loss': 0.6329342081089212, 'epoch': 5.0, 'step': 3960}, {'eval_loss': 0.9099588394165039, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 2.402, 'eval_samples_per_second': 164.863, 'eval_steps_per_second': 20.816, 'epoch': 5.0, 'step': 3960}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 02:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.867900</td>\n",
       "      <td>0.745706</td>\n",
       "      <td>0.497475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.737400</td>\n",
       "      <td>0.678604</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.674200</td>\n",
       "      <td>0.645023</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.630700</td>\n",
       "      <td>0.607369</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.569800</td>\n",
       "      <td>0.577939</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5779391527175903, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.847, 'eval_steps_per_second': 20.94, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 14:04:28,398] Trial 98 finished with values: [0.5779391527175903, 0.7247474747474747] and parameters: {'lr': 0.00014284290340818136, 'batch': 4, 'accum': 4, 'dropout_rate': 0.2080290627140376, 'weight_decay': 1.0061476346999425e-05, 'warmup_pct': 0.29354509394905237}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.8679, 'learning_rate': 2.433984068401025e-05, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.7457062005996704, 'eval_accuracy': 0.49747474747474746, 'eval_runtime': 2.4168, 'eval_samples_per_second': 163.854, 'eval_steps_per_second': 20.689, 'epoch': 1.0, 'step': 99}, {'loss': 0.7374, 'learning_rate': 4.86796813680205e-05, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6786036491394043, 'eval_accuracy': 0.5909090909090909, 'eval_runtime': 2.3837, 'eval_samples_per_second': 166.131, 'eval_steps_per_second': 20.976, 'epoch': 2.0, 'step': 198}, {'loss': 0.6742, 'learning_rate': 7.301952205203076e-05, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.6450227499008179, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 2.3875, 'eval_samples_per_second': 165.86, 'eval_steps_per_second': 20.942, 'epoch': 3.0, 'step': 297}, {'loss': 0.6307, 'learning_rate': 9.7359362736041e-05, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.6073693037033081, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 2.3867, 'eval_samples_per_second': 165.921, 'eval_steps_per_second': 20.95, 'epoch': 4.0, 'step': 396}, {'loss': 0.5698, 'learning_rate': 0.00012169920342005126, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5779391527175903, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3886, 'eval_samples_per_second': 165.786, 'eval_steps_per_second': 20.933, 'epoch': 5.0, 'step': 495}, {'train_runtime': 135.7004, 'train_samples_per_second': 58.364, 'train_steps_per_second': 3.648, 'total_flos': 0.0, 'train_loss': 0.6960141653966422, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5779391527175903, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 2.3877, 'eval_samples_per_second': 165.847, 'eval_steps_per_second': 20.94, 'epoch': 5.0, 'step': 495}]\n",
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 03:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.150600</td>\n",
       "      <td>0.712496</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.825900</td>\n",
       "      <td>0.651871</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.627800</td>\n",
       "      <td>0.571132</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.559200</td>\n",
       "      <td>0.559837</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.506600</td>\n",
       "      <td>0.526643</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm_no_lora.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm_no_lora.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5266426801681519, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3902, 'eval_samples_per_second': 165.674, 'eval_steps_per_second': 20.918, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 14:08:02,922] Trial 99 finished with values: [0.5266426801681519, 0.7575757575757576] and parameters: {'lr': 0.0012567998518264842, 'batch': 2, 'accum': 8, 'dropout_rate': 0.7871000533947469, 'weight_decay': 6.274182292518844e-05, 'warmup_pct': 0.27746533877747237}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.1506, 'learning_rate': 0.00011331801942697808, 'epoch': 1.0, 'step': 99}, {'eval_loss': 0.7124963402748108, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 2.4108, 'eval_samples_per_second': 164.261, 'eval_steps_per_second': 20.74, 'epoch': 1.0, 'step': 99}, {'loss': 0.8259, 'learning_rate': 0.00022663603885395616, 'epoch': 2.0, 'step': 198}, {'eval_loss': 0.6518712043762207, 'eval_accuracy': 0.6792929292929293, 'eval_runtime': 2.3839, 'eval_samples_per_second': 166.114, 'eval_steps_per_second': 20.974, 'epoch': 2.0, 'step': 198}, {'loss': 0.6278, 'learning_rate': 0.0003399540582809343, 'epoch': 3.0, 'step': 297}, {'eval_loss': 0.5711320042610168, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 2.3882, 'eval_samples_per_second': 165.814, 'eval_steps_per_second': 20.936, 'epoch': 3.0, 'step': 297}, {'loss': 0.5592, 'learning_rate': 0.0004532720777079123, 'epoch': 4.0, 'step': 396}, {'eval_loss': 0.5598366856575012, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 2.3874, 'eval_samples_per_second': 165.868, 'eval_steps_per_second': 20.943, 'epoch': 4.0, 'step': 396}, {'loss': 0.5066, 'learning_rate': 0.0005665900971348905, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5266426801681519, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3874, 'eval_samples_per_second': 165.873, 'eval_steps_per_second': 20.944, 'epoch': 5.0, 'step': 495}, {'train_runtime': 201.6721, 'train_samples_per_second': 39.272, 'train_steps_per_second': 2.454, 'total_flos': 0.0, 'train_loss': 0.7340051978525489, 'epoch': 5.0, 'step': 495}, {'eval_loss': 0.5266426801681519, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 2.3902, 'eval_samples_per_second': 165.674, 'eval_steps_per_second': 20.918, 'epoch': 5.0, 'step': 495}]\n",
      "Loss: 0.5057934522628784, Accuracy: 0.7575757575757576\n",
      "Loss: 0.5067949891090393, Accuracy: 0.7626262626262627\n",
      "Loss: 0.5312367677688599, Accuracy: 0.7853535353535354\n",
      "Loss: 0.517328143119812, Accuracy: 0.7803030303030303\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to be optimized\n",
    "    # Updated to use suggest_float with log=True for loguniform distribution\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    batch = trial.suggest_categorical('batch', [1, 2, 4, 8])\n",
    "    accum = trial.suggest_categorical('accum', [2, 4, 8])\n",
    "    # Updated to use suggest_float for uniform distribution\n",
    "    dropout = trial.suggest_float('dropout_rate', 0.1, 0.9)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    warmup_pct = trial.suggest_float(\"warmup_pct\", 0.01, 0.3)  # Warmup percentage between 1% and 30%\n",
    "    # lora_rank = trial.suggest_int('lora_rank', 4, 32, step=4)\n",
    "    # lora_init_scale = trial.suggest_float('lora_init_scale', 1e-4, 1e-1, log=True)\n",
    "    # lora_scaling_rank = trial.suggest_int('lora_scaling_rank', 1, 4)\n",
    "\n",
    "\n",
    "    # Training and evaluation\n",
    "    tokenizer, model, history = train_per_protein(\n",
    "        train_dataset=train_set, \n",
    "        valid_dataset=valid_set, \n",
    "        num_labels=2, \n",
    "        batch=batch, \n",
    "        accum=accum, \n",
    "        epochs=5,  # Fewer epochs for the trial runs\n",
    "        lr=lr,\n",
    "        dropout=dropout,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_pct=warmup_pct,\n",
    "        lora_rank=4,\n",
    "        lora_init_scale=0.01,\n",
    "        lora_scaling_rank=1,\n",
    "    )\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    # torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"History: \", history)\n",
    "    \n",
    "    # Extract the last validation accuracy from the history\n",
    "    val_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry][-1]\n",
    "    val_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry][-1]\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "directions=['minimize', 'maximize']  # Set the direction to maximize the validation accuracy, can also be 'minimize'\n",
    "study = optuna.create_study(directions=directions,\n",
    "                            storage=\"sqlite:///all_dephos_noLORA_esm.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"all_dephos_noLORA_esm\")\n",
    "study.optimize(objective, n_trials=100)  # Adjust the number of trials based on your computational resources\n",
    "\n",
    "# Analyzing results\n",
    "pareto_front = study.best_trials  # Get the Pareto front (best non-dominated solutions)\n",
    "for trial in pareto_front:\n",
    "    print(f\"Loss: {trial.values[0]}, Accuracy: {trial.values[1]}\")  # Note the negation of accuracy\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# print(\"  Value: \", study.best_trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in study.best_trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a28d3c1-8e24-4437-a1d9-dda9cefccfd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:37.168731Z",
     "iopub.status.busy": "2024-04-05T14:04:37.168220Z",
     "iopub.status.idle": "2024-04-05T14:04:38.081706Z",
     "shell.execute_reply": "2024-04-05T14:04:38.080275Z",
     "shell.execute_reply.started": "2024-04-05T14:04:37.168675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Truncate the longer list to the size of the shorter one\n",
    "min_length = min(len(loss), len(val_loss))\n",
    "loss = loss[:min_length]\n",
    "val_loss = val_loss[:min_length]\n",
    "\n",
    "# Get spearman (for regression) or accuracy value (for classification)\n",
    "if [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x] != []:\n",
    "    metric = [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x]\n",
    "else:\n",
    "    metric = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n",
    "\n",
    "epochs = [x['epoch'] for x in history if 'loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "line1 = ax1.plot(epochs, loss, label='train_loss')\n",
    "line2 = ax1.plot(epochs, val_loss, label='validation_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "#line3 = ax2.plot(epochs, metric, color='red', label='validation_metric')\n",
    "ax2.set_ylabel('Metric')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Add grid lines\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 \n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History for fine-tuning\")\n",
    "plt.savefig(f\"../Plots/Without_3rdline_Training_History_new.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccb1bbda-d70e-4b4c-a8d4-24600495171a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:38.083526Z",
     "iopub.status.busy": "2024-04-05T14:04:38.083162Z",
     "iopub.status.idle": "2024-04-05T14:04:38.092729Z",
     "shell.execute_reply": "2024-04-05T14:04:38.091278Z",
     "shell.execute_reply.started": "2024-04-05T14:04:38.083490Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "# def load_model(filepath, num_labels=2):\n",
    "# # Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "#     # load a new model\n",
    "#     model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=0.4540649581660329, lora_rank=8, lora_init_scale=0.01054546478690803, lora_scaling_rank=3)\n",
    "    \n",
    "#     # Load the non-frozen parameters from the saved file\n",
    "#     non_frozen_params = torch.load(filepath)\n",
    "\n",
    "#     # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "#     for param_name, param in model.named_parameters():\n",
    "#         if param_name in non_frozen_params:\n",
    "#             param.data = non_frozen_params[param_name].data\n",
    "\n",
    "#     return tokenizer, model\n",
    "\n",
    "def load_model(filepath, num_labels=2):\n",
    "    # Creates a new ESM model and loads the finetuned weights from a file\n",
    "\n",
    "    # Load a new model\n",
    "    model, batch_converter = ESM_classification_model(num_labels=num_labels, dropout=0.4540649581660329, lora_rank=8, lora_init_scale=0.01054546478690803, lora_scaling_rank=3)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return model, batch_converter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98e915-c8a8-433a-870a-c6dcaf191e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:38.095733Z",
     "iopub.status.busy": "2024-04-05T14:04:38.095313Z",
     "iopub.status.idle": "2024-04-05T14:05:24.016922Z",
     "shell.execute_reply": "2024-04-05T14:05:24.014560Z",
     "shell.execute_reply.started": "2024-04-05T14:04:38.095698Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def save_model(model, filepath):\n",
    "#     torch.save(model.state_dict(), filepath)\n",
    "\n",
    "# save_model(model, \"../finetuned_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa9b15",
   "metadata": {},
   "source": [
    "lr 0.0007818596894056708\n",
    "\n",
    "batch 4\n",
    "\n",
    "accum 4\n",
    "\n",
    "dropout_rate 0.4540649581660329\n",
    "\n",
    "weight_decay 1.0585189745148587e-05\n",
    "\n",
    "warmup_pct 0.01886939819712101\n",
    "\n",
    "lora_rank 8\n",
    "\n",
    "lora_init_scale 0.01054546478690803\n",
    "\n",
    "lora_scaling_rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c97fa52-3aea-42e8-b72f-c4bb84808576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:05:24.020589Z",
     "iopub.status.busy": "2024-04-05T14:05:24.019788Z",
     "iopub.status.idle": "2024-04-05T14:08:10.428922Z",
     "shell.execute_reply": "2024-04-05T14:08:10.426805Z",
     "shell.execute_reply.started": "2024-04-05T14:05:24.020524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_Classfier\n",
      "Trainable Parameter: 652361657.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 179203.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "# tokenizer, model_reload = load_model(\"model_output/finetuned_model_all_bfd.pth\",num_labels=2)\n",
    "\n",
    "model_reload, batch_converter = load_model(\"model_output/finetuned_model_all_esm.pth\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2c20e75-5f40-4ca1-9579-5df49b738fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:10.432313Z",
     "iopub.status.busy": "2024-04-05T14:08:10.431835Z",
     "iopub.status.idle": "2024-04-05T14:08:19.838631Z",
     "shell.execute_reply": "2024-04-05T14:08:19.836988Z",
     "shell.execute_reply.started": "2024-04-05T14:08:10.432274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have identical weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a62aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = from_pretrained(\"model_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50b8a403-e7c5-4912-9c7a-f404c060c32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.841225Z",
     "iopub.status.busy": "2024-04-05T14:08:19.840752Z",
     "iopub.status.idle": "2024-04-05T14:08:19.864579Z",
     "shell.execute_reply": "2024-04-05T14:08:19.862993Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.841173Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WUI4|HDAC7_HUMAN%342%358</td>\n",
       "      <td>ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|Q13950|RUNX2_HUMAN%416%432</td>\n",
       "      <td>THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q15796|SMAD2_HUMAN%229%245</td>\n",
       "      <td>DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%416%432</td>\n",
       "      <td>TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2798%2814</td>\n",
       "      <td>MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0   sp|Q8WUI4|HDAC7_HUMAN%342%358  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
       "1   sp|Q13950|RUNX2_HUMAN%416%432  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
       "2   sp|Q15796|SMAD2_HUMAN%229%245  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
       "3    sp|P05787|K2C8_HUMAN%416%432  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2798%2814  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "    \n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_Y.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2d18716-fd26-49fe-9ba4-b84c936a364c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.867076Z",
     "iopub.status.busy": "2024-04-05T14:08:19.866598Z",
     "iopub.status.idle": "2024-04-05T14:08:19.887853Z",
     "shell.execute_reply": "2024-04-05T14:08:19.886215Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.867024Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sequence  label\n",
      "0  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
      "1  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
      "2  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
      "3  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
      "4  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1\n"
     ]
    }
   ],
   "source": [
    "my_test=df[[\"sequence\", \"label\"]]\n",
    "\n",
    "print(my_test.head(5))\n",
    "\n",
    "'''\n",
    "my_test[\"sequence\"]=my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "my_test['sequence']=my_test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "'''\n",
    "\n",
    "#Using .loc ensures that you are modifying the original DataFrame rather than a view of it, which helps avoid the SettingWithCopyWarning.\n",
    "# Replace characters in the \"sequence\" column\n",
    "my_test.loc[:, \"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Convert each sequence to a space-separated string\n",
    "my_test.loc[:, 'sequence'] = my_test.apply(lambda row: \" \".join(row[\"sequence\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eee8fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = sequence.split()\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "my_test['middle_char'] = my_test['sequence'].apply(get_middle_char)\n",
    "\n",
    "# Split the DataFrame\n",
    "my_test_S = my_test[my_test['middle_char'] == 'S'].drop(columns=['middle_char'])\n",
    "my_test_T = my_test[my_test['middle_char'] == 'T'].drop(columns=['middle_char'])\n",
    "my_test_Y = my_test[my_test['middle_char'] == 'Y'].drop(columns=['middle_char'])\n",
    "my_test_ST = my_test[my_test['middle_char'].isin(['S', 'T'])].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcd9ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0dff151-a667-4717-af18-401818bc4c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.889951Z",
     "iopub.status.busy": "2024-04-05T14:08:19.889601Z",
     "iopub.status.idle": "2024-04-05T14:08:22.641629Z",
     "shell.execute_reply": "2024-04-05T14:08:22.639919Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.889916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:00<00:00, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.599359 |      0.807692 |      0.791667 |        0.8 |  0.892628 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[21  5]\n",
      " [ 5 19]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "# from tabulate import tabulate\n",
    "\n",
    "# # Set the device to use\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# model_reload.to(device)\n",
    "\n",
    "# # create Dataset\n",
    "# test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# # make compatible with torch DataLoader\n",
    "# test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# # Create a dataloader for the test dataset\n",
    "# test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# # Put the model in evaluation mode\n",
    "# model_reload.eval()\n",
    "\n",
    "# # Make predictions on the test dataset\n",
    "# raw_logits = []\n",
    "# labels = []\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_dataloader):\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         # add batch results (logits) to predictions\n",
    "#         raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "#         labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# # Convert logits to predictions\n",
    "# raw_logits = np.array(raw_logits)\n",
    "# predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# # Calculate metrics\n",
    "# conf_matrix = confusion_matrix(labels, predictions)\n",
    "# tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# mcc = matthews_corrcoef(labels, predictions)\n",
    "# specificity = tn / (tn + fp)\n",
    "# sensitivity = tp / (tp + fn)\n",
    "# accuracy = accuracy_score(labels, predictions)\n",
    "# roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "# metrics_table = [\n",
    "#     [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "#     [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "# ]\n",
    "\n",
    "# print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "# print(conf_matrix)\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import esm\n",
    "\n",
    "# Ensure the device is set correctly\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# Function to create dataset for ESM model\n",
    "def create_dataset(sequences, labels, batch_converter):\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(list(zip(labels, sequences)))\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"input_ids\": batch_tokens.tolist(),\n",
    "        \"labels\": labels\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "# Assuming my_test is a DataFrame containing test sequences and labels\n",
    "# Replace uncommon AAs with \"X\"\n",
    "my_test[\"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Create test dataset\n",
    "test_set = create_dataset(list(my_test['sequence']), list(my_test['label']), batch_converter)\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        outputs = model_reload(input_ids)\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "        raw_logits.append(logits)\n",
    "        labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.concatenate(raw_logits, axis=0)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ce2f51a-887c-4684-82b9-22ea5fffd334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:22.647264Z",
     "iopub.status.busy": "2024-04-05T14:08:22.646121Z",
     "iopub.status.idle": "2024-04-05T14:08:23.557189Z",
     "shell.execute_reply": "2024-04-05T14:08:23.555594Z",
     "shell.execute_reply.started": "2024-04-05T14:08:22.647207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['0', '1']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"../Plots/Confusion_matrix_for_dephos_new.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07603226",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5e0d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 28/28 [00:02<00:00, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.547153 |      0.767857 |      0.779279 |   0.773543 |  0.850587 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[172  52]\n",
      " [ 49 173]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "# from tabulate import tabulate\n",
    "\n",
    "# # Set the device to use\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# model_reload.to(device)\n",
    "\n",
    "# # create Dataset\n",
    "# test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# # make compatible with torch DataLoader\n",
    "# test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# # Create a dataloader for the test dataset\n",
    "# test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# # Put the model in evaluation mode\n",
    "# model_reload.eval()\n",
    "\n",
    "# # Make predictions on the test dataset\n",
    "# raw_logits = []\n",
    "# labels = []\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_dataloader):\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         # add batch results (logits) to predictions\n",
    "#         raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "#         labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# # Convert logits to predictions\n",
    "# raw_logits = np.array(raw_logits)\n",
    "# predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# # Calculate metrics\n",
    "# conf_matrix = confusion_matrix(labels, predictions)\n",
    "# tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# mcc = matthews_corrcoef(labels, predictions)\n",
    "# specificity = tn / (tn + fp)\n",
    "# sensitivity = tp / (tp + fn)\n",
    "# accuracy = accuracy_score(labels, predictions)\n",
    "# roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "# metrics_table = [\n",
    "#     [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "#     [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "# ]\n",
    "\n",
    "# print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "# print(conf_matrix)\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import esm\n",
    "\n",
    "# Ensure the device is set correctly\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# Function to create dataset for ESM model\n",
    "def create_dataset(sequences, labels, batch_converter):\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(list(zip(labels, sequences)))\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"input_ids\": batch_tokens.tolist(),\n",
    "        \"labels\": labels\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "# Assuming my_test is a DataFrame containing test sequences and labels\n",
    "# Replace uncommon AAs with \"X\"\n",
    "my_test[\"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Create test dataset\n",
    "test_set = create_dataset(list(my_test['sequence']), list(my_test['label']), batch_converter)\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        outputs = model_reload(input_ids)\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "        raw_logits.append(logits)\n",
    "        labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.concatenate(raw_logits, axis=0)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5528dc-6e06-456d-920f-8f05055d0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, n_neighbors=5, min_dist=0.01, metric='euclidean'):\n",
    "    umap_model = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric\n",
    "    )\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    df = pd.DataFrame({\n",
    "        \"UMAP1\": embeddings[:, 0],\n",
    "        \"UMAP2\": embeddings[:, 1],\n",
    "        \"Label\": labels\n",
    "    })\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = sns.scatterplot(\n",
    "        x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9\n",
    "    )\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.legend(title='Label', bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_ST.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "    embeddings = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch = sequences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "            embeddings.extend(hidden_states[:, 0, :])\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(sequences) // batch_size + 1}\")\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7718f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = list(sequence)\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "valid_df = df\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "valid_df['middle_char'] = valid_df['sequence'].apply(get_middle_char)\n",
    "\n",
    "valid_df = valid_df[valid_df['middle_char'] == 'T'].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a162964f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sp|Q9GZM8|NDEL1_HUMAN%203%219</td>\n",
       "      <td>CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>sp|Q8N163|CCAR2_HUMAN%438%454</td>\n",
       "      <td>EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>sp|P10636-8|TAU_HUMAN%196%212</td>\n",
       "      <td>GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>sp|Q02241|KIF23_HUMAN%434%450</td>\n",
       "      <td>QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sp|Q04206|TF65_HUMAN%419%435</td>\n",
       "      <td>QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>sp|Q76N33|STALP_MOUSE%326%342</td>\n",
       "      <td>ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>sp|P49790|NU153_HUMAN%1098%1114</td>\n",
       "      <td>FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>sp|Q8NFC6|BD1L1_HUMAN%2789%2805</td>\n",
       "      <td>DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>sp|Q5T6F2|UBAP2_HUMAN%514%530</td>\n",
       "      <td>SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>sp|Q9H040|SPRTN_HUMAN%265%281</td>\n",
       "      <td>NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name                           sequence  label\n",
       "180    sp|Q9GZM8|NDEL1_HUMAN%203%219  CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI      1\n",
       "181    sp|Q8N163|CCAR2_HUMAN%438%454  EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA      1\n",
       "182    sp|P10636-8|TAU_HUMAN%196%212  GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV      1\n",
       "183    sp|Q02241|KIF23_HUMAN%434%450  QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE      1\n",
       "184     sp|Q04206|TF65_HUMAN%419%435  QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG      1\n",
       "..                               ...                                ...    ...\n",
       "441    sp|Q76N33|STALP_MOUSE%326%342  ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS      0\n",
       "442  sp|P49790|NU153_HUMAN%1098%1114  FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ      0\n",
       "443  sp|Q8NFC6|BD1L1_HUMAN%2789%2805  DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL      0\n",
       "444    sp|Q5T6F2|UBAP2_HUMAN%514%530  SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS      0\n",
       "445    sp|Q9H040|SPRTN_HUMAN%265%281  NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN      0\n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a44d9187-1ac5-4e36-89a0-8f827a7f0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 3559427.0\n",
      "\n",
      "Processed batch 1/3\n",
      "Processed batch 2/3\n",
      "Processed batch 3/3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_df = my_valid\n",
    "\n",
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_ST.pth\",num_labels=2)\n",
    "\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "valid_sequences = list(valid_df['sequence'])\n",
    "valid_embeddings = get_embeddings(model_reload, tokenizer, valid_sequences)\n",
    "\n",
    "umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "\n",
    "labels = list(valid_df['label'])\n",
    "\n",
    "plot_umap(umap_embeddings, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f029bcf-42ef-4476-b575-3c14adb71b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da0e6c-e921-493b-9304-8ba9aad07d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2319a5",
   "metadata": {},
   "source": [
    "This notebook will implement combining D + P dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bab9a05",
   "metadata": {},
   "source": [
    "The dataset is balance \n",
    "This is before \n",
    "Number of LABEL=1 entries: 991\n",
    "  S: 723\n",
    "  T: 167\n",
    "  Y: 101\n",
    "Number of LABEL=0 entries: 989\n",
    "  S: 722\n",
    "  T: 167\n",
    "  Y: 100\n",
    "\n",
    "  Now we add some more from phos dataset and it looks like this\n",
    "  Number of LABEL=1 entries: \n",
    "  S: 723\n",
    "  T: 723\n",
    "  Y: 723\n",
    "Number of LABEL=0 entries: \n",
    "  S: 722\n",
    "  T: 722\n",
    "  Y: 722\n",
    "  We do not sample any more S entries as it is already balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a377270-2995-4da1-a673-5369769a6279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install umap-learn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0148ff8f-80eb-4bbd-aac7-fe1f371da27a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.1.1+cu121\n",
      "Cuda version:  12.1\n",
      "Numpy version:  1.26.4\n",
      "Pandas version:  2.1.3\n",
      "Transformers version:  4.35.2\n",
      "Datasets version:  2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96bd9396-a81c-4d87-a722-0d2020627dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WWI1|LMO7_HUMAN%260%276</td>\n",
       "      <td>SCSSDITLRGGREGFESDTDSEFTFKMQDYNKD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|sp|Q07157|ZO1_HUMAN|Tight</td>\n",
       "      <td>RSKGKLKMVVQRDERATLLNVPDLSDSIHSANA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|P24928|RPB1_HUMAN%1775%1791</td>\n",
       "      <td>NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|sp|Q9Y2U8|MAN1_HUMAN|Inner</td>\n",
       "      <td>PHSWWGARRPAGPELQTPPGKDGAVEDEEGEGE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q14980|NUMA1_HUMAN%2061%2077</td>\n",
       "      <td>NSLLRRGASKKALSKASPNTRSGTRRSPRIATT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name                           sequence  label\n",
       "0     sp|Q8WWI1|LMO7_HUMAN%260%276  SCSSDITLRGGREGFESDTDSEFTFKMQDYNKD      1\n",
       "1     sp|sp|Q07157|ZO1_HUMAN|Tight  RSKGKLKMVVQRDERATLLNVPDLSDSIHSANA      1\n",
       "2   sp|P24928|RPB1_HUMAN%1775%1791  NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS      1\n",
       "3    sp|sp|Q9Y2U8|MAN1_HUMAN|Inner  PHSWWGARRPAGPELQTPPGKDGAVEDEEGEGE      1\n",
       "4  sp|Q14980|NUMA1_HUMAN%2061%2077  NSLLRRGASKKALSKASPNTRSGTRRSPRIATT      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/merged_output_D+P_balance_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/merged_output_D+P_balance_Y.fasta'\n",
    "\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76760f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "(3468, 2)\n",
      "\n",
      "Validation Set:\n",
      "(867, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "my_train, my_valid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "my_train=my_train[[\"sequence\", \"label\"]]\n",
    "my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the training set\n",
    "print(\"Training Set:\")\n",
    "print(my_train.shape)\n",
    "\n",
    "# Print the first 5 rows of the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a424877b-787c-44fe-bf87-33346ffd3be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifies an existing transformer and introduce the LoRA layers\n",
    "\n",
    "class LoRAConfig:\n",
    "    def __init__(self, lora_rank=8, lora_init_scale=0.01, lora_scaling_rank=2):\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_init_scale = lora_init_scale\n",
    "        self.lora_modules = \".*SelfAttention|.*EncDecAttention\"\n",
    "        self.lora_layers = \"q|k|v|o\"\n",
    "        self.trainable_param_names = \".*layer_norm.*|.*lora_[ab].*\"\n",
    "        self.lora_scaling_rank = lora_scaling_rank\n",
    "        # lora_modules and lora_layers are specified with regular expressions\n",
    "        # see https://www.w3schools.com/python/python_regex.asp for reference\n",
    "        \n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, scaling_rank, init_scale):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.rank = rank\n",
    "        self.scaling_rank = scaling_rank\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        if self.rank > 0:\n",
    "            self.lora_a = nn.Parameter(torch.randn(rank, linear_layer.in_features) * init_scale)\n",
    "            if init_scale < 0:\n",
    "                self.lora_b = nn.Parameter(torch.randn(linear_layer.out_features, rank) * init_scale)\n",
    "            else:\n",
    "                self.lora_b = nn.Parameter(torch.zeros(linear_layer.out_features, rank))\n",
    "        if self.scaling_rank:\n",
    "            self.multi_lora_a = nn.Parameter(\n",
    "                torch.ones(self.scaling_rank, linear_layer.in_features)\n",
    "                + torch.randn(self.scaling_rank, linear_layer.in_features) * init_scale\n",
    "            )\n",
    "            if init_scale < 0:\n",
    "                self.multi_lora_b = nn.Parameter(\n",
    "                    torch.ones(linear_layer.out_features, self.scaling_rank)\n",
    "                    + torch.randn(linear_layer.out_features, self.scaling_rank) * init_scale\n",
    "                )\n",
    "            else:\n",
    "                self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, self.scaling_rank))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.scaling_rank == 1 and self.rank == 0:\n",
    "            # parsimonious implementation for ia3 and lora scaling\n",
    "            if self.multi_lora_a.requires_grad:\n",
    "                hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n",
    "            else:\n",
    "                hidden = F.linear(input, self.weight, self.bias)\n",
    "            if self.multi_lora_b.requires_grad:\n",
    "                hidden = hidden * self.multi_lora_b.flatten()\n",
    "            return hidden\n",
    "        else:\n",
    "            # general implementation for lora (adding and scaling)\n",
    "            weight = self.weight\n",
    "            if self.scaling_rank:\n",
    "                weight = weight * torch.matmul(self.multi_lora_b, self.multi_lora_a) / self.scaling_rank\n",
    "            if self.rank:\n",
    "                weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n",
    "            return F.linear(input, weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, rank={}, scaling_rank={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.rank, self.scaling_rank\n",
    "        )\n",
    "\n",
    "\n",
    "def modify_with_lora(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.lora_modules, m_name):\n",
    "            for c_name, layer in dict(module.named_children()).items():\n",
    "                if re.fullmatch(config.lora_layers, c_name):\n",
    "                    assert isinstance(\n",
    "                        layer, nn.Linear\n",
    "                    ), f\"LoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        c_name,\n",
    "                        LoRALinear(layer, config.lora_rank, config.lora_scaling_rank, config.lora_init_scale),\n",
    "                    )\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e79b323-4677-4723-a5fd-a60dc13a3b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.7, num_labels=2):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class T5EncoderClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, class_config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "        \n",
    "        # Trainable emphasis factor\n",
    "        self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        seq_length = hidden_states.size(1)\n",
    "        middle_idx = seq_length // 2\n",
    "        middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "        # Apply trainable emphasis factor\n",
    "        emphasized_middle_embedding = middle_embedding * self.emphasis_factor\n",
    "\n",
    "        # Combine with the average embedding\n",
    "        average_embedding = torch.mean(hidden_states, dim=1)\n",
    "        combined_embedding = emphasized_middle_embedding + average_embedding\n",
    "\n",
    "        x = self.dropout(combined_embedding)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.out_proj(x)\n",
    "        return logits\n",
    "\n",
    "    # def forward(self, hidden_states):\n",
    "\n",
    "    #     hidden_states =  torch.mean(hidden_states,dim=1)  # avg embedding\n",
    "\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.dense(hidden_states)\n",
    "    #     hidden_states = torch.tanh(hidden_states)\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.out_proj(hidden_states)\n",
    "    #     return hidden_states\n",
    "    \n",
    "    # def forward(self, hidden_states):\n",
    "    #     # Original sequence length and middle index\n",
    "    #     seq_length = hidden_states.size(1)\n",
    "    #     middle_idx = seq_length // 2\n",
    "\n",
    "    #     # Extract the middle embedding vector\n",
    "    #     middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "    #     # Amplify the influence of the middle embedding\n",
    "    #     amplified_middle_embedding = middle_embedding * 2\n",
    "\n",
    "    #     # Combine with average to retain context\n",
    "    #     average_embedding = torch.mean(hidden_states, dim=1)\n",
    "    #     combined_embedding = 0.5 * amplified_middle_embedding + 0.5 * average_embedding\n",
    "\n",
    "    #     # Classification layers\n",
    "    #     x = self.dropout(combined_embedding)\n",
    "    #     x = self.dense(x)\n",
    "    #     x = torch.tanh(x)\n",
    "    #     x = self.dropout(x)\n",
    "    #     logits = self.out_proj(x)\n",
    "    #     return logits\n",
    "\n",
    "\n",
    "class T5EncoderForSimpleSequenceClassification(T5PreTrainedModel):\n",
    "\n",
    "    def __init__(self, config: T5Config, class_config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n",
    "\n",
    "        encoder_config = copy.deepcopy(config)\n",
    "        encoder_config.use_cache = False\n",
    "        encoder_config.is_encoder_decoder = False\n",
    "        self.encoder = T5Stack(encoder_config, self.shared)\n",
    "\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate) \n",
    "        self.classifier = T5EncoderClassificationHead(config, class_config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "    def parallelize(self, device_map=None):\n",
    "        self.device_map = (\n",
    "            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
    "            if device_map is None\n",
    "            else device_map\n",
    "        )\n",
    "        assert_device_map(self.device_map, len(self.encoder.block))\n",
    "        self.encoder.parallelize(self.device_map)\n",
    "        self.classifier = self.classifier.to(self.encoder.first_device)\n",
    "        self.model_parallel = True\n",
    "\n",
    "    def deparallelize(self):\n",
    "        self.encoder.deparallelize()\n",
    "        self.encoder = self.encoder.to(\"cpu\")\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.shared\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.shared = new_embeddings\n",
    "        self.encoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "        logits = self.classifier(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71394626-6f8b-4ca5-80f3-c697e4320bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PT5_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "    # Load PT5 and tokenizer\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\") \n",
    "    \n",
    "    # Create new Classifier model with PT5 dimensions\n",
    "    class_config=ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "    class_model=T5EncoderForSimpleSequenceClassification(model.config,class_config)\n",
    "    \n",
    "    # Set encoder and embedding weights to checkpoint weights\n",
    "    class_model.shared=model.shared\n",
    "    class_model.encoder=model.encoder    \n",
    "    \n",
    "    # Delete the checkpoint model\n",
    "    model=class_model\n",
    "    del class_model\n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "    # Add model modification lora\n",
    "    config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "    # Add LoRA layers\n",
    "    model = modify_with_lora(model, config)\n",
    "    \n",
    "    # Freeze Embeddings and Encoder (except LoRA)\n",
    "    for (param_name, param) in model.shared.named_parameters():\n",
    "                param.requires_grad = False\n",
    "    for (param_name, param) in model.encoder.named_parameters():\n",
    "                param.requires_grad = False       \n",
    "\n",
    "    for (param_name, param) in model.named_parameters():\n",
    "            if re.fullmatch(config.trainable_param_names, param_name):\n",
    "                param.requires_grad = True\n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4d56b2-c9ca-460d-b977-a1e4ae1e9568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4550fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    \"\"\"Custom early stopping callback that can monitor loss or accuracy.\"\"\"\n",
    "    \n",
    "    def __init__(self, metric_name='eval_loss', early_stopping_patience=3, minimize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric_name (str): Metric to monitor, default 'eval_loss'.\n",
    "            early_stopping_patience (int): Number of checks with no improvement after which training will be stopped.\n",
    "            minimize (bool): Set to True if the metric should be minimized, False if it should be maximized.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_counter = 0\n",
    "        self.minimize = minimize\n",
    "        self.best_metric = float('inf') if minimize else float('-inf')\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        current_metric = kwargs['metrics'][self.metric_name]\n",
    "        \n",
    "        if (self.minimize and current_metric < self.best_metric) or (not self.minimize and current_metric > self.best_metric):\n",
    "            self.best_metric = current_metric\n",
    "            self.early_stopping_counter = 0\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "        \n",
    "        if self.early_stopping_counter >= self.early_stopping_patience:\n",
    "            control.should_training_stop = True\n",
    "            print(f'Stopping early! No improvement in {self.metric_name} for {self.early_stopping_patience} evaluation steps.')\n",
    "\n",
    "\n",
    "class MultiObjectiveEarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        # Extract current validation loss and accuracy\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "\n",
    "        # Check if current loss and accuracy improved significantly\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            # Update best scores and reset wait time\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            # If no improvement, increment the wait counter\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                # If wait exceeds the patience, stop training\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "class MultiObjectiveEarlyStoppingAndSaveCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001, output_dir='./model_output', filename='finetuned_model'):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "        self.output_dir = output_dir\n",
    "        self.filename = filename\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "        model = kwargs['model']\n",
    "\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "            # Save the model as the best so far\n",
    "            self.save_finetuned_parameters(model, os.path.join(self.output_dir, self.filename))\n",
    "            print(f\"Saved improved model to {self.output_dir}/{self.filename}\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "    def save_finetuned_parameters(self, model, filepath):\n",
    "        # Create a dictionary to hold the non-frozen parameters\n",
    "        non_frozen_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "        # Save only the finetuned parameters \n",
    "        torch.save(non_frozen_params, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb8bb11-79b0-4936-9099-f9f8ef97e105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "# Set random seeds for reproducibility of your trainings run\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, min_dist=0.01):\n",
    "    umap_model = umap.UMAP(n_components=n_components)\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    data = {\"UMAP1\": embeddings[:, 0], \"UMAP2\": embeddings[:, 1], \"Label\": labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9)\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_new.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "# Main training fuction\n",
    "def train_per_protein(\n",
    "        train_dataset,         #training data\n",
    "        valid_dataset,         #validation data      \n",
    "        weight_decay,\n",
    "        warmup_pct,\n",
    "        num_labels= 2,    #1 for regression, >1 for classification\n",
    "    \n",
    "        # effective training batch size is batch * accum\n",
    "        # we recommend an effective batch size of 8 \n",
    "        batch= 4,         #for training\n",
    "        accum= 2,         #gradient accumulation\n",
    "    \n",
    "        val_batch = 16,   #batch size for evaluation\n",
    "        epochs=1,       #training epochs\n",
    "        lr= 3e-4,         #recommended learning rate\n",
    "        seed= 42,         #random seed\n",
    "        deepspeed=False,  #if gpu is large enough disable deepspeed for training speedup\n",
    "        gpu= 1,\n",
    "        dropout=0.5, #dropout rate\n",
    "         #L2 weight regularization\n",
    "        lora_rank=4,      #lora rank\n",
    "        lora_init_scale=0.01, #lora scaling rank\n",
    "        lora_scaling_rank=1,       #lora a\n",
    "        ):         #gpu selection (1 for first gpu)\n",
    "\n",
    "    # Set gpu device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # load model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=dropout, lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    total_steps = epochs * len(train_dataset) // batch\n",
    "    warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "    # Define TrainingArguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir='./results',              # where to save the model\n",
    "        evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "        logging_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        learning_rate=lr,                    # initial learning rate\n",
    "        per_device_train_batch_size=batch,   # batch size per device\n",
    "        gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "        num_train_epochs=epochs,             # number of epochs to train\n",
    "        weight_decay=weight_decay,           # L2 weight regularization\n",
    "        warmup_steps=warmup_steps,           # 10% of total steps\n",
    "        load_best_model_at_end=False,         # load the best model at the end of training\n",
    "        seed=seed,                           # random seed\n",
    "        push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "        logging_dir='./logs',\n",
    "    )\n",
    "    # metric_for_best_model='eval_loss|accuracy'\n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        # Check if predictions have the expected shape\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "        # Now, compute the metric (e.g., accuracy)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        # Return the metric(s) as a dictionary\n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    # For minimizing loss\n",
    "    early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "    # For maximizing accuracy\n",
    "    early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "            early_stopping_patience=3,\n",
    "            min_delta=0.001,\n",
    "            output_dir='./model_output',\n",
    "            filename='finetuned_model_D_and_P_balance_dataset_smac.pth'\n",
    "        )],\n",
    "    )    \n",
    "\n",
    "    def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "        embeddings = []\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "    \n",
    "        # Iterate over the sequences in batches\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            # Extract a batch of sequences\n",
    "            batch = sequences[i:i + batch_size]\n",
    "    \n",
    "            # Tokenize the batch using the specified tokenizer and convert to PyTorch tensors\n",
    "            inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                # Forward pass through the model to obtain outputs\n",
    "                outputs = model(**inputs)\n",
    "    \n",
    "            # Extract hidden states from the second-to-last layer (penultimate layer)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "    \n",
    "            # Take the embeddings from the second-to-last layer\n",
    "            embeddings_from_layer = hidden_states[:, 0, :]\n",
    "    \n",
    "            # Extend the list with the generated embeddings\n",
    "            embeddings.extend(embeddings_from_layer)\n",
    "    \n",
    "            print(f\"Batch {i // batch_size + 1}, Second-to-Last Layer Embeddings Shape: {embeddings_from_layer.shape}\")\n",
    "    \n",
    "        return np.array(embeddings)\n",
    "\n",
    "        \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    # Get the best model\n",
    "    # model = trainer.model\n",
    "    # Ensure the best model is loaded\n",
    "    best_model_path = os.path.join('./model_output', 'finetuned_model_D_and_P_balance_dataset_smac.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        state_dict = torch.load(best_model_path)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "    # Evaluate the best model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(eval_results)\n",
    "    \n",
    "    # Print the current learning rate\n",
    "    # current_lr = trainer.optimizer.param_groups[0]['lr']\n",
    "    # print(f\"Current learning rate: {current_lr}\")\n",
    "    \n",
    "    # valid_sequences = list(valid_dataset['sequence'])\n",
    "    # valid_embeddings = get_embeddings(model, tokenizer, valid_sequences)\n",
    "\n",
    "    # # Apply UMAP for dimensionality reduction\n",
    "    # umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "    # # Plot UMAP embeddings\n",
    "    # labels = list(valid_dataset['label'])\n",
    "    # plot_umap(umap_embeddings, labels)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b300952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Dataset creation\n",
    "def create_dataset(tokenizer,seqs,labels):\n",
    "    tokenized = tokenizer(seqs, max_length=1024, padding=True, truncation=True)\n",
    "    dataset = Dataset.from_dict(tokenized)\n",
    "    dataset = dataset.add_column(\"labels\", labels)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\") \n",
    "\n",
    "train_df = my_train\n",
    "valid_df = my_valid\n",
    "\n",
    "# Preprocess inputs\n",
    "# Replace uncommon AAs with \"X\"\n",
    "train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "# Add spaces between each amino acid for PT5 to correctly use them\n",
    "train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "# Create Datasets\n",
    "train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']))\n",
    "valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from ConfigSpace import ConfigurationSpace, Configuration\n",
    "from ConfigSpace.hyperparameters import UniformFloatHyperparameter, CategoricalHyperparameter, UniformIntegerHyperparameter\n",
    "from smac import HyperparameterOptimizationFacade as HPOFacade\n",
    "from smac import Scenario\n",
    "from smac.intensifier.hyperband import Hyperband\n",
    "from smac.multi_objective.parego import ParEGO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "class ProteinModel:\n",
    "    @property\n",
    "    def configspace(self) -> ConfigurationSpace:\n",
    "        cs = ConfigurationSpace()\n",
    "\n",
    "        cs.add_hyperparameters([\n",
    "            UniformFloatHyperparameter('lr', lower=1e-5, upper=1e-2, log=True),\n",
    "            CategoricalHyperparameter('batch', choices=[1, 2, 4, 8]),\n",
    "            CategoricalHyperparameter('accum', choices=[2, 4, 8]),\n",
    "            UniformFloatHyperparameter('dropout_rate', lower=0.1, upper=0.9),\n",
    "            UniformFloatHyperparameter('weight_decay', lower=1e-5, upper=1e-3, log=True),\n",
    "            UniformFloatHyperparameter('warmup_pct', lower=0.01, upper=0.3),\n",
    "            UniformIntegerHyperparameter('lora_rank', lower=4, upper=32),\n",
    "            UniformFloatHyperparameter('lora_init_scale', lower=1e-4, upper=1e-1, log=True),\n",
    "            UniformIntegerHyperparameter('lora_scaling_rank', lower=1, upper=4)\n",
    "        ])\n",
    "\n",
    "        cs['lora_rank'].q = 4\n",
    "\n",
    "        return cs\n",
    "\n",
    "    def train(self, config: Configuration, seed: int = 42, budget: int = 10) -> dict[str, float]:\n",
    "        logger.info(f\"Training with budget (epochs): {budget}\")\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "            # Call your training function\n",
    "            tokenizer, model, history = train_per_protein(\n",
    "                train_dataset=train_set,\n",
    "                valid_dataset=valid_set,\n",
    "                num_labels=2,\n",
    "                batch=int(config['batch']),\n",
    "                accum=int(config['accum']),\n",
    "                epochs=int(budget),\n",
    "                lr=config['lr'],\n",
    "                dropout=config['dropout_rate'],\n",
    "                weight_decay=config['weight_decay'],\n",
    "                warmup_pct=config['warmup_pct'],\n",
    "                lora_rank=config['lora_rank'],\n",
    "                lora_init_scale=config['lora_init_scale'],\n",
    "                lora_scaling_rank=config['lora_scaling_rank'],\n",
    "                seed=seed\n",
    "            )\n",
    "\n",
    "            # Extract the last validation accuracy and loss from the history\n",
    "            val_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry][-1]\n",
    "            val_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry][-1]\n",
    "\n",
    "        logger.info(f\"Completed training. Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n",
    "        return {\n",
    "            \"val_loss\": val_loss,\n",
    "            \"1 - val_accuracy\": 1 - val_accuracy,  # We minimize, so we use 1 - accuracy\n",
    "        }\n",
    "\n",
    "def plot_pareto(smac: HPOFacade, incumbents: list[Configuration]) -> None:\n",
    "    \"\"\"Plots configurations from SMAC and highlights the best configurations in a Pareto front.\"\"\"\n",
    "    average_costs = []\n",
    "    average_pareto_costs = []\n",
    "    for config in smac.runhistory.get_configs():\n",
    "        # Since we use multiple seeds, we have to average them to get only one cost value pair for each configuration\n",
    "        average_cost = smac.runhistory.average_cost(config)\n",
    "\n",
    "        if config in incumbents:\n",
    "            average_pareto_costs += [average_cost]\n",
    "        else:\n",
    "            average_costs += [average_cost]\n",
    "\n",
    "    # Let's work with a numpy array\n",
    "    costs = np.vstack(average_costs)\n",
    "    pareto_costs = np.vstack(average_pareto_costs)\n",
    "    pareto_costs = pareto_costs[pareto_costs[:, 0].argsort()]  # Sort them\n",
    "\n",
    "    costs_x, costs_y = costs[:, 0], costs[:, 1]\n",
    "    pareto_costs_x, pareto_costs_y = pareto_costs[:, 0], pareto_costs[:, 1]\n",
    "\n",
    "    plt.scatter(costs_x, costs_y, marker=\"x\", label=\"Configuration\")\n",
    "    plt.scatter(pareto_costs_x, pareto_costs_y, marker=\"x\", c=\"r\", label=\"Incumbent\")\n",
    "    plt.step(\n",
    "        [pareto_costs_x[0]] + pareto_costs_x.tolist() + [np.max(costs_x)],  # We add bounds\n",
    "        [np.max(costs_y)] + pareto_costs_y.tolist() + [np.min(pareto_costs_y)],  # We add bounds\n",
    "        where=\"post\",\n",
    "        linestyle=\":\",\n",
    "    )\n",
    "\n",
    "    plt.title(\"Pareto-Front\")\n",
    "    plt.xlabel(smac.scenario.objectives[0])\n",
    "    plt.ylabel(smac.scenario.objectives[1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    protein_model = ProteinModel()\n",
    "    objectives = [\"val_loss\", \"1 - val_accuracy\"]\n",
    "\n",
    "    # Define output directory\n",
    "    output_dir = \"./smac3_output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define our environment variables\n",
    "    scenario = Scenario(\n",
    "        protein_model.configspace,\n",
    "        objectives=objectives,\n",
    "        # walltime_limit=1800,  # After 30 minutes, we stop the hyperparameter optimization\n",
    "        n_trials=30,  # Evaluate up to 30 different configurations\n",
    "        min_budget=5,\n",
    "        max_budget=20,\n",
    "        n_workers=1,\n",
    "        output_directory=output_dir,\n",
    "        name=\"ProteinModelOptimization_6\",\n",
    "    )\n",
    "\n",
    "    # We want to run five random configurations before starting the optimization.\n",
    "    initial_design = HPOFacade.get_initial_design(scenario, n_configs=5)\n",
    "\n",
    "    intensifier = HPOFacade.get_intensifier(scenario, max_config_calls=2)\n",
    "\n",
    "    # Set up the multi-objective optimizer\n",
    "    multi_objective_algorithm = ParEGO(scenario=scenario)\n",
    "\n",
    "    # Create our SMAC object and pass the scenario and the train method\n",
    "    smac = HPOFacade(\n",
    "        scenario,\n",
    "        protein_model.train,\n",
    "        initial_design=initial_design,\n",
    "        multi_objective_algorithm=multi_objective_algorithm,\n",
    "        intensifier=intensifier,\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    # Let's optimize\n",
    "    incumbents = smac.optimize()\n",
    "\n",
    "    # Prepare results\n",
    "    # all_runs = []\n",
    "\n",
    "    print(\"**************\")\n",
    "    print(\"\\nBest configurations:\")\n",
    "    for incumbent in incumbents:\n",
    "        print(\"Configuration: \", incumbent)\n",
    "        print(\"Average Cost: \", smac.runhistory.average_cost(incumbent))\n",
    "        print(\"Value: \", smac.runhistory.get_cost(incumbent))\n",
    "        print(\"Hyperparameters: \", dict(incumbent))\n",
    "        # print(\"---\", cost)\n",
    "\n",
    "    # Let's plot a pareto front\n",
    "    plot_pareto(smac, incumbents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18ba4c83-ddaa-4e0f-b7c5-3df0e61e59b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING][target_function_runner.py:74] The argument budget is not set by SMAC: Consider removing it from the target function.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5202515721321106, 'eval_accuracy': 0.7393310265282583, 'eval_runtime': 13.2158, 'eval_samples_per_second': 65.603, 'eval_steps_per_second': 8.248, 'epoch': 4.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.5202515721321106, Val Accuracy: 0.7393310265282583\n",
      "[INFO][abstract_intensifier.py:516] Added config b74743 as new incumbent because there are no incumbents yet.\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.4882161021232605, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.2959, 'eval_samples_per_second': 70.511, 'eval_steps_per_second': 8.865, 'epoch': 4.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.4882161021232605, Val Accuracy: 0.7854671280276817\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 6017027.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "{'eval_loss': 0.5297576189041138, 'eval_accuracy': 0.748558246828143, 'eval_runtime': 12.1143, 'eval_samples_per_second': 71.568, 'eval_steps_per_second': 8.998, 'epoch': 9.99}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.5297576189041138, Val Accuracy: 0.748558246828143\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 6017027.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "{'eval_loss': 0.5301133394241333, 'eval_accuracy': 0.7439446366782007, 'eval_runtime': 12.1776, 'eval_samples_per_second': 71.197, 'eval_steps_per_second': 8.951, 'epoch': 9.99}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.5301133394241333, Val Accuracy: 0.7439446366782007\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 8474627.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "{'eval_loss': 0.6433594226837158, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.1827, 'eval_samples_per_second': 71.166, 'eval_steps_per_second': 8.947, 'epoch': 9.95}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.6433594226837158, Val Accuracy: 0.7854671280276817\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 8474627.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.4629347324371338, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.1685, 'eval_samples_per_second': 71.25, 'eval_steps_per_second': 8.958, 'epoch': 6.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.4629347324371338, Val Accuracy: 0.7866205305651672\n",
      "[INFO][abstract_intensifier.py:603] Config 5d50d2 is a new incumbent. Total number of incumbents: 2.\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 11423747.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "{'eval_loss': 1.049824595451355, 'eval_accuracy': 0.7946943483275664, 'eval_runtime': 12.144, 'eval_samples_per_second': 71.393, 'eval_steps_per_second': 8.976, 'epoch': 10.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 1.049824595451355, Val Accuracy: 0.7946943483275664\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 11423747.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "{'eval_loss': 1.0475374460220337, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.1522, 'eval_samples_per_second': 71.345, 'eval_steps_per_second': 8.97, 'epoch': 10.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 1.0475374460220337, Val Accuracy: 0.7889273356401384\n",
      "[INFO][abstract_intensifier.py:603] Config e680e4 is a new incumbent. Total number of incumbents: 3.\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13881347.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.4918089807033539, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.1395, 'eval_samples_per_second': 71.42, 'eval_steps_per_second': 8.979, 'epoch': 7.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.4918089807033539, Val Accuracy: 0.7854671280276817\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13881347.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.4886687994003296, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.1803, 'eval_samples_per_second': 71.18, 'eval_steps_per_second': 8.949, 'epoch': 7.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.4886687994003296, Val Accuracy: 0.7889273356401384\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 14864387.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.995391705069125: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.995391705069125: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5760974287986755, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.2277, 'eval_samples_per_second': 70.905, 'eval_steps_per_second': 8.914, 'epoch': 9.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.5760974287986755, Val Accuracy: 0.7773933102652826\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 14864387.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 5.990783410138249: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 5.990783410138249: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.4665573835372925, 'eval_accuracy': 0.790080738177624, 'eval_runtime': 12.2353, 'eval_samples_per_second': 70.861, 'eval_steps_per_second': 8.909, 'epoch': 5.99}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.4665573835372925, Val Accuracy: 0.790080738177624\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13389827.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 9.953917050691244: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 1.0270317792892456, 'eval_accuracy': 0.7820069204152249, 'eval_runtime': 12.189, 'eval_samples_per_second': 71.13, 'eval_steps_per_second': 8.943, 'epoch': 9.95}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 1.0270317792892456, Val Accuracy: 0.7820069204152249\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13389827.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 5.990783410138249: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 5.990783410138249: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.4617999494075775, 'eval_accuracy': 0.7877739331026529, 'eval_runtime': 12.1983, 'eval_samples_per_second': 71.076, 'eval_steps_per_second': 8.936, 'epoch': 5.99}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.4617999494075775, Val Accuracy: 0.7877739331026529\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 12898307.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.48141640424728394, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.2282, 'eval_samples_per_second': 70.902, 'eval_steps_per_second': 8.914, 'epoch': 8.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.48141640424728394, Val Accuracy: 0.7866205305651672\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 12898307.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.4641232490539551, 'eval_accuracy': 0.7970011534025375, 'eval_runtime': 12.1716, 'eval_samples_per_second': 71.231, 'eval_steps_per_second': 8.955, 'epoch': 8.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.4641232490539551, Val Accuracy: 0.7970011534025375\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 12898307.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.4993082582950592, 'eval_accuracy': 0.7797001153402537, 'eval_runtime': 12.1591, 'eval_samples_per_second': 71.305, 'eval_steps_per_second': 8.964, 'epoch': 8.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.4993082582950592, Val Accuracy: 0.7797001153402537\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 12898307.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.49491098523139954, 'eval_accuracy': 0.7912341407151096, 'eval_runtime': 12.1786, 'eval_samples_per_second': 71.19, 'eval_steps_per_second': 8.95, 'epoch': 8.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.49491098523139954, Val Accuracy: 0.7912341407151096\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 14864387.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 5.990783410138249: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 5.990783410138249: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.489064484834671, 'eval_accuracy': 0.7820069204152249, 'eval_runtime': 12.1918, 'eval_samples_per_second': 71.113, 'eval_steps_per_second': 8.94, 'epoch': 5.99}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.489064484834671, Val Accuracy: 0.7820069204152249\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 14864387.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 5.990783410138249: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 5.990783410138249: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.48687440156936646, 'eval_accuracy': 0.7704728950403691, 'eval_runtime': 12.1982, 'eval_samples_per_second': 71.076, 'eval_steps_per_second': 8.936, 'epoch': 5.99}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.48687440156936646, Val Accuracy: 0.7704728950403691\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 16338947.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "{'eval_loss': 1.1454253196716309, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1984, 'eval_samples_per_second': 71.075, 'eval_steps_per_second': 8.936, 'epoch': 9.95}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 1.1454253196716309, Val Accuracy: 0.7785467128027682\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 16338947.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 9.953917050691244: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.9187631011009216, 'eval_accuracy': 0.7935409457900807, 'eval_runtime': 12.191, 'eval_samples_per_second': 71.118, 'eval_steps_per_second': 8.941, 'epoch': 9.95}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.9187631011009216, Val Accuracy: 0.7935409457900807\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 4542467.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5624089241027832, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.1337, 'eval_samples_per_second': 71.454, 'eval_steps_per_second': 8.983, 'epoch': 8.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.5624089241027832, Val Accuracy: 0.7866205305651672\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 4542467.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 9.953917050691244: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.9960983991622925, 'eval_accuracy': 0.7912341407151096, 'eval_runtime': 12.1422, 'eval_samples_per_second': 71.404, 'eval_steps_per_second': 8.977, 'epoch': 9.95}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.9960983991622925, Val Accuracy: 0.7912341407151096\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13881347.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.995391705069125: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.995391705069125: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6515878438949585, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.2406, 'eval_samples_per_second': 70.83, 'eval_steps_per_second': 8.905, 'epoch': 9.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.6515878438949585, Val Accuracy: 0.7866205305651672\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13881347.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 5.990783410138249: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 5.990783410138249: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.4630812704563141, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.1986, 'eval_samples_per_second': 71.073, 'eval_steps_per_second': 8.935, 'epoch': 5.99}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.4630812704563141, Val Accuracy: 0.7854671280276817\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13389827.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.4817901849746704, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.1539, 'eval_samples_per_second': 71.335, 'eval_steps_per_second': 8.968, 'epoch': 8.0}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.4817901849746704, Val Accuracy: 0.7889273356401384\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13389827.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "{'eval_loss': 0.9914658069610596, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.1579, 'eval_samples_per_second': 71.311, 'eval_steps_per_second': 8.965, 'epoch': 9.97}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.9914658069610596, Val Accuracy: 0.7866205305651672\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 7491587.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 9.965397923875432: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 9.965397923875432: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5553668737411499, 'eval_accuracy': 0.8016147635524798, 'eval_runtime': 12.1559, 'eval_samples_per_second': 71.323, 'eval_steps_per_second': 8.967, 'epoch': 9.97}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.5553668737411499, Val Accuracy: 0.8016147635524798\n",
      "[INFO][1461220437.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 7491587.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "{'eval_loss': 0.8698313236236572, 'eval_accuracy': 0.7935409457900807, 'eval_runtime': 12.2545, 'eval_samples_per_second': 70.749, 'eval_steps_per_second': 8.895, 'epoch': 9.97}\n",
      "[INFO][1461220437.py:79] Completed training. Val Loss: 0.8698313236236572, Val Accuracy: 0.7935409457900807\n",
      "[INFO][abstract_intensifier.py:603] Config 55ee59 is a new incumbent. Total number of incumbents: 2.\n",
      "[INFO][smbo.py:328] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:329] --- Remaining wallclock time: inf\n",
      "[INFO][smbo.py:330] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:331] --- Remaining trials: 0\n",
      "**************\n",
      "\n",
      "Best configurations:\n",
      "Configuration:  Configuration(values={\n",
      "  'accum': 8,\n",
      "  'batch': 8,\n",
      "  'dropout_rate': 0.6617722454093,\n",
      "  'lora_init_scale': 0.0622625181343,\n",
      "  'lora_rank': 22,\n",
      "  'lora_scaling_rank': 2,\n",
      "  'lr': 0.0015438741689,\n",
      "  'warmup_pct': 0.0668364202135,\n",
      "  'weight_decay': 0.0001124074649,\n",
      "})\n",
      "Average Cost:  [0.4727698266506195, 0.20818915801614762]\n",
      "Value:  0.07889249236553378\n",
      "Hyperparameters:  {'accum': 8, 'batch': 8, 'dropout_rate': 0.6617722454093, 'lora_init_scale': 0.0622625181343, 'lora_rank': 22, 'lora_scaling_rank': 2, 'lr': 0.0015438741689, 'warmup_pct': 0.0668364202135, 'weight_decay': 0.0001124074649}\n",
      "Configuration:  Configuration(values={\n",
      "  'accum': 8,\n",
      "  'batch': 2,\n",
      "  'dropout_rate': 0.8339231837091,\n",
      "  'lora_init_scale': 0.0677173944981,\n",
      "  'lora_rank': 10,\n",
      "  'lora_scaling_rank': 3,\n",
      "  'lr': 0.0010560703692,\n",
      "  'warmup_pct': 0.0665784582469,\n",
      "  'weight_decay': 0.0001247476148,\n",
      "})\n",
      "Average Cost:  [0.7125990986824036, 0.20242214532871972]\n",
      "Value:  0.20385728296960656\n",
      "Hyperparameters:  {'accum': 8, 'batch': 2, 'dropout_rate': 0.8339231837091, 'lora_init_scale': 0.0677173944981, 'lora_rank': 10, 'lora_scaling_rank': 3, 'lr': 0.0010560703692, 'warmup_pct': 0.0665784582469, 'weight_decay': 0.0001247476148}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_886757/1461220437.py:35: DeprecationWarning: Please use `space.add(hyperparameters)`\n",
      "  cs.add_hyperparameters([\n",
      "2024-08-10 06:45:07,475 - INFO - Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1734' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1734/4330 10:13 < 15:19, 2.82 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.602800</td>\n",
       "      <td>0.520252</td>\n",
       "      <td>0.739331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.681800</td>\n",
       "      <td>0.606049</td>\n",
       "      <td>0.681661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.680100</td>\n",
       "      <td>0.757214</td>\n",
       "      <td>0.549020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='605' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 605/4330 03:28 < 21:29, 2.89 it/s, Epoch 1.39/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.594700</td>\n",
       "      <td>0.488216</td>\n",
       "      <td>0.785467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 59/109 00:05 < 00:05, 9.72 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8179' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8179/8670 37:55 < 02:16, 3.59 it/s, Epoch 9.43/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.736700</td>\n",
       "      <td>0.628481</td>\n",
       "      <td>0.697809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.670100</td>\n",
       "      <td>0.562179</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.643400</td>\n",
       "      <td>0.530708</td>\n",
       "      <td>0.760092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.599900</td>\n",
       "      <td>0.525060</td>\n",
       "      <td>0.769319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.576025</td>\n",
       "      <td>0.769319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.578800</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.782007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.537700</td>\n",
       "      <td>0.757489</td>\n",
       "      <td>0.785467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.516300</td>\n",
       "      <td>0.871133</td>\n",
       "      <td>0.788927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.469600</td>\n",
       "      <td>1.089143</td>\n",
       "      <td>0.787774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1459' max='2170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1459/2170 12:24 < 06:03, 1.96 it/s, Epoch 6.72/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.613900</td>\n",
       "      <td>0.520799</td>\n",
       "      <td>0.743945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.542900</td>\n",
       "      <td>0.488683</td>\n",
       "      <td>0.760092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.463900</td>\n",
       "      <td>0.493469</td>\n",
       "      <td>0.772780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.368300</td>\n",
       "      <td>0.491809</td>\n",
       "      <td>0.785467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.707894</td>\n",
       "      <td>0.779700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.971444</td>\n",
       "      <td>0.780854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='325' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [325/540 10:53 < 07:15, 0.49 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.702300</td>\n",
       "      <td>0.579899</td>\n",
       "      <td>0.704729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.527088</td>\n",
       "      <td>0.741638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>0.466557</td>\n",
       "      <td>0.790081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.506100</td>\n",
       "      <td>0.484205</td>\n",
       "      <td>0.752018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.421900</td>\n",
       "      <td>0.629328</td>\n",
       "      <td>0.742791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='421' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [421/540 13:53 < 03:56, 0.50 it/s, Epoch 7.74/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>0.520694</td>\n",
       "      <td>0.739331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.497446</td>\n",
       "      <td>0.750865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.530500</td>\n",
       "      <td>0.492189</td>\n",
       "      <td>0.769319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.353100</td>\n",
       "      <td>0.571288</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.698440</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.144100</td>\n",
       "      <td>0.831684</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='434' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [434/540 14:40 < 03:35, 0.49 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.634800</td>\n",
       "      <td>0.545923</td>\n",
       "      <td>0.722030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.552200</td>\n",
       "      <td>0.494261</td>\n",
       "      <td>0.762399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.496765</td>\n",
       "      <td>0.758939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>0.499308</td>\n",
       "      <td>0.779700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.603215</td>\n",
       "      <td>0.777393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.728055</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.913470</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='272' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [272/540 08:57 < 08:53, 0.50 it/s, Epoch 5.00/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.633400</td>\n",
       "      <td>0.548556</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.558600</td>\n",
       "      <td>0.481114</td>\n",
       "      <td>0.768166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.520400</td>\n",
       "      <td>0.459899</td>\n",
       "      <td>0.786621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.464800</td>\n",
       "      <td>0.658047</td>\n",
       "      <td>0.656286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 13/109 00:01 < 00:09, 9.94 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 18:08, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.635700</td>\n",
       "      <td>0.551912</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.559100</td>\n",
       "      <td>0.481245</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.529000</td>\n",
       "      <td>0.461555</td>\n",
       "      <td>0.783160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.417200</td>\n",
       "      <td>0.495982</td>\n",
       "      <td>0.790081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.345500</td>\n",
       "      <td>0.664335</td>\n",
       "      <td>0.756632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.678066</td>\n",
       "      <td>0.768166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>1.055101</td>\n",
       "      <td>0.780854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>1.105560</td>\n",
       "      <td>0.783160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='158' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [158/540 05:02 < 12:19, 0.52 it/s, Epoch 2.89/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.622100</td>\n",
       "      <td>0.514777</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.564500</td>\n",
       "      <td>0.500608</td>\n",
       "      <td>0.749712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='325' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [325/540 10:55 < 07:16, 0.49 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.618700</td>\n",
       "      <td>0.509428</td>\n",
       "      <td>0.746251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.567700</td>\n",
       "      <td>0.469779</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.463081</td>\n",
       "      <td>0.785467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.617218</td>\n",
       "      <td>0.782007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.693265</td>\n",
       "      <td>0.777393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='728' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 728/1080 16:17 < 07:53, 0.74 it/s, Epoch 6.71/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.650300</td>\n",
       "      <td>0.554260</td>\n",
       "      <td>0.724337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.562400</td>\n",
       "      <td>0.496682</td>\n",
       "      <td>0.768166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.518400</td>\n",
       "      <td>0.480988</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.470100</td>\n",
       "      <td>0.474394</td>\n",
       "      <td>0.777393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.423900</td>\n",
       "      <td>0.481790</td>\n",
       "      <td>0.788927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.368200</td>\n",
       "      <td>0.518571</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='572' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 572/2160 10:10 < 28:19, 0.93 it/s, Epoch 2.63/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.703800</td>\n",
       "      <td>0.607554</td>\n",
       "      <td>0.702422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.632200</td>\n",
       "      <td>0.520699</td>\n",
       "      <td>0.752018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a57f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"8\": {\n",
    "      \"accum\": 8,\n",
    "      \"batch\": 8,\n",
    "      \"dropout_rate\": 0.6617722454093,\n",
    "      \"lora_init_scale\": 0.0622625181343,\n",
    "      \"lora_rank\": 22,\n",
    "      \"lora_scaling_rank\": 2,\n",
    "      \"lr\": 0.0015438741689,\n",
    "      \"warmup_pct\": 0.0668364202135,\n",
    "      \"weight_decay\": 0.0001124074649\n",
    "    },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddfce510-da2b-4b95-9491-49f9ae8efb06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 12898307.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='651' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 651/1080 22:08 < 14:38, 0.49 it/s, Epoch 12/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.681000</td>\n",
       "      <td>0.614965</td>\n",
       "      <td>0.707036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.606300</td>\n",
       "      <td>0.539045</td>\n",
       "      <td>0.740484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.499283</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.478122</td>\n",
       "      <td>0.763552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.495221</td>\n",
       "      <td>0.770473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.475917</td>\n",
       "      <td>0.777393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.304400</td>\n",
       "      <td>0.591473</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.260300</td>\n",
       "      <td>0.720314</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.210600</td>\n",
       "      <td>0.785313</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.852586</td>\n",
       "      <td>0.760092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n",
      "Stopping early at epoch 12.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 12.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5914725065231323, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1734, 'eval_samples_per_second': 71.221, 'eval_steps_per_second': 8.954, 'epoch': 12.0}\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model, history = train_per_protein(train_set, valid_set, num_labels=2, batch=8, accum=8, epochs=20, seed=42, lr=0.0015438741689, dropout=0.6617722454093, weight_decay=0.0001124074649, warmup_pct=0.0668364202135, lora_rank=22, lora_init_scale=0.0622625181343, lora_scaling_rank=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a28d3c1-8e24-4437-a1d9-dda9cefccfd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Truncate the longer list to the size of the shorter one\n",
    "min_length = min(len(loss), len(val_loss))\n",
    "loss = loss[:min_length]\n",
    "val_loss = val_loss[:min_length]\n",
    "\n",
    "# Get spearman (for regression) or accuracy value (for classification)\n",
    "if [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x] != []:\n",
    "    metric = [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x]\n",
    "else:\n",
    "    metric = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n",
    "\n",
    "epochs = [x['epoch'] for x in history if 'loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "line1 = ax1.plot(epochs, loss, label='train_loss')\n",
    "line2 = ax1.plot(epochs, val_loss, label='validation_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "#line3 = ax2.plot(epochs, metric, color='red', label='validation_metric')\n",
    "ax2.set_ylabel('Metric')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Add grid lines\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 \n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History for fine-tuning\")\n",
    "plt.savefig(f\"../Plots/Without_3rdline_Training_History_new.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccb1bbda-d70e-4b4c-a8d4-24600495171a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "def load_model(filepath, num_labels=2):\n",
    "# Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "    # load a new model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=0.6617722454093, lora_rank=22, lora_init_scale=0.0622625181343, lora_scaling_rank=2)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd98e915-c8a8-433a-870a-c6dcaf191e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def save_model(model, filepath):\n",
    "#     torch.save(model.state_dict(), filepath)\n",
    "\n",
    "# save_model(model, \"../finetuned_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa9b15",
   "metadata": {},
   "source": [
    "{'lr': 0.00010175943017273118, 'batch': 8, 'accum': 2, 'dropout_rate': 0.4882243131202929, 'weight_decay': 0.00014993579804161342, 'warmup_pct': 0.18496515086758566, 'lora_rank': 24, 'lora_init_scale': 0.01370043600756871, 'lora_scaling_rank': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c97fa52-3aea-42e8-b72f-c4bb84808576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 12898307.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_D_and_P_balance_dataset_smac.pth\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2c20e75-5f40-4ca1-9579-5df49b738fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have identical weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60a62aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = from_pretrained(\"model_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50b8a403-e7c5-4912-9c7a-f404c060c32a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WUI4|HDAC7_HUMAN%342%358</td>\n",
       "      <td>ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|Q13950|RUNX2_HUMAN%416%432</td>\n",
       "      <td>THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q15796|SMAD2_HUMAN%229%245</td>\n",
       "      <td>DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%416%432</td>\n",
       "      <td>TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2798%2814</td>\n",
       "      <td>MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0   sp|Q8WUI4|HDAC7_HUMAN%342%358  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
       "1   sp|Q13950|RUNX2_HUMAN%416%432  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
       "2   sp|Q15796|SMAD2_HUMAN%229%245  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
       "3    sp|P05787|K2C8_HUMAN%416%432  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2798%2814  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "    \n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_Y.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2d18716-fd26-49fe-9ba4-b84c936a364c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sequence  label\n",
      "0  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
      "1  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
      "2  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
      "3  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
      "4  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1\n"
     ]
    }
   ],
   "source": [
    "my_test=df[[\"sequence\", \"label\"]]\n",
    "\n",
    "print(my_test.head(5))\n",
    "\n",
    "'''\n",
    "my_test[\"sequence\"]=my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "my_test['sequence']=my_test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "'''\n",
    "\n",
    "#Using .loc ensures that you are modifying the original DataFrame rather than a view of it, which helps avoid the SettingWithCopyWarning.\n",
    "# Replace characters in the \"sequence\" column\n",
    "my_test.loc[:, \"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Convert each sequence to a space-separated string\n",
    "my_test.loc[:, 'sequence'] = my_test.apply(lambda row: \" \".join(row[\"sequence\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eee8fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = sequence.split()\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "my_test['middle_char'] = my_test['sequence'].apply(get_middle_char)\n",
    "\n",
    "# Split the DataFrame\n",
    "my_test_S = my_test[my_test['middle_char'] == 'S'].drop(columns=['middle_char'])\n",
    "my_test_T = my_test[my_test['middle_char'] == 'T'].drop(columns=['middle_char'])\n",
    "my_test_Y = my_test[my_test['middle_char'] == 'Y'].drop(columns=['middle_char'])\n",
    "my_test_ST = my_test[my_test['middle_char'].isin(['S', 'T'])].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcd9ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0dff151-a667-4717-af18-401818bc4c22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:01<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.659082 |      0.615385 |             1 |        0.8 |  0.955128 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[16 10]\n",
      " [ 0 24]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ce2f51a-887c-4684-82b9-22ea5fffd334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['0', '1']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"../Plots/Confusion_matrix_for_dephos_new.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07603226",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5e0d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 28/28 [00:04<00:00,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.558964 |      0.674107 |      0.873874 |   0.773543 |  0.875784 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[151  73]\n",
      " [ 28 194]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5528dc-6e06-456d-920f-8f05055d0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, n_neighbors=5, min_dist=0.01, metric='euclidean'):\n",
    "    umap_model = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric\n",
    "    )\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    df = pd.DataFrame({\n",
    "        \"UMAP1\": embeddings[:, 0],\n",
    "        \"UMAP2\": embeddings[:, 1],\n",
    "        \"Label\": labels\n",
    "    })\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = sns.scatterplot(\n",
    "        x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9\n",
    "    )\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.legend(title='Label', bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_ST.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "    embeddings = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch = sequences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "            embeddings.extend(hidden_states[:, 0, :])\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(sequences) // batch_size + 1}\")\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7718f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = list(sequence)\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "valid_df = df\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "valid_df['middle_char'] = valid_df['sequence'].apply(get_middle_char)\n",
    "\n",
    "valid_df = valid_df[valid_df['middle_char'] == 'T'].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a162964f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sp|Q9GZM8|NDEL1_HUMAN%203%219</td>\n",
       "      <td>CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>sp|Q8N163|CCAR2_HUMAN%438%454</td>\n",
       "      <td>EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>sp|P10636-8|TAU_HUMAN%196%212</td>\n",
       "      <td>GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>sp|Q02241|KIF23_HUMAN%434%450</td>\n",
       "      <td>QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sp|Q04206|TF65_HUMAN%419%435</td>\n",
       "      <td>QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>sp|Q76N33|STALP_MOUSE%326%342</td>\n",
       "      <td>ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>sp|P49790|NU153_HUMAN%1098%1114</td>\n",
       "      <td>FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>sp|Q8NFC6|BD1L1_HUMAN%2789%2805</td>\n",
       "      <td>DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>sp|Q5T6F2|UBAP2_HUMAN%514%530</td>\n",
       "      <td>SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>sp|Q9H040|SPRTN_HUMAN%265%281</td>\n",
       "      <td>NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name                           sequence  label\n",
       "180    sp|Q9GZM8|NDEL1_HUMAN%203%219  CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI      1\n",
       "181    sp|Q8N163|CCAR2_HUMAN%438%454  EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA      1\n",
       "182    sp|P10636-8|TAU_HUMAN%196%212  GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV      1\n",
       "183    sp|Q02241|KIF23_HUMAN%434%450  QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE      1\n",
       "184     sp|Q04206|TF65_HUMAN%419%435  QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG      1\n",
       "..                               ...                                ...    ...\n",
       "441    sp|Q76N33|STALP_MOUSE%326%342  ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS      0\n",
       "442  sp|P49790|NU153_HUMAN%1098%1114  FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ      0\n",
       "443  sp|Q8NFC6|BD1L1_HUMAN%2789%2805  DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL      0\n",
       "444    sp|Q5T6F2|UBAP2_HUMAN%514%530  SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS      0\n",
       "445    sp|Q9H040|SPRTN_HUMAN%265%281  NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN      0\n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a44d9187-1ac5-4e36-89a0-8f827a7f0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 3559427.0\n",
      "\n",
      "Processed batch 1/3\n",
      "Processed batch 2/3\n",
      "Processed batch 3/3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_df = my_valid\n",
    "\n",
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_ST.pth\",num_labels=2)\n",
    "\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "valid_sequences = list(valid_df['sequence'])\n",
    "valid_embeddings = get_embeddings(model_reload, tokenizer, valid_sequences)\n",
    "\n",
    "umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "\n",
    "labels = list(valid_df['label'])\n",
    "\n",
    "plot_umap(umap_embeddings, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f029bcf-42ef-4476-b575-3c14adb71b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da0e6c-e921-493b-9304-8ba9aad07d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

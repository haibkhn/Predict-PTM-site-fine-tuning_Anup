{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2319a5",
   "metadata": {},
   "source": [
    "This notebook will implement changing lora settings and separate dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a377270-2995-4da1-a673-5369769a6279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install umap-learn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0148ff8f-80eb-4bbd-aac7-fe1f371da27a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.1.1+cu121\n",
      "Cuda version:  12.1\n",
      "Numpy version:  1.26.4\n",
      "Pandas version:  2.1.3\n",
      "Transformers version:  4.35.2\n",
      "Datasets version:  2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96bd9396-a81c-4d87-a722-0d2020627dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|P24928|RPB1_HUMAN%1775%1791</td>\n",
       "      <td>NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%58%74</td>\n",
       "      <td>SGMGGITAVTVNQSLLSPLVLEVDPNIQAVRTQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q14832|GRM3_HUMAN%829%845</td>\n",
       "      <td>QPQKNVVTHRLHLNRFSVSGTGTTYSQSSASTY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P01106|MYC_HUMAN%46%62</td>\n",
       "      <td>SEDIWKKFELLPTPPLSPSRRSGLCSPSYVAVT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2792%2808</td>\n",
       "      <td>TREGDSMALYNRTRRISQTSQVSVDAAHGYSPR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0  sp|P24928|RPB1_HUMAN%1775%1791  NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS      1\n",
       "1      sp|P05787|K2C8_HUMAN%58%74  SGMGGITAVTVNQSLLSPLVLEVDPNIQAVRTQ      1\n",
       "2    sp|Q14832|GRM3_HUMAN%829%845  QPQKNVVTHRLHLNRFSVSGTGTTYSQSSASTY      1\n",
       "3       sp|P01106|MYC_HUMAN%46%62  SEDIWKKFELLPTPPLSPSRRSGLCSPSYVAVT      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2792%2808  TREGDSMALYNRTRRISQTSQVSVDAAHGYSPR      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from Bio import SeqIO\n",
    "# import pandas as pd\n",
    "\n",
    "# sequences = []\n",
    "\n",
    "# local_fasta_path = '../src/input_datasets/train_Pos_Neg_ST.fasta'\n",
    "\n",
    "# # Load FASTA file using Biopython\n",
    "# for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "#     # Split the description to extract label\n",
    "#     description_parts = record.description.split(\"%\")\n",
    "#     label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "#     sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# local_fasta_path = '../src/input_datasets/train_Pos_Neg_Y.fasta'\n",
    "\n",
    "# for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "#     # Split the description to extract label\n",
    "#     description_parts = record.description.split(\"%\")\n",
    "#     label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "#     sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# # Create dataframe\n",
    "# df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# # Display the dataframe\n",
    "# df.head(5)\n",
    "\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "def process_fasta(file_path, label):\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        sequences.append([record.id, str(record.seq), label])\n",
    "    return sequences\n",
    "\n",
    "# Paths to your positive and negative FASTA files\n",
    "positive_fasta_path = '../src/input_datasets/positive_sites.fasta'\n",
    "negative_fasta_path = '../src/input_datasets/negative_sites.fasta'\n",
    "\n",
    "# Process both files\n",
    "positive_sequences = process_fasta(positive_fasta_path, 1)\n",
    "negative_sequences = process_fasta(negative_fasta_path, 0)\n",
    "\n",
    "# Combine positive and negative sequences\n",
    "all_sequences = positive_sequences + negative_sequences\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display some statistics\n",
    "print(f\"\\nTotal sequences: {len(df)}\")\n",
    "print(f\"Positive sequences: {len(positive_sequences)}\")\n",
    "print(f\"Negative sequences: {len(negative_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76760f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "(1584, 2)\n",
      "\n",
      "Validation Set:\n",
      "(396, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "my_train, my_valid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "my_train=my_train[[\"sequence\", \"label\"]]\n",
    "my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the training set\n",
    "print(\"Training Set:\")\n",
    "print(my_train.shape)\n",
    "\n",
    "# Print the first 5 rows of the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a424877b-787c-44fe-bf87-33346ffd3be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifies an existing transformer and introduce the LoRA layers\n",
    "\n",
    "class LoRAConfig:\n",
    "    def __init__(self, lora_rank=8, lora_init_scale=0.01, lora_scaling_rank=2):\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_init_scale = lora_init_scale\n",
    "        self.lora_modules = \".*SelfAttention|.*EncDecAttention\"\n",
    "        self.lora_layers = \"q|k|v|o\"\n",
    "        self.trainable_param_names = \".*layer_norm.*|.*lora_[ab].*\"\n",
    "        self.lora_scaling_rank = lora_scaling_rank\n",
    "        # lora_modules and lora_layers are specified with regular expressions\n",
    "        # see https://www.w3schools.com/python/python_regex.asp for reference\n",
    "        \n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, scaling_rank, init_scale):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.rank = rank\n",
    "        self.scaling_rank = scaling_rank\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        if self.rank > 0:\n",
    "            self.lora_a = nn.Parameter(torch.randn(rank, linear_layer.in_features) * init_scale)\n",
    "            if init_scale < 0:\n",
    "                self.lora_b = nn.Parameter(torch.randn(linear_layer.out_features, rank) * init_scale)\n",
    "            else:\n",
    "                self.lora_b = nn.Parameter(torch.zeros(linear_layer.out_features, rank))\n",
    "        if self.scaling_rank:\n",
    "            self.multi_lora_a = nn.Parameter(\n",
    "                torch.ones(self.scaling_rank, linear_layer.in_features)\n",
    "                + torch.randn(self.scaling_rank, linear_layer.in_features) * init_scale\n",
    "            )\n",
    "            if init_scale < 0:\n",
    "                self.multi_lora_b = nn.Parameter(\n",
    "                    torch.ones(linear_layer.out_features, self.scaling_rank)\n",
    "                    + torch.randn(linear_layer.out_features, self.scaling_rank) * init_scale\n",
    "                )\n",
    "            else:\n",
    "                self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, self.scaling_rank))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.scaling_rank == 1 and self.rank == 0:\n",
    "            # parsimonious implementation for ia3 and lora scaling\n",
    "            if self.multi_lora_a.requires_grad:\n",
    "                hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n",
    "            else:\n",
    "                hidden = F.linear(input, self.weight, self.bias)\n",
    "            if self.multi_lora_b.requires_grad:\n",
    "                hidden = hidden * self.multi_lora_b.flatten()\n",
    "            return hidden\n",
    "        else:\n",
    "            # general implementation for lora (adding and scaling)\n",
    "            weight = self.weight\n",
    "            if self.scaling_rank:\n",
    "                weight = weight * torch.matmul(self.multi_lora_b, self.multi_lora_a) / self.scaling_rank\n",
    "            if self.rank:\n",
    "                weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n",
    "            return F.linear(input, weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, rank={}, scaling_rank={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.rank, self.scaling_rank\n",
    "        )\n",
    "\n",
    "\n",
    "def modify_with_lora(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.lora_modules, m_name):\n",
    "            for c_name, layer in dict(module.named_children()).items():\n",
    "                if re.fullmatch(config.lora_layers, c_name):\n",
    "                    assert isinstance(\n",
    "                        layer, nn.Linear\n",
    "                    ), f\"LoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        c_name,\n",
    "                        LoRALinear(layer, config.lora_rank, config.lora_scaling_rank, config.lora_init_scale),\n",
    "                    )\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7762c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoRAConfig:\n",
    "    def __init__(self, dora_rank=8, dora_init_scale=0.01):\n",
    "        self.dora_rank = dora_rank\n",
    "        self.dora_init_scale = dora_init_scale\n",
    "        self.dora_modules = \".*SelfAttention|.*EncDecAttention\"\n",
    "        self.dora_layers = \"q|k|v|o\"\n",
    "        self.trainable_param_names = \".*layer_norm.*|.*dora_diag.*\"\n",
    "\n",
    "class DoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, init_scale):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.rank = rank\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        if self.rank > 0:\n",
    "            self.dora_diag = nn.Parameter(torch.randn(min(self.in_features, self.out_features)) * init_scale)\n",
    "\n",
    "    def forward(self, input):\n",
    "        weight = self.weight\n",
    "        if self.rank:\n",
    "            diag_matrix = torch.diag(self.dora_diag)  # Create a diagonal matrix from the parameters\n",
    "            diag_matrix_padded = torch.zeros_like(weight)\n",
    "            diag_matrix_padded[:diag_matrix.shape[0], :diag_matrix.shape[1]] = diag_matrix\n",
    "            weight = weight + diag_matrix_padded  # Ensure correct size\n",
    "        return F.linear(input, weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, rank={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.rank\n",
    "        )\n",
    "\n",
    "\n",
    "def modify_with_dora(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.dora_modules, m_name):\n",
    "            for c_name, layer in dict(module.named_children()).items():\n",
    "                if re.fullmatch(config.dora_layers, c_name):\n",
    "                    assert isinstance(\n",
    "                        layer, nn.Linear\n",
    "                    ), f\"DoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        c_name,\n",
    "                        DoRALinear(layer, config.dora_rank, config.dora_init_scale),\n",
    "                    )\n",
    "    return transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e79b323-4677-4723-a5fd-a60dc13a3b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.7, num_labels=2):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class T5EncoderClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, class_config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "        \n",
    "        # Trainable emphasis factor\n",
    "        self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        seq_length = hidden_states.size(1)\n",
    "        middle_idx = seq_length // 2\n",
    "        middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "        # Apply trainable emphasis factor\n",
    "        emphasized_middle_embedding = middle_embedding * self.emphasis_factor\n",
    "\n",
    "        # Combine with the average embedding\n",
    "        average_embedding = torch.mean(hidden_states, dim=1)\n",
    "        combined_embedding = emphasized_middle_embedding + average_embedding\n",
    "\n",
    "        x = self.dropout(combined_embedding)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.out_proj(x)\n",
    "        return logits\n",
    "\n",
    "    # def forward(self, hidden_states):\n",
    "\n",
    "    #     hidden_states =  torch.mean(hidden_states,dim=1)  # avg embedding\n",
    "\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.dense(hidden_states)\n",
    "    #     hidden_states = torch.tanh(hidden_states)\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.out_proj(hidden_states)\n",
    "    #     return hidden_states\n",
    "    \n",
    "    # def forward(self, hidden_states):\n",
    "    #     # Original sequence length and middle index\n",
    "    #     seq_length = hidden_states.size(1)\n",
    "    #     middle_idx = seq_length // 2\n",
    "\n",
    "    #     # Extract the middle embedding vector\n",
    "    #     middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "    #     # Amplify the influence of the middle embedding\n",
    "    #     amplified_middle_embedding = middle_embedding * 2\n",
    "\n",
    "    #     # Combine with average to retain context\n",
    "    #     average_embedding = torch.mean(hidden_states, dim=1)\n",
    "    #     combined_embedding = 0.5 * amplified_middle_embedding + 0.5 * average_embedding\n",
    "\n",
    "    #     # Classification layers\n",
    "    #     x = self.dropout(combined_embedding)\n",
    "    #     x = self.dense(x)\n",
    "    #     x = torch.tanh(x)\n",
    "    #     x = self.dropout(x)\n",
    "    #     logits = self.out_proj(x)\n",
    "    #     return logits\n",
    "\n",
    "\n",
    "class T5EncoderForSimpleSequenceClassification(T5PreTrainedModel):\n",
    "\n",
    "    def __init__(self, config: T5Config, class_config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n",
    "\n",
    "        encoder_config = copy.deepcopy(config)\n",
    "        encoder_config.use_cache = False\n",
    "        encoder_config.is_encoder_decoder = False\n",
    "        self.encoder = T5Stack(encoder_config, self.shared)\n",
    "\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate) \n",
    "        self.classifier = T5EncoderClassificationHead(config, class_config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "    def parallelize(self, device_map=None):\n",
    "        self.device_map = (\n",
    "            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
    "            if device_map is None\n",
    "            else device_map\n",
    "        )\n",
    "        assert_device_map(self.device_map, len(self.encoder.block))\n",
    "        self.encoder.parallelize(self.device_map)\n",
    "        self.classifier = self.classifier.to(self.encoder.first_device)\n",
    "        self.model_parallel = True\n",
    "\n",
    "    def deparallelize(self):\n",
    "        self.encoder.deparallelize()\n",
    "        self.encoder = self.encoder.to(\"cpu\")\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.shared\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.shared = new_embeddings\n",
    "        self.encoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "        logits = self.classifier(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71394626-6f8b-4ca5-80f3-c697e4320bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PT5_classification_model(num_labels, dropout, dora_rank, dora_init_scale):\n",
    "    # Load PT5 and tokenizer\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\") \n",
    "    \n",
    "    # Create new Classifier model with PT5 dimensions\n",
    "    class_config=ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "    class_model=T5EncoderForSimpleSequenceClassification(model.config,class_config)\n",
    "    \n",
    "    # Set encoder and embedding weights to checkpoint weights\n",
    "    class_model.shared=model.shared\n",
    "    class_model.encoder=model.encoder    \n",
    "    \n",
    "    # Delete the checkpoint model\n",
    "    model=class_model\n",
    "    del class_model\n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "    # Add model modification lora\n",
    "    config = DoRAConfig(dora_rank=dora_rank, dora_init_scale=dora_init_scale)\n",
    "    \n",
    "    # Add LoRA layers\n",
    "    model = modify_with_dora(model, config)\n",
    "    \n",
    "    # Freeze Embeddings and Encoder (except LoRA)\n",
    "    for (param_name, param) in model.shared.named_parameters():\n",
    "                param.requires_grad = False\n",
    "    for (param_name, param) in model.encoder.named_parameters():\n",
    "                param.requires_grad = False       \n",
    "\n",
    "    for (param_name, param) in model.named_parameters():\n",
    "            if re.fullmatch(config.trainable_param_names, param_name):\n",
    "                param.requires_grad = True\n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_DoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4d56b2-c9ca-460d-b977-a1e4ae1e9568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4550fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    \"\"\"Custom early stopping callback that can monitor loss or accuracy.\"\"\"\n",
    "    \n",
    "    def __init__(self, metric_name='eval_loss', early_stopping_patience=3, minimize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric_name (str): Metric to monitor, default 'eval_loss'.\n",
    "            early_stopping_patience (int): Number of checks with no improvement after which training will be stopped.\n",
    "            minimize (bool): Set to True if the metric should be minimized, False if it should be maximized.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_counter = 0\n",
    "        self.minimize = minimize\n",
    "        self.best_metric = float('inf') if minimize else float('-inf')\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        current_metric = kwargs['metrics'][self.metric_name]\n",
    "        \n",
    "        if (self.minimize and current_metric < self.best_metric) or (not self.minimize and current_metric > self.best_metric):\n",
    "            self.best_metric = current_metric\n",
    "            self.early_stopping_counter = 0\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "        \n",
    "        if self.early_stopping_counter >= self.early_stopping_patience:\n",
    "            control.should_training_stop = True\n",
    "            print(f'Stopping early! No improvement in {self.metric_name} for {self.early_stopping_patience} evaluation steps.')\n",
    "\n",
    "\n",
    "class MultiObjectiveEarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        # Extract current validation loss and accuracy\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "\n",
    "        # Check if current loss and accuracy improved significantly\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            # Update best scores and reset wait time\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            # If no improvement, increment the wait counter\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                # If wait exceeds the patience, stop training\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "class MultiObjectiveEarlyStoppingAndSaveCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001, output_dir='./model_output', filename='finetuned_model'):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "        self.output_dir = output_dir\n",
    "        self.filename = filename\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "        model = kwargs['model']\n",
    "\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "            # Save the model as the best so far\n",
    "            self.save_finetuned_parameters(model, os.path.join(self.output_dir, self.filename))\n",
    "            print(f\"Saved improved model to {self.output_dir}/{self.filename}\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "    def save_finetuned_parameters(self, model, filepath):\n",
    "        # Create a dictionary to hold the non-frozen parameters\n",
    "        non_frozen_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "        # Save only the finetuned parameters \n",
    "        torch.save(non_frozen_params, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb8bb11-79b0-4936-9099-f9f8ef97e105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "# Set random seeds for reproducibility of your trainings run\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, min_dist=0.01):\n",
    "    umap_model = umap.UMAP(n_components=n_components)\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    data = {\"UMAP1\": embeddings[:, 0], \"UMAP2\": embeddings[:, 1], \"Label\": labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9)\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_new.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "# Main training fuction\n",
    "def train_per_protein(\n",
    "        train_dataset,         #training data\n",
    "        valid_dataset,         #validation data      \n",
    "        weight_decay,\n",
    "        warmup_pct,\n",
    "        num_labels= 2,    #1 for regression, >1 for classification\n",
    "    \n",
    "        # effective training batch size is batch * accum\n",
    "        # we recommend an effective batch size of 8 \n",
    "        batch= 4,         #for training\n",
    "        accum= 2,         #gradient accumulation\n",
    "    \n",
    "        val_batch = 16,   #batch size for evaluation\n",
    "        epochs=1,       #training epochs\n",
    "        lr= 3e-4,         #recommended learning rate\n",
    "        seed= 42,         #random seed\n",
    "        deepspeed=False,  #if gpu is large enough disable deepspeed for training speedup\n",
    "        gpu= 1,\n",
    "        dropout=0.5, #dropout rate\n",
    "         #L2 weight regularization\n",
    "        dora_rank=4,      #dora rank\n",
    "        dora_init_scale=0.01, #dora scaling rank\n",
    "        ):         #gpu selection (1 for first gpu)\n",
    "\n",
    "    # Set gpu device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # load model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=dropout, dora_rank=dora_rank, dora_init_scale=dora_init_scale)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    total_steps = epochs * len(train_dataset) // batch\n",
    "    warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "    # Define TrainingArguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir='./results',              # where to save the model\n",
    "        evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "        logging_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        learning_rate=lr,                    # initial learning rate\n",
    "        per_device_train_batch_size=batch,   # batch size per device\n",
    "        gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "        num_train_epochs=epochs,             # number of epochs to train\n",
    "        weight_decay=weight_decay,           # L2 weight regularization\n",
    "        warmup_steps=warmup_steps,           # 10% of total steps\n",
    "        load_best_model_at_end=False,         # load the best model at the end of training\n",
    "        seed=seed,                           # random seed\n",
    "        push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "        logging_dir='./logs',\n",
    "    )\n",
    "    # metric_for_best_model='eval_loss|accuracy'\n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        # Check if predictions have the expected shape\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "        # Now, compute the metric (e.g., accuracy)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        # Return the metric(s) as a dictionary\n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    # For minimizing loss\n",
    "    early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "    # For maximizing accuracy\n",
    "    early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "            early_stopping_patience=3,\n",
    "            min_delta=0.001,\n",
    "            output_dir='./model_output',\n",
    "            filename='finetuned_model_all_dora_smac_otherdataset.pth'\n",
    "        )],\n",
    "    )    \n",
    "\n",
    "    def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "        embeddings = []\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "    \n",
    "        # Iterate over the sequences in batches\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            # Extract a batch of sequences\n",
    "            batch = sequences[i:i + batch_size]\n",
    "    \n",
    "            # Tokenize the batch using the specified tokenizer and convert to PyTorch tensors\n",
    "            inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                # Forward pass through the model to obtain outputs\n",
    "                outputs = model(**inputs)\n",
    "    \n",
    "            # Extract hidden states from the second-to-last layer (penultimate layer)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "    \n",
    "            # Take the embeddings from the second-to-last layer\n",
    "            embeddings_from_layer = hidden_states[:, 0, :]\n",
    "    \n",
    "            # Extend the list with the generated embeddings\n",
    "            embeddings.extend(embeddings_from_layer)\n",
    "    \n",
    "            print(f\"Batch {i // batch_size + 1}, Second-to-Last Layer Embeddings Shape: {embeddings_from_layer.shape}\")\n",
    "    \n",
    "        return np.array(embeddings)\n",
    "\n",
    "        \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    # Get the best model\n",
    "    # model = trainer.model\n",
    "    # Ensure the best model is loaded\n",
    "    best_model_path = os.path.join('./model_output', 'finetuned_model_all_dora_smac_otherdataset.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        state_dict = torch.load(best_model_path)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "    # Evaluate the best model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(eval_results)\n",
    "    \n",
    "    # Print the current learning rate\n",
    "    # current_lr = trainer.optimizer.param_groups[0]['lr']\n",
    "    # print(f\"Current learning rate: {current_lr}\")\n",
    "    \n",
    "    # valid_sequences = list(valid_dataset['sequence'])\n",
    "    # valid_embeddings = get_embeddings(model, tokenizer, valid_sequences)\n",
    "\n",
    "    # # Apply UMAP for dimensionality reduction\n",
    "    # umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "    # # Plot UMAP embeddings\n",
    "    # labels = list(valid_dataset['label'])\n",
    "    # plot_umap(umap_embeddings, labels)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b300952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Dataset creation\n",
    "def create_dataset(tokenizer,seqs,labels):\n",
    "    tokenized = tokenizer(seqs, max_length=1024, padding=True, truncation=True)\n",
    "    dataset = Dataset.from_dict(tokenized)\n",
    "    dataset = dataset.add_column(\"labels\", labels)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\") \n",
    "\n",
    "\n",
    "train_df = my_train\n",
    "valid_df = my_valid\n",
    "\n",
    "# Preprocess inputs\n",
    "# Replace uncommon AAs with \"X\"\n",
    "train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "# Add spaces between each amino acid for PT5 to correctly use them\n",
    "train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "# Create Datasets\n",
    "train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']))\n",
    "valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from ConfigSpace import ConfigurationSpace, Configuration\n",
    "from ConfigSpace.hyperparameters import UniformFloatHyperparameter, CategoricalHyperparameter, UniformIntegerHyperparameter\n",
    "from smac import HyperparameterOptimizationFacade as HPOFacade\n",
    "from smac import Scenario\n",
    "from smac.intensifier.hyperband import Hyperband\n",
    "from smac.multi_objective.parego import ParEGO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "class ProteinModel:\n",
    "    @property\n",
    "    def configspace(self) -> ConfigurationSpace:\n",
    "        cs = ConfigurationSpace()\n",
    "\n",
    "        cs.add_hyperparameters([\n",
    "            UniformFloatHyperparameter('lr', lower=1e-5, upper=1e-2, log=True),\n",
    "            CategoricalHyperparameter('batch', choices=[1, 2, 4, 8]),\n",
    "            CategoricalHyperparameter('accum', choices=[2, 4, 8]),\n",
    "            UniformFloatHyperparameter('dropout_rate', lower=0.1, upper=0.9),\n",
    "            UniformFloatHyperparameter('weight_decay', lower=1e-5, upper=1e-3, log=True),\n",
    "            UniformFloatHyperparameter('warmup_pct', lower=0.01, upper=0.3),\n",
    "            UniformIntegerHyperparameter('dora_rank', lower=4, upper=32),\n",
    "            UniformFloatHyperparameter('dora_init_scale', lower=1e-4, upper=1e-1, log=True),\n",
    "        ])\n",
    "\n",
    "        cs['dora_rank'].q = 4\n",
    "\n",
    "        return cs\n",
    "\n",
    "    def train(self, config: Configuration, seed: int = 42, budget: int = 10) -> dict[str, float]:\n",
    "        logger.info(f\"Training with budget (epochs): {budget}\")\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "            # Call your training function\n",
    "            tokenizer, model, history = train_per_protein(\n",
    "                train_dataset=train_set,\n",
    "                valid_dataset=valid_set,\n",
    "                num_labels=2,\n",
    "                batch=int(config['batch']),\n",
    "                accum=int(config['accum']),\n",
    "                epochs=int(budget),\n",
    "                lr=config['lr'],\n",
    "                dropout=config['dropout_rate'],\n",
    "                weight_decay=config['weight_decay'],\n",
    "                warmup_pct=config['warmup_pct'],\n",
    "                dora_rank=config['dora_rank'],\n",
    "                dora_init_scale=config['dora_init_scale'],\n",
    "                seed=seed\n",
    "            )\n",
    "\n",
    "            # Extract the last validation accuracy and loss from the history\n",
    "            val_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry][-1]\n",
    "            val_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry][-1]\n",
    "\n",
    "        logger.info(f\"Completed training. Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n",
    "        return {\n",
    "            \"val_loss\": val_loss,\n",
    "            \"1 - val_accuracy\": 1 - val_accuracy,  # We minimize, so we use 1 - accuracy\n",
    "        }\n",
    "\n",
    "def plot_pareto(smac: HPOFacade, incumbents: list[Configuration]) -> None:\n",
    "    \"\"\"Plots configurations from SMAC and highlights the best configurations in a Pareto front.\"\"\"\n",
    "    average_costs = []\n",
    "    average_pareto_costs = []\n",
    "    for config in smac.runhistory.get_configs():\n",
    "        # Since we use multiple seeds, we have to average them to get only one cost value pair for each configuration\n",
    "        average_cost = smac.runhistory.average_cost(config)\n",
    "\n",
    "        if config in incumbents:\n",
    "            average_pareto_costs += [average_cost]\n",
    "        else:\n",
    "            average_costs += [average_cost]\n",
    "\n",
    "    # Let's work with a numpy array\n",
    "    costs = np.vstack(average_costs)\n",
    "    pareto_costs = np.vstack(average_pareto_costs)\n",
    "    pareto_costs = pareto_costs[pareto_costs[:, 0].argsort()]  # Sort them\n",
    "\n",
    "    costs_x, costs_y = costs[:, 0], costs[:, 1]\n",
    "    pareto_costs_x, pareto_costs_y = pareto_costs[:, 0], pareto_costs[:, 1]\n",
    "\n",
    "    plt.scatter(costs_x, costs_y, marker=\"x\", label=\"Configuration\")\n",
    "    plt.scatter(pareto_costs_x, pareto_costs_y, marker=\"x\", c=\"r\", label=\"Incumbent\")\n",
    "    plt.step(\n",
    "        [pareto_costs_x[0]] + pareto_costs_x.tolist() + [np.max(costs_x)],  # We add bounds\n",
    "        [np.max(costs_y)] + pareto_costs_y.tolist() + [np.min(pareto_costs_y)],  # We add bounds\n",
    "        where=\"post\",\n",
    "        linestyle=\":\",\n",
    "    )\n",
    "\n",
    "    plt.title(\"Pareto-Front\")\n",
    "    plt.xlabel(smac.scenario.objectives[0])\n",
    "    plt.ylabel(smac.scenario.objectives[1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    protein_model = ProteinModel()\n",
    "    objectives = [\"val_loss\", \"1 - val_accuracy\"]\n",
    "\n",
    "    # Define output directory\n",
    "    output_dir = \"./smac3_output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define our environment variables\n",
    "    scenario = Scenario(\n",
    "        protein_model.configspace,\n",
    "        objectives=objectives,\n",
    "        # walltime_limit=1800,  # After 30 minutes, we stop the hyperparameter optimization\n",
    "        n_trials=30,  # Evaluate up to 30 different configurations\n",
    "        min_budget=5,\n",
    "        max_budget=20,\n",
    "        n_workers=1,\n",
    "        output_directory=output_dir,\n",
    "        name=\"ProteinModelOptimization_9\",\n",
    "    )\n",
    "\n",
    "    # We want to run five random configurations before starting the optimization.\n",
    "    initial_design = HPOFacade.get_initial_design(scenario, n_configs=5)\n",
    "\n",
    "    intensifier = HPOFacade.get_intensifier(scenario, max_config_calls=2)\n",
    "\n",
    "    # Set up the multi-objective optimizer\n",
    "    multi_objective_algorithm = ParEGO(scenario=scenario)\n",
    "\n",
    "    # Create our SMAC object and pass the scenario and the train method\n",
    "    smac = HPOFacade(\n",
    "        scenario,\n",
    "        protein_model.train,\n",
    "        initial_design=initial_design,\n",
    "        multi_objective_algorithm=multi_objective_algorithm,\n",
    "        intensifier=intensifier,\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    # Let's optimize\n",
    "    incumbents = smac.optimize()\n",
    "\n",
    "    # Prepare results\n",
    "    # all_runs = []\n",
    "\n",
    "    print(\"**************\")\n",
    "    print(\"\\nBest configurations:\")\n",
    "    for incumbent in incumbents:\n",
    "        print(\"Configuration: \", incumbent)\n",
    "        print(\"Average Cost: \", smac.runhistory.average_cost(incumbent))\n",
    "        print(\"Value: \", smac.runhistory.get_cost(incumbent))\n",
    "        print(\"Hyperparameters: \", dict(incumbent))\n",
    "        # print(\"---\", cost)\n",
    "\n",
    "    # Let's plot a pareto front\n",
    "    plot_pareto(smac, incumbents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f20a2048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING][target_function_runner.py:74] The argument budget is not set by SMAC: Consider removing it from the target function.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.5229111313819885, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 4.7586, 'eval_samples_per_second': 83.217, 'eval_steps_per_second': 10.507, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5229111313819885, Val Accuracy: 0.7474747474747475\n",
      "[INFO][abstract_intensifier.py:516] Added config 64bf09 as new incumbent because there are no incumbents yet.\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5287478566169739, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 4.5953, 'eval_samples_per_second': 86.175, 'eval_steps_per_second': 10.881, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5287478566169739, Val Accuracy: 0.7474747474747475\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5388045907020569, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 4.6274, 'eval_samples_per_second': 85.578, 'eval_steps_per_second': 10.805, 'epoch': 6.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5388045907020569, Val Accuracy: 0.7550505050505051\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.547199547290802, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 4.5901, 'eval_samples_per_second': 86.273, 'eval_steps_per_second': 10.893, 'epoch': 5.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.547199547290802, Val Accuracy: 0.7626262626262627\n",
      "[INFO][abstract_intensifier.py:603] Config 236c68 is a new incumbent. Total number of incumbents: 2.\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 4.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 4.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5371304154396057, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 4.6006, 'eval_samples_per_second': 86.076, 'eval_steps_per_second': 10.868, 'epoch': 4.99}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5371304154396057, Val Accuracy: 0.7474747474747475\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 4.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 4.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.541582465171814, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 4.5924, 'eval_samples_per_second': 86.229, 'eval_steps_per_second': 10.888, 'epoch': 4.99}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.541582465171814, Val Accuracy: 0.7474747474747475\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5357666015625, 'eval_accuracy': 0.7752525252525253, 'eval_runtime': 4.5932, 'eval_samples_per_second': 86.214, 'eval_steps_per_second': 10.886, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5357666015625, Val Accuracy: 0.7752525252525253\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5388187170028687, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 4.5908, 'eval_samples_per_second': 86.26, 'eval_steps_per_second': 10.891, 'epoch': 8.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5388187170028687, Val Accuracy: 0.7626262626262627\n",
      "[INFO][abstract_intensifier.py:595] Added config 40ee93 and rejected config 236c68 as incumbent because it is not better than the incumbents on 2 instances:\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.5270348191261292, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 4.5976, 'eval_samples_per_second': 86.133, 'eval_steps_per_second': 10.875, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5270348191261292, Val Accuracy: 0.7727272727272727\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.5330994129180908, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 4.5923, 'eval_samples_per_second': 86.231, 'eval_steps_per_second': 10.888, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5330994129180908, Val Accuracy: 0.76010101010101\n",
      "[INFO][abstract_intensifier.py:603] Config c16cb2 is a new incumbent. Total number of incumbents: 3.\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5225592851638794, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 4.5927, 'eval_samples_per_second': 86.224, 'eval_steps_per_second': 10.887, 'epoch': 9.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5225592851638794, Val Accuracy: 0.7575757575757576\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5271132588386536, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 4.5942, 'eval_samples_per_second': 86.195, 'eval_steps_per_second': 10.883, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5271132588386536, Val Accuracy: 0.7575757575757576\n",
      "[INFO][abstract_intensifier.py:595] Added config ec0ed2 and rejected config 64bf09 as incumbent because it is not better than the incumbents on 2 instances:\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5354554057121277, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 4.5903, 'eval_samples_per_second': 86.268, 'eval_steps_per_second': 10.892, 'epoch': 5.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5354554057121277, Val Accuracy: 0.7626262626262627\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5318551659584045, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 4.5916, 'eval_samples_per_second': 86.244, 'eval_steps_per_second': 10.889, 'epoch': 5.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5318551659584045, Val Accuracy: 0.76010101010101\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.5223730206489563, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 4.5032, 'eval_samples_per_second': 87.937, 'eval_steps_per_second': 11.103, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5223730206489563, Val Accuracy: 0.7550505050505051\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5292856097221375, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 4.6203, 'eval_samples_per_second': 85.708, 'eval_steps_per_second': 10.822, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5292856097221375, Val Accuracy: 0.7474747474747475\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5371798276901245, 'eval_accuracy': 0.7651515151515151, 'eval_runtime': 4.6152, 'eval_samples_per_second': 85.804, 'eval_steps_per_second': 10.834, 'epoch': 9.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5371798276901245, Val Accuracy: 0.7651515151515151\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.541894257068634, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 4.5988, 'eval_samples_per_second': 86.109, 'eval_steps_per_second': 10.872, 'epoch': 8.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.541894257068634, Val Accuracy: 0.7550505050505051\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.52999347448349, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 4.6014, 'eval_samples_per_second': 86.061, 'eval_steps_per_second': 10.866, 'epoch': 9.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.52999347448349, Val Accuracy: 0.7727272727272727\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5380377769470215, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 4.6139, 'eval_samples_per_second': 85.827, 'eval_steps_per_second': 10.837, 'epoch': 8.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5380377769470215, Val Accuracy: 0.76010101010101\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.52849280834198, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 4.5911, 'eval_samples_per_second': 86.254, 'eval_steps_per_second': 10.891, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.52849280834198, Val Accuracy: 0.7575757575757576\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.5339053273200989, 'eval_accuracy': 0.7651515151515151, 'eval_runtime': 4.5936, 'eval_samples_per_second': 86.206, 'eval_steps_per_second': 10.885, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5339053273200989, Val Accuracy: 0.7651515151515151\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.5859256982803345, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 4.5946, 'eval_samples_per_second': 86.189, 'eval_steps_per_second': 10.882, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5859256982803345, Val Accuracy: 0.7575757575757576\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.5868285298347473, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 4.5954, 'eval_samples_per_second': 86.173, 'eval_steps_per_second': 10.88, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5868285298347473, Val Accuracy: 0.7474747474747475\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.5496403574943542, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 4.5979, 'eval_samples_per_second': 86.126, 'eval_steps_per_second': 10.875, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5496403574943542, Val Accuracy: 0.7702020202020202\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.5528393387794495, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 4.6172, 'eval_samples_per_second': 85.766, 'eval_steps_per_second': 10.829, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5528393387794495, Val Accuracy: 0.7550505050505051\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5302585363388062, 'eval_accuracy': 0.7727272727272727, 'eval_runtime': 4.5938, 'eval_samples_per_second': 86.204, 'eval_steps_per_second': 10.884, 'epoch': 9.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5302585363388062, Val Accuracy: 0.7727272727272727\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5357747673988342, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 4.61, 'eval_samples_per_second': 85.899, 'eval_steps_per_second': 10.846, 'epoch': 8.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5357747673988342, Val Accuracy: 0.7575757575757576\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.5473637580871582, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 4.5936, 'eval_samples_per_second': 86.208, 'eval_steps_per_second': 10.885, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5473637580871582, Val Accuracy: 0.7702020202020202\n",
      "[INFO][1184887808.py:51] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n",
      "{'eval_loss': 0.5497574210166931, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 4.5903, 'eval_samples_per_second': 86.269, 'eval_steps_per_second': 10.893, 'epoch': 10.0}\n",
      "[INFO][1184887808.py:77] Completed training. Val Loss: 0.5497574210166931, Val Accuracy: 0.7525252525252525\n",
      "[INFO][smbo.py:328] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:329] --- Remaining wallclock time: inf\n",
      "[INFO][smbo.py:330] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:331] --- Remaining trials: 0\n",
      "**************\n",
      "\n",
      "Best configurations:\n",
      "Configuration:  Configuration(values={\n",
      "  'accum': 2,\n",
      "  'batch': 2,\n",
      "  'dora_init_scale': 0.024006745661,\n",
      "  'dora_rank': 29,\n",
      "  'dropout_rate': 0.6721760936081,\n",
      "  'lr': 5.48587897e-05,\n",
      "  'warmup_pct': 0.0297671536077,\n",
      "  'weight_decay': 0.0001951187595,\n",
      "})\n",
      "Average Cost:  [0.5372926592826843, 0.23106060606060602]\n",
      "Value:  0.13304686090505893\n",
      "Hyperparameters:  {'accum': 2, 'batch': 2, 'dora_init_scale': 0.024006745661, 'dora_rank': 29, 'dropout_rate': 0.6721760936081, 'lr': 5.48587897e-05, 'warmup_pct': 0.0297671536077, 'weight_decay': 0.0001951187595}\n",
      "Configuration:  Configuration(values={\n",
      "  'accum': 2,\n",
      "  'batch': 8,\n",
      "  'dora_init_scale': 0.0117554862589,\n",
      "  'dora_rank': 25,\n",
      "  'dropout_rate': 0.5496946819127,\n",
      "  'lr': 6.71570348e-05,\n",
      "  'warmup_pct': 0.1596670631319,\n",
      "  'weight_decay': 4.08175127e-05,\n",
      "})\n",
      "Average Cost:  [0.53006711602211, 0.23358585858585862]\n",
      "Value:  0.1617554890629116\n",
      "Hyperparameters:  {'accum': 2, 'batch': 8, 'dora_init_scale': 0.0117554862589, 'dora_rank': 25, 'dropout_rate': 0.5496946819127, 'lr': 6.71570348e-05, 'warmup_pct': 0.1596670631319, 'weight_decay': 4.08175127e-05}\n",
      "Configuration:  Configuration(values={\n",
      "  'accum': 2,\n",
      "  'batch': 8,\n",
      "  'dora_init_scale': 0.0137852934656,\n",
      "  'dora_rank': 27,\n",
      "  'dropout_rate': 0.2688213481119,\n",
      "  'lr': 7.7842881e-05,\n",
      "  'warmup_pct': 0.1156380270012,\n",
      "  'weight_decay': 1.78651801e-05,\n",
      "})\n",
      "Average Cost:  [0.5248362720012665, 0.24242424242424243]\n",
      "Value:  0.3182450227585391\n",
      "Hyperparameters:  {'accum': 2, 'batch': 8, 'dora_init_scale': 0.0137852934656, 'dora_rank': 27, 'dropout_rate': 0.2688213481119, 'lr': 7.7842881e-05, 'warmup_pct': 0.1156380270012, 'weight_decay': 1.78651801e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_857310/1184887808.py:35: DeprecationWarning: Please use `space.add(hyperparameters)`\n",
      "  cs.add_hyperparameters([\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 08:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.703500</td>\n",
       "      <td>0.658976</td>\n",
       "      <td>0.661616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.658300</td>\n",
       "      <td>0.607222</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.621700</td>\n",
       "      <td>0.569210</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.604700</td>\n",
       "      <td>0.543950</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.589900</td>\n",
       "      <td>0.540848</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.597500</td>\n",
       "      <td>0.539803</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.567100</td>\n",
       "      <td>0.532893</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>0.529608</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>0.522911</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.522968</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='613' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 613/1980 02:34 < 05:46, 3.95 it/s, Epoch 3.09/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>0.656477</td>\n",
       "      <td>0.646465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.603181</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.619600</td>\n",
       "      <td>0.561543</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='247' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [247/490 03:21 < 03:19, 1.22 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.647500</td>\n",
       "      <td>0.573561</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.512400</td>\n",
       "      <td>0.539052</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.494100</td>\n",
       "      <td>0.561860</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='247' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [247/490 03:21 < 03:19, 1.22 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.651800</td>\n",
       "      <td>0.573205</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.578178</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.497100</td>\n",
       "      <td>0.584244</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1760' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1760/3960 05:18 < 06:39, 5.51 it/s, Epoch 4.44/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.664100</td>\n",
       "      <td>0.612092</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.596200</td>\n",
       "      <td>0.566200</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.569800</td>\n",
       "      <td>0.551561</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.564700</td>\n",
       "      <td>0.542403</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='796' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [796/990 05:27 < 01:19, 2.43 it/s, Epoch 8.03/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.686200</td>\n",
       "      <td>0.669610</td>\n",
       "      <td>0.618687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>0.625629</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.585198</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.574600</td>\n",
       "      <td>0.557433</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>0.543222</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.542800</td>\n",
       "      <td>0.536010</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.531589</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.510700</td>\n",
       "      <td>0.528458</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/3960 06:01 < 06:01, 5.47 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.593419</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.556500</td>\n",
       "      <td>0.535455</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.551654</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.494900</td>\n",
       "      <td>0.575025</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.473800</td>\n",
       "      <td>0.590542</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='559' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 559/3960 01:40 < 10:11, 5.56 it/s, Epoch 1.41/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>0.595500</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2547' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2547/3960 08:06 < 04:29, 5.24 it/s, Epoch 6.43/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.674600</td>\n",
       "      <td>0.640235</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.608300</td>\n",
       "      <td>0.571276</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.540043</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.535200</td>\n",
       "      <td>0.540364</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.510300</td>\n",
       "      <td>0.543052</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.537180</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2113' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2113/3960 06:24 < 05:36, 5.48 it/s, Epoch 5.33/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.665820</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.649000</td>\n",
       "      <td>0.616016</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.600700</td>\n",
       "      <td>0.573478</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.573500</td>\n",
       "      <td>0.547915</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.540500</td>\n",
       "      <td>0.537132</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 06:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>0.678906</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>0.650339</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.639400</td>\n",
       "      <td>0.618275</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.613100</td>\n",
       "      <td>0.588356</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.583400</td>\n",
       "      <td>0.563829</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.573700</td>\n",
       "      <td>0.546238</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.537600</td>\n",
       "      <td>0.537064</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.527700</td>\n",
       "      <td>0.532242</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.524900</td>\n",
       "      <td>0.528493</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.527950</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='410' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [410/990 02:47 < 03:58, 2.43 it/s, Epoch 4.13/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.697700</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.588384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>0.651068</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.645100</td>\n",
       "      <td>0.617434</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.615200</td>\n",
       "      <td>0.588286</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 06:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.680890</td>\n",
       "      <td>0.580808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.670300</td>\n",
       "      <td>0.655762</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.640300</td>\n",
       "      <td>0.625675</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.611500</td>\n",
       "      <td>0.597101</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.576254</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.570400</td>\n",
       "      <td>0.564383</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>0.556924</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.541600</td>\n",
       "      <td>0.552039</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.536700</td>\n",
       "      <td>0.549640</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.537900</td>\n",
       "      <td>0.548931</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 06:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.679968</td>\n",
       "      <td>0.578283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.672600</td>\n",
       "      <td>0.656012</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.643100</td>\n",
       "      <td>0.625264</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.613800</td>\n",
       "      <td>0.596136</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.586600</td>\n",
       "      <td>0.578677</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.564800</td>\n",
       "      <td>0.567458</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.552600</td>\n",
       "      <td>0.559816</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.537900</td>\n",
       "      <td>0.553496</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.538500</td>\n",
       "      <td>0.552839</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3564' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3564/3960 10:51 < 01:12, 5.47 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.682700</td>\n",
       "      <td>0.662612</td>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>0.608652</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.593600</td>\n",
       "      <td>0.566550</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.544211</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>0.536345</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.550700</td>\n",
       "      <td>0.530259</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.523000</td>\n",
       "      <td>0.536047</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.526600</td>\n",
       "      <td>0.539420</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.527300</td>\n",
       "      <td>0.538127</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2691' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2691/3960 08:08 < 03:50, 5.51 it/s, Epoch 6.79/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.661348</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.643900</td>\n",
       "      <td>0.607413</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.595200</td>\n",
       "      <td>0.569252</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.567100</td>\n",
       "      <td>0.545332</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.535600</td>\n",
       "      <td>0.535775</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.543400</td>\n",
       "      <td>0.540514</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36bb3767-9ed8-49b9-a166-d7de567b03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm all_dephos_withDORA_datasetloader.sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcbe5f",
   "metadata": {},
   "source": [
    "    \"4\": {\n",
    "      \"accum\": 2,\n",
    "      \"batch\": 2,\n",
    "      \"dora_init_scale\": 0.024006745661,\n",
    "      \"dora_rank\": 29,\n",
    "      \"dropout_rate\": 0.6721760936081,\n",
    "      \"lr\": 5.48587897e-05,\n",
    "      \"warmup_pct\": 0.0297671536077,\n",
    "      \"weight_decay\": 0.0001951187595\n",
    "    },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a57f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddfce510-da2b-4b95-9491-49f9ae8efb06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3564' max='7920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3564/7920 11:03 < 13:31, 5.37 it/s, Epoch 9/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.637263</td>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.571090</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>0.548799</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.556200</td>\n",
       "      <td>0.541911</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.545200</td>\n",
       "      <td>0.538152</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.543900</td>\n",
       "      <td>0.533146</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.527200</td>\n",
       "      <td>0.534975</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>0.536380</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.530500</td>\n",
       "      <td>0.540802</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_dora_smac.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_dora_smac.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5331458449363708, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 4.7, 'eval_samples_per_second': 84.254, 'eval_steps_per_second': 10.638, 'epoch': 9.0}\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model, history = train_per_protein(train_set, valid_set, num_labels=2, batch=2, accum=2, epochs=20, seed=42, lr=5.48587897e-05, dropout=0.6721760936081, weight_decay=0.0001951187595, warmup_pct=0.0297671536077, dora_rank=29, dora_init_scale=0.024006745661)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a28d3c1-8e24-4437-a1d9-dda9cefccfd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Truncate the longer list to the size of the shorter one\n",
    "min_length = min(len(loss), len(val_loss))\n",
    "loss = loss[:min_length]\n",
    "val_loss = val_loss[:min_length]\n",
    "\n",
    "# Get spearman (for regression) or accuracy value (for classification)\n",
    "if [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x] != []:\n",
    "    metric = [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x]\n",
    "else:\n",
    "    metric = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n",
    "\n",
    "epochs = [x['epoch'] for x in history if 'loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "line1 = ax1.plot(epochs, loss, label='train_loss')\n",
    "line2 = ax1.plot(epochs, val_loss, label='validation_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "#line3 = ax2.plot(epochs, metric, color='red', label='validation_metric')\n",
    "ax2.set_ylabel('Metric')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Add grid lines\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 \n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History for fine-tuning\")\n",
    "plt.savefig(f\"../Plots/Without_3rdline_Training_History_new.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09bdab8",
   "metadata": {},
   "source": [
    "      \"dora_init_scale\": 0.024006745661,\n",
    "      \"dora_rank\": 29,\n",
    "      \"dropout_rate\": 0.6721760936081,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccb1bbda-d70e-4b4c-a8d4-24600495171a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "def load_model(filepath, num_labels=2):\n",
    "# Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "    # load a new model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=0.6721760936081, dora_rank=29, dora_init_scale=0.024006745661)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c97fa52-3aea-42e8-b72f-c4bb84808576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_DoRA_Classfier\n",
      "Trainable Parameter: 1200131.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_all_dora_smac_otherdataset.pth\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2c20e75-5f40-4ca1-9579-5df49b738fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have identical weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a62aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = from_pretrained(\"model_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50b8a403-e7c5-4912-9c7a-f404c060c32a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WUI4|HDAC7_HUMAN%342%358</td>\n",
       "      <td>ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|Q13950|RUNX2_HUMAN%416%432</td>\n",
       "      <td>THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q15796|SMAD2_HUMAN%229%245</td>\n",
       "      <td>DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%416%432</td>\n",
       "      <td>TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2798%2814</td>\n",
       "      <td>MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0   sp|Q8WUI4|HDAC7_HUMAN%342%358  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
       "1   sp|Q13950|RUNX2_HUMAN%416%432  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
       "2   sp|Q15796|SMAD2_HUMAN%229%245  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
       "3    sp|P05787|K2C8_HUMAN%416%432  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2798%2814  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "    \n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_Y.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2d18716-fd26-49fe-9ba4-b84c936a364c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sequence  label\n",
      "0  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
      "1  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
      "2  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
      "3  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
      "4  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1\n"
     ]
    }
   ],
   "source": [
    "my_test=df[[\"sequence\", \"label\"]]\n",
    "\n",
    "print(my_test.head(5))\n",
    "\n",
    "'''\n",
    "my_test[\"sequence\"]=my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "my_test['sequence']=my_test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "'''\n",
    "\n",
    "#Using .loc ensures that you are modifying the original DataFrame rather than a view of it, which helps avoid the SettingWithCopyWarning.\n",
    "# Replace characters in the \"sequence\" column\n",
    "my_test.loc[:, \"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Convert each sequence to a space-separated string\n",
    "my_test.loc[:, 'sequence'] = my_test.apply(lambda row: \" \".join(row[\"sequence\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eee8fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = sequence.split()\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "my_test['middle_char'] = my_test['sequence'].apply(get_middle_char)\n",
    "\n",
    "# Split the DataFrame\n",
    "my_test_S = my_test[my_test['middle_char'] == 'S'].drop(columns=['middle_char'])\n",
    "my_test_T = my_test[my_test['middle_char'] == 'T'].drop(columns=['middle_char'])\n",
    "my_test_Y = my_test[my_test['middle_char'] == 'Y'].drop(columns=['middle_char'])\n",
    "my_test_ST = my_test[my_test['middle_char'].isin(['S', 'T'])].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcd9ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0dff151-a667-4717-af18-401818bc4c22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:00<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.720577 |      0.846154 |         0.875 |       0.86 |    0.9375 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[22  4]\n",
      " [ 3 21]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ce2f51a-887c-4684-82b9-22ea5fffd334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['0', '1']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"../Plots/Confusion_matrix_for_dephos_new.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07603226",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5e0d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 28/28 [00:03<00:00,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+---------------+------------+-----------+\n",
      "|    MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+========+===============+===============+============+===========+\n",
      "| 0.6368 |      0.825893 |      0.810811 |   0.818386 |  0.868082 |\n",
      "+--------+---------------+---------------+------------+-----------+\n",
      "[[185  39]\n",
      " [ 42 180]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5528dc-6e06-456d-920f-8f05055d0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, n_neighbors=5, min_dist=0.01, metric='euclidean'):\n",
    "    umap_model = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric\n",
    "    )\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    df = pd.DataFrame({\n",
    "        \"UMAP1\": embeddings[:, 0],\n",
    "        \"UMAP2\": embeddings[:, 1],\n",
    "        \"Label\": labels\n",
    "    })\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = sns.scatterplot(\n",
    "        x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9\n",
    "    )\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.legend(title='Label', bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_ST.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "    embeddings = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch = sequences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "            embeddings.extend(hidden_states[:, 0, :])\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(sequences) // batch_size + 1}\")\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7718f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = list(sequence)\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "valid_df = df\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "valid_df['middle_char'] = valid_df['sequence'].apply(get_middle_char)\n",
    "\n",
    "valid_df = valid_df[valid_df['middle_char'] == 'T'].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a162964f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sp|Q9GZM8|NDEL1_HUMAN%203%219</td>\n",
       "      <td>CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>sp|Q8N163|CCAR2_HUMAN%438%454</td>\n",
       "      <td>EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>sp|P10636-8|TAU_HUMAN%196%212</td>\n",
       "      <td>GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>sp|Q02241|KIF23_HUMAN%434%450</td>\n",
       "      <td>QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sp|Q04206|TF65_HUMAN%419%435</td>\n",
       "      <td>QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>sp|Q76N33|STALP_MOUSE%326%342</td>\n",
       "      <td>ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>sp|P49790|NU153_HUMAN%1098%1114</td>\n",
       "      <td>FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>sp|Q8NFC6|BD1L1_HUMAN%2789%2805</td>\n",
       "      <td>DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>sp|Q5T6F2|UBAP2_HUMAN%514%530</td>\n",
       "      <td>SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>sp|Q9H040|SPRTN_HUMAN%265%281</td>\n",
       "      <td>NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name                           sequence  label\n",
       "180    sp|Q9GZM8|NDEL1_HUMAN%203%219  CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI      1\n",
       "181    sp|Q8N163|CCAR2_HUMAN%438%454  EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA      1\n",
       "182    sp|P10636-8|TAU_HUMAN%196%212  GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV      1\n",
       "183    sp|Q02241|KIF23_HUMAN%434%450  QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE      1\n",
       "184     sp|Q04206|TF65_HUMAN%419%435  QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG      1\n",
       "..                               ...                                ...    ...\n",
       "441    sp|Q76N33|STALP_MOUSE%326%342  ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS      0\n",
       "442  sp|P49790|NU153_HUMAN%1098%1114  FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ      0\n",
       "443  sp|Q8NFC6|BD1L1_HUMAN%2789%2805  DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL      0\n",
       "444    sp|Q5T6F2|UBAP2_HUMAN%514%530  SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS      0\n",
       "445    sp|Q9H040|SPRTN_HUMAN%265%281  NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN      0\n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a44d9187-1ac5-4e36-89a0-8f827a7f0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 3559427.0\n",
      "\n",
      "Processed batch 1/3\n",
      "Processed batch 2/3\n",
      "Processed batch 3/3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_df = my_valid\n",
    "\n",
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_ST.pth\",num_labels=2)\n",
    "\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "valid_sequences = list(valid_df['sequence'])\n",
    "valid_embeddings = get_embeddings(model_reload, tokenizer, valid_sequences)\n",
    "\n",
    "umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "\n",
    "labels = list(valid_df['label'])\n",
    "\n",
    "plot_umap(umap_embeddings, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f029bcf-42ef-4476-b575-3c14adb71b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da0e6c-e921-493b-9304-8ba9aad07d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a179b21",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a2319a5",
   "metadata": {},
   "source": [
    "This notebook will implement changing lora settings and separate dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1959ca-a3c9-46d8-8519-064c38f52007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:48:44.051741Z",
     "iopub.status.busy": "2024-04-05T12:48:44.050047Z",
     "iopub.status.idle": "2024-04-05T12:52:49.260801Z",
     "shell.execute_reply": "2024-04-05T12:52:49.259100Z",
     "shell.execute_reply.started": "2024-04-05T12:48:44.051657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torch==2.1.1 torchaudio torchvision tqdm==4.66.1 accelerate==0.24.1 biopython==1.81 numpy==1.26.2 pandas==2.1.3 \\\n",
    "# transformers==4.35.2 datasets==2.15.0 scikit-learn==1.3.2 umap-learn==0.5.5 sentencepiece==0.1.99 seaborn==0.13.0 scipy==1.11.4 \\\n",
    "# matplotlib==3.8.2 evaluate==0.4.1 deepspeed==0.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060d0bba-32ad-4dc9-b1b8-d1124da1336c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a377270-2995-4da1-a673-5369769a6279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:52:49.264011Z",
     "iopub.status.busy": "2024-04-05T12:52:49.263502Z",
     "iopub.status.idle": "2024-04-05T12:53:29.491461Z",
     "shell.execute_reply": "2024-04-05T12:53:29.490156Z",
     "shell.execute_reply.started": "2024-04-05T12:52:49.263956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install umap-learn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0148ff8f-80eb-4bbd-aac7-fe1f371da27a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.508233Z",
     "iopub.status.busy": "2024-04-05T12:53:29.507801Z",
     "iopub.status.idle": "2024-04-05T12:53:29.536614Z",
     "shell.execute_reply": "2024-04-05T12:53:29.514877Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.508197Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.1.1+cu121\n",
      "Cuda version:  12.1\n",
      "Numpy version:  1.26.4\n",
      "Pandas version:  2.1.3\n",
      "Transformers version:  4.35.2\n",
      "Datasets version:  2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96bd9396-a81c-4d87-a722-0d2020627dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.538488Z",
     "iopub.status.busy": "2024-04-05T12:53:29.538089Z",
     "iopub.status.idle": "2024-04-05T12:53:29.768968Z",
     "shell.execute_reply": "2024-04-05T12:53:29.767620Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.538452Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name                           sequence  label\n",
      "0  sp|P75863|-|344  CGSCRVQLLEGEVTPLKKSAMGDDGTILCCSCV      1\n",
      "1    sp|P0ABS8|-|7  ----------MLKNLAKLDQTEMDKVNVDLAAA      1\n",
      "2   sp|P0ABS8|-|74  AHRLASVNLSRLPYEPKLK--------------      1\n",
      "3    sp|P0A7D7|-|3  --------------MQKQAELYRGKAKTVYSTE      1\n",
      "4   sp|P0A7D7|-|52  DGARIEQFDRKGMVNNKFNYFIMSKLAEAGIPT      1\n",
      "\n",
      "Total sequences: 9499\n",
      "Positive sequences: 4749\n",
      "Negative sequences: 4750\n"
     ]
    }
   ],
   "source": [
    "# from Bio import SeqIO\n",
    "# import pandas as pd\n",
    "\n",
    "# sequences = []\n",
    "\n",
    "# local_fasta_path = '../src/input_datasets/train_Pos_Neg_ST.fasta'\n",
    "\n",
    "# # Load FASTA file using Biopython\n",
    "# for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "#     # Split the description to extract label\n",
    "#     description_parts = record.description.split(\"%\")\n",
    "#     label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "#     sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# local_fasta_path = '../src/input_datasets/train_Pos_Neg_Y.fasta'\n",
    "\n",
    "# for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "#     # Split the description to extract label\n",
    "#     description_parts = record.description.split(\"%\")\n",
    "#     label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "#     sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# # Create dataframe\n",
    "# df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# # Display the dataframe\n",
    "# df.head(5)\n",
    "\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "def process_fasta(file_path, label):\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        sequences.append([record.id, str(record.seq), label])\n",
    "    return sequences\n",
    "\n",
    "# Paths to your positive and negative FASTA files\n",
    "positive_fasta_path = '../src/input_datasets/positive_sites.fasta'\n",
    "negative_fasta_path = '../src/input_datasets/negative_sites.fasta'\n",
    "\n",
    "# Process both files\n",
    "positive_sequences = process_fasta(positive_fasta_path, 1)\n",
    "negative_sequences = process_fasta(negative_fasta_path, 0)\n",
    "\n",
    "# Combine positive and negative sequences\n",
    "all_sequences = positive_sequences + negative_sequences\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display some statistics\n",
    "print(f\"\\nTotal sequences: {len(df)}\")\n",
    "print(f\"Positive sequences: {len(positive_sequences)}\")\n",
    "print(f\"Negative sequences: {len(negative_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76760f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "(7599, 2)\n",
      "\n",
      "Validation Set:\n",
      "(1900, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "my_train, my_valid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "my_train=my_train[[\"sequence\", \"label\"]]\n",
    "my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the training set\n",
    "print(\"Training Set:\")\n",
    "print(my_train.shape)\n",
    "\n",
    "# Print the first 5 rows of the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a424877b-787c-44fe-bf87-33346ffd3be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.789138Z",
     "iopub.status.busy": "2024-04-05T12:53:29.788675Z",
     "iopub.status.idle": "2024-04-05T12:53:29.816779Z",
     "shell.execute_reply": "2024-04-05T12:53:29.815341Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.789094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifies an existing transformer and introduce the LoRA layers\n",
    "\n",
    "class LoRAConfig:\n",
    "    def __init__(self, lora_rank=8, lora_init_scale=0.01, lora_scaling_rank=2):\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_init_scale = lora_init_scale\n",
    "        self.lora_modules = \".*SelfAttention|.*EncDecAttention\"\n",
    "        self.lora_layers = \"q|k|v|o\"\n",
    "        self.trainable_param_names = \".*layer_norm.*|.*lora_[ab].*\"\n",
    "        self.lora_scaling_rank = lora_scaling_rank\n",
    "        # lora_modules and lora_layers are specified with regular expressions\n",
    "        # see https://www.w3schools.com/python/python_regex.asp for reference\n",
    "        \n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, scaling_rank, init_scale):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.rank = rank\n",
    "        self.scaling_rank = scaling_rank\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        if self.rank > 0:\n",
    "            self.lora_a = nn.Parameter(torch.randn(rank, linear_layer.in_features) * init_scale)\n",
    "            if init_scale < 0:\n",
    "                self.lora_b = nn.Parameter(torch.randn(linear_layer.out_features, rank) * init_scale)\n",
    "            else:\n",
    "                self.lora_b = nn.Parameter(torch.zeros(linear_layer.out_features, rank))\n",
    "        if self.scaling_rank:\n",
    "            self.multi_lora_a = nn.Parameter(\n",
    "                torch.ones(self.scaling_rank, linear_layer.in_features)\n",
    "                + torch.randn(self.scaling_rank, linear_layer.in_features) * init_scale\n",
    "            )\n",
    "            if init_scale < 0:\n",
    "                self.multi_lora_b = nn.Parameter(\n",
    "                    torch.ones(linear_layer.out_features, self.scaling_rank)\n",
    "                    + torch.randn(linear_layer.out_features, self.scaling_rank) * init_scale\n",
    "                )\n",
    "            else:\n",
    "                self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, self.scaling_rank))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.scaling_rank == 1 and self.rank == 0:\n",
    "            # parsimonious implementation for ia3 and lora scaling\n",
    "            if self.multi_lora_a.requires_grad:\n",
    "                hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n",
    "            else:\n",
    "                hidden = F.linear(input, self.weight, self.bias)\n",
    "            if self.multi_lora_b.requires_grad:\n",
    "                hidden = hidden * self.multi_lora_b.flatten()\n",
    "            return hidden\n",
    "        else:\n",
    "            # general implementation for lora (adding and scaling)\n",
    "            weight = self.weight\n",
    "            if self.scaling_rank:\n",
    "                weight = weight * torch.matmul(self.multi_lora_b, self.multi_lora_a) / self.scaling_rank\n",
    "            if self.rank:\n",
    "                weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n",
    "            return F.linear(input, weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, rank={}, scaling_rank={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.rank, self.scaling_rank\n",
    "        )\n",
    "\n",
    "\n",
    "def modify_with_lora(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.lora_modules, m_name):\n",
    "            for c_name, layer in dict(module.named_children()).items():\n",
    "                if re.fullmatch(config.lora_layers, c_name):\n",
    "                    assert isinstance(\n",
    "                        layer, nn.Linear\n",
    "                    ), f\"LoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        c_name,\n",
    "                        LoRALinear(layer, config.lora_rank, config.lora_scaling_rank, config.lora_init_scale),\n",
    "                    )\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e79b323-4677-4723-a5fd-a60dc13a3b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.819433Z",
     "iopub.status.busy": "2024-04-05T12:53:29.818965Z",
     "iopub.status.idle": "2024-04-05T12:53:29.845976Z",
     "shell.execute_reply": "2024-04-05T12:53:29.844438Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.819335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.7, num_labels=2):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class T5EncoderClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, class_config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "        \n",
    "        # Trainable emphasis factor\n",
    "        self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "    # def forward(self, hidden_states):\n",
    "    #     seq_length = hidden_states.size(1)\n",
    "    #     middle_idx = seq_length // 2\n",
    "    #     middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "    #     # Apply trainable emphasis factor\n",
    "    #     emphasized_middle_embedding = middle_embedding * self.emphasis_factor\n",
    "\n",
    "    #     # Combine with the average embedding\n",
    "    #     average_embedding = torch.mean(hidden_states, dim=1)\n",
    "    #     combined_embedding = emphasized_middle_embedding + average_embedding\n",
    "\n",
    "    #     x = self.dropout(combined_embedding)\n",
    "    #     x = self.dense(x)\n",
    "    #     x = torch.tanh(x)\n",
    "    #     x = self.dropout(x)\n",
    "    #     logits = self.out_proj(x)\n",
    "    #     return logits\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "\n",
    "        hidden_states =  torch.mean(hidden_states,dim=1)  # avg embedding\n",
    "\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = torch.tanh(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.out_proj(hidden_states)\n",
    "        return hidden_states\n",
    "    \n",
    "    # def forward(self, hidden_states):\n",
    "    #     # Original sequence length and middle index\n",
    "    #     seq_length = hidden_states.size(1)\n",
    "    #     middle_idx = seq_length // 2\n",
    "\n",
    "    #     # Extract the middle embedding vector\n",
    "    #     middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "    #     # Amplify the influence of the middle embedding\n",
    "    #     amplified_middle_embedding = middle_embedding * 2\n",
    "\n",
    "    #     # Combine with average to retain context\n",
    "    #     average_embedding = torch.mean(hidden_states, dim=1)\n",
    "    #     combined_embedding = 0.5 * amplified_middle_embedding + 0.5 * average_embedding\n",
    "\n",
    "    #     # Classification layers\n",
    "    #     x = self.dropout(combined_embedding)\n",
    "    #     x = self.dense(x)\n",
    "    #     x = torch.tanh(x)\n",
    "    #     x = self.dropout(x)\n",
    "    #     logits = self.out_proj(x)\n",
    "    #     return logits\n",
    "\n",
    "\n",
    "class T5EncoderForSimpleSequenceClassification(T5PreTrainedModel):\n",
    "\n",
    "    def __init__(self, config: T5Config, class_config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n",
    "\n",
    "        encoder_config = copy.deepcopy(config)\n",
    "        encoder_config.use_cache = False\n",
    "        encoder_config.is_encoder_decoder = False\n",
    "        self.encoder = T5Stack(encoder_config, self.shared)\n",
    "\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate) \n",
    "        self.classifier = T5EncoderClassificationHead(config, class_config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "    def parallelize(self, device_map=None):\n",
    "        self.device_map = (\n",
    "            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
    "            if device_map is None\n",
    "            else device_map\n",
    "        )\n",
    "        assert_device_map(self.device_map, len(self.encoder.block))\n",
    "        self.encoder.parallelize(self.device_map)\n",
    "        self.classifier = self.classifier.to(self.encoder.first_device)\n",
    "        self.model_parallel = True\n",
    "\n",
    "    def deparallelize(self):\n",
    "        self.encoder.deparallelize()\n",
    "        self.encoder = self.encoder.to(\"cpu\")\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.shared\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.shared = new_embeddings\n",
    "        self.encoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "        logits = self.classifier(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71394626-6f8b-4ca5-80f3-c697e4320bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.848217Z",
     "iopub.status.busy": "2024-04-05T12:53:29.847782Z",
     "iopub.status.idle": "2024-04-05T12:53:29.859841Z",
     "shell.execute_reply": "2024-04-05T12:53:29.858398Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.848182Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PT5_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "    # Load PT5 and tokenizer\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\") \n",
    "    \n",
    "    # Create new Classifier model with PT5 dimensions\n",
    "    class_config=ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "    class_model=T5EncoderForSimpleSequenceClassification(model.config,class_config)\n",
    "    \n",
    "    # Set encoder and embedding weights to checkpoint weights\n",
    "    class_model.shared=model.shared\n",
    "    class_model.encoder=model.encoder    \n",
    "    \n",
    "    # Delete the checkpoint model\n",
    "    model=class_model\n",
    "    del class_model\n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "    # Add model modification lora\n",
    "    config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "    # Add LoRA layers\n",
    "    model = modify_with_lora(model, config)\n",
    "    \n",
    "    # Freeze Embeddings and Encoder (except LoRA)\n",
    "    for (param_name, param) in model.shared.named_parameters():\n",
    "                param.requires_grad = False\n",
    "    for (param_name, param) in model.encoder.named_parameters():\n",
    "                param.requires_grad = False       \n",
    "\n",
    "    for (param_name, param) in model.named_parameters():\n",
    "            if re.fullmatch(config.trainable_param_names, param_name):\n",
    "                param.requires_grad = True\n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4d56b2-c9ca-460d-b977-a1e4ae1e9568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.864172Z",
     "iopub.status.busy": "2024-04-05T12:53:29.863760Z",
     "iopub.status.idle": "2024-04-05T12:53:29.873119Z",
     "shell.execute_reply": "2024-04-05T12:53:29.871609Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.864135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4550fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    \"\"\"Custom early stopping callback that can monitor loss or accuracy.\"\"\"\n",
    "    \n",
    "    def __init__(self, metric_name='eval_loss', early_stopping_patience=3, minimize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric_name (str): Metric to monitor, default 'eval_loss'.\n",
    "            early_stopping_patience (int): Number of checks with no improvement after which training will be stopped.\n",
    "            minimize (bool): Set to True if the metric should be minimized, False if it should be maximized.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_counter = 0\n",
    "        self.minimize = minimize\n",
    "        self.best_metric = float('inf') if minimize else float('-inf')\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        current_metric = kwargs['metrics'][self.metric_name]\n",
    "        \n",
    "        if (self.minimize and current_metric < self.best_metric) or (not self.minimize and current_metric > self.best_metric):\n",
    "            self.best_metric = current_metric\n",
    "            self.early_stopping_counter = 0\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "        \n",
    "        if self.early_stopping_counter >= self.early_stopping_patience:\n",
    "            control.should_training_stop = True\n",
    "            print(f'Stopping early! No improvement in {self.metric_name} for {self.early_stopping_patience} evaluation steps.')\n",
    "\n",
    "\n",
    "class MultiObjectiveEarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        # Extract current validation loss and accuracy\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "\n",
    "        # Check if current loss and accuracy improved significantly\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            # Update best scores and reset wait time\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            # If no improvement, increment the wait counter\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                # If wait exceeds the patience, stop training\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "class MultiObjectiveEarlyStoppingAndSaveCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001, output_dir='./model_output', filename='finetuned_model'):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "        self.output_dir = output_dir\n",
    "        self.filename = filename\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "        model = kwargs['model']\n",
    "\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "            # Save the model as the best so far\n",
    "            self.save_finetuned_parameters(model, os.path.join(self.output_dir, self.filename))\n",
    "            print(f\"Saved improved model to {self.output_dir}/{self.filename}\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "    def save_finetuned_parameters(self, model, filepath):\n",
    "        # Create a dictionary to hold the non-frozen parameters\n",
    "        non_frozen_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "        # Save only the finetuned parameters \n",
    "        torch.save(non_frozen_params, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb8bb11-79b0-4936-9099-f9f8ef97e105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.875565Z",
     "iopub.status.busy": "2024-04-05T12:53:29.875038Z",
     "iopub.status.idle": "2024-04-05T12:53:30.214710Z",
     "shell.execute_reply": "2024-04-05T12:53:30.213349Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.875495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "# Set random seeds for reproducibility of your trainings run\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, min_dist=0.01):\n",
    "    umap_model = umap.UMAP(n_components=n_components)\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    data = {\"UMAP1\": embeddings[:, 0], \"UMAP2\": embeddings[:, 1], \"Label\": labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9)\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_new.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "# Main training fuction\n",
    "def train_per_protein(\n",
    "        train_dataset,         #training data\n",
    "        valid_dataset,         #validation data      \n",
    "        weight_decay,\n",
    "        warmup_pct,\n",
    "        num_labels= 2,    #1 for regression, >1 for classification\n",
    "    \n",
    "        # effective training batch size is batch * accum\n",
    "        # we recommend an effective batch size of 8 \n",
    "        batch= 4,         #for training\n",
    "        accum= 2,         #gradient accumulation\n",
    "    \n",
    "        val_batch = 16,   #batch size for evaluation\n",
    "        epochs=1,       #training epochs\n",
    "        lr= 3e-4,         #recommended learning rate\n",
    "        seed= 42,         #random seed\n",
    "        deepspeed=False,  #if gpu is large enough disable deepspeed for training speedup\n",
    "        gpu= 1,\n",
    "        dropout=0.5, #dropout rate\n",
    "         #L2 weight regularization\n",
    "        lora_rank=4,      #lora rank\n",
    "        lora_init_scale=0.01, #lora scaling rank\n",
    "        lora_scaling_rank=1,       #lora a\n",
    "        ):         #gpu selection (1 for first gpu)\n",
    "\n",
    "    # Set gpu device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # load model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=dropout, lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    total_steps = epochs * len(train_dataset) // batch\n",
    "    warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "    # Define TrainingArguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir='./results',              # where to save the model\n",
    "        evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "        logging_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        learning_rate=lr,                    # initial learning rate\n",
    "        per_device_train_batch_size=batch,   # batch size per device\n",
    "        gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "        num_train_epochs=epochs,             # number of epochs to train\n",
    "        weight_decay=weight_decay,           # L2 weight regularization\n",
    "        warmup_steps=warmup_steps,           # 10% of total steps\n",
    "        load_best_model_at_end=False,         # load the best model at the end of training\n",
    "        seed=seed,                           # random seed\n",
    "        push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "        logging_dir='./logs',\n",
    "    )\n",
    "    # metric_for_best_model='eval_loss|accuracy'\n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        # Check if predictions have the expected shape\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "        # Now, compute the metric (e.g., accuracy)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        # Return the metric(s) as a dictionary\n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    # For minimizing loss\n",
    "    early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "    # For maximizing accuracy\n",
    "    early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "            early_stopping_patience=3,\n",
    "            min_delta=0.001,\n",
    "            output_dir='./model_output',\n",
    "            filename='finetuned_model_smac_succ.pth'\n",
    "        )],\n",
    "    )    \n",
    "\n",
    "    def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "        embeddings = []\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "    \n",
    "        # Iterate over the sequences in batches\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            # Extract a batch of sequences\n",
    "            batch = sequences[i:i + batch_size]\n",
    "    \n",
    "            # Tokenize the batch using the specified tokenizer and convert to PyTorch tensors\n",
    "            inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                # Forward pass through the model to obtain outputs\n",
    "                outputs = model(**inputs)\n",
    "    \n",
    "            # Extract hidden states from the second-to-last layer (penultimate layer)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "    \n",
    "            # Take the embeddings from the second-to-last layer\n",
    "            embeddings_from_layer = hidden_states[:, 0, :]\n",
    "    \n",
    "            # Extend the list with the generated embeddings\n",
    "            embeddings.extend(embeddings_from_layer)\n",
    "    \n",
    "            print(f\"Batch {i // batch_size + 1}, Second-to-Last Layer Embeddings Shape: {embeddings_from_layer.shape}\")\n",
    "    \n",
    "        return np.array(embeddings)\n",
    "\n",
    "        \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    # Get the best model\n",
    "    # model = trainer.model\n",
    "    # Ensure the best model is loaded\n",
    "    best_model_path = os.path.join('./model_output', 'finetuned_model_smac_succ.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        state_dict = torch.load(best_model_path)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "    # Evaluate the best model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(eval_results)\n",
    "    \n",
    "    # Print the current learning rate\n",
    "    # current_lr = trainer.optimizer.param_groups[0]['lr']\n",
    "    # print(f\"Current learning rate: {current_lr}\")\n",
    "    \n",
    "    # valid_sequences = list(valid_dataset['sequence'])\n",
    "    # valid_embeddings = get_embeddings(model, tokenizer, valid_sequences)\n",
    "\n",
    "    # # Apply UMAP for dimensionality reduction\n",
    "    # umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "    # # Plot UMAP embeddings\n",
    "    # labels = list(valid_dataset['label'])\n",
    "    # plot_umap(umap_embeddings, labels)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b300952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Dataset creation\n",
    "def create_dataset(tokenizer,seqs,labels):\n",
    "    tokenized = tokenizer(seqs, max_length=64, padding=True, truncation=True)\n",
    "    dataset = Dataset.from_dict(tokenized)\n",
    "    dataset = dataset.add_column(\"labels\", labels)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\") \n",
    "\n",
    "train_df = my_train\n",
    "valid_df = my_valid\n",
    "\n",
    "# Preprocess inputs\n",
    "# Replace uncommon AAs with \"X\"\n",
    "train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\",\"-\"]),\"X\",regex=True)\n",
    "valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\",\"-\"]),\"X\",regex=True)\n",
    "# Add spaces between each amino acid for PT5 to correctly use them\n",
    "train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "# Create Datasets\n",
    "train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']))\n",
    "valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f20a2048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'all_dephos_withLORA_datasetloader.sqlite3': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%rm all_dephos_withLORA_datasetloader.sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcbe5f",
   "metadata": {},
   "source": [
    "lr 0.00044666038459356726\n",
    "\n",
    "batch 1\n",
    "\n",
    "accum 2\n",
    "\n",
    "dropout_rate 0.6001375640608175\n",
    "\n",
    "weight_decay 9.882084078511897e-05\n",
    "\n",
    "warmup_pct 0.133784608876732\n",
    "\n",
    "lora_rank 16\n",
    "\n",
    "lora_init_scale 0.011516737020968842\n",
    "\n",
    "lora_scaling_rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1d2a136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_522026/991506286.py:35: DeprecationWarning: Please use `space.add(hyperparameters)`\n",
      "  cs.add_hyperparameters([\n",
      "2024-08-08 11:22:19,860 - INFO - Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING][target_function_runner.py:74] The argument budget is not set by SMAC: Consider removing it from the target function.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 792/1980 04:39 < 06:59, 2.83 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.595600</td>\n",
       "      <td>0.573732</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>0.579824</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.637800</td>\n",
       "      <td>0.750046</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.967900</td>\n",
       "      <td>0.852732</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.573732316493988, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 5.5917, 'eval_samples_per_second': 70.819, 'eval_steps_per_second': 8.942, 'epoch': 4.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.573732316493988, Val Accuracy: 0.7550505050505051\n",
      "[INFO][abstract_intensifier.py:516] Added config b74743 as new incumbent because there are no incumbents yet.\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 990/1980 05:49 < 05:49, 2.83 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.629375</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.573900</td>\n",
       "      <td>0.685211</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.593300</td>\n",
       "      <td>0.668511</td>\n",
       "      <td>0.661616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.739100</td>\n",
       "      <td>0.688399</td>\n",
       "      <td>0.532828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.723000</td>\n",
       "      <td>0.929336</td>\n",
       "      <td>0.537879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6852107048034668, 'eval_accuracy': 0.7070707070707071, 'eval_runtime': 5.4177, 'eval_samples_per_second': 73.093, 'eval_steps_per_second': 9.229, 'epoch': 5.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.6852107048034668, Val Accuracy: 0.7070707070707071\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 6017027.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 29:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.701300</td>\n",
       "      <td>0.688108</td>\n",
       "      <td>0.535354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>0.679701</td>\n",
       "      <td>0.578283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.675100</td>\n",
       "      <td>0.667482</td>\n",
       "      <td>0.618687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.666700</td>\n",
       "      <td>0.653064</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.657100</td>\n",
       "      <td>0.637194</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>0.620604</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.616900</td>\n",
       "      <td>0.603634</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.603300</td>\n",
       "      <td>0.587516</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.574013</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.569652</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5696515440940857, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 5.3929, 'eval_samples_per_second': 73.43, 'eval_steps_per_second': 9.271, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5696515440940857, Val Accuracy: 0.7626262626262627\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 6017027.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 29:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>0.687065</td>\n",
       "      <td>0.537879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.679260</td>\n",
       "      <td>0.588384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.667892</td>\n",
       "      <td>0.641414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.671100</td>\n",
       "      <td>0.652891</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.636904</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.634400</td>\n",
       "      <td>0.619482</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.629200</td>\n",
       "      <td>0.603574</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.605200</td>\n",
       "      <td>0.587478</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.588200</td>\n",
       "      <td>0.573275</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.572300</td>\n",
       "      <td>0.568883</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5688832402229309, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 5.3932, 'eval_samples_per_second': 73.426, 'eval_steps_per_second': 9.271, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5688832402229309, Val Accuracy: 0.7550505050505051\n",
      "[INFO][abstract_intensifier.py:595] Added config 8648e5 and rejected config b74743 as incumbent because it is not better than the incumbents on 2 instances:\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 8474627.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='297' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [297/490 05:01 < 03:17, 0.98 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>0.572975</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.474100</td>\n",
       "      <td>0.527205</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.372200</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.338100</td>\n",
       "      <td>0.637221</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5272051692008972, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 5.3928, 'eval_samples_per_second': 73.431, 'eval_steps_per_second': 9.272, 'epoch': 6.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5272051692008972, Val Accuracy: 0.7575757575757576\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 8474627.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 08:18, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.651900</td>\n",
       "      <td>0.573095</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.480400</td>\n",
       "      <td>0.593110</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.388600</td>\n",
       "      <td>0.678905</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.704599</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.833503</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 9.8989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.8989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.7045990824699402, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 5.4149, 'eval_samples_per_second': 73.132, 'eval_steps_per_second': 9.234, 'epoch': 9.9}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.7045990824699402, Val Accuracy: 0.7626262626262627\n",
      "[INFO][abstract_intensifier.py:603] Config 5d50d2 is a new incumbent. Total number of incumbents: 2.\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 11423747.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3564' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3564/3960 16:36 < 01:50, 3.57 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.730700</td>\n",
       "      <td>0.651437</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.712600</td>\n",
       "      <td>0.586856</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.653600</td>\n",
       "      <td>0.551881</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.604700</td>\n",
       "      <td>0.630608</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.590700</td>\n",
       "      <td>0.667125</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.561500</td>\n",
       "      <td>0.700620</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.508500</td>\n",
       "      <td>0.993057</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>1.158761</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.437700</td>\n",
       "      <td>1.289775</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.7006202340126038, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 5.4068, 'eval_samples_per_second': 73.241, 'eval_steps_per_second': 9.248, 'epoch': 9.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.7006202340126038, Val Accuracy: 0.7676767676767676\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 11423747.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2772' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2772/3960 12:52 < 05:31, 3.59 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.761200</td>\n",
       "      <td>0.653806</td>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.592377</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.675800</td>\n",
       "      <td>0.587610</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.619100</td>\n",
       "      <td>0.564974</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.565100</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.562900</td>\n",
       "      <td>0.646494</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.495500</td>\n",
       "      <td>0.856913</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5649739503860474, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 5.418, 'eval_samples_per_second': 73.09, 'eval_steps_per_second': 9.229, 'epoch': 7.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5649739503860474, Val Accuracy: 0.76010101010101\n",
      "[INFO][abstract_intensifier.py:603] Config e680e4 is a new incumbent. Total number of incumbents: 3.\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13881347.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 08:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.610200</td>\n",
       "      <td>0.539161</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.529300</td>\n",
       "      <td>0.589855</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.437900</td>\n",
       "      <td>0.567329</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.336900</td>\n",
       "      <td>0.679723</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.806441</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.135500</td>\n",
       "      <td>1.148924</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>1.384664</td>\n",
       "      <td>0.780303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>1.687588</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>1.639764</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>1.679265</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 1.384663701057434, 'eval_accuracy': 0.7803030303030303, 'eval_runtime': 5.4003, 'eval_samples_per_second': 73.33, 'eval_steps_per_second': 9.259, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 1.384663701057434, Val Accuracy: 0.7803030303030303\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13881347.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='891' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [891/990 07:39 < 00:51, 1.93 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.615900</td>\n",
       "      <td>0.556868</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.531600</td>\n",
       "      <td>0.539008</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.443900</td>\n",
       "      <td>0.574656</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.656146</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.930002</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.140900</td>\n",
       "      <td>1.023836</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>1.283737</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>1.534178</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>1.694149</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 1.023836374282837, 'eval_accuracy': 0.7777777777777778, 'eval_runtime': 5.3902, 'eval_samples_per_second': 73.466, 'eval_steps_per_second': 9.276, 'epoch': 9.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 1.023836374282837, Val Accuracy: 0.7777777777777778\n",
      "[INFO][abstract_intensifier.py:603] Config 21fac9 is a new incumbent. Total number of incumbents: 4.\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 16830467.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 18:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.713100</td>\n",
       "      <td>0.687776</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.708100</td>\n",
       "      <td>0.678499</td>\n",
       "      <td>0.593434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>0.665808</td>\n",
       "      <td>0.621212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.685600</td>\n",
       "      <td>0.651272</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.672200</td>\n",
       "      <td>0.634565</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.650500</td>\n",
       "      <td>0.618985</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.634800</td>\n",
       "      <td>0.607908</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.633200</td>\n",
       "      <td>0.601292</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>0.597289</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.624900</td>\n",
       "      <td>0.596075</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5960754156112671, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 5.4128, 'eval_samples_per_second': 73.159, 'eval_steps_per_second': 9.237, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5960754156112671, Val Accuracy: 0.76010101010101\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 16830467.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 18:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.687004</td>\n",
       "      <td>0.547980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.713000</td>\n",
       "      <td>0.678768</td>\n",
       "      <td>0.593434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.666120</td>\n",
       "      <td>0.641414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.651136</td>\n",
       "      <td>0.674242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.635602</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.658100</td>\n",
       "      <td>0.619908</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.648700</td>\n",
       "      <td>0.609616</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.603055</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.623600</td>\n",
       "      <td>0.598954</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.597833</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5978333950042725, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 5.4065, 'eval_samples_per_second': 73.245, 'eval_steps_per_second': 9.248, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5978333950042725, Val Accuracy: 0.73989898989899\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13881347.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 11:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.731600</td>\n",
       "      <td>0.684394</td>\n",
       "      <td>0.550505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.709800</td>\n",
       "      <td>0.667898</td>\n",
       "      <td>0.621212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.701900</td>\n",
       "      <td>0.646954</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>0.623962</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.650400</td>\n",
       "      <td>0.602786</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.636500</td>\n",
       "      <td>0.580011</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>0.562257</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>0.553058</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.581200</td>\n",
       "      <td>0.546964</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.578300</td>\n",
       "      <td>0.544929</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.544929027557373, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 5.3951, 'eval_samples_per_second': 73.4, 'eval_steps_per_second': 9.268, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.544929027557373, Val Accuracy: 0.7550505050505051\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13881347.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 11:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.735800</td>\n",
       "      <td>0.683180</td>\n",
       "      <td>0.560606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.730700</td>\n",
       "      <td>0.666950</td>\n",
       "      <td>0.646465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.705100</td>\n",
       "      <td>0.643514</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.672600</td>\n",
       "      <td>0.619808</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.641500</td>\n",
       "      <td>0.598819</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.648800</td>\n",
       "      <td>0.577620</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.627700</td>\n",
       "      <td>0.561221</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.550417</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.586100</td>\n",
       "      <td>0.544215</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.593300</td>\n",
       "      <td>0.542916</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5429160594940186, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 5.3924, 'eval_samples_per_second': 73.437, 'eval_steps_per_second': 9.272, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5429160594940186, Val Accuracy: 0.7702020202020202\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 16830467.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 18:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.735200</td>\n",
       "      <td>0.689456</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.749800</td>\n",
       "      <td>0.685415</td>\n",
       "      <td>0.550505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>0.679472</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.721400</td>\n",
       "      <td>0.672435</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>0.626263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.709300</td>\n",
       "      <td>0.653610</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.684500</td>\n",
       "      <td>0.645306</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.639967</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>0.637066</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.636207</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6370664834976196, 'eval_accuracy': 0.7095959595959596, 'eval_runtime': 5.4502, 'eval_samples_per_second': 72.658, 'eval_steps_per_second': 9.174, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.6370664834976196, Val Accuracy: 0.7095959595959596\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 16830467.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 18:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.752500</td>\n",
       "      <td>0.688904</td>\n",
       "      <td>0.535354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.736700</td>\n",
       "      <td>0.685255</td>\n",
       "      <td>0.563131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.679648</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.750700</td>\n",
       "      <td>0.672473</td>\n",
       "      <td>0.621212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.735900</td>\n",
       "      <td>0.664271</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.716100</td>\n",
       "      <td>0.654349</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.705300</td>\n",
       "      <td>0.646439</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.705200</td>\n",
       "      <td>0.641538</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.695100</td>\n",
       "      <td>0.638476</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>0.637586</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6384759545326233, 'eval_accuracy': 0.6919191919191919, 'eval_runtime': 5.4214, 'eval_samples_per_second': 73.044, 'eval_steps_per_second': 9.223, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.6384759545326233, Val Accuracy: 0.6919191919191919\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 18:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.688988</td>\n",
       "      <td>0.542929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.706300</td>\n",
       "      <td>0.682387</td>\n",
       "      <td>0.565657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.697900</td>\n",
       "      <td>0.672974</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.678700</td>\n",
       "      <td>0.648794</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.662400</td>\n",
       "      <td>0.636052</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.651600</td>\n",
       "      <td>0.626459</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.648500</td>\n",
       "      <td>0.620485</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.617010</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.639600</td>\n",
       "      <td>0.615938</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6159383654594421, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 5.4169, 'eval_samples_per_second': 73.105, 'eval_steps_per_second': 9.23, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.6159383654594421, Val Accuracy: 0.7474747474747475\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 18:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.715700</td>\n",
       "      <td>0.687909</td>\n",
       "      <td>0.532828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.711900</td>\n",
       "      <td>0.682047</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.709500</td>\n",
       "      <td>0.673064</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.703300</td>\n",
       "      <td>0.661723</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.649511</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.671100</td>\n",
       "      <td>0.637028</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>0.628323</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>0.622521</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>0.619009</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.648500</td>\n",
       "      <td>0.617975</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6179752349853516, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 5.4209, 'eval_samples_per_second': 73.051, 'eval_steps_per_second': 9.224, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.6179752349853516, Val Accuracy: 0.7323232323232324\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 14864387.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1188' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1188/1980 07:00 < 04:41, 2.82 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.622954</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.639400</td>\n",
       "      <td>0.557748</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.574900</td>\n",
       "      <td>0.529380</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.537200</td>\n",
       "      <td>0.600448</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.483500</td>\n",
       "      <td>0.604236</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>0.649543</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5293797850608826, 'eval_accuracy': 0.7651515151515151, 'eval_runtime': 5.4144, 'eval_samples_per_second': 73.138, 'eval_steps_per_second': 9.235, 'epoch': 6.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5293797850608826, Val Accuracy: 0.7651515151515151\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 14864387.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1386' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1386/1980 08:11 < 03:30, 2.82 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.699900</td>\n",
       "      <td>0.619979</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.648000</td>\n",
       "      <td>0.547719</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.587400</td>\n",
       "      <td>0.534916</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>0.554201</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.473400</td>\n",
       "      <td>0.617457</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.651695</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>0.815638</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5542012453079224, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 5.414, 'eval_samples_per_second': 73.144, 'eval_steps_per_second': 9.235, 'epoch': 7.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5542012453079224, Val Accuracy: 0.7626262626262627\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 16830467.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3564' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3564/3960 16:39 < 01:51, 3.56 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.703100</td>\n",
       "      <td>0.665103</td>\n",
       "      <td>0.628788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.661200</td>\n",
       "      <td>0.610793</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>0.572258</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.589900</td>\n",
       "      <td>0.544163</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.560100</td>\n",
       "      <td>0.538227</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.553900</td>\n",
       "      <td>0.536382</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.524700</td>\n",
       "      <td>0.544643</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.552829</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.523600</td>\n",
       "      <td>0.554856</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5363819003105164, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 5.4082, 'eval_samples_per_second': 73.223, 'eval_steps_per_second': 9.245, 'epoch': 9.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5363819003105164, Val Accuracy: 0.7575757575757576\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 16830467.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3564' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3564/3960 16:39 < 01:51, 3.57 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.664318</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.614599</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.631600</td>\n",
       "      <td>0.579041</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.604400</td>\n",
       "      <td>0.552210</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.569900</td>\n",
       "      <td>0.538921</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.569200</td>\n",
       "      <td>0.537242</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.536200</td>\n",
       "      <td>0.537281</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.527900</td>\n",
       "      <td>0.544105</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>0.546843</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5372416973114014, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 5.4107, 'eval_samples_per_second': 73.188, 'eval_steps_per_second': 9.241, 'epoch': 9.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5372416973114014, Val Accuracy: 0.7676767676767676\n",
      "[INFO][abstract_intensifier.py:603] Config c9e214 is a new incumbent. Total number of incumbents: 3.\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 11:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.716300</td>\n",
       "      <td>0.673780</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.683300</td>\n",
       "      <td>0.638177</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.658100</td>\n",
       "      <td>0.601038</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>0.564193</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>0.531414</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.534200</td>\n",
       "      <td>0.528823</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.527523</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.514900</td>\n",
       "      <td>0.527087</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>0.526904</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5269044637680054, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 5.414, 'eval_samples_per_second': 73.144, 'eval_steps_per_second': 9.235, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5269044637680054, Val Accuracy: 0.7702020202020202\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 11:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.721200</td>\n",
       "      <td>0.672538</td>\n",
       "      <td>0.618687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.704900</td>\n",
       "      <td>0.636926</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>0.594693</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.612700</td>\n",
       "      <td>0.566455</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.544578</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.578200</td>\n",
       "      <td>0.531193</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.559300</td>\n",
       "      <td>0.525227</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>0.528440</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.526464</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>0.527039</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5252269506454468, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 5.4145, 'eval_samples_per_second': 73.137, 'eval_steps_per_second': 9.234, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5252269506454468, Val Accuracy: 0.7626262626262627\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13881347.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7128' max='7920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7128/7920 27:04 < 03:00, 4.39 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.756400</td>\n",
       "      <td>0.650107</td>\n",
       "      <td>0.623737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.709000</td>\n",
       "      <td>0.579307</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.681300</td>\n",
       "      <td>0.679399</td>\n",
       "      <td>0.765152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.826200</td>\n",
       "      <td>1.124417</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.863500</td>\n",
       "      <td>1.251565</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.827600</td>\n",
       "      <td>1.227833</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.716700</td>\n",
       "      <td>1.412935</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.648400</td>\n",
       "      <td>1.699336</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.619200</td>\n",
       "      <td>1.637307</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 1.2278326749801636, 'eval_accuracy': 0.7702020202020202, 'eval_runtime': 5.4247, 'eval_samples_per_second': 72.999, 'eval_steps_per_second': 9.217, 'epoch': 9.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 1.2278326749801636, Val Accuracy: 0.7702020202020202\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13881347.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5544' max='7920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5544/7920 21:02 < 09:01, 4.39 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.757400</td>\n",
       "      <td>0.649366</td>\n",
       "      <td>0.646465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.710300</td>\n",
       "      <td>0.577288</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.712600</td>\n",
       "      <td>0.717456</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.815500</td>\n",
       "      <td>1.039168</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.811900</td>\n",
       "      <td>1.309226</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.828800</td>\n",
       "      <td>1.340148</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.711900</td>\n",
       "      <td>1.510613</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 1.039168119430542, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 5.411, 'eval_samples_per_second': 73.184, 'eval_steps_per_second': 9.24, 'epoch': 7.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 1.039168119430542, Val Accuracy: 0.7626262626262627\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 11:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.724600</td>\n",
       "      <td>0.688282</td>\n",
       "      <td>0.532828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.709300</td>\n",
       "      <td>0.680588</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.710500</td>\n",
       "      <td>0.669776</td>\n",
       "      <td>0.616162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.703400</td>\n",
       "      <td>0.657041</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.642747</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.626884</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>0.611631</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.639700</td>\n",
       "      <td>0.599202</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.623100</td>\n",
       "      <td>0.591787</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>0.589487</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5894865393638611, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 5.4167, 'eval_samples_per_second': 73.108, 'eval_steps_per_second': 9.231, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5894865393638611, Val Accuracy: 0.7550505050505051\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 11:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.687206</td>\n",
       "      <td>0.537879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.732400</td>\n",
       "      <td>0.679884</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.719100</td>\n",
       "      <td>0.668402</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>0.654189</td>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.674200</td>\n",
       "      <td>0.640301</td>\n",
       "      <td>0.691919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.679900</td>\n",
       "      <td>0.626063</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.657800</td>\n",
       "      <td>0.611217</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.630400</td>\n",
       "      <td>0.597301</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.624200</td>\n",
       "      <td>0.589973</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.626900</td>\n",
       "      <td>0.588152</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5881519317626953, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 5.4229, 'eval_samples_per_second': 73.024, 'eval_steps_per_second': 9.22, 'epoch': 10.0}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5881519317626953, Val Accuracy: 0.7474747474747475\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 11:18, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.736700</td>\n",
       "      <td>0.687292</td>\n",
       "      <td>0.535354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.718800</td>\n",
       "      <td>0.662640</td>\n",
       "      <td>0.669192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.671800</td>\n",
       "      <td>0.629597</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.642800</td>\n",
       "      <td>0.594780</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.608800</td>\n",
       "      <td>0.563977</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.547295</td>\n",
       "      <td>0.762626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.547295331954956, 'eval_accuracy': 0.7626262626262627, 'eval_runtime': 5.4196, 'eval_samples_per_second': 73.068, 'eval_steps_per_second': 9.226, 'epoch': 9.9}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.547295331954956, Val Accuracy: 0.7626262626262627\n",
      "[INFO][991506286.py:52] Training with budget (epochs): 10\n",
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 11:17, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.739300</td>\n",
       "      <td>0.686323</td>\n",
       "      <td>0.547980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.724700</td>\n",
       "      <td>0.661091</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.667600</td>\n",
       "      <td>0.626574</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.652900</td>\n",
       "      <td>0.594720</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.616200</td>\n",
       "      <td>0.559537</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.587400</td>\n",
       "      <td>0.545864</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_1.pth\n",
      "Loaded best model from ./model_output/finetuned_model_smac_1.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5458642840385437, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 5.4144, 'eval_samples_per_second': 73.138, 'eval_steps_per_second': 9.235, 'epoch': 9.9}\n",
      "[INFO][991506286.py:79] Completed training. Val Loss: 0.5458642840385437, Val Accuracy: 0.7550505050505051\n",
      "[INFO][smbo.py:328] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:329] --- Remaining wallclock time: inf\n",
      "[INFO][smbo.py:330] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:331] --- Remaining trials: 0\n",
      "**************\n",
      "\n",
      "Best configurations:\n",
      "Configuration:  Configuration(values={\n",
      "  'accum': 2,\n",
      "  'batch': 8,\n",
      "  'dropout_rate': 0.543320761621,\n",
      "  'lora_init_scale': 0.0847156651915,\n",
      "  'lora_rank': 24,\n",
      "  'lora_scaling_rank': 2,\n",
      "  'lr': 0.0013756617011,\n",
      "  'warmup_pct': 0.0429553569574,\n",
      "  'weight_decay': 5.57899472e-05,\n",
      "})\n",
      "Average Cost:  [1.2042500376701355, 0.22095959595959597]\n",
      "Value:  0.4360502236642993\n",
      "Hyperparameters:  {'accum': 2, 'batch': 8, 'dropout_rate': 0.543320761621, 'lora_init_scale': 0.0847156651915, 'lora_rank': 24, 'lora_scaling_rank': 2, 'lr': 0.0013756617011, 'warmup_pct': 0.0429553569574, 'weight_decay': 5.57899472e-05}\n",
      "Configuration:  Configuration(values={\n",
      "  'accum': 2,\n",
      "  'batch': 4,\n",
      "  'dropout_rate': 0.8225703034974,\n",
      "  'lora_init_scale': 0.0229565737821,\n",
      "  'lora_rank': 27,\n",
      "  'lora_scaling_rank': 2,\n",
      "  'lr': 0.0001057218498,\n",
      "  'warmup_pct': 0.1738724707511,\n",
      "  'weight_decay': 0.0001855847042,\n",
      "})\n",
      "Average Cost:  [0.5260657072067261, 0.23358585858585856]\n",
      "Value:  0.07836483928382162\n",
      "Hyperparameters:  {'accum': 2, 'batch': 4, 'dropout_rate': 0.8225703034974, 'lora_init_scale': 0.0229565737821, 'lora_rank': 27, 'lora_scaling_rank': 2, 'lr': 0.0001057218498, 'warmup_pct': 0.1738724707511, 'weight_decay': 0.0001855847042}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from ConfigSpace import ConfigurationSpace, Configuration\n",
    "from ConfigSpace.hyperparameters import UniformFloatHyperparameter, CategoricalHyperparameter, UniformIntegerHyperparameter\n",
    "from smac import HyperparameterOptimizationFacade as HPOFacade\n",
    "from smac import Scenario\n",
    "from smac.intensifier.hyperband import Hyperband\n",
    "from smac.multi_objective.parego import ParEGO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "class ProteinModel:\n",
    "    @property\n",
    "    def configspace(self) -> ConfigurationSpace:\n",
    "        cs = ConfigurationSpace()\n",
    "\n",
    "        cs.add_hyperparameters([\n",
    "            UniformFloatHyperparameter('lr', lower=1e-5, upper=1e-2, log=True),\n",
    "            CategoricalHyperparameter('batch', choices=[1, 2, 4, 8]),\n",
    "            CategoricalHyperparameter('accum', choices=[2, 4, 8]),\n",
    "            UniformFloatHyperparameter('dropout_rate', lower=0.1, upper=0.9),\n",
    "            UniformFloatHyperparameter('weight_decay', lower=1e-5, upper=1e-3, log=True),\n",
    "            UniformFloatHyperparameter('warmup_pct', lower=0.01, upper=0.3),\n",
    "            UniformIntegerHyperparameter('lora_rank', lower=4, upper=32),\n",
    "            UniformFloatHyperparameter('lora_init_scale', lower=1e-4, upper=1e-1, log=True),\n",
    "            UniformIntegerHyperparameter('lora_scaling_rank', lower=1, upper=4)\n",
    "        ])\n",
    "\n",
    "        cs['lora_rank'].q = 4\n",
    "\n",
    "        return cs\n",
    "\n",
    "    def train(self, config: Configuration, seed: int = 42, budget: int = 10) -> dict[str, float]:\n",
    "        logger.info(f\"Training with budget (epochs): {budget}\")\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "            # Call your training function\n",
    "            tokenizer, model, history = train_per_protein(\n",
    "                train_dataset=train_set,\n",
    "                valid_dataset=valid_set,\n",
    "                num_labels=2,\n",
    "                batch=int(config['batch']),\n",
    "                accum=int(config['accum']),\n",
    "                epochs=int(budget),\n",
    "                lr=config['lr'],\n",
    "                dropout=config['dropout_rate'],\n",
    "                weight_decay=config['weight_decay'],\n",
    "                warmup_pct=config['warmup_pct'],\n",
    "                lora_rank=config['lora_rank'],\n",
    "                lora_init_scale=config['lora_init_scale'],\n",
    "                lora_scaling_rank=config['lora_scaling_rank'],\n",
    "                seed=seed\n",
    "            )\n",
    "\n",
    "            # Extract the last validation accuracy and loss from the history\n",
    "            val_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry][-1]\n",
    "            val_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry][-1]\n",
    "\n",
    "        logger.info(f\"Completed training. Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n",
    "        return {\n",
    "            \"val_loss\": val_loss,\n",
    "            \"1 - val_accuracy\": 1 - val_accuracy,  # We minimize, so we use 1 - accuracy\n",
    "        }\n",
    "\n",
    "def plot_pareto(smac: HPOFacade, incumbents: list[Configuration]) -> None:\n",
    "    \"\"\"Plots configurations from SMAC and highlights the best configurations in a Pareto front.\"\"\"\n",
    "    average_costs = []\n",
    "    average_pareto_costs = []\n",
    "    for config in smac.runhistory.get_configs():\n",
    "        # Since we use multiple seeds, we have to average them to get only one cost value pair for each configuration\n",
    "        average_cost = smac.runhistory.average_cost(config)\n",
    "\n",
    "        if config in incumbents:\n",
    "            average_pareto_costs += [average_cost]\n",
    "        else:\n",
    "            average_costs += [average_cost]\n",
    "\n",
    "    # Let's work with a numpy array\n",
    "    costs = np.vstack(average_costs)\n",
    "    pareto_costs = np.vstack(average_pareto_costs)\n",
    "    pareto_costs = pareto_costs[pareto_costs[:, 0].argsort()]  # Sort them\n",
    "\n",
    "    costs_x, costs_y = costs[:, 0], costs[:, 1]\n",
    "    pareto_costs_x, pareto_costs_y = pareto_costs[:, 0], pareto_costs[:, 1]\n",
    "\n",
    "    plt.scatter(costs_x, costs_y, marker=\"x\", label=\"Configuration\")\n",
    "    plt.scatter(pareto_costs_x, pareto_costs_y, marker=\"x\", c=\"r\", label=\"Incumbent\")\n",
    "    plt.step(\n",
    "        [pareto_costs_x[0]] + pareto_costs_x.tolist() + [np.max(costs_x)],  # We add bounds\n",
    "        [np.max(costs_y)] + pareto_costs_y.tolist() + [np.min(pareto_costs_y)],  # We add bounds\n",
    "        where=\"post\",\n",
    "        linestyle=\":\",\n",
    "    )\n",
    "\n",
    "    plt.title(\"Pareto-Front\")\n",
    "    plt.xlabel(smac.scenario.objectives[0])\n",
    "    plt.ylabel(smac.scenario.objectives[1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    protein_model = ProteinModel()\n",
    "    objectives = [\"val_loss\", \"1 - val_accuracy\"]\n",
    "\n",
    "    # Define output directory\n",
    "    output_dir = \"./smac3_output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define our environment variables\n",
    "    scenario = Scenario(\n",
    "        protein_model.configspace,\n",
    "        objectives=objectives,\n",
    "        # walltime_limit=1800,  # After 30 minutes, we stop the hyperparameter optimization\n",
    "        n_trials=30,  # Evaluate up to 30 different configurations\n",
    "        min_budget=5,\n",
    "        max_budget=20,\n",
    "        n_workers=1,\n",
    "        output_directory=output_dir,\n",
    "        name=\"ProteinModelOptimization_1\",\n",
    "    )\n",
    "\n",
    "    # We want to run five random configurations before starting the optimization.\n",
    "    initial_design = HPOFacade.get_initial_design(scenario, n_configs=5)\n",
    "\n",
    "    intensifier = HPOFacade.get_intensifier(scenario, max_config_calls=2)\n",
    "\n",
    "    # Set up the multi-objective optimizer\n",
    "    multi_objective_algorithm = ParEGO(scenario=scenario)\n",
    "\n",
    "    # Create our SMAC object and pass the scenario and the train method\n",
    "    smac = HPOFacade(\n",
    "        scenario,\n",
    "        protein_model.train,\n",
    "        initial_design=initial_design,\n",
    "        multi_objective_algorithm=multi_objective_algorithm,\n",
    "        intensifier=intensifier,\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    # Let's optimize\n",
    "    incumbents = smac.optimize()\n",
    "\n",
    "    # Prepare results\n",
    "    # all_runs = []\n",
    "\n",
    "    print(\"**************\")\n",
    "    print(\"\\nBest configurations:\")\n",
    "    for incumbent in incumbents:\n",
    "        print(\"Configuration: \", incumbent)\n",
    "        print(\"Average Cost: \", smac.runhistory.average_cost(incumbent))\n",
    "        print(\"Value: \", smac.runhistory.get_cost(incumbent))\n",
    "        print(\"Hyperparameters: \", dict(incumbent))\n",
    "        # print(\"---\", cost)\n",
    "\n",
    "    # Let's plot a pareto front\n",
    "    plot_pareto(smac, incumbents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f19fd",
   "metadata": {},
   "source": [
    "    \"12\": {\n",
    "      \"accum\": 2,\n",
    "      \"batch\": 4,\n",
    "      \"dropout_rate\": 0.8225703034974,\n",
    "      \"lora_init_scale\": 0.0229565737821,\n",
    "      \"lora_rank\": 27,\n",
    "      \"lora_scaling_rank\": 2,\n",
    "      \"lr\": 0.0001057218498,\n",
    "      \"warmup_pct\": 0.1738724707511,\n",
    "      \"weight_decay\": 0.0001855847042\n",
    "    },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddfce510-da2b-4b95-9491-49f9ae8efb06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T13:08:03.246094Z",
     "iopub.status.busy": "2024-04-05T13:08:03.244479Z",
     "iopub.status.idle": "2024-04-05T14:04:37.162324Z",
     "shell.execute_reply": "2024-04-05T14:04:37.160516Z",
     "shell.execute_reply.started": "2024-04-05T13:08:03.246029Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3016' max='19000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3016/19000 18:08 < 1:36:14, 2.77 it/s, Epoch 3.17/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.690120</td>\n",
       "      <td>0.572632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.682235</td>\n",
       "      <td>0.587895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>0.669391</td>\n",
       "      <td>0.603684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_smac_succ.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_succ.pth\n",
      "Saved improved model to ./model_output/finetuned_model_smac_succ.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer, model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_per_protein\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001057218498\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8225703034974\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001855847042\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1738724707511\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m27\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_init_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0229565737821\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_scaling_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 153\u001b[0m, in \u001b[0;36mtrain_per_protein\u001b[0;34m(train_dataset, valid_dataset, weight_decay, warmup_pct, num_labels, batch, accum, val_batch, epochs, lr, seed, deepspeed, gpu, dropout, lora_rank, lora_init_scale, lora_scaling_rank)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(embeddings)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Get the best model\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# model = trainer.model\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Ensure the best model is loaded\u001b[39;00m\n\u001b[1;32m    158\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model_output\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetuned_model_smac_succ.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1860\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:2725\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2724\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2725\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2728\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:2748\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2747\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2748\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2749\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2750\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 145\u001b[0m, in \u001b[0;36mT5EncoderForSimpleSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    134\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ):\n\u001b[1;32m    143\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 145\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    156\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(hidden_states)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1113\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1099\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1100\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         output_attentions,\n\u001b[1;32m   1111\u001b[0m     )\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1113\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:754\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    751\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m attention_outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:343\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    342\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 343\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDenseReluDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwarded_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(forwarded_states)\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:288\u001b[0m, in \u001b[0;36mT5DenseActDense.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m--> 288\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(hidden_states)\n\u001b[1;32m    290\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer, model, history = train_per_protein(train_set, valid_set, num_labels=2, batch=4, accum=2, epochs=20, seed=42, lr=0.0001057218498, dropout=0.8225703034974, weight_decay=0.0001855847042, warmup_pct=0.1738724707511, lora_rank=27, lora_init_scale=0.0229565737821, lora_scaling_rank=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a28d3c1-8e24-4437-a1d9-dda9cefccfd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:37.168731Z",
     "iopub.status.busy": "2024-04-05T14:04:37.168220Z",
     "iopub.status.idle": "2024-04-05T14:04:38.081706Z",
     "shell.execute_reply": "2024-04-05T14:04:38.080275Z",
     "shell.execute_reply.started": "2024-04-05T14:04:37.168675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Truncate the longer list to the size of the shorter one\n",
    "min_length = min(len(loss), len(val_loss))\n",
    "loss = loss[:min_length]\n",
    "val_loss = val_loss[:min_length]\n",
    "\n",
    "# Get spearman (for regression) or accuracy value (for classification)\n",
    "if [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x] != []:\n",
    "    metric = [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x]\n",
    "else:\n",
    "    metric = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n",
    "\n",
    "epochs = [x['epoch'] for x in history if 'loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "line1 = ax1.plot(epochs, loss, label='train_loss')\n",
    "line2 = ax1.plot(epochs, val_loss, label='validation_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "#line3 = ax2.plot(epochs, metric, color='red', label='validation_metric')\n",
    "ax2.set_ylabel('Metric')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Add grid lines\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 \n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History for fine-tuning\")\n",
    "plt.savefig(f\"../Plots/Without_3rdline_Training_History_new.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccb1bbda-d70e-4b4c-a8d4-24600495171a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:38.083526Z",
     "iopub.status.busy": "2024-04-05T14:04:38.083162Z",
     "iopub.status.idle": "2024-04-05T14:04:38.092729Z",
     "shell.execute_reply": "2024-04-05T14:04:38.091278Z",
     "shell.execute_reply.started": "2024-04-05T14:04:38.083490Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "def load_model(filepath, num_labels=2):\n",
    "# Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "    # load a new model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=0.8225703034974, lora_rank=27, lora_init_scale=0.0229565737821, lora_scaling_rank=2)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9902a4c",
   "metadata": {},
   "source": [
    "    \"12\": {\n",
    "      \"accum\": 2,\n",
    "      \"batch\": 4,\n",
    "      \"dropout_rate\": 0.8225703034974,\n",
    "      \"lora_init_scale\": 0.0229565737821,\n",
    "      \"lora_rank\": 27,\n",
    "      \"lora_scaling_rank\": 2,\n",
    "      \"lr\": 0.0001057218498,\n",
    "      \"warmup_pct\": 0.1738724707511,\n",
    "      \"weight_decay\": 0.0001855847042\n",
    "    },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98e915-c8a8-433a-870a-c6dcaf191e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:38.095733Z",
     "iopub.status.busy": "2024-04-05T14:04:38.095313Z",
     "iopub.status.idle": "2024-04-05T14:05:24.016922Z",
     "shell.execute_reply": "2024-04-05T14:05:24.014560Z",
     "shell.execute_reply.started": "2024-04-05T14:04:38.095698Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def save_model(model, filepath):\n",
    "#     torch.save(model.state_dict(), filepath)\n",
    "\n",
    "# save_model(model, \"../finetuned_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa9b15",
   "metadata": {},
   "source": [
    "Hyperparameters:  {'accum': 2, 'batch': 20, 'dropout_rate': 0.1860063053668, 'lora_init_scale': 0.0004318458108, 'lora_rank': 28, 'lora_scaling_rank': 4, 'lr': 0.0075844928051, 'warmup_pct': 0.2990663754661, 'weight_decay': 0.0003501633591}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c97fa52-3aea-42e8-b72f-c4bb84808576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:05:24.020589Z",
     "iopub.status.busy": "2024-04-05T14:05:24.019788Z",
     "iopub.status.idle": "2024-04-05T14:08:10.428922Z",
     "shell.execute_reply": "2024-04-05T14:08:10.426805Z",
     "shell.execute_reply.started": "2024-04-05T14:05:24.020524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_smac_succ.pth\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2c20e75-5f40-4ca1-9579-5df49b738fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:10.432313Z",
     "iopub.status.busy": "2024-04-05T14:08:10.431835Z",
     "iopub.status.idle": "2024-04-05T14:08:19.838631Z",
     "shell.execute_reply": "2024-04-05T14:08:19.836988Z",
     "shell.execute_reply.started": "2024-04-05T14:08:10.432274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have identical weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a62aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = from_pretrained(\"model_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50b8a403-e7c5-4912-9c7a-f404c060c32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.841225Z",
     "iopub.status.busy": "2024-04-05T14:08:19.840752Z",
     "iopub.status.idle": "2024-04-05T14:08:19.864579Z",
     "shell.execute_reply": "2024-04-05T14:08:19.862993Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.841173Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WUI4|HDAC7_HUMAN%342%358</td>\n",
       "      <td>ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|Q13950|RUNX2_HUMAN%416%432</td>\n",
       "      <td>THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q15796|SMAD2_HUMAN%229%245</td>\n",
       "      <td>DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%416%432</td>\n",
       "      <td>TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2798%2814</td>\n",
       "      <td>MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0   sp|Q8WUI4|HDAC7_HUMAN%342%358  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
       "1   sp|Q13950|RUNX2_HUMAN%416%432  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
       "2   sp|Q15796|SMAD2_HUMAN%229%245  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
       "3    sp|P05787|K2C8_HUMAN%416%432  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2798%2814  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "    \n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_Y.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2d18716-fd26-49fe-9ba4-b84c936a364c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.867076Z",
     "iopub.status.busy": "2024-04-05T14:08:19.866598Z",
     "iopub.status.idle": "2024-04-05T14:08:19.887853Z",
     "shell.execute_reply": "2024-04-05T14:08:19.886215Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.867024Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sequence  label\n",
      "0  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
      "1  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
      "2  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
      "3  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
      "4  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1\n"
     ]
    }
   ],
   "source": [
    "my_test=df[[\"sequence\", \"label\"]]\n",
    "\n",
    "print(my_test.head(5))\n",
    "\n",
    "'''\n",
    "my_test[\"sequence\"]=my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "my_test['sequence']=my_test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "'''\n",
    "\n",
    "#Using .loc ensures that you are modifying the original DataFrame rather than a view of it, which helps avoid the SettingWithCopyWarning.\n",
    "# Replace characters in the \"sequence\" column\n",
    "my_test.loc[:, \"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Convert each sequence to a space-separated string\n",
    "my_test.loc[:, 'sequence'] = my_test.apply(lambda row: \" \".join(row[\"sequence\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eee8fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = sequence.split()\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "my_test['middle_char'] = my_test['sequence'].apply(get_middle_char)\n",
    "\n",
    "# Split the DataFrame\n",
    "my_test_S = my_test[my_test['middle_char'] == 'S'].drop(columns=['middle_char'])\n",
    "my_test_T = my_test[my_test['middle_char'] == 'T'].drop(columns=['middle_char'])\n",
    "my_test_Y = my_test[my_test['middle_char'] == 'Y'].drop(columns=['middle_char'])\n",
    "my_test_ST = my_test[my_test['middle_char'].isin(['S', 'T'])].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcd9ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0dff151-a667-4717-af18-401818bc4c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.889951Z",
     "iopub.status.busy": "2024-04-05T14:08:19.889601Z",
     "iopub.status.idle": "2024-04-05T14:08:22.641629Z",
     "shell.execute_reply": "2024-04-05T14:08:22.639919Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.889916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:00<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.759615 |      0.884615 |         0.875 |       0.88 |  0.966346 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[23  3]\n",
      " [ 3 21]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ce2f51a-887c-4684-82b9-22ea5fffd334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:22.647264Z",
     "iopub.status.busy": "2024-04-05T14:08:22.646121Z",
     "iopub.status.idle": "2024-04-05T14:08:23.557189Z",
     "shell.execute_reply": "2024-04-05T14:08:23.555594Z",
     "shell.execute_reply.started": "2024-04-05T14:08:22.647207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['0', '1']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"../Plots/Confusion_matrix_for_dephos_new.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07603226",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5e0d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 28/28 [00:04<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.583754 |      0.767857 |      0.815315 |    0.79148 |  0.868123 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[172  52]\n",
      " [ 41 181]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5528dc-6e06-456d-920f-8f05055d0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, n_neighbors=5, min_dist=0.01, metric='euclidean'):\n",
    "    umap_model = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric\n",
    "    )\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    df = pd.DataFrame({\n",
    "        \"UMAP1\": embeddings[:, 0],\n",
    "        \"UMAP2\": embeddings[:, 1],\n",
    "        \"Label\": labels\n",
    "    })\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = sns.scatterplot(\n",
    "        x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9\n",
    "    )\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.legend(title='Label', bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_ST.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "    embeddings = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch = sequences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "            embeddings.extend(hidden_states[:, 0, :])\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(sequences) // batch_size + 1}\")\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7718f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = list(sequence)\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "valid_df = df\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "valid_df['middle_char'] = valid_df['sequence'].apply(get_middle_char)\n",
    "\n",
    "valid_df = valid_df[valid_df['middle_char'] == 'T'].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a162964f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sp|Q9GZM8|NDEL1_HUMAN%203%219</td>\n",
       "      <td>CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>sp|Q8N163|CCAR2_HUMAN%438%454</td>\n",
       "      <td>EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>sp|P10636-8|TAU_HUMAN%196%212</td>\n",
       "      <td>GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>sp|Q02241|KIF23_HUMAN%434%450</td>\n",
       "      <td>QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sp|Q04206|TF65_HUMAN%419%435</td>\n",
       "      <td>QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>sp|Q76N33|STALP_MOUSE%326%342</td>\n",
       "      <td>ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>sp|P49790|NU153_HUMAN%1098%1114</td>\n",
       "      <td>FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>sp|Q8NFC6|BD1L1_HUMAN%2789%2805</td>\n",
       "      <td>DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>sp|Q5T6F2|UBAP2_HUMAN%514%530</td>\n",
       "      <td>SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>sp|Q9H040|SPRTN_HUMAN%265%281</td>\n",
       "      <td>NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name                           sequence  label\n",
       "180    sp|Q9GZM8|NDEL1_HUMAN%203%219  CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI      1\n",
       "181    sp|Q8N163|CCAR2_HUMAN%438%454  EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA      1\n",
       "182    sp|P10636-8|TAU_HUMAN%196%212  GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV      1\n",
       "183    sp|Q02241|KIF23_HUMAN%434%450  QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE      1\n",
       "184     sp|Q04206|TF65_HUMAN%419%435  QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG      1\n",
       "..                               ...                                ...    ...\n",
       "441    sp|Q76N33|STALP_MOUSE%326%342  ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS      0\n",
       "442  sp|P49790|NU153_HUMAN%1098%1114  FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ      0\n",
       "443  sp|Q8NFC6|BD1L1_HUMAN%2789%2805  DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL      0\n",
       "444    sp|Q5T6F2|UBAP2_HUMAN%514%530  SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS      0\n",
       "445    sp|Q9H040|SPRTN_HUMAN%265%281  NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN      0\n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a44d9187-1ac5-4e36-89a0-8f827a7f0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 3559427.0\n",
      "\n",
      "Processed batch 1/3\n",
      "Processed batch 2/3\n",
      "Processed batch 3/3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7IAAAK9CAYAAAAZoVCVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACDdUlEQVR4nOzdd3hUZd6H8TuFFEpCTSB0u4hlLdhWBRfFglgWCzbsq2tZe1krrsq6lrX3AgrYFd917X2RtZdVURRF6YSahBqSzPvHgUhIMkkgM5MzuT/XNRfMOc+c+U0ykHznaSmRSCSCJEmSJEkhkZroAiRJkiRJagiDrCRJkiQpVAyykiRJkqRQMchKkiRJkkLFICtJkiRJChWDrCRJkiQpVAyykiRJkqRQMchKkiRJkkLFICtJkiRJChWDrCSFUEpKCtdcc02iy6hWx6hRo0hJSeGXX36Jax2Jet6Guummm9hoo41IS0tju+22S3Q5/PLLL6SkpHDzzTfH/Lka8j3q1asXJ5xwQuX9d999l5SUFN59992Y1SdJCheDrKTQueaaa0hJSWH+/Pk1nu/bty/9+/evvL/ml/WUlBSuu+66Gh9zzDHHkJKSQuvWrWt93n79+pGSksK9995b4/k1v6ivuWVlZbHZZptx1llnMXfu3Fqv+/zzz5OSksJDDz1Ua5s33niDlJQU7rjjjlrbNAc33HAD48ePT3QZ6+X111/n4osvZvfdd+fRRx/lhhtuqLXtCSecUOW9tO77SpKk5i490QVIUrxkZWXxxBNPcMUVV1Q5vnTpUl588cWoAeHHH3/kk08+oVevXowdO5Yzzjij1rbXXnstvXv3ZsWKFUyYMIF7772Xl19+mW+++YaWLVtWa3/ggQeSm5vLuHHjOOWUU2q85rhx40hLS+Ooo44CYPny5aSnN73/wo877jiOOuooMjMzY3L9G264gaFDh3LIIYfE9Xkbw9tvv01qaioPP/wwGRkZdbbPzMys8cONtLS0WJTXpO25554sX768Xl83SVLz0PR+C5KkGDnggAN4/vnn+eqrr9h2220rj7/44ouUlpay33778fbbb9f42DFjxpCXl8ctt9zC0KFD+eWXX+jVq1eNbffff3923HFHAE455RQ6dOjArbfeyosvvsiwYcOqtc/MzGTo0KE8+uijzJo1i4KCgirnV6xYwQsvvMA+++xDXl4eQJPtlUtLS0tI0ErU8zZEYWEh2dnZ9Q5j6enpHHvssTGuKhxSU1Ob7HtekpQYDi2W1Gzsuuuu9O7dm3HjxlU5PnbsWPbbbz/at29f62PHjRvH0KFDGTx4cGXvaX3tvffeAEydOrXWNsceeywVFRU8+eST1c79+9//pqioiGOOOaby2LpzU0tKSjj33HPp1asXmZmZ5OXlsc8++/D5559Xtll33uEa/fv3rzIUu7S0lKuuuooddtiB3NxcWrVqxR577ME777xT52tddx7kmmHgNd3WruXmm29mt912o0OHDmRnZ7PDDjvw7LPPVrl2SkoKS5cuZfTo0dWuUdv8y3vuuYetttqKzMxMCgoKOPPMM1m8eHG119+3b18mTZrEgAEDaNmyJV27duUf//hHna8XoKysjL/97W9svPHGZGZm0qtXL/7617+ycuXKKrU/+uijLF26tLL2UaNG1ev60ax53RMmTOCcc86hU6dOtG3blj/96U+UlpayePFijj/+eNq1a0e7du24+OKLiUQiNV7rn//8Jz179iQ7O5u99tqLb775plqb77//nqFDh9K+fXuysrLYcccd+b//+79q7b799lv23ntvsrOz6datG9dddx0VFRXV2kUiEa677jq6detGy5YtGTBgAN9++221djXNkW3I9+3XX39lyJAhtGrViry8PM477zxee+21atf88ccf+eMf/0jnzp3JysqiW7duHHXUURQVFdX4NZMkJY49spKalWHDhjFmzBj+/ve/V86zff3113n88cd59dVXa3zMRx99xJQpU3j00UfJyMjgsMMOY+zYsfz1r3+t13P+9NNPAHTo0KHWNnvuuSfdunVj3LhxnH/++VXOjRs3jpYtW1YbTru2008/nWeffZazzjqLPn36sGDBAiZMmMB3333H9ttvX6861yguLuahhx5i2LBhnHrqqZSUlPDwww8zaNAgPv744wYtUnTYYYexySabVDn22Wefcdttt1X2LgPcfvvtDBkyhGOOOYbS0lKefPJJDj/8cF566SUOPPBAAB5//HFOOeUU+vXrx2mnnQbAxhtvXOtzX3PNNYwYMYKBAwdyxhlnMHnyZO69914++eQTPvjgA1q0aFHZdtGiRey3334cdthhHHHEETz77LNccsklbL311uy///5RX+Mpp5zC6NGjGTp0KBdccAEfffQRI0eO5LvvvuOFF16orP2BBx7g448/rhwuvNtuu9X59atpHnhGRgY5OTlVjp199tl07tyZESNG8OGHH/LAAw/Qtm1bJk6cSI8ePbjhhht4+eWXuemmm+jbty/HH398lcc/9thjlJSUcOaZZ7JixQpuv/129t57b77++mvy8/OBIJzuvvvudO3alUsvvZRWrVrx9NNPc8ghh/Dcc89x6KGHAjBnzhwGDBhAWVlZZbsHHniA7Ozsaq/lqquu4rrrruOAAw7ggAMO4PPPP2ffffeltLS0zq8N1O/7tnTpUvbee29mz57NX/7yFzp37sy4ceOqfTBTWlrKoEGDWLlyZeXXc+bMmbz00kssXryY3NzcetUkSYqTiCSFzNVXXx0BIvPmzavx/FZbbRXZa6+9Ku9PnTo1AkRuuummyDfffBMBIv/5z38ikUgkcvfdd0dat24dWbp0aWT48OGRVq1aVbveWWedFenevXukoqIiEolEIq+//noEiHzxxRdV2j366KMRIPLmm29G5s2bF5k+fXrkySefjHTo0CGSnZ0dmTFjRtTXddFFF0WAyOTJkyuPFRUVRbKysiLDhg2r0haIXH311ZX3c3NzI2eeeWbU6/fs2TMyfPjwasf32muvKl+vsrKyyMqVK6u0WbRoUSQ/Pz9y0kknRa1jzddg6tSpNdYwb968SI8ePSJbb711ZMmSJZXHly1bVqVdaWlppG/fvpG99967yvFWrVrV+BrWfd7CwsJIRkZGZN99942Ul5dXtrvrrrsiQOSRRx6p8vqByGOPPVZ5bOXKlZHOnTtH/vjHP9b4Otb48ssvI0DklFNOqXL8wgsvjACRt99+u/JYbe+vmgwfPjwC1HgbNGhQtdc9aNCgyvdnJBKJ7LrrrpGUlJTI6aefXnmsrKws0q1btxr/baz7/vzoo48iQOS8886rPPaHP/whsvXWW0dWrFhReayioiKy2267RTbddNPKY+eee24EiHz00UeVxwoLCyO5ubk1fo8OPPDAKrX/9a9/jQBVvs/vvPNOBIi88847lcfq+3275ZZbIkBk/PjxlceWL18e2WKLLapc84svvogAkWeeeSYiSWr6HFosqVnZaqut2GabbXjiiSeAoLfz4IMPrnERJgiGjT711FMceeSRpKSkAMFQ4by8PMaOHVvjYwYOHEinTp3o3r07Rx11FK1bt+aFF16ga9euUWtbMx9y7WHLzz33HCtWrKgyrLgmbdu25aOPPmLWrFlR29VHWlpa5TzOiooKFi5cSFlZGTvuuGOVocoNVV5ezrBhwygpKeGFF16gVatWlefW7q1btGgRRUVF7LHHHuv9fG+++SalpaWce+65pKb+9qPu1FNPJScnh3//+99V2rdu3brKfNSMjAz69evHzz//HPV5Xn75ZYBqvegXXHABQLXnaYisrCzeeOONare///3v1dqefPLJle9PgJ133plIJMLJJ59ceSwtLY0dd9yxxtd0yCGHVHl/9uvXj5133rny9S1cuJC3336bI444gpKSEubPn8/8+fNZsGABgwYN4scff2TmzJlA8DXZZZdd6NevX+X1OnXqVO09vOZ7dPbZZ1ep/dxzz63316g+37dXX32Vrl27MmTIkMpjWVlZnHrqqVWutabH9bXXXmPZsmX1rkGSlBgGWUlJae1fjNd19NFH88wzzzBlyhQmTpzI0UcfXWvb119/nXnz5tGvXz+mTJnClClTmDp1KgMGDOCJJ56ocd7f3XffzRtvvME777zDpEmT+Pnnnxk0aFCdNW+zzTb07du3MmRDEGo7duxY5+P/8Y9/8M0339C9e3f69evHNddcU2cIi2b06NFss802ZGVl0aFDBzp16lQ5V3d9XXHFFbz99tuMGzeu2pDgl156iV122YWsrCzat29Pp06duPfee9f7+X799VcANt988yrHMzIy2GijjSrPr9GtW7dq75l27dqxaNGiOp8nNTW12vDpzp0707Zt22rP0xBpaWkMHDiw2q2mod09evSocn9NKOvevXu14zW9pk033bTasc0226xyzvGUKVOIRCJceeWVdOrUqcrt6quvBoLFrCD4mtR0vXW/F2u+Nuu27dSpE+3atav2+JrU5/v266+/svHGG1drt+73rHfv3px//vk89NBDlf/m7r77bufHSlITZZCVFDprVi9dvnx5jeeXLVsWdYXTYcOGMX/+fE499VQ6dOjAvvvuW2vbNb2uRxxxBJtuumnl7amnnmLmzJm899571R7Tr18/Bg4cSP/+/dlyyy2r9AjW5dhjj+WHH37g008/Zc6cObzzzjscccQRdW61c8QRR/Dzzz9z5513UlBQwE033cRWW23FK6+8UtmmtnBfXl5e5f6YMWM44YQT2HjjjXn44Yd59dVXeeONN9h7771rDO71MX78eG688UauvfZa9ttvvyrn/vOf/zBkyBCysrK45557ePnll3njjTc4+uija12YqLHVtuJxfZ8/2gcn8VBb/TUdX5+v6Zrv+4UXXlhjL/Ebb7xRLRjGw4Z+39Z1yy238L///Y+//vWvLF++nHPOOYetttqKGTNmbEiZkqQYcLEnSaHTs2dPACZPnlytx2nZsmVMnz49ajjt0aMHu+++O++++y5nnHFGrSFxzf6yRx55JEOHDq12/pxzzmHs2LEMGDBgA15NVcOGDeOyyy5j3Lhx9OzZk/Ly8jqHFa/RpUsX/vznP/PnP/+ZwsJCtt9+e66//vrKRW/atWtXbcVeCHqsNtpoo8r7zz77LBtttBHPP/98lYC2puetoX744QeGDx/OIYccUuMCWc899xxZWVm89tprVfaBffTRR6u1rW9gXPs9svZrKy0tZerUqQwcOLChL6PW56moqODHH39kyy23rDw+d+5cFi9eXFlHU/fjjz9WO/bDDz9UbjG15mvYokWLOr92PXv2rPF6kydPrtZuzXOv/T2aN29enT3hDdGzZ08mTZpEJBKp8v6ZMmVKje233nprtt56a6644gomTpzI7rvvzn333cd1113XaDVJkjacPbKSQucPf/gDGRkZ3HvvvdV6CB944AHKysrqXGn2uuuu4+qrr+bss8+utc0LL7zA0qVLOfPMMxk6dGi12+DBg3nuueeqbLOyoXr06MEee+zBU089xZgxY+jdu3edq9uWl5dXG/6Yl5dHQUFBldo23nhjPvzwwyorwr700ktMnz69ymPX9HKt3av10Ucf8d///rfBr2fJkiUceuihdO3atXLbnHWlpaWRkpJSpWf4l19+Yfz48dXatmrVqsYwvq6BAweSkZHBHXfcUeV1PPzwwxQVFVWuhLyhDjjgAABuu+22KsdvvfVWgEZ7nlgbP3585RxXgI8//piPPvqo8t9RXl4e/fv35/7772f27NnVHj9v3rzKvx9wwAF8+OGHfPzxx1XOrzunfODAgbRo0YI777yzyvdo3a/lhho0aBAzZ86ssk3QihUrePDBB6u0Ky4upqysrMqxrbfemtTU1Eb9Ny5Jahz2yEoKnby8PK666iquuOIK9txzT4YMGULLli2ZOHEiTzzxBPvuuy8HHXRQ1Gvstdde7LXXXlHbjB07lg4dOtQaJIcMGcKDDz7Iv//9bw477LD1fj3rOvbYYznttNOYNWsWl19+eZ3tS0pK6NatG0OHDmXbbbeldevWvPnmm3zyySfccsstle1OOeUUnn32Wfbbbz+OOOIIfvrpJ8aMGVNtvurgwYN5/vnnOfTQQznwwAOZOnUq9913H3369GHJkiUNei0jRoxg0qRJXHHFFbz44otVzm288cbsuuuuHHjggdx6663st99+HH300RQWFnL33XezySab8L///a/KY3bYYQfefPNNbr31VgoKCujduzc777xzteft1KkTl112GSNGjGC//fZjyJAhTJ48mXvuuYeddtqpygJBG2Lbbbdl+PDhPPDAAyxevJi99tqLjz/+mNGjR3PIIYdsUG99WVkZY8aMqfHcoYceWmWxrA21ySab8Pvf/54zzjiDlStXctttt9GhQwcuvvjiyjZ33303v//979l666059dRT2WijjZg7dy7//e9/mTFjBl999RUAF198MY8//jj77bcff/nLXyq33+nZs2eV72enTp248MILGTlyJIMHD+aAAw7giy++4JVXXqFjx46N9tr+9Kc/cddddzFs2DD+8pe/0KVLF8aOHVs5/WDNhytvv/02Z511FocffjibbbYZZWVlPP7446SlpfHHP/6x0eqRJDWSRC2XLEkbasyYMZFddtkl0qpVq0hmZmZkiy22iIwYMaLK9iCRSNXtd6JZe3uUuXPnRtLT0yPHHXdcre2XLVsWadmyZeTQQw+NRCK/bYXyySefbNDrWrhwYSQzMzMCRCZNmlRjG9ba9mblypWRiy66KLLttttG2rRpE2nVqlVk2223jdxzzz3VHnfLLbdEunbtGsnMzIzsvvvukU8//bTa9jsVFRWRG264IdKzZ89IZmZm5He/+13kpZdeigwfPjzSs2fPWutY+2uwZouVaNvIrL29ysMPPxzZdNNNK7+Pjz76aOU2S2v7/vvvI3vuuWckOzu7yjVq2/bnrrvuimyxxRaRFi1aRPLz8yNnnHFGZNGiRVXa7LXXXpGtttqq2teqptdbk1WrVkVGjBgR6d27d6RFixaR7t27Ry677LJq78PG2n5n7ddZ23uuti2q1q1h7X8bt9xyS6R79+6RzMzMyB577BH56quvqtX1008/RY4//vhI586dIy1atIh07do1Mnjw4Mizzz5bpd3//ve/yF577RXJysqKdO3aNfK3v/0t8vDDD1f7HpWXl0dGjBgR6dKlSyQ7OzvSv3//yDfffFNtq6jatt+p7/ft559/jhx44IGR7OzsSKdOnSIXXHBB5LnnnosAkQ8//LCyzUknnRTZeOONI1lZWZH27dtHBgwYEHnzzTerPYckKfFSIpE4raQhSZLURNx2222cd955zJgxo86tsSRJTY9BVpIkJbXly5dX2at4xYoV/O53v6O8vJwffvghgZVJktaXc2QlSVJSO+yww+jRowfbbbcdRUVFjBkzhu+//77aAlSSpPAwyEqSpKQ2aNAgHnroIcaOHUt5eTl9+vThySef5Mgjj0x0aZKk9eTQYkmSJElSqLiPrCRJkiQpVAyykiRJkqRQSfo5shUVFcyaNYs2bdpUbnouSZIkqfmJRCKUlJRQUFBAaqp9emGW9EF21qxZdO/ePdFlSJIkSWoipk+fTrdu3RJdhjZA0gfZNm3aAMGbNScnJ8HVSJIkSUqU4uJiunfvXpkRFF5JH2TXDCfOyckxyEqSJElyymEScGC4JEmSJClUDLKSJEmSpFAxyEqSJEmSQiXp58hKkiRJUjKIRCKUlZVRXl6e6FJiIi0tjfT09HrNYTbISpIkSVITV1payuzZs1m2bFmiS4mpli1b0qVLFzIyMqK2M8hKkiRJUhNWUVHB1KlTSUtLo6CggIyMjKRbeTkSiVBaWsq8efOYOnUqm266Kamptc+ENchKkiRJUhNWWlpKRUUF3bt3p2XLlokuJ2ays7Np0aIFv/76K6WlpWRlZdXa1sWeJEmSJCkEovVQJov6vsbk/0pIkiRJkpKKQVaSJEmSFCoGWUmSJElSpVGjRtG2bdsNvk5KSgrjx4/f4OvUxCArSZIkSUnmhBNO4JBDDkl0GTFjkJUkSZIkhYpBVpIkSZKakVtvvZWtt96aVq1a0b17d/785z+zZMmSau3Gjx/PpptuSlZWFoMGDWL69OlVzr/44otsv/32ZGVlsdFGGzFixAjKysri8hoMspIkSZLUjKSmpnLHHXfw7bffMnr0aN5++20uvvjiKm2WLVvG9ddfz2OPPcYHH3zA4sWLOeqooyrP/+c//+H444/nL3/5C5MmTeL+++9n1KhRXH/99fF5DXF5FkmSJElSk3DuuecyYMAAevXqxd577811113H008/XaXNqlWruOuuu9h1113ZYYcdGD16NBMnTuTjjz8GYMSIEVx66aUMHz6cjTbaiH322Ye//e1v3H///XF5DelxeRZJkiRJUpPw5ptvMnLkSL7//nuKi4spKytjxYoVLFu2jJYtWwKQnp7OTjvtVPmYLbbYgrZt2/Ldd9/Rr18/vvrqKz744IMqPbDl5eXVrhMrBllJkiRJaiZ++eUXBg8ezBlnnMH1119P+/btmTBhAieffDKlpaX1DqBLlixhxIgRHHbYYdXOZWVlNXbZ1RhkJUmSJKmZ+Oyzz6ioqOCWW24hNTWYabrusGKAsrIyPv30U/r16wfA5MmTWbx4MVtuuSUA22+/PZMnT2aTTTaJX/FrMcjG02KgDGgDZCa2FEmSJEnJraioiC+//LLKsY4dO7Jq1SruvPNODjroID744APuu+++ao9t0aIFZ599NnfccQfp6emcddZZ7LLLLpXB9qqrrmLw4MH06NGDoUOHkpqayldffcU333zDddddF/PX5mJP8TAHeAE4BTgWuAr4Hqi+wrUkSZIkNYp3332X3/3ud1Vujz/+OLfeeis33ngjffv2ZezYsYwcObLaY1u2bMkll1zC0Ucfze67707r1q156qmnKs8PGjSIl156iddff52ddtqJXXbZhX/+85/07NkzLq8tJRKJROLyTAlSXFxMbm4uRUVF5OTkxL+AGcDxBMF1banAP4AhQOt4FyVJkiQ1PwnPButpxYoVTJ06ld69e8dl/mki1fe12iMbSyXA9VQPsQAVwMXAzLhWJEmSJEmhZ5CNpcXAy1HOVwCPAaVxqUaSJEmSkoJBNpYWAqvqaPM1sDQOtUiSJElSkjDIxlJ2Pdq0oura0UUEAbg8JhVJkiRJUui5/U4s5QKbAFOitBlOsB3PNGAC8Nzq43sD+wMFQHLP55YkSZKkBjHIxlI+cA3BqsUVNZzfFtgBmAwcChQCK4DlBNv1dCAItn2AjrEvV5IkSZLCwKHFsbYz8Diw6VrHsoAjgYeBMoL9ZQsJFodaShB6I8B8YCjw4+q/S5IkSZLskY25VsAAYCuC7XhWEgwl7gC0BL4AviJYFKqmebHzgE+BFtgrK0mSJEkYZOMnb/VtXV8DGQQhtzZfEPTcbgaEZ99mSZIkSYoJg2yitSYYRlxXm7kEc2cNspIkSZLWQ1kZFBZCJAIpKZCXB+khTYTOkU2031H3Nj2DgNlAZuzLkSRJkpR8Zs2CO+6AwYOhX7/gzzvuCI7H2t13302vXr3Iyspi55135uOPP97gaxpkEy0POJPaQ+pgYDpwNNA2TjVJkiRJShqzZsFxx8HNN8OcOUGP7Jw5wf3jj49tmH3qqac4//zzufrqq/n888/ZdtttGTRoEIWFhRt0XYNsorUCTgL+TtXFnFoSrGb8J+ATgp5bSZIkSWqAsjJ48kn47ruaz0+aBE89BeU1LTzbCG699VZOPfVUTjzxRPr06cN9991Hy5YteeSRRzbougbZpiAfOB34EHgdeBb4F7ARMAcYSc0LRUmSJElSFIWFMGZM9DZjxgTtGltpaSmfffYZAwcOrDyWmprKwIED+e9//7tB1w7p1N4klAVsDBQAiwi24tmSIOT6cYMkSZKk9bBmGHE0c+ZARUXjP/f8+fMpLy8nPz+/yvH8/Hy+//77Dbq2QbapyabuxZ/qUgIsI/judtjgiiRJkiSFVEoKdO4cPcx27gypIes8C1m5imoRwfDkM4E/AscDTxEMT5YkSZLU7OTlwbHHRm9z7LFBu8bWsWNH0tLSmDt3bpXjc+fOpXPnzht0bYNsslgE3AkcBrwJ/Ax8AZwHDAfisKy2JEmSpKYlPR2OOgr69Kn5fJ8+wfm0tMZ/7oyMDHbYYQfeeuutymMVFRW89dZb7Lrrrht0bYNssvgeuK+Wc5OB8UBp3KqRJEmS1EQUFMBjj8FFF0GXLsFw4y5dgvuPPx78PVbOP/98HnzwQUaPHs13333HGWecwdKlSznxxBM36LoJDbLvv/8+Bx10EAUFBaSkpDB+/Phqbb777juGDBlCbm4urVq1YqeddmLatGnxL7YpKwbuqeF4OhSfDlMfgdHFcOc9MGECzJ4dTPqWJEmS1DwUFMA558BLL8HHHwd/nnNObEMswJFHHsnNN9/MVVddxXbbbceXX37Jq6++Wm0BqIZK6GJPS5cuZdttt+Wkk07isMMOq3b+p59+4ve//z0nn3wyI0aMICcnh2+//ZasrKwEVNuELQOmrHMsDRbcBLe9DaP2W70vVMfgePfu8MgjwTCClJT4lytJkiQp/tLSYh9ca3LWWWdx1llnNeo1Expk999/f/bff/9az19++eUccMAB/OMf/6g8tvHGG8ejtHBJB3KrHiodAqO/gIcfqt58+nQYNgxeeQW6do1LhZIkSZLUaJrsHNmKigr+/e9/s9lmmzFo0CDy8vLYeeedaxx+vLaVK1dSXFxc5Zb0OhKsULyWeQfBgw+udSCDKt/t+fPhjTccYixJkiQpfJpskC0sLGTJkiX8/e9/Z7/99uP111/n0EMP5bDDDuO9996r9XEjR44kNze38ta9e/c4Vp1AewNbrv57JixYBUWLV99PAdqs/nMtL70EJSXxKlCSJEmSGkeTDbIVFRUAHHzwwZx33nlst912XHrppQwePJj77qtteV647LLLKCoqqrxNnz49XiUnVmfgMeAYIHutntYMoD01DiK3N1aSJElSGCV0jmw0HTt2JD09nT7rbHi05ZZbMmHChFofl5mZSWZmZqzLa5q6AtcC50DHUsjZCIqXUK0ndo0DDoA2beJYnyRJkiQ1gibbI5uRkcFOO+3E5MmTqxz/4Ycf6NmzZ4KqCoFsoDt06g4nnUqtIbZ9exg0yFWLJUmSJIVPQntklyxZwpQpv+0bM3XqVL788kvat29Pjx49uOiiizjyyCPZc889GTBgAK+++ir/+te/ePfddxNXdEhkZMBJJ8GiRcEmx6tHagPBSsWPPBLsJSVJkiRJYZMSiSRupuS7777LgAEDqh0fPnw4o0aNAuCRRx5h5MiRzJgxg80335wRI0Zw8MEH1/s5iouLyc3NpaioiJycnMYqPTSKimDBAnjrrWBhpx12gM02g86d7Y2VJElS8xLWbLBixQqmTp1K7969ycrKSnQ5MVXf15rQIBsPYX2zSpIkSWpcYc0GBtnqmuxiT5IkSZKkRlQGFAIRgrV08ghtImyyiz1JkiRJkhrJLOAOYDDQb/Wfd6w+HkPvv/8+Bx10EAUFBaSkpDB+/PhGua5BVpIkSZKS2SzgOOBmYA5Bj+yc1fePJ6ZhdunSpWy77bbcfffdjXrdkHYkS5IkSZLqVAY8CXxXy/lJwFPAOUBa4z/9/vvvz/7779/o17VHVpIkSZKSVSEwpo42Y1a3CxGDrCRJkiQlqzXDiKOZA1TEoZZGZJCVJEmSpGSVAnSuo01nQpcMQ1auJEmSJKne8oBj62hz7Op2IWKQlSRJkqRklQ4cBfSp5Xyf1edjsNBTLLlqsSRJkiQlswLgMYLViccQzIntTNATexTQJXZPvWTJEqZMmVJ5f+rUqXz55Ze0b9+eHj16rPd1DbKSJEmSlOwKCLbYOYpgYadUguHEMe6J/fTTTxkwYEDl/fPPPx+A4cOHM2rUqPW+rkFWkiRJkpqDNGLa+1qT/v37E4lEGv26zpGVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSpBCIxaJJTU19X6NBVpIkSZKasBYtWgCwbNmyBFcSe2te45rXXBu335EkSZKkJiwtLY22bdtSWFgIQMuWLUlJSUlwVY0rEomwbNkyCgsLadu2LWlp0Te4NchKkiRJUhPXuXNngMowm6zatm1b+VqjMchKkiRJUhOXkpJCly5dyMvLY9WqVYkuJyZatGhRZ0/sGgZZSZIkSQqJtLS0eoe9ZOZiT5IkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQSGmTff/99DjroIAoKCkhJSWH8+PG1tj399NNJSUnhtttui1t9kiRJkqSmJ6FBdunSpWy77bbcfffdUdu98MILfPjhhxQUFMSpMkmSJElSU5WeyCfff//92X///aO2mTlzJmeffTavvfYaBx54YJwqkyRJkiQ1VQkNsnWpqKjguOOO46KLLmKrrbaq12NWrlzJypUrK+8XFxfHqjxJkiRJUgI06cWebrzxRtLT0znnnHPq/ZiRI0eSm5tbeevevXsMK5QkSZIkxVuTDbKfffYZt99+O6NGjSIlJaXej7vssssoKiqqvE2fPj2GVUqSJEmS4q3JBtn//Oc/FBYW0qNHD9LT00lPT+fXX3/lggsuoFevXrU+LjMzk5ycnCo3SZIkSVLyaLJzZI877jgGDhxY5digQYM47rjjOPHEExNUlSRJkiQp0RIaZJcsWcKUKVMq70+dOpUvv/yS9u3b06NHDzp06FClfYsWLejcuTObb755vEuVJEmSJDURCQ2yn376KQMGDKi8f/755wMwfPhwRo0alaCqJEmSJElNWUKDbP/+/YlEIvVu/8svv8SuGEmSJElSKDTZxZ4kSZIkSaqJQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKQVaSJEmSFCoGWUmSJElSqKQnugBJyW3JEli0CMrLoUULyM+HdP/nkSRJ0gbw10lJMVFeDlOnws03wyuvwKpV0L49HHssnHACdO6c6AolSZIUVgZZSTHx009w6KFBb+waCxfCHXfAhAnw8MNB76wkSZLUUM6RldToiovhhhuqhti1ff45vP9+fGuSJElS8jDISmp0ixfD229Hb/PoozB/fvXjc+cGQ5J//jn4eyQSkxIlSZIUYg4tltToSkuhrCx6m/nzq7YpKgqGHN90E/zwQ3Csd2/4y19g4MBgfq0kSZIE9shKioHMTMjOjt6mZ0/Iygr+vnw5vPACnHrqbyEWgp7Zc88Nem9LSmJWriRJkkLGICup0XXsGCz0FM0ZZ0DbtsHfFyyA666rve3ttwdtJEmSJDDISoqB7OygJ3WTTWo+f/jhsM02v93/7DNYtqz265WVwRtvNGqJkiRJCjHnyEqKiW7d4Mkn4f/+D8aNC7be2WijoCe2Xz/o0OG3toWFdV9vzpzY1SpJkqRwMchKipmCAjjttGCYcXl5MHd27QC7xuab132trbZq/PokSZIUTgZZSTGVmgr5+dHbbLIJdO5ce69rmzaw886NX5skSZLCyTmykhIuPx/uuw9atqx+LiMD7r0X8vLiX5ckSZKaJntkJSVcWhr87nfw+uswalSwsFNFBey5Z7AlT48e0KJFoquUJElSU5ESiUQiiS4iloqLi8nNzaWoqIicnJxElyOpDqWlwcJQALm5de9HK0mSVF9mg+Rhj6ykJiUjI5gvK0mSJNXGICtJqy1aBEuWBMOas7KCebkpKYmuSpIkSesyyEpq9pYtg2+/hZEj4aOPIBIJ9rw980zYd9+atwySJElS4hhkJYXSokXBXNqpU4N5tL16QadOwdDkhigvh4kT4aSToKzst+M//wwXXACnnALnnw9t2zZm9ZIkSdoQBllJoTNtGlxyCbz/ftB7CsHCUOedB4cfDu3a1f9ahYXBtdYOsWt76CE45hiDrCRJUlPiPrKSQmXOHBg+HN5777cQC1BUBNdcA+PH1x5KazJjBsyeHb3NE0+sT6WSJEmKFYOspFD56iuYPLn287feGvSy1te8eXW3mTmzYeFYkiRJsWWQlRQay5fX3Tu6YEHdPaxr69at7jZbbAHpTsSQJElqMgyykkKjvBxWrqy7XWlp/a+Znw+bbFL7+bQ0OOyw+l9PkiRJsWeQlRQaLVvCHntEb9OiBRQU1P+a+flw553Qpk31cykpcMMNwX6ykiRJajoMspJCIzUVBg+GVq1qbzN4MLRv37Dr9u0Lr74abLXTpUuwb+y++8KLL8Ihh0R/PkmSJMVfSiSy9rqfyae4uJjc3FyKiorIyclJdDmSNtCqVfDJJ3DCCbBkSdVzO+0E997bsB7Zta1cGexNG4lA69bgfxmSJCUXs0HycPkSSaHSogX06wdvvQVvvAETJgRDjo85BjbeeMOGAWdmBj2ykiRJatrskZUUaqWlwZDjdVcVrqiAuXODXtbU1KB3tW3bhJQoSZKaCLNB8rBHVlKoZWRUPzZ/PowfDw88ADNmBEH297+HSy8NttLJyop7mZIkSWpELvYkKaksWAAjRsBVVwUhFoLe2fffDxZu+vzzhJYnSZKkRmCQlZRUfv0Vnnuu5nOlpUGv7Ny58a1JkiRJjcsgKylplJbCqFHR20yZEgw9liRJUngZZCUljZUrobCw7naLF8e8FEmSJMWQQVZS0sjOhk03rbvdhmzRI0mSpMQzyEpKGunpcOyx0dvssAO0bx+feiRJkhQbBllJSaVLF7j88prPdegAN90U/ClJkqTwMshKSio5OUGv7PPPQ//+QWjt1g3OPBP+/W/YbLNEVyhJkqQNlZ7oAiSpseXmwi67wJZbwtKlkJICHTtCixaJrkySJEmNwSArKWnl5gY3SZIkJReHFkuSJEmSQsUeWUlKkOLiYE/bZcuCrYNyc6Ft20RXJUmS1PQZZCUpAX7+Gf72N3jrLSgrC+bx7r47XHNNsCBVuv87S5Ik1cqhxZIUZ9Onw+GHw2uvBSEWIBKBCRPgsMNg6tTE1idJktTUGWQlKY7KymDMGJg9u+bzxcVw223BasuSJEmqmUFWkuJo3jx47rnobV5+OZg7K0mSpJoZZCUpjioqgl7XaFauhPLy+NQjSZIURgZZSYqjzEzYZJPobbp2hRYt4lOPJElSGBlkJSmOOnaEM8+M3ubkkyE/Pz71SJIkhZFBVpLibJdd4Jhjaj43cGCwcnGq/ztLkiTVyp0KJSnOOnSAyy6DP/4R7r8/2I6nUyc49VTYeuvg75IkSaqdQVaSEqB9+6Bntm9fKC0NFoFq3RqyshJdmSRJUtNnkJWkBFm6FObOhXHj4JtvIDcXhg+HzTazV1aSJCmaBs/CWr58ORMmTGDSpEnVzq1YsYLHHnusUQqTpGS2ZAm89BL07w/33gv/+U9w//DDg8Wg5sxJdIWSJElNV4OC7A8//MCWW27JnnvuydZbb81ee+3F7NmzK88XFRVx4oknNnqRkpRspk2DCy6oeb/YCRPgvvuC/WQlSZJUXYOC7CWXXELfvn0pLCxk8uTJtGnTht13351p06bFqj5JSjrLl8MjjwTzYmvzxBMwb178apIkSQqTBgXZiRMnMnLkSDp27Mgmm2zCv/71LwYNGsQee+zBzz//HKsaJSWBaKGtuVmyBL74InqbkpJgDq0kSZKqa9BiT8uXLyc9/beHpKSkcO+993LWWWex1157MW7cuEYvUFJ4LVoUzPV8+ulgUaPf/Q4GDYK8vOa9Om9qKmRn192uRYvY1yJJkhRGDQqyW2yxBZ9++ilbbrllleN33XUXAEOGDGm8yiSF2vz5MHJkMER2jfHjg2N33QUDBtQvzCWj9u3hiCPg889rb9OnT7AdjyRJkqpr0NDiQw89lCfW/q10LXfddRfDhg0jEok0SmGSwqu8HJ56qmqIXWPFCjj9dPj11/jX1VSkpMDAgdCzZ83nU1PhiiuCnmtJkiRVlxJJ8uRZXFxMbm4uRUVF5OTkJLocqVmYNQsOOAAKC2tvc8wxcO21zbdXFuCXX+Cyy4Ktd9bMIe7RI/i67LabPbKSJDU2s0HyaNDQYoBffvmFN954g9LSUvbaay/69u0bi7okhdiyZTWE2HJgFVAKpMKHE6B4HmT3iH99TUWvXsEesosWBV+v1q2hQwfIzw96bSVJklSzBgXZd955h8GDB7N8+fLgwenpPPLIIxx77LExKU5SOKWuO2lhFbAIWGv8R/pSSPkCyAKa8RDatm2DW+/eia5EkiQpPBo0R/bKK69kn332YebMmSxYsIBTTz2Viy++OFa1SQqpVq1g881X3ymnWogFOGg/6DAeuA9YGc/qJEmSFHYNmiPbtm1bJk6cSJ8+fQBYtmwZOTk5zJ07lw4dOsSsyA3hOHgpMV57DU48EVgKLKl6rkMnePlJ6D4cyATeBrrFvURJktTMmA2SR4N6ZIuLi+nYsWPl/ZYtW5KdnU1RUVGjFyYp3HbdFW6/Ddqvs2DR5lvBk6Og600EQ46XAAvjXl6jKSmBmTNhxozoi1tJkiSp8TR4safXXnuN3NzcyvsVFRW89dZbfPPNN5XH3E9WUk4OHLIv7P4E/DQNFi4M5oF2XgB5NwBT1mqclqgq119pKUyZArfcAm+8AWVlsNlmcNZZwR65TXSQiiRJUlJo0NDi1GoruNRwwZQUysvLN6ioxuTwASnBHgduA1oBhUDxOufzgJeBgviWtaE++QSOOgpWr31XxQknwEUXQbt2cS9LkiRFYTZIHg0aWlxRUVHnrSmFWElNwN5ACkEP7LohFuBcID+eBW24uXODoFpTiAUYNSoYbixJkqTYaFCQrUtFRQUvvfRSY15SUth1BZ4A1t1yuiVwOXAwoRtavGAB/PBD9DajRwfDjSVJktT4GjxHtiZTpkzhkUceYdSoUcybN49Vq1Y1xmUlJYtNgTHAXOB7oA1BsO0AZCewrvW0sB6LU82YAStXQnqj/C8rSZKkta13j+zy5ct57LHH2HPPPdl8882ZOHEiV111FTNmzGjM+iQlizxga+BwYD+C7XZCGGIBOnWqu03v3pCZGftaJEmSmqMG9xV88sknPPTQQzz55JNsvPHGHHPMMUycOJF77rmncn9ZSUpm7dvD1lvD11/X3ub44+2NlSRJipUG9chus802HH744XTo0IGJEyfy+eefc8EFF5CSkhKr+iSpyenUCW6+Gdq0qfn8eedBly7xrUmSJKk5aVCQnTx5MnvuuScDBgyw91VSs9anD7zyChx7bLDNTnY27LQTjBkDp54Ka223LUmSpEbWoIFvP//8M6NGjeKMM85g+fLlDBs2jGOOOcYeWUlJZ9UqKCwMFmxq0SIIpmtvN5eWBhttBNdeC+eeC5EIZGVBhw4JK1mSJKnZaFCPbNeuXbn88suZMmUKjz/+OHPmzGH33XenrKyMUaNG8UNd+1Gs4/333+eggw6ioKCAlJQUxo8fX3lu1apVXHLJJWy99da0atWKgoICjj/+eGbNmtWg55CkhpozB266CQYNgt//HnbfHc45B777rvqWOllZUFAAXbsaYiVWAbOAacBMYGViy5EkJa/1XrV47733ZsyYMcyePZu77rqLt99+my222IJtttmm3tdYunQp2267LXfffXe1c8uWLePzzz/nyiuv5PPPP+f5559n8uTJDBkyZH1LlqQ6zZ0Lf/oT3HXXb9vslJXB66/DwQfXvX+s1GzNAv4B7AvsAuwNXAdMT2RRkqRklRKJRCKNdbEvv/ySRx55hDvuuKPhhaSk8MILL3DIIYfU2uaTTz6hX79+/Prrr/To0aNe1y0uLiY3N5eioiJy1h4XKEk1ePFFOOOM2s/vuSfcdx+0bRu3kqSmbxZwDDC5hnM9gGeA7nGtSJJqZDZIHo26OcR22223XiG2voqKikhJSaFtlN8gV65cycqVv41lKi4ujlk9kpLLokXw6KPR20yYAEVFBlmpUjnwLDWHWAiGGT8EXA5kRLnOcmABUAS0AHKAfMBlOCRJNWhQkN17773rbJOSksJbb7213gXVZsWKFVxyySUMGzYs6qcnI0eOZMSIEY3+/JLCa948mDUL/vOfYG/XvfaCvLzqc1pLS38bTlybiopgAShJq80DxtTR5ingT0BBLefnALcCzxEEWgh6cq8A9iQItZIkraVBQfbdd9+lZ8+eHHjggbRo0SJWNVWzatUqjjjiCCKRCPfee2/Utpdddhnnn39+5f3i4mK6d3c8k9RcTZ8eDBX+/POqxwcMCPaCXXu/15YtoVcvmDKl9utlZQVb7UharRyYX0eb4tXtajIPOAuYuM7xacBpwN3AECBtA2qUJCWdBgXZG2+8kUcffZRnnnmGY445hpNOOom+ffvGqjbgtxD766+/8vbbb9c5lj0zM5PMzMyY1iQpHAoL4ZRT4Ouvq5975x249FL45z+hffvgWJs2cPrp8OabtV/zwANdnViqIh3oCvwUpU1Hag+iP1I9xK7tGmBT4PXVz7Pb6uv5gZIkNWsNWrX4oosuYtKkSYwfP56SkhJ23313+vXrx3333ReTuahrQuyPP/7Im2++SQd/e5TUAL/+WnOIXePNN2H+Oj1JW2wBJ5xQc/uNNoKLLw56bqV4WLwYpk2Dn38Ohsevu/1Tk5AHnFRHm+NXt1tXKfBYLY+JEGzf8y0wBbgPOA/oTzAn1yUwJKlZW6/td3bddVcefPBBZs+ezZlnnskjjzxCQUFBg8PskiVL+PLLL/nyyy8BmDp1Kl9++SXTpk1j1apVDB06lE8//ZSxY8dSXl7OnDlzmDNnDqWlpetTtqRm5vXXo5+PRODjj6sea98eLrwQxo6FXXeF/HzYdFO4+mp4+mlwpoLiobQ0+BDmjDNgt92C/Yz32w9uuy3YIqpJSQEOINhypyZ9CVY0rmkM2CpqD6TlwGKCQLsEyFp9fDlwCfB5zQ+TJDUPG7Rq8eeff857773Hd999R9++fRs8b/bTTz9lwIABlffXzG0dPnw411xzDf/3f/8HBKshr+2dd96hf//+G1K6pGZgfTcXa98+mEP7u9/BsmXBAlEdO0Lqeu+8rTArLw+GqZeVBe+BDh2CudKx9M03cPjhsHz5b8fmz4dbb4XPPoPbbw8WLGsy8oF7gdeAhwm248kj6IkdAnSp5XHZwI7Au+scjwBLV/89dfXjF6/T5mZga8DBWpLULDU4yM6aNYtRo0YxatQoiouLOfbYY/noo4/o06dPg5+8f//+RNvGthG3uJXUDA0aBPfcE71Nv361n2vb1m12mru5c+Gpp2DUKJgzB1q3hj/+MZhL3bNnbJ5z/ny44oqqIXZt770H337bxIIsBGH2OGAQUEYwJzaP6GO/UoHDgNsJemfXiBAMOwb4A0Hv67rDqj8HlmGQlaRmqkFB9oADDuCdd95h33335aabbuLAAw8kPb1Rt6KVpEbTsydsvXXt82T/8Iegp1Wqydy5QWD96KPfji1ZAqNHB8PWn3suWOW6sRUXw+oZN7V66CHYcsvg71lZTegDlxSCQNsQnQl6c0+neljdDLiYYG5sbc8nSWqWUiIN6PZMTU2lS5cu5OXlkZJS+0+Pz9fd5yKBiouLyc3NpaioqM4VjyUln2nT4E9/gq++qnp8r73gllugoLZ9LdXsPfUUnFdbgAKGDoW//73xF//69lvYZ5/az1dUwFZbwfHHw913Q9euwVza7bcP8Qczy4GZwDjgYyAT2BfoSbBq8bQaHrMj8Cj2yEpqELNB8mhQd+pVV10VNcBKUlPTowc89hjMnBkMyUxLC+a/du7sNjqq3bx58Mgj0du89BJcdFHjB9k2bYJ52TWtUFxREaxknJcHkybBjBnB7aOP4OCD4W9/C2mYzQY2AS4DSgiGJc8HBlC9lxaCntgLMcRKUjPWoCB7zTXXxKgMSYqdTp2C2zrrxkm1WrUqWOApmhUrgnaNrW1b2HvvmlfdXr48eM6jj4a//rXquRdfhP33hyFDGr+muGkBrN7XmQzgIeAvQNFabVoCfwO2i2tlkqQmpkFBtl27djX2yObm5rLZZptx4YUXsk+08VCSJIVARkYw7DzaVjctWwbtGltODlxzzW89rmtUVASraJ93HkyeDAsWVH/svfcG2/WEsld2XdkEPbJvAl8CPwHdgH5AR37bjkeS1Cw1KMjedtttNR5fvHgxn332GYMHD+bZZ5/loIMOaozaJElKiI4d4bTTgrmntTnssNgNT+/VC154Ibg9/XSwyNSmm8Khhwbh+uaba37c1KnBHrRJowXQdfVNkqS1NGixp7rceuutPPvss0ycOLGxLrnBnNAtSVofhYVwwQXw1lvVz/XqFSwG1b17bGsoLw+246moCP5+9NEwZUrt7Xv2DMJv586xrUuSwspskDyi7e7WYIMHD+b7779vzEtKkpQQeXnBytY33RT0hmZmBsONL7gAnnkm9iEWgsXJ8vOhSxdo3x623TZ6+2HDgvngkiQlu0bdBHblypVkxGLCkCRJCZCXB8ccAwMHBqsIp6YGQTERW6i3bBnMj3333Zrnx260Efzxj0H4lSQp2TVqj+zDDz/Mdi4LKklKMvn5wX6tXbokJsSusWbu7P77/1ZHdjYcdRSMGxfUKElSc9CgH8fnn39+jceLior4/PPP+eGHH3j//fcbpTBJklRVaipssgncdluwn+zKlcGQ544dg0ArSVJz0aAg+8UXX9R4PCcnh3322Yfnn3+e3r17N0phkiSpZm3aBDdJkpqrBgXZd955J1Z1SJLCoAxYuPrvbQGXRZAkSQmQwJk+kqTQKANmAuOA14EIMAA4DuhOsN+nJElSnBhkJUnRVQBfAUcDJWsd/wF4DHgc6Ic/USRJUtw06qrFkqQkNBc4jaohdo3lwKmr20iSJMWJQVaSFN2PwOwo5xcBNa8FKEmSFBMGWUlSdN/Vo83XMa9CkiSpkkFWkhRd+3q06RjzKiRJkioZZCVJ0e0CZEY5nw7sE6daJEmSMMhKkurSAbgwyvnTV7eRVH9lBIukzQFWJLgWSQohN0uQJEXXEjiGYPjwP4Fpq493Bc4EhgBtElOaFDpr78n8ClAO7AacAvQAshNXmiSFiUFWklS3tsARwF7AEiACtAbygLTElSWFSgT4FjgKKFrr+FTgaeAhYE+iD+WXJAEGWUlSfaUAnRNdhBRic4EzqBpi11i1+ty7QLc41iRJIeUcWUmSpHiYAfwS5fwygiArSaqTQVaSJCkefqxHm69iXoUkJQWDrCRJUjzUZ3Vvh+9LUr0YZCVJqq8KglVnpfXRh+grfKcAB8epFkkKOYOsJEl1KQQ+AM4l2HLoaYItVCoSWJPCpxNwVZTzJxNscyVJqpOrFkuSFM1MgoDxv7WO/QtoD4wBtsGPhVU/mcBggvfOjcAPq493JVix+GCCra4kSXUyyEqSVJvFwGVUDbFrLASOBV4jCCJSfeQC+wPbA0sJ9pZtCeTTtD8QWUywqnIaQa+x+0dLSjCDrCRJtVkAvB3l/EJgInB4fMpREslPdAH1tAj4Grgb+B7IAYauvvkBjqQEasqf/UmSlFg/Uvc82LdwASglp8XAPcBRwH+AecBPBMOiDyX6nriSFGMGWUmSatOiHm2y8KepktNUgp7YmswArgVK4leOJK3NH72SJNVmc4L5i9EcgT9NlXyWAw/U0eZNgqHHkpQA/uiVJKk2HYDTopzfDtg4PqVIcbUU+LmONmXAkjjUIkk1MMhKklSbbIKtd86jas9sKjAQeJDwLNojNUQmwQc5dcmOdSGSVDNXLZYkKZoOwFnAMILFn0qBTQn2Am2buLKkmGoDnAK8G6XNjgSrGEtSAhhkJUmqSzbQbfUtBJYvh/nzYeVKyMiAnBxo2zbRVSl0+gL9qTnMZhMs9lSfXtsGKCqC4mIoL4fMTMjPh1THD0qqgf81SJKURGbMgCuvhP79Yc89Ybfd4M9/hu++gzK3CVJD5AH/BC4AOq4+lgb8Afg/YKvGe6qVK+Hrr4P36m67BbchQ+Dhh4MPZSRpXSmRSCSS6CJiqbi4mNzcXIqKisjJcfyLJG2IefNg+nR47TWoqIB99oGePYNeEzWuVauC3qmUFGjXrn69UrNnw1FHwY8/Vj/XujW8+CJsuWXj16okVwYUAisJxvLlALmN+xQffxy8d1esqH7u4IPhuuugQyP3/qp5MhskD4cWS5LqVgQzFsIZp8NnnxH0yqTB3XdDnz5Br0nPnokuMjmUlga9qmPHwoQJQYA96KDg1q1bEGxrEonAK6/UHGIBliyBv/8d7rwzGGos1Vs6UBC7yxcWwqWX1hxiIfgA5qSTDLKSqnJosSQpupkw/z34y0nw2Zp9IxcQbM9RAZMmwSmnwNy5iS0zGaxaBR9+GPR033tvMNTyq6+C3qgDDwyGB9dm3rwg/EbzzjtBL6/UlCxaBN9/H73NqFG1B11JzZNBVpJUu0LgHChsAf99f63jEYL9I5cHd7/9FqZNi395yWbu3OBDgeXLq5+bPx9OP732DwzKy+sOqWVlQViWmpLi4rrbzJkTzKOVpDUMspKk2n0PrIT/flLL+dW9shD09mnDTJgQDAGuzZQpMGtWzeeysqB37+jXz80NVoKVmpL6DBneeGPIds9aSWsxyEqSalYGPAlEIC2tljaR1e1wi4zG8OmndbeZPLnm4+3awZlnRn/skUdCp04Nr0uKpbZtoV+/6G1OOCHYSkqS1vDXDklSzcoJVin9AXbrV/siQ2vss088ioqh+cC3wFjgOeAXoCS+JXTsWHebdu1qP7fNNjB8eM3nttsOTjvNMKCmp317+Mc/an//X3ABdO1aw4li4FfgO2AqsDBmJUpqggyykqSaZQL9gaXQaRLse2At7dJg552hIIarmsbcNOBkYB/gIuBsYE/gemBe/Mo49NDo51u3hq2i7N3Zvj1ceCE8/XSwj2yvXrD99nD77fDIIyH/HimpbbopvPQSnHVWEFrbt4c99gjeyyefHAyLr+In4Czg9wT72v4eOIngwyj3S5aaBfeRlSTVbgYwEIjAnNvhr/fBay8FW70AkAl7HAS33lpLj0kYzAGOAn6o5fzJwKVAq9iXsmgR/O1v8OSTNZ+/9lo49thgPmxdioth2TJo0cJtSxQeZWXBCtwVFdCyZS0jEKYDhwCzazjXGngJ2CyGRSrUzAbJwyArSapdOfA5cDxQAYtOhwVbB4s/VaTDzvtDpy4hD0rvAkdHOZ8FvAd0j0s1zJsHY8YEe/MuXD1Usnv3oKd1n32C+YRNUXl5sB/ovHnBqsudOwchxB+9alRlwM3AHVHaHATcQhBqpXWYDZKHQVaSFF05Qc/HOwShL4cg2PYE2ieurEZRAZwLPFtHu9EEw47jpKws2GZnyZJgbnKbNpCf33QX1CoqgjffhBtugNmre8nS04PgPWIEdOuW2PqURGYDQ4CZUdq0AD4AfN+pBmaD5JGe6AIkSU1cGsEvhMcBRxKsrpAsPz0iQH32VS2PdSFVpaeHZ6h2eTm89RacfXbV42Vl8Mor8MsvMHZs0EMrbbAKgkWeollFTP7NlpbC0qXBgmmt4jDVQFJ0TfSzXUlSk5RB8oRYCEL6AXW0SQe2iEMtIVVYCCNH1n7+u+/gyy/jVo6SXRaweR1tuhL8X9VISkqCba9GjIATT4Qzzgj2zS4sbLznkNRwBllJUvO2A9AlyvkDCP8Q6hhauBBmRhvmSdAju3RpfOpRkusA1LFfMicBeY3zdCUl8MIL8Ie94dEH4eO34c3n4ZhD4fTTYM6sxnkeSQ1nkJUkNW8FBHvH1jSUdw/gaoJ5warRihV1t1m2LBhqLDWKnYATajm3D/BHgtEWjWDaNLjsEqgoBhYAS4HlQAl8+BLc9U9YUddQZ0kxkUwDxCRJWj9bAP8HTCJY1CoTOJgg5HZMYF0h0KlTsMXPqihzjXfe2TmFakTtgQuBQ4EHCPaB7gScCvRZ/fdGsHw5PPAARFYAy2poEIGnHwx6Zrv5YZcUdwZZSZIgGF7cBfhDogsJl3btYPDgYPhlTTIy4PDDgwWspEbTfvWtD0EPaSbQpnGfoqQEvv6KoBe2FktKYGkhwYiOlo37/JKi88eKJElab23awOWXw88/w1dfVT2XkQH33Qddos1BljZEq9W3GEhPXz2SoI4VkFuUAUUYZGtQUhLMo589G7KyIC8vuPnBlhqDbyNJkrRBCgpg1CiYNAkefzyYE7vTTvDHPwbb7mRlJbpCVVpCELoAsnEhsyjat4cjj4DPXq29Td/toPUs6l5JuRmaOTNY6fnVV3+bI9+pE1xyCRxwALRtm9DylAQMspIkaYPl5we3XXYJfmlt2RLSGmnBHTWClcDPwO3Am0ApsD1wHrAdkJuwypq0vQfAxn3gp0nVz6WlwVUXQ14JwWrKqjR3Lpx8Mvzvf1WPz5sHF14Y/P2II+yZ1YZx1WJJkqJZCcxdfYuyoJEC2dnBcGNDbAJUALOB6cBMflugqAL4DDiQYFGzZUAZ8DEwDBgHlMS72HAo6AFjn4H9DqoaujbZHB4fBdt/AQwEWiSowCbq22+rh9i13Xij+/Bqw/k5iCRJNVlJEAgeBd4HUoBBwDFAN/wJqqalEBgPPATMALIIguu5BIsgnQvUtlXS9QTv7UZeLClZ9OgGt10Oi86HhQugZWtoOxfy3wfOALonusKmZcUKGDMmept584Je24KC+NSk5OSPYUmS1rUK+BA4kaq//E8BHgOeIBiO6bgmNQXzCLajeXOtYyuA54C3CN6vkSiPrwBeAC6IVYEh1xpytoOcedAzheDr3YegJzaf4EMuVSorC7Yuqkt92kjR+CNYkqR1zQX+RM09WCWrz82Na0VS7b6maohd22LgWuCIOq4xhSDQqmYtCPaV3gM4jGB+cWcMsTXIzg7mykeTnm5vrDacQVaSpHV9DBRHOT+TYOEcKdGKgQfqaDMB2KGONhvhb4VqFGlpcMgh0Vcr32efYFVoaUP4X5YkSev6uh5tvo95FVLdVhDMj40mhehDi1OBPzZaRRKdO8ODD9YcZvv2DbblycmJf11KLs6RlSRpXXn1aNMx5lVIdcsmWHws2gcrGUDX1X+W1nD+YqBT45em5iszE37/e3jnHRg/Hj78MAi1xx4bBNn8/ERXqGSQEolEon1GF3rFxcXk5uZSVFREjh/9SJLqYyqwJ1Bey/ls4D2CACEl2gfA4VHO7wfcQjAk/p8E82nLgN8RrGa8I9A2phWqGSsvDxZ2SksL5s8mmtkgedgjK0nSujoApwN313L+0tVtpKZgC4LFnJ6u4Vxn4Aqg3erbbQQLlkUItujxfawYS0uD1q0TXYWSkUFWkqR15RAE2e7AXQT7cgJsTLBFSX+CXtnGVkYw3/Gb1bdOBD3DHQB/EVRtOhCE1b2BewhWIM4hmPd6PFX3OW2D+8VKSgoGWUmSatIBOBbYB1hKsGBOa4J9I2NhFfApwdY+89c63oJg+OcJBD1qUk06AkOA3fhtHmwngvePJCUhg6wkSbVJBbrE6bmmA8cBy9Y5vgq4iWCI6FG4b6WicxEySc2E2+9IkpRopcBjVA+xa7sdmBufciRJauoMspIkJdoi4O062kwDlsShFkmSQsChxZIkhYXDiuOnApi3+s9WBIsnSZKaDIOsJEmJ1g4YSLDabG16EgQqxd5M4F/AkwQLfW0BnLn6z7aJK0uS9BuDrCRJiZZBsEJytHmy5xK7FZP1m18IFtWattaxmcBbwPnAKRhmJakJcI6sJElNQXdgLNVXnc0ALgH2xaHFsVYCXEvVELu2W4Ff41eOJKl29shKktQUtAB2AF4FJgHfAHnA74H2BHvYKrYWAm/W0eYh4B9AduzLkcKmrAxWrYKsLEjxgzfFmEFWkqSmIh0oWH0bmOBamqMlQFkdbX4kmDdrkJUqzZ8Pv/4Kjz0GixfDttvCYYdBfj5k+29FMWKQlSRJgvqF0/ZAZmyevrQUFiyASARat4YcV0pWCBQWwkUXwRtv/HbsjTfgttvgzjthn32gZcuElack5hxZSZIkCLbY2aaONicDbRr3acvL4Zdf4O9/hyFDYL/94Oyz4ZNPoLi4cZ9LakylpfDAA1VD7BplZcH7ePr0+Nel5sEgK0mSBMFCW9cDWbWc/z2wdeM/7XffwQEHwH33wcyZwTDNN96AQw6BZ5+FkpLGf05pgy2BebNg7OO1Nykrg0cfhRUr4leWmg+DrCRJ0hp9gRcIQuuaxWraA+cAdxIswNWICgvh/PODeYXrikTgqquCNlKTUQR8BvwFlvwMRb8SbBtWUXNzRxYoVgyykiRJa2QC2wIPABOB/wCvARcSk31858+Hb76p/XxFBTzzTBBqpYQrItjv+iDgFUivAFYRbF21ECiv/pDMTEg1cSgGfFtJkiStqy3QE9gY6ErMlsecNavuNt9/DytXxub5pQaZBoz87W7r2bDJFqvvlBME2nU+dBk6FDp0iE95al4MspIkSQlSn1/wO3eGjIzY1yJFtYJgH+W15D8NV1y81p6xK6kyxLhrVxg0yD1lFRsGWUmS1OgWLIBJk+DBB+Ghh4IFjRYsSHRVTU/nztCtW/Q2xx3n0Ew1AUuBH9Y59hns+hPcew90Llh9bHWPbL9+8OSTQZiVYsF9ZCVJUqOaORPOOw8mTKh6vH9/uPlmKCio8WHNUn4+3HgjDB8erPC6rmOPhS5d4l+XVE0GwZD7dbR5CA7cC3a8E2aVQ0kOdOsF7ds7pFixlRKJJPfyAcXFxeTm5lJUVESOO4tLkhRT8+fDaafBhx/WfL5/f7jzTn/BXdvy5fDtt0GgnTgxWNipRw844wwYPNivlZqQ14ETopzfBXgQaMLvWbNB8rBHVpKkZmrJkmC47/vvBwF0m21gyy2DXsK0tPW75uzZtYdYgHffDbaT6ZBBsMrpTIKVgrsAnYAW6/e8YZadDTvuCA88EOwZW1EBWVnB98G5hWpStiMIqzX9G88ALqVJh1glF4OsJEnN0MKF8PDDQe/o2kNa8/KCOa3bbQfp6/Fbwltv1d3mP+/ClkuBO4A1z90eOA84DGjX8OdNBu3aBTepycoD7gHuB54k2I4HoB9wFdAnQXWpWTLISpLUzJSXw7/+Bf/8Z/VzhYVw9NHw+uvQq1fDr13nhKUKqFgAfMpvIRaC3tkrCbbwOIGgd0dS09MZuAw4BVhOkCbaYE+s4s418CRJamYKC+Guu2o/v2QJPP10zYsP1aV//zoalMEe21N99dM1/gnMa/jzSoqjDIL9lTcBemGIVUIYZCVJamaWLAlWFo7mjTdg0aKGX7tbt2BYcm123h7yZwKLa2lQBPzS8OeVJDUvBllJktRoOnWC+++Hbbetfm6nneDOv0HHO+u4yIqYlCZJSiLOkZUkqZlp3TrYy3XWrNrbDBwIbduu3/W7d4fRo2HGDHj7bUhNhT/8IXjOTq8D86M8OJVgqKIkSVEYZCVJamby8uCss+Cvf635fOvWcOSR0GIDtsLJywtu22+/zok9gdbAkloeuCfOt5Mk1cmhxZIkNTNpaTBkCJx7bvUtdjp1grFjg7muMdEFGA20quHcFsCNQNsYPbckKWmkRCJ1LpQfasXFxeTm5lJUVEROTk6iy5EkqclYsgQWLID33gv+3GYb2HJLyM8Pwm7MrAJmAy8D7wOZwDBgG4KtPSQpRswGycMgK0mSEqOCYB/KVCA7wbVIahbMBsnDObKSJCkxUql5iLEkSXVwjqwkSZIkKVQMspIkSZKkUDHISpIkSZJCxSArSZIkSQoVg6wkSZIkKVQMspIkSZKkUHH7HUmSFB6LV98KCbbu6QDkAymJK0mSFH8GWUmS4iUCzAF+AD4H2gH9gfZATuLKCo1fgMuB94CK1cd6AX8DdsE9aSWpGTHISpIUD+XAt8DJwMy1jqcDJwFnAR0TUFdYzAKGAb+uc/wX4ARgLLBnfEuSJCWOc2QlSYqHNUFs5jrHy4AHgCdW/13VRYA3qR5i1ygHriMYbixJahYMspIkxVoF8BKwKEqb+zGI1WYh8FQdbb4BlsShFklSk+DQYkmSYq0IeK2G4xUEvYkrgGKCXluALrh40drKgWX1aGePtlSjpUth0SJYuRIyM6F9e2jZMtFVSRvGHllJkhKhgiDgLiQIacuBecBBBL2LkcSV1uS0AbarRxt/MZeq+eUXuOQS2GOP4LbnnnDxxcFxKcwMspIkxVoOMGit+xGgBChd61jH1cdnA8fwW++sIBs4hei/tRwNdIpPOVJYTJsGQ4fC888HvbEAK1YE9w8/HKZPT2x90oYwyEqSFGtpwGCC7XYg6I1dsU6bU4EXV/99PvDf+JQWGj2AG6n5N5ffA6cDmXGtSGrSSkvh4YdhVi0fis2cCY8+GrSTwsggK0lSPBQQrExcQNW5nGnAaUAf4OW1jr+Ocz7X1gY4GHgX+BOwO7A/8DRwF5CfsMqkJmn+fHjmmehtnnkmaCeFkYs9SZIUD2lAX+BfwFfA2wRDjncD/gNcSrCo0RrpuODTuloDmwCXE8wrbkEw7FhSNZEILF4cvc2iRUE7KYwMspIkxUsqwYrEEWAM8B3wEFXnyq5xBEH4VXXpBB8CSKpVWhr06BHMk61Nr15Bu/qYNy+41ksvQVkZ7LMPbLYZdO7cKOVKDWaQlSQp3toBWwD31HJ+89XnJWk95eXBKafAVVfV3uaUUyC/HsPyZ86E00+Hzz5bfaACHr4XNuoOox+AjVsCebjgmuLKObKSJMVbNsHiRH+i+gJFuwCjAXs5JG2A1FQYMgT696/5/IABcMABkFLHFIaFC+GCC9YKseXAouD28/9g+HEwZzJwMjCzsaqX6pbQIPv+++9z0EEHUVBQQEpKCuPHj69yPhKJcNVVV9GlSxeys7MZOHAgP/74Y2KKlSSpMXUELgTeBx4A7iSYN/sgwQq9krSB8vLgttvgvvtgxx2ha9fgz/vvh3/+Mzhfl3nz4P33V9+pABZTZSG6n3+EH5YR7IN9IcHe2FIcJHRo8dKlS9l222056aSTOOyww6qd/8c//sEdd9zB6NGj6d27N1deeSWDBg1i0qRJZGVlJaBiSZIaUavVt+6JLkQKgWJgAfAZQZD6HcFQ1vaJLKrpy8sLemZ33z3YaicjAzp0qP/jP/98rTtl1Lia+hsfwJ5bAq8SbB/m90RxkNAgu//++7P//vvXeC4SiXDbbbdxxRVXcPDBBwPw2GOPkZ+fz/jx4znqqKPiWaokSZISZS5wA/A8VVf33gu4GeiaiKLCpSHhdW3pa6eFlbW0SSPorQX4FNhs/Z5LaogmO0d26tSpzJkzh4EDB1Yey83NZeedd+a//619l/iVK1dSXFxc5SZJkqSQKgKuB56haogFeI9gvvm8eBfVfOyww1orG9cyn3bwH4AvV99xKVnFSZMNsnPmzAEgf52l1PLz8yvP1WTkyJHk5uZW3rp3d7yWJElSaC0EXohy/jMgyhYz2jAdOsAhh6y+s+7idMAOO0P3pUAhwZZhO8atNDVzTTbIrq/LLruMoqKiytv06dMTXZIkSZLW12dU74ld10vxKKR5ys2FK66Aww6DtAygxW/n9tgb7r0W8v6x+sDBwHoOYZYaqsl2/ndevbvy3Llz6dKlS+XxuXPnst1229X6uMzMTDIza/i4SJIkSeGzqh5tSmNeRbOWnw/XXx9sw/PJh1BWCDtsCR1/gA7nEWzHcyhwJZCb2FrVfDTZINu7d286d+7MW2+9VRlci4uL+eijjzjjjDMSW5wkKbBg9e1Lgp8o2xOsVpmTwJq0YYoJhnJOBJYRDBMsAOqxTYcUE9vXo82+Ma+i2cvNDW69exNswVNIMDf5cqAfwf/9bRNWnpqhhAbZJUuWMGXKlMr7U6dO5csvv6R9+/b06NGDc889l+uuu45NN920cvudgoICDqkcqC9JSpgZwAXAf9Y6lg4MBS7F4BNG84BbgHFU3WJjK+A+YONEFKVmrxOwB1X/r1lbb2Dz+JUjgsDaFlcnVkIlNMh++umnDBgwoPL++eefD8Dw4cMZNWoUF198MUuXLuW0005j8eLF/P73v+fVV191D1lJSrRC4E/AF+scLwOeJFiB4WqgTZzr0vpbDtwDPFbDuW+BYwgW3OlSw3kpltoTfMByBsF82bX1BkYDneNdlKRES4lEIpFEFxFLxcXF5ObmUlRURE6OY90kqVF8QrCoR23SCXpPesanHDWC6UB/gkBbm4eAA+JSjVRdIcH79CWCObH7EvTEGmLVAGaD5NFk58hKkpqwF+s4X0bQW7uBQbasDBYsgIoKaN0a2oS1h7eIYL5pKsEwyaa4Z8AvRA+xAM8DA4GMmFcjVZe3+rZDoguR1BQYZCVJDVefVUTL6m5Sm0gEZsyAp5+G8eNhxQrYZhs46yzYZJMQBdpFBMNy7wKmEAy1Pgo4iGABpaakPuOzKurZTpKkGDPISpIabhDweJTzKcC263/5H36Aww+H+fN/OzZzJrz6arAFxNChQQ9tk7aIYM7p3escH0EwD/UJoEe8i4qiF0FPa7RtTAYD7nAnSWoCmuLgJklSU7cl0UPYXkCH9bv0ggVw0UVVQ+wakQhccQXMnbt+146rn6geYteYCowElsSvnDq1J1hxujb5wC5xqkVqgPnzYdIkePFFePtNmDkNVixLdFWSYs0gK0lquC4EvYo1hdkdgJsIgtF6WLgQPv209vMVFfDEE1Bevn7Xj4ulwP11tHmFYL/WpqI1cBE1L+bUjWBLHlcsVhPz008wfDgM3BvOOAGOPQj23hEefwAWTWeDpjhIatocWixJWj+bEWzH8j3wGsGQ0yFAdzZoD9k5c+pu8913wbzZVq3W/3liainwcx1tSql7caV4ywf+AVwIvExQ3+4EK8MaYtXEzJoFRx0FM38lGMpfERwvWQBXXwDZFTBsEKRtjr/xSknIf9aSpPXXZfVtQF0NV1tFsIXGD8ACYCOgK0GAWi03t+7LdOoEGU155dwMoF092jXF+abtV9+2SHQhUnTvvgszpxOsCl5R/fw/b4M/bApdcglGFUhKKg4tliTFRzFBD+4+wDHAOQSLBw0F/gesHiqclwc96lgEafhwaNEidqVusLbASXW06Qe4haG0XoqK4IUXCAJsLcOHZ8+ExS2Aj+NYmKS4MchKkuLjY+BcYPE6x38i2JJmRnA3Px9GjoT0WsYMHXxw3UG3SdgR2LmWc9kEqxev5zxiqbmrqIBVq6hzK7CyMuDDeFQkKd4MspKk2CskWKW3NosJtqMpg5QU2HlneOYZ2Gmn35p07gyXXw7XXgsd1nNF5LjKA+4FzuS3YcapQH/gRaBPYsqSkkGbNrDHHkT9TbZ1G2iXSTBCQlLSSYlEIkm9tXlxcTG5ubkUFRWRk+MYLklKiKkEiwZFswnwDFXmyy5YAEuWBCsUZ2UFvbVpabErMybWzAteAbQgGE7cNpEFhce8eTB7Nnz9dbCw1/bbBx9iNNlFvhRXv/wCfxgAy6cDNfw2e8qf4K+ZkHUawZZhorAQFi+G4mJo3x7atg3+bE7MBsnDxZ4kSbFXw0Is1ayi2i+jHTqEpPc1mhYEC1qpQX7+Gc44Iwixa2RkwCmnBMdD/77QBuvaFUY/BicNgyWzq54bdCCceQBkvUGVD8eaq5Ur4auv4LLLglXf4bfRL3//O2y6aXBfChODrCQp9loShLmZUdrsAtRjxWIlv9mzYdgwmD696vHSUrjnHsjOhrPOgsymuOqz4qZFC9h5F3j7A3jnFfjwA2jbGo48ELrOgw7fAVfgXHTghx+CrYpWrPjtWCQCH34IQ4fCv/8N3bsnrj5pfTi0WJIUe+XAaIJfKmuSTrAXrcP/BIwfD3/+c+3n27SBt98OeuQkAMqhoghSlwElQBugE01zi6s4KyoKRjG8+27tbc45By68sPZF9pKJ2SB5uNiTJCn20oCDgRNrOJcF3Af0imdBaqqWL1+9rUoUJSUwM1rvvpqfNEhtT7Bf7Jar/zTEAsF82Pffj97m+eeDOelSmDSDz10kSU1CB+AiYDjwPDAb2JZgX9lOBIFWzV5FxeotU+pQXh77WqRkUF4e/LuKZvnyYKixFCYGWUlS/LRdfbs0sWWo6WrZEvbdF955p/Y2WVnQrVv8apLCLDMzGIYfbRTDVlsF//akMHFosSRJajJSUuAPf4i+JcjQoa5aLNVXXl6w2nc0Z58dbMUjhYlBVpIkNSkFBTBuHHTqVP3c/vvDBRc0zd6jFStg/vxgn06pqUhLg8MOg8GDaz5/4YVBj6wUNq5aLEmSmpyKCpgzJ9j7csIEaN0ahgyBzp2bXm9sSQlMmwYPPwzffhusqnzcccEenZ07J7o6KTB/PkydCo88AoWFsPHGcMIJwbDj3Ga09ZnZIHkYZCVJktZTSQk8+yxccUX1xXL69oVHH3WbIDUtK1bAypXBfswZGYmuJv7MBsnDocWSJEnradq0mkMswDffwD/+AcuWxb8uqTZZWUEPbHMMsUouBllJkqT1sGJFMJw42ti2f/0LFiyIX02S1Fy4/Y4kSdJ6WLIkmBMbzYoVwfDjuJoLTAe+AloDuxDs49w6znVIUgwZZCVJktZDenqwsFNdMjNjX0ulycCpwJS1jrUATgNOJwi0Sj6LgYXA50AE+B3QkWDfbilJGWQlSZLWQ9u2cOyxMHFi7W369Klf2G0UM4GjCHpk17YKuJugR/bPBMFWyWMOcDXwb6Bi9bEUYD/gOqBLguqSYsw5spIkSetpl12C1Ylrkp4OI0ZAXl6cinmH6iF2bQ8AhXGqRfGxCLgc+Be/hVgIemVfAS4EnKOtJGWQlSRJWk+dOwdb7AwdGqwGu0afPvDEE7D99nEqpJggzESzCJgfh1oUP/MIAmtt6vpwQwoxhxZLkiRtgK5d4e9/h4suChZ2yswMhhPHrSd2jYq6m9SrjcLj/Xq0eQPoE+tCpPgzyEqSJG2gli2DW8K0hlWnw4qtIKMYMt+keu9ra6BTAmpT7JTVo015zKuQEsIgK0mStB4iEZg7F5YuDe63ahUMNY63oiKYORNGvwpTv4LOeXDi36DHLOhwI1C6uuHxGGSTza71aLNHzKuQEsIgK0mS1EALF8Krr8Idd8C0acGxTTaBCy6AvfYKVjSOh8WL4aGH4NZbVx9YBSyGZ5+AI4+CK26EDhcAfwT+BMRzKyDFXgGwHfBlLef7AD3iVYwUXy72JEmS1AAlJfDww3Dhhb+FWIApU+CMM+CZZ2D58vjU8tVXa4VYCLbW6QC0haf+BS8vhMh/gWuwNzYZdQLuo+Y5sJsCDwH5ca1IipuUSCQSSXQRsVRcXExubi5FRUXk5OQkuhxJkhRyv/wCe+4JZbXMT8zOhnffhe7dY1vHokVw8snw4Ye1t+ndG557LjFDnlWz+fOhtBQyMqBjx0a66FzgZ+Algq13DiAIsobYaswGycOhxZIkSQ3wxhu1h1gIemM//TT2QXbZMvj22+htpk4NQlMolBPsc7sKSAPaA9kJrahRFRbChAnwwAMwe3bw4cLJJ0P//o2wwnX+6lt95sxKScIgK0mS1ABz67Ev57x5sa8jJSXo/S0pqb1NejqkhmEi2VzgGeARYA5BgD0YOBvoSegnwxUWwjnnwPtrbZczbx6cey7svjvcdRfk23sqNUjI/1uQJEmKr759626z+eaxr6NjRzj44Oht/vAHaPKjJwuBs4AbCEIswHLgSYIwOzVBdTWSSAReeqlqiF3bBx/A+PFQ4R6/UoMYZCVJkhpgp50gN7f28507w6abxr6OjAw48URo377m89nZwYJUTT7ITgQ+qOXcfODvQJRe56Zu7txgcbBoHn446LWVVH8GWUmSpAbIy4P77oOsrOrnWreG+++P3zDR7t2DVZJ32KHq8S22gCefjE+g3iALgTpCHq8Bi2NfSqyUl8Ovv0ZvM2NG0E5S/TlHVpIkqQFatIBddoHXX4dHHoH33gvmoe6zDxx3XBAu09LiU0taGmy5JYwaFaxiPH8+tGsX3NZrAaG5QCmQAuQCbRqz2hqUEgwtjqYMWBnjOmIoJSXoNZ8/v/Y27doF7STVn0FWkiSpgTIzYZNN4KqrYPHiIIS0axcM902EDh2C2yabrOcFFgCvA/cAPxH8hrgPcAHBNi4tGqXM6jKBrsD0KG2yVt9CqlMnOPJIuPvu2tsccUQjbsUjNRMOLZYkSVpPWVnBnNj8/MSF2A22kGAe6gUEIRaCXtBXgIOAr2L43O2A0+tocyDBVjwh1aIFDB9e+3ZMXbvCSSeF+P0jJYhBVpIkqTmbBoyt5dxy4BLqHv67IbYHBtdyrjtwEdAyhs8fB926BXOZhw0LFuGC4M8jj4Rnn439nsNSMkqJRCKRRBcRS8XFxeTm5lJUVEROk1+2T5IkKY5KCYLiM3W0exvYIoZ1zAPeB+4DfibogT0SGEYw9DhJLF8OCxZAaWnQA9uhw2/BVvFhNkgezpGVJElqrlby296t0SyKcR2dgD8CexKE69TVx5LsN9Xs7KB3VtKGc2ixJElSc5UF9KxHu3gtRNSJoAe2C0kXYiU1LoOsJElSc9UCOKGONtsR6sWWJCUng6wkSVJz1hX4Sy3n2gI3AR3iVo0k1YtBVpIkqTnLBf4EjAH6EawQ3BE4Efg3sV3kSZLWk7MPJEmSmru2wN4Ew4iXAykEvbCZiStJkqIxyEqSJCngXFhJIeHQYkmSJElSqBhkJUmSJEmh4tBiSZKkRhKJwNy5sGwZpKRA69bQqVOiq5Kk5GOQlSRJagQLF8LLL8Ndd8G0acGxPn3g4othl10gJyex9UlSMnFosSRJ0gYqLoZ77w1C65oQCzBpEpxwAvz737ByZcLKk6SkY5CVJEnaQPPnB0G2NtdcE7SRJDUOg6wkSdIG+te/oKKi9vMlJfDNN/GrR5KSnUFWkiRpA82eXXcbe2QlqfEYZCVJkjbQ1lvX3WbjjWNfhyQ1FwZZSZKkDbTXXtCyZe3nu3WDnj3jV48kJTuDrCRJ0gbq1AnuvhvSa9jYsHVruO8+yM+Pf12SlKzcR1aSJGkDZWbCnnvC66/D/ffDBx8EoXa//eC446B7d0i1+0CSGo1BVpIkqRFkZ8MWW8ANN8DixZCSAu3bQ0ZGoiuTpORjkJUkSWpE2dnBTZIUOw5ykSRJkiSFikFWkiRJkhQqBllJkiRJUqgYZCVJkiRJoWKQlSRJkiSFiqsWS5IkxUFZGRQWwvTpsHAh9OgBnTpBXl6iK5Ok8DHISpIkxVhJCbz7LlxxBcyb99vxvn3h9tth880h1XFyklRv/pcpSZIUY599BqefXjXEAnzzDRxxBMyYkZi6JCmsDLKSJEnrqawMli+Hiora28ybByNHQiRS8/kFC+CZZ4JrSZLqx6HFkiQ1VSXAImAlkAW0A1ontCKttmABTJsGjz8O8+dDnz5Bz2p+PrRqVbXt0qXw9dfRr/fii3DsscHjJUl1M8hKktTURICpwEjgdWAVkAHsD1wC9EpYZSLoYb3qqiB8rvHmm3D33UHP68EHQ5s2v50rL6/7mqWltffYSpKqc2ixJElNzTTgUODfBCEWoBR4ERgKTE9QXaK8HJ56qmqIXfvcJZfA1KlVj2dnQ+fO0a+7006Qk9N4dUpSsjPISpLUlKwA7gPm1XJ+FjCa3wKu4mruXHjoodrPRyJw772wZMlvx/Lz4eSTa39MWlqwEFTLlo1XpyQlO4OsJElNyULguTraPE3tQVcxtXx5sBdsNJ9/XjXIpqXBkUcGt3W1aAG33Qa9ejVmlZKU/JwjK0lSU1IBLKmjzWKCebSKu7S0uttkZkJKStVjHTvClVfCKafAuHFBGN5mGxgyBPLyguHHkqT6M8hKkpQIEWAuQWiNEKxGnEfwk7k70efBbgS0iHWBqkmbNvC738EXX9Te5tBDoUOH6sfbtw9u110XbLXTwu+hJK03hxZLkhRvi4EXgD8CewJ7AUMI5r6mA6fV8fjTCEKv4q5DB7j88tp7Zjt1gqFDIT1KV0FKiiFWkjaUQVaSpHhaDjwDnEWwxc4aM4ErgHuAA4ABtTx+P2CfWBaoumy7LTzyCHTrVvX49tvD009XPy5JanwpkUhy71pWXFxMbm4uRUVF5LiuvSQp0WYQ9MAur+V8KvA+wVDjT4EHCIYgdwH+BGwPdIp9mYquoiJYwXjuXFi8GAoKgmHDHTsmujJJ0ZgNkodzZCVJiqfPqT3EQrDY0yvAmQQ9s7sCK4FMoF3Mq1M9paZCly7BTZIUfwZZSZLiaUE92qy9tY7hVZKkapwjK0lSPG1ejzbbxLwKSZJCzSArSVI89QaiLQaUA+wcp1okSQopg6wkSfGUD9xPEFjXlUWwuJNb60iSFJVzZCVJiqdUgqHDrwFPESzsVE6w3c7xBL217jEqSVJUBllJkuItDegJnA+cAESAtgQrEzeCNVvDzJkD8+cHW8N07Aj5+Y1zfUmSEs0gK0lSoqTT6MOIV6yATz6BCy+E6dN/O7755nDbbbDVVpDuT39JUsg5R1aSpCQyeTIce2zVELvm+BFHwLRpialLkqTGZJCVJClJLF4MN94Iq1bVfL6kBB58MOi1lSQpzAyykiQliSVL4P33o7f5979h4cL41CNJUqwYZCVJShIVFcEtmtJSiETiU48kSbFikJUkKUlkZsImm0Rvs9120KpVXMqRJClmDLKSJCWJ/Hw466zobf7yF2jbNi7lSJIUMwZZSZKSyMCBcMop1Y+npMDVV0OfPvGvSZKkxpYSiST3TJni4mJyc3MpKioiJycn0eVIkhRzixfD7NkwdizMnAmbbgpHHgl5edCmTaKrk6TEMRskD7dElyQpybRtG9yuvTZY3CkzM+iRlSQpWRhkJUlKUqmpkJWV6CokSWp8zpGVJEmSJIWKQVaSJEmSFCoGWUmSJElSqBhkJUmSJEmhYpCVJEmSJIWKqxZLkqSkMm8ezJkDb7wR3O/fH7p1C/bRlSQlB4OsJElKGjNnwjnnwH//+9uxm2+GbbaBBx6AHj0SV5skqfE4tFiSJCWFBQvg/POrhtg1/vc/OPVUKCyMf12SpMZnkJUkSUmhsBD+85/az3/9NUyfHr96EmIRMB9YkehCJCm2HFosSZJCZ9kyWLoUMjIgNzc4VlNP7Lreegt22CG2tSXEbOB94AlgObANcBLQHWidwLokKUYMspIkKTQWL4apU4P5rlOmQNu2cOKJQTjNyqr78anJOBZtOnAMMGWtY18ThNqbgYOAVgmoS5JiyCArSZJCYfFieOghuPXWqsc/+AB22gluuw2ys2H58tqvMXBgLCtMgGLgaqqG2DUqgIuAHYBN41mUJMVeMn4uKUmSktAPP1QPsWt88gmMGhUs9lSbHXeErl1jUlriLALejHK+HBgDrIpPOZIULwZZSZLU5JWUwD33RG/z1FNwwAGw997Vz+28c/D4Tp1iU1/CzAfK6mjzP2BpHGqRpDhyaLEkSWryli6F77+P3qa4GMrL4fbbYd48mDABKipg990hPx86doxPrXHVsh5tcoAWsS5EkuLLICtJkpq8tLTfVieuTUoKtGgBHToEty22iE9tCdUe6A1MjdLmBFzsSVLScWixJElq8jp2hKOOit5mt90gJyc+9TQZecC11P4b3U7AVvErR5LixSArSZKavJQUGDQINtmk5vNZWXDFFdCuXXzrSrgUYBfgcWCztY63BI4D7iMIu5KUZBxaLEmSQqGgAMaOhRtugFdegdLS4PgOO8C118Z/KHFJSVBDy5bBtj8J0woYQNDzWgKUAm2ADkAi65KkGEqJRCKRRBcRS8XFxeTm5lJUVEROsxtvJElS8lmyBBYuhGXLIDMzGE7coUP8nn/ePPjmm2BP24ULYaON4NRToVcvaNs2fnVIajizQfJo0kOLy8vLufLKK+nduzfZ2dlsvPHG/O1vfyPJs7ckSYqidWvo0SPoge3dO74hdu5cOOccOOYYeOcd+OoreOGFYNufBx6ARYviV4skNWdNemjxjTfeyL333svo0aPZaqut+PTTTznxxBPJzc3lnHPOSXR5kiSpGSkrg8cfh/feq/n8bbcFW/3svntcy5KkZqlJB9mJEydy8MEHc+CBBwLQq1cvnnjiCT7++OMEVyZJkpqbuXNh9Ojobe66C/r2rXurIEnShmnSQ4t322033nrrLX744QcAvvrqKyZMmMD+++9f62NWrlxJcXFxlZskSdKGWrkSFiyI3mby5GDuriQptpp0j+yll15KcXExW2yxBWlpaZSXl3P99ddzzDHH1PqYkSNHMmLEiDhWKUmSmoP0dEhNhYqK2tu0bh20kSTFVpP+r/bpp59m7NixjBs3js8//5zRo0dz8803MzrKuJ7LLruMoqKiytv06dPjWLEkSUpWOTmwxx7R2xwxFDpmAVHCriRpwzXp7Xe6d+/OpZdeyplnnll57LrrrmPMmDF8//339bqGS2xLkqTG8vXXcMghsHz5OifKoVsevHAfdL0ZGAQMBgpo4t0GUvNiNkgeTfq/1mXLlpG6zvictLQ0KqKN6ZEkSYqRzTeHZ56B7bb77Vh6BPbZGZ6+HbpeBnwEXAvsD0wCmmyXgSSFV5OeI3vQQQdx/fXX06NHD7baaiu++OILbr31Vk466aRElyZJkpqhjAzYfnt47DEoLoblJdCmCNpOgJzzgHlrNV4A/Al4DuickHIlKWk16aHFJSUlXHnllbzwwgsUFhZSUFDAsGHDuOqqq8jIyKjXNRw+IEmSYuZl4JQ62owH+sW+FEl1MxskjyYdZBuDb1ZJkhQzI4D762hzPXBiHGqRVCezQfJo0nNkJUmSmrT29WiTG/MqJKnZMchKkiStr/2BlCjns4Cd4lSLJDUjBllJkqT11RE4Lsr5s6lfr60kqUGa9KrFkiRJTVpb4EIgH3gYWLj6eD5wDnAw0CohlUlSUjPISpIkbYiOwFnAkUARwXi3NgRhNi2BdUlSEjPISpIkbagWQMHqmyQp5pwjK0mSJEkKFYOsJEmSJClUDLKSJEmSpFAxyEqSJEmSQsUgK0mSJEkKFYOsJEmSJClUDLKSJEmSpFAxyEqSJEmSQsUgK0mSJEkKFYOsJEmSJClUDLKSJEmSpFAxyEqSJEmSQsUgK0mSJEkKFYOsJEmSJClUDLKSJEmSpFAxyEqSJEmSQsUgK0mSJEkKFYOsJEmSJClUDLKSJEmSpFAxyEqSJEmSQsUgK0mSJEkKlfREFxBrkUgEgOLi4gRXIkmSJCmR1mSCNRlB4ZX0QbakpASA7t27J7gSSZIkSU1BSUkJubm5iS5DGyAlkuQfR1RUVDBr1izatGlDSkrKel2juLiY7t27M336dHJychq5QjWE34umwe9D0+H3omnw+9A0+H1oOvxeNA1+H6qLRCKUlJRQUFBAaqqzLMMs6XtkU1NT6dat2/+3d/8xVdV/HMdf94uAd0wgTeFeNwhMJUHtlouJudxiJFMqV/5AMe3mP87NMHW6FcqSbNiqrXQ42wWcPyrcjNJ+MFQWac4f4XW5SiFJU9TWEpBfSXC+fzTvIgjN0HMv5/nY7h98zuH4unvvXve6n8u9fXKt8PBwngT8BLPwD8zBfzAL/8Ac/ANz8B/Mwj8wh67Yie0feBkCAAAAABBQKLIAAAAAgIBCkb0FoaGhWrt2rUJDQ82OYnnMwj8wB//BLPwDc/APzMF/MAv/wBzQn/X7D3sCAAAAAPQv7MgCAAAAAAIKRRYAAAAAEFAosgAAAACAgEKRBQAAAAAEFIpsL3Jzc2Wz2brcEhISzI5lSRcvXlRWVpaGDBkiu92usWPH6vjx42bHspz77ruv22PCZrNpyZIlZkezlI6ODuXk5CguLk52u10jRozQunXrxGf33X3Xrl1Tdna2YmNjZbfblZKSomPHjpkdq9+rrKxURkaGnE6nbDabSktLuxw3DENr1qyRw+GQ3W5XamqqqqurzQnbz91sFrt371ZaWpqGDBkim80mr9drSs7+rrc5tLe3a9WqVRo7dqzCwsLkdDr13HPPqa6uzrzAQB+gyN5EYmKiLl265LsdPHjQ7EiWc/XqVU2aNEnBwcH6/PPP9d133+nNN9/UPffcY3Y0yzl27FiXx0N5ebkkaebMmSYns5b8/HwVFBRo48aN+v7775Wfn68NGzbo3XffNTua5SxatEjl5eXatm2bvv32W6WlpSk1NVUXL140O1q/1tzcrPHjx2vTpk09Ht+wYYPeeecdbd68WUeOHFFYWJieeOIJtbW13eWk/d/NZtHc3KxHH31U+fn5dzmZtfQ2h5aWFlVVVSknJ0dVVVXavXu3Tp8+rSeffNKEpEDf4et3epGbm6vS0lJePTTZ6tWrdejQIX311VdmR8HfZGdna+/evaqurpbNZjM7jmVMnz5dUVFR8ng8vrVnnnlGdrtd27dvNzGZtbS2tmrQoEH6+OOPNW3aNN/6ww8/rPT0dOXl5ZmYzjpsNps++ugjPf3005L+3I11Op1avny5VqxYIUlqaGhQVFSUiouLNWfOHBPT9m9/n8Vf/fTTT4qLi9OJEyf04IMP3vVsVtLbHG44duyYHnnkEZ07d04xMTF3LxzQh9iRvYnq6mo5nU7Fx8dr3rx5On/+vNmRLOeTTz7RhAkTNHPmTA0bNkwul0vvvfee2bEs7/r169q+fbvcbjcl9i5LSUnR/v37debMGUnSyZMndfDgQaWnp5uczFr++OMPdXR0aODAgV3W7XY7794xUW1trS5fvqzU1FTfWkREhJKTk3X48GETkwH+o6GhQTabTZGRkWZHAW4bRbYXycnJKi4u1hdffKGCggLV1tZq8uTJunbtmtnRLOXs2bMqKCjQyJEjVVZWpsWLF2vp0qXaunWr2dEsrbS0VPX19Vq4cKHZUSxn9erVmjNnjhISEhQcHCyXy6Xs7GzNmzfP7GiWMmjQIE2cOFHr1q1TXV2dOjo6tH37dh0+fFiXLl0yO55lXb58WZIUFRXVZT0qKsp3DLCytrY2rVq1SpmZmQoPDzc7DnDbBpgdwJ/9dXdj3LhxSk5OVmxsrEpKSvTCCy+YmMxaOjs7NWHCBK1fv16S5HK5dOrUKW3evFkLFiwwOZ11eTwepaeny+l0mh3FckpKSrRjxw7t3LlTiYmJ8nq9ys7OltPp5DFxl23btk1ut1vDhw9XUFCQHnroIWVmZuqbb74xOxoAdNPe3q5Zs2bJMAwVFBSYHQf4T9iR/RciIyM1atQo1dTUmB3FUhwOh8aMGdNl7YEHHuBt3iY6d+6c9u3bp0WLFpkdxZJWrlzp25UdO3as5s+fr2XLlun11183O5rljBgxQl9++aWampr0888/6+jRo2pvb1d8fLzZ0SwrOjpaknTlypUu61euXPEdA6zoRok9d+6cysvL2Y1FwKPI/gtNTU368ccf5XA4zI5iKZMmTdLp06e7rJ05c0axsbEmJUJRUZGGDRvW5QNucPe0tLTof//r+vQdFBSkzs5OkxIhLCxMDodDV69eVVlZmZ566imzI1lWXFycoqOjtX//ft9aY2Ojjhw5ookTJ5qYDDDPjRJbXV2tffv2aciQIWZHAv4z3lrcixUrVigjI0OxsbGqq6vT2rVrFRQUpMzMTLOjWcqyZcuUkpKi9evXa9asWTp69Ki2bNmiLVu2mB3Nkjo7O1VUVKQFCxZowACeQsyQkZGh1157TTExMUpMTNSJEyf01ltvye12mx3NcsrKymQYhkaPHq2amhqtXLlSCQkJev75582O1q81NTV1eXdUbW2tvF6vBg8erJiYGGVnZysvL08jR45UXFyccnJy5HQ6e/0UV9yem83it99+0/nz533fWXrjheno6Gh2yPtQb3NwOBx69tlnVVVVpb1796qjo8P39+KDBw9WSEiIWbGB/8bAP5o9e7bhcDiMkJAQY/jw4cbs2bONmpoas2NZ0p49e4ykpCQjNDTUSEhIMLZs2WJ2JMsqKyszJBmnT582O4plNTY2Gi+++KIRExNjDBw40IiPjzdefvll4/fffzc7muV8+OGHRnx8vBESEmJER0cbS5YsMerr682O1e9VVFQYkrrdFixYYBiGYXR2dho5OTlGVFSUERoaajz++OM8Z90hN5tFUVFRj8fXrl1rau7+prc51NbW9nhMklFRUWF2dOC28T2yAAAAAICAwt/IAgAAAAACCkUWAAAAABBQKLIAAAAAgIBCkQUAAAAABBSKLAAAAAAgoFBkAQAAAAABhSILAAAAAAgoFFkAAAAAQEChyAIAAAAAAgpFFgDgN6ZMmaLs7Oxu68XFxYqMjJQk5ebmymazaerUqd3Oe+ONN2Sz2TRlypRuxy5cuKCQkBAlJSX1+G/bbDbfLSIiQpMmTdKBAwd8xysrK5WRkSGn0ymbzabS0tLbuYsAAKAPUGQBAAHH4XCooqJCFy5c6LJeWFiomJiYHn+nuLhYs2bNUmNjo44cOdLjOUVFRbp06ZIOHTqke++9V9OnT9fZs2clSc3NzRo/frw2bdrUt3cGAAD8axRZAEDAGTZsmNLS0rR161bf2tdff61ff/1V06ZN63a+YRgqKirS/PnzNXfuXHk8nh6vGxkZqejoaCUlJamgoECtra0qLy+XJKWnpysvL08zZsy4M3cKAADcMoosACAgud1uFRcX+34uLCzUvHnzFBIS0u3ciooKtbS0KDU1VVlZWfrggw/U3Nzc6/Xtdrsk6fr1632aGwAA/HcUWQBAQJo+fboaGxtVWVmp5uZmlZSUyO1293iux+PRnDlzFBQUpKSkJMXHx2vXrl3/eO2Wlha98sorCgoK0mOPPXan7gIAALhNA8wOAADA7QgODlZWVpaKiop09uxZjRo1SuPGjet2Xn19vXbv3q2DBw/61rKysuTxeLRw4cIu52ZmZiooKEitra0aOnSoPB5Pj9cEAADmosgCAPxGeHi4Ghoauq3X19crIiKi27rb7VZycrJOnTr1j7uxO3fuVFtbm5KTk31rhmGos7NTZ86c0ahRo3zrb7/9tlJTUxUREaGhQ4f2wT0CAAB3Am8tBgD4jdGjR6uqqqrbelVVVZfCeUNiYqISExN16tQpzZ07t8drejweLV++XF6v13c7efKkJk+erMLCwi7nRkdH6/7776fEAgDg59iRBQD4jcWLF2vjxo1aunSpFi1apNDQUH366ad6//33tWfPnh5/58CBA2pvb/d9z+xfeb1eVVVVaceOHUpISOhyLDMzU6+++qry8vI0YMDN/ztsampSTU2N7+fa2lp5vV4NHjz4H7/yBwAA3BnsyAIA/EZ8fLwqKyv1ww8/KDU1VcnJySopKdGuXbs0derUHn8nLCysxxIr/bkbO2bMmG4lVpJmzJihX375RZ999tktZTt+/LhcLpdcLpck6aWXXpLL5dKaNWtu7c4BAIA+YzMMwzA7BAAAAAAAt4odWQAAAABAQKHIAgAAAAACCkUWAAAAABBQKLIAAAAAgIBCkQUAAAAABBSKLAAAAAAgoFBkAQAAAAABhSILAAAAAAgoFFkAAAAAQEChyAIAAAAAAgpFFgAAAAAQUP4PTVpedbFqsXoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_df = my_valid\n",
    "\n",
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_ST.pth\",num_labels=2)\n",
    "\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "valid_sequences = list(valid_df['sequence'])\n",
    "valid_embeddings = get_embeddings(model_reload, tokenizer, valid_sequences)\n",
    "\n",
    "umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "\n",
    "labels = list(valid_df['label'])\n",
    "\n",
    "plot_umap(umap_embeddings, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f029bcf-42ef-4476-b575-3c14adb71b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da0e6c-e921-493b-9304-8ba9aad07d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

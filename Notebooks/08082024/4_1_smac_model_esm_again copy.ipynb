{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2319a5",
   "metadata": {},
   "source": [
    "This notebook will implement changing lora settings and separate dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1959ca-a3c9-46d8-8519-064c38f52007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:48:44.051741Z",
     "iopub.status.busy": "2024-04-05T12:48:44.050047Z",
     "iopub.status.idle": "2024-04-05T12:52:49.260801Z",
     "shell.execute_reply": "2024-04-05T12:52:49.259100Z",
     "shell.execute_reply.started": "2024-04-05T12:48:44.051657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torch==2.1.1 torchaudio torchvision tqdm==4.66.1 accelerate==0.24.1 biopython==1.81 numpy==1.26.2 pandas==2.1.3 \\\n",
    "# transformers==4.35.2 datasets==2.15.0 scikit-learn==1.3.2 umap-learn==0.5.5 sentencepiece==0.1.99 seaborn==0.13.0 scipy==1.11.4 \\\n",
    "# matplotlib==3.8.2 evaluate==0.4.1 deepspeed==0.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060d0bba-32ad-4dc9-b1b8-d1124da1336c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a377270-2995-4da1-a673-5369769a6279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "# from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "# from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from transformers import EsmModel, EsmConfig, EsmTokenizer\n",
    "\n",
    "\n",
    "# Initializing a ESM facebook/esm-1b style configuration >>> configuration = EsmConfig()\n",
    "\n",
    "# Initializing a model from the configuration >>> model = ESMModel(configuration)\n",
    "\n",
    "# Accessing the model configuration >>> configuration = model.config\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install umap-learn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0148ff8f-80eb-4bbd-aac7-fe1f371da27a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.1.1+cu121\n",
      "Cuda version:  12.1\n",
      "Numpy version:  1.26.4\n",
      "Pandas version:  2.1.3\n",
      "Transformers version:  4.35.2\n",
      "Datasets version:  2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96bd9396-a81c-4d87-a722-0d2020627dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q9UQC2|GAB2_HUMAN%598%614</td>\n",
       "      <td>SGTNSPAPKKSTGSVDYLALDFQPSSPSPHRKP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|P18031|PTN1_HUMAN%137%153</td>\n",
       "      <td>DTNLKLTLISEDIKSYYTVRQLELENLTTQETR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|P08581|MET_HUMAN%1340%1356</td>\n",
       "      <td>IFSTFIGEHYVHVNATYVNVKCVAPYPSLLSSE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P35968|VGFR2_HUMAN%980%996</td>\n",
       "      <td>EKSLSDVEEEEAPEDLYKDFLTLEHLICYSFQV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|P35568|IRS1_HUMAN%880%896</td>\n",
       "      <td>QQQPLLHPPEPKSPGEYVNIEFGSDQSGYLSGP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name                           sequence  label\n",
       "0   sp|Q9UQC2|GAB2_HUMAN%598%614  SGTNSPAPKKSTGSVDYLALDFQPSSPSPHRKP      1\n",
       "1   sp|P18031|PTN1_HUMAN%137%153  DTNLKLTLISEDIKSYYTVRQLELENLTTQETR      1\n",
       "2  sp|P08581|MET_HUMAN%1340%1356  IFSTFIGEHYVHVNATYVNVKCVAPYPSLLSSE      1\n",
       "3  sp|P35968|VGFR2_HUMAN%980%996  EKSLSDVEEEEAPEDLYKDFLTLEHLICYSFQV      1\n",
       "4   sp|P35568|IRS1_HUMAN%880%896  QQQPLLHPPEPKSPGEYVNIEFGSDQSGYLSGP      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "# local_fasta_path = '../src/input_datasets/train_Pos_Neg_ST.fasta'\n",
    "\n",
    "# # Load FASTA file using Biopython\n",
    "# for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "#     # Split the description to extract label\n",
    "#     description_parts = record.description.split(\"%\")\n",
    "#     label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "#     sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/train_Pos_Neg_Y.fasta'\n",
    "\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76760f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "(160, 2)\n",
      "\n",
      "Validation Set:\n",
      "(41, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "my_train, my_valid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "my_train=my_train[[\"sequence\", \"label\"]]\n",
    "my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the training set\n",
    "print(\"Training Set:\")\n",
    "print(my_train.shape)\n",
    "\n",
    "# Print the first 5 rows of the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a424877b-787c-44fe-bf87-33346ffd3be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifies an existing transformer and introduce the LoRA layers\n",
    "\n",
    "class LoRAConfig:\n",
    "    def __init__(self, lora_rank=8, lora_init_scale=0.01, lora_scaling_rank=2):\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_init_scale = lora_init_scale\n",
    "        self.lora_modules = \".*SelfAttention|.*EncDecAttention\"\n",
    "        self.lora_layers = \"q|k|v|o\"\n",
    "        self.trainable_param_names = \".*layer_norm.*|.*lora_[ab].*\"\n",
    "        self.lora_scaling_rank = lora_scaling_rank\n",
    "        # lora_modules and lora_layers are specified with regular expressions\n",
    "        # see https://www.w3schools.com/python/python_regex.asp for reference\n",
    "        \n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, scaling_rank, init_scale):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.rank = rank\n",
    "        self.scaling_rank = scaling_rank\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        if self.rank > 0:\n",
    "            self.lora_a = nn.Parameter(torch.randn(rank, linear_layer.in_features) * init_scale)\n",
    "            if init_scale < 0:\n",
    "                self.lora_b = nn.Parameter(torch.randn(linear_layer.out_features, rank) * init_scale)\n",
    "            else:\n",
    "                self.lora_b = nn.Parameter(torch.zeros(linear_layer.out_features, rank))\n",
    "        if self.scaling_rank:\n",
    "            self.multi_lora_a = nn.Parameter(\n",
    "                torch.ones(self.scaling_rank, linear_layer.in_features)\n",
    "                + torch.randn(self.scaling_rank, linear_layer.in_features) * init_scale\n",
    "            )\n",
    "            if init_scale < 0:\n",
    "                self.multi_lora_b = nn.Parameter(\n",
    "                    torch.ones(linear_layer.out_features, self.scaling_rank)\n",
    "                    + torch.randn(linear_layer.out_features, self.scaling_rank) * init_scale\n",
    "                )\n",
    "            else:\n",
    "                self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, self.scaling_rank))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.scaling_rank == 1 and self.rank == 0:\n",
    "            # parsimonious implementation for ia3 and lora scaling\n",
    "            if self.multi_lora_a.requires_grad:\n",
    "                hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n",
    "            else:\n",
    "                hidden = F.linear(input, self.weight, self.bias)\n",
    "            if self.multi_lora_b.requires_grad:\n",
    "                hidden = hidden * self.multi_lora_b.flatten()\n",
    "            return hidden\n",
    "        else:\n",
    "            # general implementation for lora (adding and scaling)\n",
    "            weight = self.weight\n",
    "            if self.scaling_rank:\n",
    "                weight = weight * torch.matmul(self.multi_lora_b, self.multi_lora_a) / self.scaling_rank\n",
    "            if self.rank:\n",
    "                weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n",
    "            return F.linear(input, weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, rank={}, scaling_rank={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.rank, self.scaling_rank\n",
    "        )\n",
    "\n",
    "\n",
    "def modify_with_lora(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.lora_modules, m_name):\n",
    "            for c_name, layer in dict(module.named_children()).items():\n",
    "                if re.fullmatch(config.lora_layers, c_name):\n",
    "                    assert isinstance(\n",
    "                        layer, nn.Linear\n",
    "                    ), f\"LoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        c_name,\n",
    "                        LoRALinear(layer, config.lora_rank, config.lora_scaling_rank, config.lora_init_scale),\n",
    "                    )\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e79b323-4677-4723-a5fd-a60dc13a3b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.7, num_labels=2):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class ESMClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, class_config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "   \n",
    "        # Trainable emphasis factor\n",
    "        self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        seq_length = hidden_states.size(1)\n",
    "        middle_idx = seq_length // 2\n",
    "        middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "        # Apply trainable emphasis factor\n",
    "        emphasized_middle_embedding = middle_embedding * self.emphasis_factor\n",
    "\n",
    "        # Combine with the average embedding\n",
    "        average_embedding = torch.mean(hidden_states, dim=1)\n",
    "        combined_embedding = emphasized_middle_embedding + average_embedding\n",
    "\n",
    "        x = self.dropout(combined_embedding)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.out_proj(x)\n",
    "        return logits\n",
    "    \n",
    "from transformers import PreTrainedModel, EsmModel, EsmConfig\n",
    "\n",
    "class ESMForSequenceClassification(PreTrainedModel):\n",
    "    config_class = EsmConfig\n",
    "\n",
    "    def __init__(self, config: EsmConfig, class_config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.esm_model = EsmModel(config)\n",
    "        self.classifier = ESMClassificationHead(config, class_config)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.esm_model(input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        logits = self.classifier(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "            elif self.num_labels > 1 and labels.dtype in (torch.long, torch.int):\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71394626-6f8b-4ca5-80f3-c697e4320bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "def ESM_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "    model_checkpoint = \"facebook/esm2_t36_3B_UR50D\"\n",
    "\n",
    "    # Load PT5 and tokenizer\n",
    "    tokenizer = EsmTokenizer.from_pretrained(model_checkpoint)\n",
    "    model = EsmModel.from_pretrained(model_checkpoint)\n",
    "    \n",
    "    # Create new Classifier model with PT5 dimensions\n",
    "    class_config=ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "    class_model = ESMForSequenceClassification(model.config, class_config)\n",
    "    \n",
    "    # # Set encoder and embedding weights to checkpoint weights\n",
    "    # class_model.shared=model.shared\n",
    "    # class_model.encoder=model.encoder    \n",
    "    \n",
    "    # # Delete the checkpoint model\n",
    "    class_model.esm_model = model\n",
    "    model=class_model\n",
    "    del class_model\n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ESM_LoRA_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "    # Add model modification lora\n",
    "    config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "    # Add LoRA layers\n",
    "    model = modify_with_lora(model, config)\n",
    "    \n",
    "    # Freeze Embeddings and Encoder (except LoRA)\n",
    "    for (param_name, param) in model.named_parameters():\n",
    "                param.requires_grad = False\n",
    "    for (param_name, param) in model.classifier.named_parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # for (param_name, param) in model.named_parameters():\n",
    "    #         if re.fullmatch(config.trainable_param_names, param_name):\n",
    "    #             param.requires_grad = True\n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ESM_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4d56b2-c9ca-460d-b977-a1e4ae1e9568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4550fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    \"\"\"Custom early stopping callback that can monitor loss or accuracy.\"\"\"\n",
    "    \n",
    "    def __init__(self, metric_name='eval_loss', early_stopping_patience=3, minimize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric_name (str): Metric to monitor, default 'eval_loss'.\n",
    "            early_stopping_patience (int): Number of checks with no improvement after which training will be stopped.\n",
    "            minimize (bool): Set to True if the metric should be minimized, False if it should be maximized.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_counter = 0\n",
    "        self.minimize = minimize\n",
    "        self.best_metric = float('inf') if minimize else float('-inf')\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        current_metric = kwargs['metrics'][self.metric_name]\n",
    "        \n",
    "        if (self.minimize and current_metric < self.best_metric) or (not self.minimize and current_metric > self.best_metric):\n",
    "            self.best_metric = current_metric\n",
    "            self.early_stopping_counter = 0\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "        \n",
    "        if self.early_stopping_counter >= self.early_stopping_patience:\n",
    "            control.should_training_stop = True\n",
    "            print(f'Stopping early! No improvement in {self.metric_name} for {self.early_stopping_patience} evaluation steps.')\n",
    "\n",
    "\n",
    "class MultiObjectiveEarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        # Extract current validation loss and accuracy\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "\n",
    "        # Check if current loss and accuracy improved significantly\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            # Update best scores and reset wait time\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            # If no improvement, increment the wait counter\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                # If wait exceeds the patience, stop training\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "class MultiObjectiveEarlyStoppingAndSaveCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001, output_dir='./model_output', filename='finetuned_model'):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "        self.output_dir = output_dir\n",
    "        self.filename = filename\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "        model = kwargs['model']\n",
    "\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "            # Save the model as the best so far\n",
    "            self.save_finetuned_parameters(model, os.path.join(self.output_dir, self.filename))\n",
    "            print(f\"Saved improved model to {self.output_dir}/{self.filename}\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "    def save_finetuned_parameters(self, model, filepath):\n",
    "        # Create a dictionary to hold the non-frozen parameters\n",
    "        non_frozen_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "        # Save only the finetuned parameters \n",
    "        torch.save(non_frozen_params, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfb8bb11-79b0-4936-9099-f9f8ef97e105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "# Set random seeds for reproducibility of your trainings run\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, min_dist=0.01):\n",
    "    umap_model = umap.UMAP(n_components=n_components)\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    data = {\"UMAP1\": embeddings[:, 0], \"UMAP2\": embeddings[:, 1], \"Label\": labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9)\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_new.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "# Main training fuction\n",
    "def train_per_protein(\n",
    "        train_dataset,         #training data\n",
    "        valid_dataset,         #validation data      \n",
    "        weight_decay,\n",
    "        warmup_pct,\n",
    "        num_labels= 2,    #1 for regression, >1 for classification\n",
    "    \n",
    "        # effective training batch size is batch * accum\n",
    "        # we recommend an effective batch size of 8 \n",
    "        batch= 4,         #for training\n",
    "        accum= 2,         #gradient accumulation\n",
    "    \n",
    "        val_batch = 16,   #batch size for evaluation\n",
    "        epochs=1,       #training epochs\n",
    "        lr= 3e-4,         #recommended learning rate\n",
    "        seed= 42,         #random seed\n",
    "        deepspeed=False,  #if gpu is large enough disable deepspeed for training speedup\n",
    "        gpu= 1,\n",
    "        dropout=0.5, #dropout rate\n",
    "         #L2 weight regularization\n",
    "        lora_rank=4,      #lora rank\n",
    "        lora_init_scale=0.01, #lora scaling rank\n",
    "        lora_scaling_rank=1,       #lora a\n",
    "        ):         #gpu selection (1 for first gpu)\n",
    "\n",
    "    # Set gpu device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # load model\n",
    "    model, tokenizer = ESM_classification_model(num_labels=num_labels, dropout=dropout, lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    total_steps = epochs * len(train_dataset) // batch\n",
    "    warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "    # Define TrainingArguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir='./results',              # where to save the model\n",
    "        evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "        logging_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        learning_rate=lr,                    # initial learning rate\n",
    "        per_device_train_batch_size=batch,   # batch size per device\n",
    "        gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "        num_train_epochs=epochs,             # number of epochs to train\n",
    "        weight_decay=weight_decay,           # L2 weight regularization\n",
    "        warmup_steps=warmup_steps,           # 10% of total steps\n",
    "        load_best_model_at_end=False,         # load the best model at the end of training\n",
    "        seed=seed,                           # random seed\n",
    "        push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "        logging_dir='./logs',\n",
    "    )\n",
    "    # metric_for_best_model='eval_loss|accuracy'\n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        # Check if predictions have the expected shape\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "        # Now, compute the metric (e.g., accuracy)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        # Return the metric(s) as a dictionary\n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    # For minimizing loss\n",
    "    early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "    # For maximizing accuracy\n",
    "    early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "            early_stopping_patience=3,\n",
    "            min_delta=0.001,\n",
    "            output_dir='./model_output',\n",
    "            filename='finetuned_model_all_esm2_smac.pth'\n",
    "        )],\n",
    "    )    \n",
    "\n",
    "    def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "        embeddings = []\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "    \n",
    "        # Iterate over the sequences in batches\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            # Extract a batch of sequences\n",
    "            batch = sequences[i:i + batch_size]\n",
    "    \n",
    "            # Tokenize the batch using the specified tokenizer and convert to PyTorch tensors\n",
    "            inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                # Forward pass through the model to obtain outputs\n",
    "                outputs = model(**inputs)\n",
    "    \n",
    "            # Extract hidden states from the second-to-last layer (penultimate layer)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "    \n",
    "            # Take the embeddings from the second-to-last layer\n",
    "            embeddings_from_layer = hidden_states[:, 0, :]\n",
    "    \n",
    "            # Extend the list with the generated embeddings\n",
    "            embeddings.extend(embeddings_from_layer)\n",
    "    \n",
    "            print(f\"Batch {i // batch_size + 1}, Second-to-Last Layer Embeddings Shape: {embeddings_from_layer.shape}\")\n",
    "    \n",
    "        return np.array(embeddings)\n",
    "\n",
    "        \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    # Get the best model\n",
    "    # model = trainer.model\n",
    "    # Ensure the best model is loaded\n",
    "    best_model_path = os.path.join('./model_output', 'finetuned_model_all_esm2_smac.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        state_dict = torch.load(best_model_path)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "    # Evaluate the best model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(eval_results)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b300952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Dataset creation\n",
    "def create_dataset(tokenizer,seqs,labels):\n",
    "    tokenized = tokenizer(seqs, max_length=1024, padding=True, truncation=True)\n",
    "    dataset = Dataset.from_dict(tokenized)\n",
    "    dataset = dataset.add_column(\"labels\", labels)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Initialize the tokenizer\n",
    "model_checkpoint = \"facebook/esm2_t36_3B_UR50D\"\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_checkpoint)\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", do_lower_case=False, force_download=True) \n",
    "\n",
    "train_df = my_train\n",
    "valid_df = my_valid\n",
    "\n",
    "# Preprocess inputs\n",
    "# Replace uncommon AAs with \"X\"\n",
    "train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "# Add spaces between each amino acid for PT5 to correctly use them\n",
    "train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "# Create Datasets\n",
    "train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']))\n",
    "valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a57f7fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 161\u001b[0m\n\u001b[1;32m    151\u001b[0m smac \u001b[38;5;241m=\u001b[39m HPOFacade(\n\u001b[1;32m    152\u001b[0m     scenario,\n\u001b[1;32m    153\u001b[0m     protein_model\u001b[38;5;241m.\u001b[39mtrain,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Let's optimize\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m incumbents \u001b[38;5;241m=\u001b[39m \u001b[43msmac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Prepare results\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# all_runs = []\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/smac/facade/abstract_facade.py:322\u001b[0m, in \u001b[0;36mAbstractFacade.optimize\u001b[0;34m(self, data_to_scatter)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_to_scatter must be None or dict with some elements, but got an empty dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 322\u001b[0m     incumbents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_to_scatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_to_scatter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/smac/main/smbo.py:305\u001b[0m, in \u001b[0;36mSMBO.optimize\u001b[0;34m(self, data_to_scatter)\u001b[0m\n\u001b[1;32m    301\u001b[0m     trial_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask()\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# We submit the trial to the runner\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;66;03m# In multi-worker mode, SMAC waits till a new worker is available here\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdask_data_to_scatter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/smac/runner/abstract_serial_runner.py:22\u001b[0m, in \u001b[0;36mAbstractSerialRunner.submit_trial\u001b[0;34m(self, trial_info)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial_info: TrialInfo) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function submits a trial_info object in a serial fashion. As there is a single\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m     worker for this task, this interface can be considered a wrapper over the `run` method.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m        An object containing the configuration launched.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results_queue\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_info\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/smac/runner/abstract_runner.py:110\u001b[0m, in \u001b[0;36mAbstractRunner.run_wrapper\u001b[0;34m(self, trial_info, **dask_data_to_scatter)\u001b[0m\n\u001b[1;32m    107\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     status, cost, runtime, additional_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbudget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdask_data_to_scatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    118\u001b[0m     status \u001b[38;5;241m=\u001b[39m StatusType\u001b[38;5;241m.\u001b[39mCRASHED\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/smac/runner/target_function_runner.py:186\u001b[0m, in \u001b[0;36mTargetFunctionRunner.run\u001b[0;34m(self, config, instance, budget, seed, **dask_data_to_scatter)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 186\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_copy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     runtime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    188\u001b[0m     status \u001b[38;5;241m=\u001b[39m StatusType\u001b[38;5;241m.\u001b[39mSUCCESS\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/smac/runner/target_function_runner.py:259\u001b[0m, in \u001b[0;36mTargetFunctionRunner.__call__\u001b[0;34m(self, config, algorithm, algorithm_kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    247\u001b[0m     config: Configuration,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], \u001b[38;5;28mdict\u001b[39m]\n\u001b[1;32m    257\u001b[0m ):\n\u001b[1;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the algorithm, which is processed in the ``run`` method.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43malgorithm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 58\u001b[0m, in \u001b[0;36mProteinModel.train\u001b[0;34m(self, config, seed, budget)\u001b[0m\n\u001b[1;32m     55\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Call your training function\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m tokenizer, model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_per_protein\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdropout_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwarmup_pct\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlora_rank\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_init_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlora_init_scale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_scaling_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlora_scaling_rank\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Extract the last validation accuracy and loss from the history\u001b[39;00m\n\u001b[1;32m     76\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m [entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m history \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m entry][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[14], line 61\u001b[0m, in \u001b[0;36mtrain_per_protein\u001b[0;34m(train_dataset, valid_dataset, weight_decay, warmup_pct, num_labels, batch, accum, val_batch, epochs, lr, seed, deepspeed, gpu, dropout, lora_rank, lora_init_scale, lora_scaling_rank)\u001b[0m\n\u001b[1;32m     58\u001b[0m set_seeds(seed)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mESM_classification_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_init_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_init_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_scaling_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_scaling_rank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Huggingface Trainer arguments\u001b[39;00m\n\u001b[1;32m     64\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m epochs \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataset) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch\n",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m, in \u001b[0;36mESM_classification_model\u001b[0;34m(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load PT5 and tokenizer\u001b[39;00m\n\u001b[1;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m EsmTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_checkpoint)\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mEsmModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create new Classifier model with PT5 dimensions\u001b[39;00m\n\u001b[1;32m     13\u001b[0m class_config\u001b[38;5;241m=\u001b[39mClassConfig(num_labels\u001b[38;5;241m=\u001b[39mnum_labels, dropout\u001b[38;5;241m=\u001b[39mdropout)\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/modeling_utils.py:3128\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3125\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   3126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[1;32m   3127\u001b[0m     \u001b[38;5;66;03m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3128\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3144\u001b[0m     is_safetensors_available()\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3147\u001b[0m ):\n\u001b[1;32m   3148\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/utils/hub.py:1052\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1051\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshard_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/utils/hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to request access at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and pass a token having permission to this repo either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1221\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m   1203\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1219\u001b[0m     )\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1367\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1365\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1367\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1377\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1884\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1881\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1882\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1884\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1893\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1894\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:459\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resume_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    457\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (resume_size,)\n\u001b[0;32m--> 459\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHF_HUB_DOWNLOAD_TIMEOUT\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m    463\u001b[0m content_length \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:395\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/utils/_http.py:66\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     68\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/requests/adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    586\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/urllib3/connectionpool.py:1099\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/urllib3/connection.py:616\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    615\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m    618\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/urllib3/util/connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m     62\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/socket.py:954\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# We override this function since we want to translate the numeric family\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# and socket type values to enum constants.\u001b[39;00m\n\u001b[1;32m    953\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    955\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m    956\u001b[0m     addrlist\u001b[38;5;241m.\u001b[39mappend((_intenum_converter(af, AddressFamily),\n\u001b[1;32m    957\u001b[0m                      _intenum_converter(socktype, SocketKind),\n\u001b[1;32m    958\u001b[0m                      proto, canonname, sa))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from ConfigSpace import ConfigurationSpace, Configuration\n",
    "from ConfigSpace.hyperparameters import UniformFloatHyperparameter, CategoricalHyperparameter, UniformIntegerHyperparameter\n",
    "from smac import HyperparameterOptimizationFacade as HPOFacade\n",
    "from smac import Scenario\n",
    "from smac.intensifier.hyperband import Hyperband\n",
    "from smac.multi_objective.parego import ParEGO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "class ProteinModel:\n",
    "    @property\n",
    "    def configspace(self) -> ConfigurationSpace:\n",
    "        cs = ConfigurationSpace()\n",
    "\n",
    "        cs.add_hyperparameters([\n",
    "            UniformFloatHyperparameter('lr', lower=1e-5, upper=1e-2, log=True),\n",
    "            CategoricalHyperparameter('batch', choices=[1, 2, 4, 8]),\n",
    "            CategoricalHyperparameter('accum', choices=[2, 4, 8]),\n",
    "            UniformFloatHyperparameter('dropout_rate', lower=0.1, upper=0.9),\n",
    "            UniformFloatHyperparameter('weight_decay', lower=1e-5, upper=1e-3, log=True),\n",
    "            UniformFloatHyperparameter('warmup_pct', lower=0.01, upper=0.3),\n",
    "            UniformIntegerHyperparameter('lora_rank', lower=4, upper=32),\n",
    "            UniformFloatHyperparameter('lora_init_scale', lower=1e-4, upper=1e-1, log=True),\n",
    "            UniformIntegerHyperparameter('lora_scaling_rank', lower=1, upper=4)\n",
    "        ])\n",
    "\n",
    "        cs['lora_rank'].q = 4\n",
    "\n",
    "        return cs\n",
    "\n",
    "    def train(self, config: Configuration, seed: int = 42, budget: int = 10) -> dict[str, float]:\n",
    "        logger.info(f\"Training with budget (epochs): {budget}\")\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "            # Call your training function\n",
    "            tokenizer, model, history = train_per_protein(\n",
    "                train_dataset=train_set,\n",
    "                valid_dataset=valid_set,\n",
    "                num_labels=2,\n",
    "                batch=int(config['batch']),\n",
    "                accum=int(config['accum']),\n",
    "                epochs=int(budget),\n",
    "                lr=config['lr'],\n",
    "                dropout=config['dropout_rate'],\n",
    "                weight_decay=config['weight_decay'],\n",
    "                warmup_pct=config['warmup_pct'],\n",
    "                lora_rank=config['lora_rank'],\n",
    "                lora_init_scale=config['lora_init_scale'],\n",
    "                lora_scaling_rank=config['lora_scaling_rank'],\n",
    "                seed=seed\n",
    "            )\n",
    "\n",
    "            # Extract the last validation accuracy and loss from the history\n",
    "            val_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry][-1]\n",
    "            val_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry][-1]\n",
    "\n",
    "        logger.info(f\"Completed training. Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n",
    "        return {\n",
    "            \"val_loss\": val_loss,\n",
    "            \"1 - val_accuracy\": 1 - val_accuracy,  # We minimize, so we use 1 - accuracy\n",
    "        }\n",
    "\n",
    "def plot_pareto(smac: HPOFacade, incumbents: list[Configuration]) -> None:\n",
    "    \"\"\"Plots configurations from SMAC and highlights the best configurations in a Pareto front.\"\"\"\n",
    "    average_costs = []\n",
    "    average_pareto_costs = []\n",
    "    for config in smac.runhistory.get_configs():\n",
    "        # Since we use multiple seeds, we have to average them to get only one cost value pair for each configuration\n",
    "        average_cost = smac.runhistory.average_cost(config)\n",
    "\n",
    "        if config in incumbents:\n",
    "            average_pareto_costs += [average_cost]\n",
    "        else:\n",
    "            average_costs += [average_cost]\n",
    "\n",
    "    # Let's work with a numpy array\n",
    "    costs = np.vstack(average_costs)\n",
    "    pareto_costs = np.vstack(average_pareto_costs)\n",
    "    pareto_costs = pareto_costs[pareto_costs[:, 0].argsort()]  # Sort them\n",
    "\n",
    "    costs_x, costs_y = costs[:, 0], costs[:, 1]\n",
    "    pareto_costs_x, pareto_costs_y = pareto_costs[:, 0], pareto_costs[:, 1]\n",
    "\n",
    "    plt.scatter(costs_x, costs_y, marker=\"x\", label=\"Configuration\")\n",
    "    plt.scatter(pareto_costs_x, pareto_costs_y, marker=\"x\", c=\"r\", label=\"Incumbent\")\n",
    "    plt.step(\n",
    "        [pareto_costs_x[0]] + pareto_costs_x.tolist() + [np.max(costs_x)],  # We add bounds\n",
    "        [np.max(costs_y)] + pareto_costs_y.tolist() + [np.min(pareto_costs_y)],  # We add bounds\n",
    "        where=\"post\",\n",
    "        linestyle=\":\",\n",
    "    )\n",
    "\n",
    "    plt.title(\"Pareto-Front\")\n",
    "    plt.xlabel(smac.scenario.objectives[0])\n",
    "    plt.ylabel(smac.scenario.objectives[1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    protein_model = ProteinModel()\n",
    "    objectives = [\"val_loss\", \"1 - val_accuracy\"]\n",
    "\n",
    "    # Define output directory\n",
    "    output_dir = \"./smac3_output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define our environment variables\n",
    "    scenario = Scenario(\n",
    "        protein_model.configspace,\n",
    "        objectives=objectives,\n",
    "        # walltime_limit=1800,  # After 30 minutes, we stop the hyperparameter optimization\n",
    "        n_trials=30,  # Evaluate up to 30 different configurations\n",
    "        min_budget=5,\n",
    "        max_budget=20,\n",
    "        n_workers=1,\n",
    "        output_directory=output_dir,\n",
    "        name=\"ProteinModelOptimization_4_again\",\n",
    "    )\n",
    "\n",
    "    # We want to run five random configurations before starting the optimization.\n",
    "    initial_design = HPOFacade.get_initial_design(scenario, n_configs=5)\n",
    "\n",
    "    intensifier = HPOFacade.get_intensifier(scenario, max_config_calls=2)\n",
    "\n",
    "    # Set up the multi-objective optimizer\n",
    "    multi_objective_algorithm = ParEGO(scenario=scenario)\n",
    "\n",
    "    # Create our SMAC object and pass the scenario and the train method\n",
    "    smac = HPOFacade(\n",
    "        scenario,\n",
    "        protein_model.train,\n",
    "        initial_design=initial_design,\n",
    "        multi_objective_algorithm=multi_objective_algorithm,\n",
    "        intensifier=intensifier,\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    # Let's optimize\n",
    "    incumbents = smac.optimize()\n",
    "\n",
    "    # Prepare results\n",
    "    # all_runs = []\n",
    "\n",
    "    print(\"**************\")\n",
    "    print(\"\\nBest configurations:\")\n",
    "    for incumbent in incumbents:\n",
    "        print(\"Configuration: \", incumbent)\n",
    "        print(\"Average Cost: \", smac.runhistory.average_cost(incumbent))\n",
    "        print(\"Value: \", smac.runhistory.get_cost(incumbent))\n",
    "        print(\"Hyperparameters: \", dict(incumbent))\n",
    "        # print(\"---\", cost)\n",
    "\n",
    "    # Let's plot a pareto front\n",
    "    plot_pareto(smac, incumbents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12eca2f6-0062-4c84-a48a-f9dfa06773cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING][target_function_runner.py:74] The argument budget is not set by SMAC: Consider removing it from the target function.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 1.0032942295074463, 'eval_accuracy': 0.6313131313131313, 'eval_runtime': 8.7219, 'eval_samples_per_second': 45.403, 'eval_steps_per_second': 5.733, 'epoch': 4.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 1.0032942295074463, Val Accuracy: 0.6313131313131313\n",
      "[INFO][abstract_intensifier.py:516] Added config b74743 as new incumbent because there are no incumbents yet.\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6875739097595215, 'eval_accuracy': 0.7222222222222222, 'eval_runtime': 8.7124, 'eval_samples_per_second': 45.452, 'eval_steps_per_second': 5.739, 'epoch': 6.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.6875739097595215, Val Accuracy: 0.7222222222222222\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.5584241151809692, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.7225, 'eval_samples_per_second': 45.4, 'eval_steps_per_second': 5.732, 'epoch': 10.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5584241151809692, Val Accuracy: 0.7373737373737373\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.5595582127571106, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.7233, 'eval_samples_per_second': 45.396, 'eval_steps_per_second': 5.732, 'epoch': 10.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5595582127571106, Val Accuracy: 0.7323232323232324\n",
      "[INFO][abstract_intensifier.py:595] Added config 8648e5 and rejected config b74743 as incumbent because it is not better than the incumbents on 2 instances:\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5425368547439575, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7026, 'eval_samples_per_second': 45.504, 'eval_steps_per_second': 5.745, 'epoch': 6.99}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5425368547439575, Val Accuracy: 0.7424242424242424\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5282009243965149, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7052, 'eval_samples_per_second': 45.49, 'eval_steps_per_second': 5.744, 'epoch': 6.99}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5282009243965149, Val Accuracy: 0.7424242424242424\n",
      "[INFO][abstract_intensifier.py:595] Added config 5d50d2 and rejected config 8648e5 as incumbent because it is not better than the incumbents on 2 instances:\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5540337562561035, 'eval_accuracy': 0.7045454545454546, 'eval_runtime': 8.7316, 'eval_samples_per_second': 45.353, 'eval_steps_per_second': 5.726, 'epoch': 8.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5540337562561035, Val Accuracy: 0.7045454545454546\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.542227029800415, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.7383, 'eval_samples_per_second': 45.318, 'eval_steps_per_second': 5.722, 'epoch': 10.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.542227029800415, Val Accuracy: 0.7323232323232324\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5375558137893677, 'eval_accuracy': 0.7247474747474747, 'eval_runtime': 8.7032, 'eval_samples_per_second': 45.5, 'eval_steps_per_second': 5.745, 'epoch': 8.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5375558137893677, Val Accuracy: 0.7247474747474747\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 7.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5280433297157288, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.7314, 'eval_samples_per_second': 45.354, 'eval_steps_per_second': 5.726, 'epoch': 7.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5280433297157288, Val Accuracy: 0.7348484848484849\n",
      "[INFO][abstract_intensifier.py:603] Config 21fac9 is a new incumbent. Total number of incumbents: 2.\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 4.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 4.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5499128699302673, 'eval_accuracy': 0.7196969696969697, 'eval_runtime': 8.7277, 'eval_samples_per_second': 45.373, 'eval_steps_per_second': 5.729, 'epoch': 4.99}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5499128699302673, Val Accuracy: 0.7196969696969697\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 4.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 4.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5335100889205933, 'eval_accuracy': 0.73989898989899, 'eval_runtime': 8.7036, 'eval_samples_per_second': 45.499, 'eval_steps_per_second': 5.745, 'epoch': 4.99}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5335100889205933, Val Accuracy: 0.73989898989899\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5263095498085022, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.7008, 'eval_samples_per_second': 45.513, 'eval_steps_per_second': 5.747, 'epoch': 6.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5263095498085022, Val Accuracy: 0.7348484848484849\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.5545506477355957, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.6985, 'eval_samples_per_second': 45.525, 'eval_steps_per_second': 5.748, 'epoch': 9.9}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5545506477355957, Val Accuracy: 0.7424242424242424\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.5452086925506592, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.7017, 'eval_samples_per_second': 45.508, 'eval_steps_per_second': 5.746, 'epoch': 9.9}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5452086925506592, Val Accuracy: 0.7348484848484849\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.5479008555412292, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.7003, 'eval_samples_per_second': 45.516, 'eval_steps_per_second': 5.747, 'epoch': 9.9}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5479008555412292, Val Accuracy: 0.7323232323232324\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5405221581459045, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7008, 'eval_samples_per_second': 45.513, 'eval_steps_per_second': 5.747, 'epoch': 6.99}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5405221581459045, Val Accuracy: 0.7424242424242424\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.527576744556427, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 8.7117, 'eval_samples_per_second': 45.456, 'eval_steps_per_second': 5.739, 'epoch': 6.99}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.527576744556427, Val Accuracy: 0.7474747474747475\n",
      "[INFO][abstract_intensifier.py:595] Added config 6e2878 and rejected config 5d50d2 as incumbent because it is not better than the incumbents on 2 instances:\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.5467162728309631, 'eval_accuracy': 0.7297979797979798, 'eval_runtime': 8.7053, 'eval_samples_per_second': 45.489, 'eval_steps_per_second': 5.744, 'epoch': 9.9}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5467162728309631, Val Accuracy: 0.7297979797979798\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.5486463904380798, 'eval_accuracy': 0.7373737373737373, 'eval_runtime': 8.7038, 'eval_samples_per_second': 45.498, 'eval_steps_per_second': 5.745, 'epoch': 9.9}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5486463904380798, Val Accuracy: 0.7373737373737373\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.5177323222160339, 'eval_accuracy': 0.7424242424242424, 'eval_runtime': 8.7239, 'eval_samples_per_second': 45.393, 'eval_steps_per_second': 5.731, 'epoch': 9.9}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5177323222160339, Val Accuracy: 0.7424242424242424\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.5206154584884644, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 8.7091, 'eval_samples_per_second': 45.47, 'eval_steps_per_second': 5.741, 'epoch': 9.9}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5206154584884644, Val Accuracy: 0.7474747474747475\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.517875075340271, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.701, 'eval_samples_per_second': 45.512, 'eval_steps_per_second': 5.746, 'epoch': 9.9}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.517875075340271, Val Accuracy: 0.7449494949494949\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.5200099945068359, 'eval_accuracy': 0.7550505050505051, 'eval_runtime': 8.7028, 'eval_samples_per_second': 45.503, 'eval_steps_per_second': 5.745, 'epoch': 9.9}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5200099945068359, Val Accuracy: 0.7550505050505051\n",
      "[INFO][abstract_intensifier.py:595] Added config 1f620e and rejected config a955ad as incumbent because it is not better than the incumbents on 2 instances:\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.98989898989899: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5682356357574463, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.7033, 'eval_samples_per_second': 45.5, 'eval_steps_per_second': 5.745, 'epoch': 6.99}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5682356357574463, Val Accuracy: 0.7348484848484849\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5756850838661194, 'eval_accuracy': 0.7348484848484849, 'eval_runtime': 8.6999, 'eval_samples_per_second': 45.518, 'eval_steps_per_second': 5.747, 'epoch': 6.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5756850838661194, Val Accuracy: 0.7348484848484849\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5555273294448853, 'eval_accuracy': 0.7121212121212122, 'eval_runtime': 8.7308, 'eval_samples_per_second': 45.357, 'eval_steps_per_second': 5.727, 'epoch': 6.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5555273294448853, Val Accuracy: 0.7121212121212122\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "{'eval_loss': 0.542090117931366, 'eval_accuracy': 0.7323232323232324, 'eval_runtime': 8.7253, 'eval_samples_per_second': 45.385, 'eval_steps_per_second': 5.73, 'epoch': 10.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.542090117931366, Val Accuracy: 0.7323232323232324\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5228741765022278, 'eval_accuracy': 0.7449494949494949, 'eval_runtime': 8.7287, 'eval_samples_per_second': 45.368, 'eval_steps_per_second': 5.728, 'epoch': 8.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5228741765022278, Val Accuracy: 0.7449494949494949\n",
      "[INFO][3092310503.py:52] Training with budget (epochs): 10\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Loaded best model from ./model_output/finetuned_model_all_esm2_smac.pth\n",
      "Stopping early at epoch 10.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5179407000541687, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 8.7353, 'eval_samples_per_second': 45.333, 'eval_steps_per_second': 5.724, 'epoch': 10.0}\n",
      "[INFO][3092310503.py:79] Completed training. Val Loss: 0.5179407000541687, Val Accuracy: 0.7474747474747475\n",
      "[INFO][smbo.py:328] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:329] --- Remaining wallclock time: inf\n",
      "[INFO][smbo.py:330] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:331] --- Remaining trials: 0\n",
      "**************\n",
      "\n",
      "Best configurations:\n",
      "Configuration:  Configuration(values={\n",
      "  'accum': 4,\n",
      "  'batch': 8,\n",
      "  'dropout_rate': 0.2093265843513,\n",
      "  'lora_init_scale': 0.0014337078791,\n",
      "  'lora_rank': 13,\n",
      "  'lora_scaling_rank': 4,\n",
      "  'lr': 6.98836083e-05,\n",
      "  'warmup_pct': 0.0621490381419,\n",
      "  'weight_decay': 0.0004463029508,\n",
      "})\n",
      "Average Cost:  [0.5189425349235535, 0.25]\n",
      "Value:  0.020413299275637273\n",
      "Hyperparameters:  {'accum': 4, 'batch': 8, 'dropout_rate': 0.2093265843513, 'lora_init_scale': 0.0014337078791, 'lora_rank': 13, 'lora_scaling_rank': 4, 'lr': 6.98836083e-05, 'warmup_pct': 0.0621490381419, 'weight_decay': 0.0004463029508}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_845055/3092310503.py:35: DeprecationWarning: Please use `space.add(hyperparameters)`\n",
      "  cs.add_hyperparameters([\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [01:17<00:00, 38.77s/it]\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [01:55<00:00, 57.68s/it]\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:02<00:00, 61.28s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [01:23<00:00, 41.90s/it]\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [01:23<00:00, 41.70s/it]\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [00:46<00:00, 23.08s/it]\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [01:14<00:00, 37.31s/it]\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [01:09<00:00, 34.54s/it]\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:03<00:00, 61.72s/it]\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [01:33<00:00, 46.99s/it]\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:56<00:00, 88.15s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:43<00:00, 81.55s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:46<00:00, 83.37s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:58<00:00, 89.22s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:50<00:00, 85.19s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:34<00:00, 77.16s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:52<00:00, 86.28s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:59<00:00, 89.65s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [03:06<00:00, 93.46s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:45<00:00, 82.66s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:43<00:00, 81.85s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:34<00:00, 77.29s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:40<00:00, 80.34s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:17<00:00, 68.70s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:46<00:00, 83.20s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:22<00:00, 71.48s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:51<00:00, 85.63s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:19<00:00, 69.65s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:40<00:00, 80.01s/it] \n",
      "Loading checkpoint shards: 100%|##########| 2/2 [02:37<00:00, 78.97s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 792/1980 03:41 < 05:33, 3.57 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.677900</td>\n",
       "      <td>1.003294</td>\n",
       "      <td>0.631313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.888100</td>\n",
       "      <td>1.262189</td>\n",
       "      <td>0.595960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.176100</td>\n",
       "      <td>1.177082</td>\n",
       "      <td>0.626263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.745800</td>\n",
       "      <td>1.894938</td>\n",
       "      <td>0.595960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1188' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1188/1980 05:33 < 03:42, 3.56 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.697300</td>\n",
       "      <td>1.811024</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.938800</td>\n",
       "      <td>1.941353</td>\n",
       "      <td>0.535354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.426100</td>\n",
       "      <td>0.687574</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.853000</td>\n",
       "      <td>2.636436</td>\n",
       "      <td>0.654040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.831500</td>\n",
       "      <td>2.248864</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.833700</td>\n",
       "      <td>3.582867</td>\n",
       "      <td>0.507576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='356' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 356/1980 02:19 < 10:40, 2.53 it/s, Epoch 1.79/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.685675</td>\n",
       "      <td>0.641414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='346' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [346/490 05:10 < 02:09, 1.11 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.649800</td>\n",
       "      <td>0.565377</td>\n",
       "      <td>0.702020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.542300</td>\n",
       "      <td>0.529242</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.466700</td>\n",
       "      <td>0.538562</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.565411</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [149/490 02:03 < 04:46, 1.19 it/s, Epoch 2.99/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.655700</td>\n",
       "      <td>0.568374</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.561700</td>\n",
       "      <td>0.532766</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/50 00:06 < 00:02, 5.67 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3960/3960 10:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.772400</td>\n",
       "      <td>0.656064</td>\n",
       "      <td>0.616162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.764300</td>\n",
       "      <td>0.593832</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.756700</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.562978</td>\n",
       "      <td>0.699495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.574070</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.801600</td>\n",
       "      <td>0.602183</td>\n",
       "      <td>0.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.775200</td>\n",
       "      <td>0.545487</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.722200</td>\n",
       "      <td>0.543772</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.726400</td>\n",
       "      <td>0.542227</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.756500</td>\n",
       "      <td>0.541344</td>\n",
       "      <td>0.729798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [792/990 05:56 < 01:29, 2.21 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.699400</td>\n",
       "      <td>0.557189</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.701400</td>\n",
       "      <td>0.565354</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.705900</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.603535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.683900</td>\n",
       "      <td>0.543604</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.598500</td>\n",
       "      <td>0.537556</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.592400</td>\n",
       "      <td>0.537131</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.560400</td>\n",
       "      <td>0.538476</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.542100</td>\n",
       "      <td>0.599518</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='693' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [693/990 05:12 < 02:14, 2.21 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.716400</td>\n",
       "      <td>0.552265</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.732600</td>\n",
       "      <td>0.582087</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>0.773394</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.649100</td>\n",
       "      <td>0.528043</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.658797</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.633400</td>\n",
       "      <td>0.699496</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>0.569518</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/490 02:31 < 04:33, 1.15 it/s, Epoch 3.54/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.648500</td>\n",
       "      <td>0.561261</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.569200</td>\n",
       "      <td>0.560920</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 07:21, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.668487</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.616300</td>\n",
       "      <td>0.591293</td>\n",
       "      <td>0.714646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.567600</td>\n",
       "      <td>0.562686</td>\n",
       "      <td>0.742424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.554473</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.539300</td>\n",
       "      <td>0.547901</td>\n",
       "      <td>0.732323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.547240</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='346' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [346/490 05:10 < 02:09, 1.11 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.628300</td>\n",
       "      <td>0.536795</td>\n",
       "      <td>0.724747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.516100</td>\n",
       "      <td>0.527055</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.577312</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.587032</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='163' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [163/490 02:22 < 04:49, 1.13 it/s, Epoch 3.27/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.640200</td>\n",
       "      <td>0.714632</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.515300</td>\n",
       "      <td>0.785814</td>\n",
       "      <td>0.633838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 07:21, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.628788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.594100</td>\n",
       "      <td>0.571383</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.517300</td>\n",
       "      <td>0.531741</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>0.525063</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.461900</td>\n",
       "      <td>0.520615</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.435500</td>\n",
       "      <td>0.519989</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 07:21, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.688500</td>\n",
       "      <td>0.638486</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.561900</td>\n",
       "      <td>0.541461</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.499200</td>\n",
       "      <td>0.529698</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.524251</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>0.519062</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>0.517875</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/50 00:02 < 00:05, 5.71 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1226' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1226/1980 06:33 < 04:02, 3.11 it/s, Epoch 6.19/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.768600</td>\n",
       "      <td>0.631465</td>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.762200</td>\n",
       "      <td>0.599440</td>\n",
       "      <td>0.679293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.785800</td>\n",
       "      <td>0.595215</td>\n",
       "      <td>0.669192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.847800</td>\n",
       "      <td>0.560733</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.764800</td>\n",
       "      <td>0.602337</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.760800</td>\n",
       "      <td>0.591073</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 10:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.679200</td>\n",
       "      <td>0.639155</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.616800</td>\n",
       "      <td>0.579296</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.553700</td>\n",
       "      <td>0.548992</td>\n",
       "      <td>0.709596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.520400</td>\n",
       "      <td>0.530813</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.498900</td>\n",
       "      <td>0.528907</td>\n",
       "      <td>0.739899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.481500</td>\n",
       "      <td>0.524717</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>0.519860</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.454500</td>\n",
       "      <td>0.517941</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.451400</td>\n",
       "      <td>0.519852</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.441000</td>\n",
       "      <td>0.519565</td>\n",
       "      <td>0.744949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bcfe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"12\": {\n",
    "      \"accum\": 4,\n",
    "      \"batch\": 8,\n",
    "      \"dropout_rate\": 0.2093265843513,\n",
    "      \"lora_init_scale\": 0.0014337078791,\n",
    "      \"lora_rank\": 13,\n",
    "      \"lora_scaling_rank\": 4,\n",
    "      \"lr\": 6.98836083e-05,\n",
    "      \"warmup_pct\": 0.0621490381419,\n",
    "      \"weight_decay\": 0.0004463029508\n",
    "    },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddfce510-da2b-4b95-9491-49f9ae8efb06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|| 2/2 [34:28<00:00, 1034.27s/it]\n",
      "Loading checkpoint shards: 100%|| 2/2 [01:02<00:00, 31.07s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EsmModel' object has no attribute 'shared'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer, model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_per_protein\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6.98836083e-05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2093265843513\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0004463029508\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0621490381419\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_init_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0014337078791\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_scaling_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 61\u001b[0m, in \u001b[0;36mtrain_per_protein\u001b[0;34m(train_dataset, valid_dataset, weight_decay, warmup_pct, num_labels, batch, accum, val_batch, epochs, lr, seed, deepspeed, gpu, dropout, lora_rank, lora_init_scale, lora_scaling_rank)\u001b[0m\n\u001b[1;32m     58\u001b[0m set_seeds(seed)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mESM_classification_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_init_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_init_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_scaling_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_scaling_rank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Huggingface Trainer arguments\u001b[39;00m\n\u001b[1;32m     64\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m epochs \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataset) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch\n",
      "Cell \u001b[0;32mIn[12], line 17\u001b[0m, in \u001b[0;36mESM_classification_model\u001b[0;34m(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank)\u001b[0m\n\u001b[1;32m     14\u001b[0m class_model \u001b[38;5;241m=\u001b[39m ESMForSequenceClassification(model\u001b[38;5;241m.\u001b[39mconfig, class_config)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# # Set encoder and embedding weights to checkpoint weights\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m class_model\u001b[38;5;241m.\u001b[39mshared\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\n\u001b[1;32m     18\u001b[0m class_model\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencoder    \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# # Delete the checkpoint model\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/users/anup/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EsmModel' object has no attribute 'shared'"
     ]
    }
   ],
   "source": [
    "tokenizer, model, history = train_per_protein(train_set, valid_set, num_labels=2, batch=8, accum=4, epochs=20, seed=42, lr=6.98836083e-05, dropout=0.2093265843513, weight_decay=0.0004463029508, warmup_pct=0.0621490381419, lora_rank=13, lora_init_scale=0.0014337078791, lora_scaling_rank=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a28d3c1-8e24-4437-a1d9-dda9cefccfd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Truncate the longer list to the size of the shorter one\n",
    "min_length = min(len(loss), len(val_loss))\n",
    "loss = loss[:min_length]\n",
    "val_loss = val_loss[:min_length]\n",
    "\n",
    "# Get spearman (for regression) or accuracy value (for classification)\n",
    "if [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x] != []:\n",
    "    metric = [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x]\n",
    "else:\n",
    "    metric = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n",
    "\n",
    "epochs = [x['epoch'] for x in history if 'loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "line1 = ax1.plot(epochs, loss, label='train_loss')\n",
    "line2 = ax1.plot(epochs, val_loss, label='validation_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "#line3 = ax2.plot(epochs, metric, color='red', label='validation_metric')\n",
    "ax2.set_ylabel('Metric')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Add grid lines\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 \n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History for fine-tuning\")\n",
    "plt.savefig(f\"../Plots/Without_3rdline_Training_History_new.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4ef6f",
   "metadata": {},
   "source": [
    "lr 0.0003459380673689418\n",
    "batch 4\n",
    "accum 4\n",
    "dropout_rate 0.6303139405233136\n",
    "weight_decay 7.145415686725527e-05\n",
    "warmup_pct 0.12121786012551566\n",
    "lora_rank 20\n",
    "lora_init_scale 0.004413381171295235\n",
    "lora_scaling_rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccb1bbda-d70e-4b4c-a8d4-24600495171a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "def load_model(filepath, num_labels=2):\n",
    "# Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "    # load a new model\n",
    "    model, tokenizer = ESM_classification_model(num_labels=num_labels, dropout=0.2093265843513, lora_rank=13, lora_init_scale=0.0014337078791, lora_scaling_rank=4)\n",
    "    # model_checkpoint = \"facebook/esm2_t36_3B_UR50D\"\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "    # model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c97fa52-3aea-42e8-b72f-c4bb84808576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|| 2/2 [02:28<00:00, 74.03s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 2848188324.0\n",
      "ESM_LoRA_Classfier\n",
      "Trainable Parameter: 6561283.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_all_esm2_smac.pth\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2c20e75-5f40-4ca1-9579-5df49b738fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have different weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50b8a403-e7c5-4912-9c7a-f404c060c32a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WUI4|HDAC7_HUMAN%342%358</td>\n",
       "      <td>ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|Q13950|RUNX2_HUMAN%416%432</td>\n",
       "      <td>THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q15796|SMAD2_HUMAN%229%245</td>\n",
       "      <td>DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%416%432</td>\n",
       "      <td>TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2798%2814</td>\n",
       "      <td>MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0   sp|Q8WUI4|HDAC7_HUMAN%342%358  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
       "1   sp|Q13950|RUNX2_HUMAN%416%432  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
       "2   sp|Q15796|SMAD2_HUMAN%229%245  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
       "3    sp|P05787|K2C8_HUMAN%416%432  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2798%2814  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "    \n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_Y.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2d18716-fd26-49fe-9ba4-b84c936a364c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sequence  label\n",
      "0  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
      "1  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
      "2  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
      "3  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
      "4  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1\n"
     ]
    }
   ],
   "source": [
    "my_test=df[[\"sequence\", \"label\"]]\n",
    "\n",
    "print(my_test.head(5))\n",
    "\n",
    "'''\n",
    "my_test[\"sequence\"]=my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "my_test['sequence']=my_test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "'''\n",
    "\n",
    "#Using .loc ensures that you are modifying the original DataFrame rather than a view of it, which helps avoid the SettingWithCopyWarning.\n",
    "# Replace characters in the \"sequence\" column\n",
    "my_test.loc[:, \"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Convert each sequence to a space-separated string\n",
    "my_test.loc[:, 'sequence'] = my_test.apply(lambda row: \" \".join(row[\"sequence\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eee8fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = sequence.split()\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "my_test['middle_char'] = my_test['sequence'].apply(get_middle_char)\n",
    "\n",
    "# Split the DataFrame\n",
    "my_test_S = my_test[my_test['middle_char'] == 'S'].drop(columns=['middle_char'])\n",
    "my_test_T = my_test[my_test['middle_char'] == 'T'].drop(columns=['middle_char'])\n",
    "my_test_Y = my_test[my_test['middle_char'] == 'Y'].drop(columns=['middle_char'])\n",
    "my_test_ST = my_test[my_test['middle_char'].isin(['S', 'T'])].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcd9ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0dff151-a667-4717-af18-401818bc4c22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:01<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.720577 |      0.846154 |         0.875 |       0.86 |  0.953526 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[22  4]\n",
      " [ 3 21]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ce2f51a-887c-4684-82b9-22ea5fffd334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['0', '1']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"../Plots/Confusion_matrix_for_dephos_new.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07603226",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5e0d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 28/28 [00:08<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.574849 |      0.816964 |      0.756757 |   0.786996 |  0.865488 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[183  41]\n",
      " [ 54 168]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5528dc-6e06-456d-920f-8f05055d0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, n_neighbors=5, min_dist=0.01, metric='euclidean'):\n",
    "    umap_model = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric\n",
    "    )\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    df = pd.DataFrame({\n",
    "        \"UMAP1\": embeddings[:, 0],\n",
    "        \"UMAP2\": embeddings[:, 1],\n",
    "        \"Label\": labels\n",
    "    })\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = sns.scatterplot(\n",
    "        x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9\n",
    "    )\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.legend(title='Label', bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_ST.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "    embeddings = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch = sequences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "            embeddings.extend(hidden_states[:, 0, :])\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(sequences) // batch_size + 1}\")\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7718f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = list(sequence)\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "valid_df = df\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "valid_df['middle_char'] = valid_df['sequence'].apply(get_middle_char)\n",
    "\n",
    "valid_df = valid_df[valid_df['middle_char'] == 'T'].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a162964f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sp|Q9GZM8|NDEL1_HUMAN%203%219</td>\n",
       "      <td>CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>sp|Q8N163|CCAR2_HUMAN%438%454</td>\n",
       "      <td>EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>sp|P10636-8|TAU_HUMAN%196%212</td>\n",
       "      <td>GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>sp|Q02241|KIF23_HUMAN%434%450</td>\n",
       "      <td>QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sp|Q04206|TF65_HUMAN%419%435</td>\n",
       "      <td>QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>sp|Q76N33|STALP_MOUSE%326%342</td>\n",
       "      <td>ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>sp|P49790|NU153_HUMAN%1098%1114</td>\n",
       "      <td>FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>sp|Q8NFC6|BD1L1_HUMAN%2789%2805</td>\n",
       "      <td>DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>sp|Q5T6F2|UBAP2_HUMAN%514%530</td>\n",
       "      <td>SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>sp|Q9H040|SPRTN_HUMAN%265%281</td>\n",
       "      <td>NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name                           sequence  label\n",
       "180    sp|Q9GZM8|NDEL1_HUMAN%203%219  CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI      1\n",
       "181    sp|Q8N163|CCAR2_HUMAN%438%454  EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA      1\n",
       "182    sp|P10636-8|TAU_HUMAN%196%212  GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV      1\n",
       "183    sp|Q02241|KIF23_HUMAN%434%450  QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE      1\n",
       "184     sp|Q04206|TF65_HUMAN%419%435  QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG      1\n",
       "..                               ...                                ...    ...\n",
       "441    sp|Q76N33|STALP_MOUSE%326%342  ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS      0\n",
       "442  sp|P49790|NU153_HUMAN%1098%1114  FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ      0\n",
       "443  sp|Q8NFC6|BD1L1_HUMAN%2789%2805  DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL      0\n",
       "444    sp|Q5T6F2|UBAP2_HUMAN%514%530  SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS      0\n",
       "445    sp|Q9H040|SPRTN_HUMAN%265%281  NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN      0\n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a44d9187-1ac5-4e36-89a0-8f827a7f0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 3559427.0\n",
      "\n",
      "Processed batch 1/3\n",
      "Processed batch 2/3\n",
      "Processed batch 3/3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_df = my_valid\n",
    "\n",
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_ST.pth\",num_labels=2)\n",
    "\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "valid_sequences = list(valid_df['sequence'])\n",
    "valid_embeddings = get_embeddings(model_reload, tokenizer, valid_sequences)\n",
    "\n",
    "umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "\n",
    "labels = list(valid_df['label'])\n",
    "\n",
    "plot_umap(umap_embeddings, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f029bcf-42ef-4476-b575-3c14adb71b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da0e6c-e921-493b-9304-8ba9aad07d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

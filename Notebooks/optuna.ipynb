{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2319a5",
   "metadata": {},
   "source": [
    "This notebook will implement combining D + P dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bab9a05",
   "metadata": {},
   "source": [
    "The dataset is balance \n",
    "This is before \n",
    "Number of LABEL=1 entries: 991\n",
    "  S: 723\n",
    "  T: 167\n",
    "  Y: 101\n",
    "Number of LABEL=0 entries: 989\n",
    "  S: 722\n",
    "  T: 167\n",
    "  Y: 100\n",
    "\n",
    "  Now we add some more from phos dataset and it looks like this\n",
    "  Number of LABEL=1 entries: \n",
    "  S: 723\n",
    "  T: 723\n",
    "  Y: 723\n",
    "Number of LABEL=0 entries: \n",
    "  S: 722\n",
    "  T: 722\n",
    "  Y: 722\n",
    "  We do not sample any more S entries as it is already balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a377270-2995-4da1-a673-5369769a6279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:52:49.264011Z",
     "iopub.status.busy": "2024-04-05T12:52:49.263502Z",
     "iopub.status.idle": "2024-04-05T12:53:29.491461Z",
     "shell.execute_reply": "2024-04-05T12:53:29.490156Z",
     "shell.execute_reply.started": "2024-04-05T12:52:49.263956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install umap-learn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0148ff8f-80eb-4bbd-aac7-fe1f371da27a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.508233Z",
     "iopub.status.busy": "2024-04-05T12:53:29.507801Z",
     "iopub.status.idle": "2024-04-05T12:53:29.536614Z",
     "shell.execute_reply": "2024-04-05T12:53:29.514877Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.508197Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.1.1+cu121\n",
      "Cuda version:  12.1\n",
      "Numpy version:  1.26.2\n",
      "Pandas version:  2.1.3\n",
      "Transformers version:  4.35.2\n",
      "Datasets version:  2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96bd9396-a81c-4d87-a722-0d2020627dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.538488Z",
     "iopub.status.busy": "2024-04-05T12:53:29.538089Z",
     "iopub.status.idle": "2024-04-05T12:53:29.768968Z",
     "shell.execute_reply": "2024-04-05T12:53:29.767620Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.538452Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WWI1|LMO7_HUMAN%260%276</td>\n",
       "      <td>SCSSDITLRGGREGFESDTDSEFTFKMQDYNKD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|sp|Q07157|ZO1_HUMAN|Tight</td>\n",
       "      <td>RSKGKLKMVVQRDERATLLNVPDLSDSIHSANA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|P24928|RPB1_HUMAN%1775%1791</td>\n",
       "      <td>NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|sp|Q9Y2U8|MAN1_HUMAN|Inner</td>\n",
       "      <td>PHSWWGARRPAGPELQTPPGKDGAVEDEEGEGE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q14980|NUMA1_HUMAN%2061%2077</td>\n",
       "      <td>NSLLRRGASKKALSKASPNTRSGTRRSPRIATT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name                           sequence  label\n",
       "0     sp|Q8WWI1|LMO7_HUMAN%260%276  SCSSDITLRGGREGFESDTDSEFTFKMQDYNKD      1\n",
       "1     sp|sp|Q07157|ZO1_HUMAN|Tight  RSKGKLKMVVQRDERATLLNVPDLSDSIHSANA      1\n",
       "2   sp|P24928|RPB1_HUMAN%1775%1791  NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS      1\n",
       "3    sp|sp|Q9Y2U8|MAN1_HUMAN|Inner  PHSWWGARRPAGPELQTPPGKDGAVEDEEGEGE      1\n",
       "4  sp|Q14980|NUMA1_HUMAN%2061%2077  NSLLRRGASKKALSKASPNTRSGTRRSPRIATT      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../input_datasets/merged_output_D+P_balance_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "local_fasta_path = '../input_datasets/merged_output_D+P_balance_Y.fasta'\n",
    "\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76760f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "(3468, 2)\n",
      "\n",
      "Validation Set:\n",
      "(867, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "my_train, my_valid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "my_train=my_train[[\"sequence\", \"label\"]]\n",
    "my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the training set\n",
    "print(\"Training Set:\")\n",
    "print(my_train.shape)\n",
    "\n",
    "# Print the first 5 rows of the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a424877b-787c-44fe-bf87-33346ffd3be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.789138Z",
     "iopub.status.busy": "2024-04-05T12:53:29.788675Z",
     "iopub.status.idle": "2024-04-05T12:53:29.816779Z",
     "shell.execute_reply": "2024-04-05T12:53:29.815341Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.789094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifies an existing transformer and introduce the LoRA layers\n",
    "\n",
    "class LoRAConfig:\n",
    "    def __init__(self, lora_rank=8, lora_init_scale=0.01, lora_scaling_rank=2):\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_init_scale = lora_init_scale\n",
    "        self.lora_modules = \".*SelfAttention|.*EncDecAttention\"\n",
    "        self.lora_layers = \"q|k|v|o\"\n",
    "        self.trainable_param_names = \".*layer_norm.*|.*lora_[ab].*\"\n",
    "        self.lora_scaling_rank = lora_scaling_rank\n",
    "        # lora_modules and lora_layers are specified with regular expressions\n",
    "        # see https://www.w3schools.com/python/python_regex.asp for reference\n",
    "        \n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, scaling_rank, init_scale):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.rank = rank\n",
    "        self.scaling_rank = scaling_rank\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        if self.rank > 0:\n",
    "            self.lora_a = nn.Parameter(torch.randn(rank, linear_layer.in_features) * init_scale)\n",
    "            if init_scale < 0:\n",
    "                self.lora_b = nn.Parameter(torch.randn(linear_layer.out_features, rank) * init_scale)\n",
    "            else:\n",
    "                self.lora_b = nn.Parameter(torch.zeros(linear_layer.out_features, rank))\n",
    "        if self.scaling_rank:\n",
    "            self.multi_lora_a = nn.Parameter(\n",
    "                torch.ones(self.scaling_rank, linear_layer.in_features)\n",
    "                + torch.randn(self.scaling_rank, linear_layer.in_features) * init_scale\n",
    "            )\n",
    "            if init_scale < 0:\n",
    "                self.multi_lora_b = nn.Parameter(\n",
    "                    torch.ones(linear_layer.out_features, self.scaling_rank)\n",
    "                    + torch.randn(linear_layer.out_features, self.scaling_rank) * init_scale\n",
    "                )\n",
    "            else:\n",
    "                self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, self.scaling_rank))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.scaling_rank == 1 and self.rank == 0:\n",
    "            # parsimonious implementation for ia3 and lora scaling\n",
    "            if self.multi_lora_a.requires_grad:\n",
    "                hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n",
    "            else:\n",
    "                hidden = F.linear(input, self.weight, self.bias)\n",
    "            if self.multi_lora_b.requires_grad:\n",
    "                hidden = hidden * self.multi_lora_b.flatten()\n",
    "            return hidden\n",
    "        else:\n",
    "            # general implementation for lora (adding and scaling)\n",
    "            weight = self.weight\n",
    "            if self.scaling_rank:\n",
    "                weight = weight * torch.matmul(self.multi_lora_b, self.multi_lora_a) / self.scaling_rank\n",
    "            if self.rank:\n",
    "                weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n",
    "            return F.linear(input, weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, rank={}, scaling_rank={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.rank, self.scaling_rank\n",
    "        )\n",
    "\n",
    "\n",
    "def modify_with_lora(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.lora_modules, m_name):\n",
    "            for c_name, layer in dict(module.named_children()).items():\n",
    "                if re.fullmatch(config.lora_layers, c_name):\n",
    "                    assert isinstance(\n",
    "                        layer, nn.Linear\n",
    "                    ), f\"LoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        c_name,\n",
    "                        LoRALinear(layer, config.lora_rank, config.lora_scaling_rank, config.lora_init_scale),\n",
    "                    )\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e79b323-4677-4723-a5fd-a60dc13a3b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.819433Z",
     "iopub.status.busy": "2024-04-05T12:53:29.818965Z",
     "iopub.status.idle": "2024-04-05T12:53:29.845976Z",
     "shell.execute_reply": "2024-04-05T12:53:29.844438Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.819335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.7, num_labels=2):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class T5EncoderClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, class_config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "        \n",
    "        # Trainable emphasis factor\n",
    "        # self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        # Original sequence length and middle index\n",
    "        seq_length = hidden_states.size(1)\n",
    "        middle_idx = seq_length // 2\n",
    "\n",
    "        # Extract the middle embedding vector\n",
    "        middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "        # Amplify the influence of the middle embedding\n",
    "        amplified_middle_embedding = middle_embedding * 2\n",
    "\n",
    "        # Combine with average to retain context\n",
    "        average_embedding = torch.mean(hidden_states, dim=1)\n",
    "        combined_embedding = 0.5 * amplified_middle_embedding + 0.5 * average_embedding\n",
    "\n",
    "        # Classification layers\n",
    "        x = self.dropout(combined_embedding)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.out_proj(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class T5EncoderForSimpleSequenceClassification(T5PreTrainedModel):\n",
    "\n",
    "    def __init__(self, config: T5Config, class_config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n",
    "\n",
    "        encoder_config = copy.deepcopy(config)\n",
    "        encoder_config.use_cache = False\n",
    "        encoder_config.is_encoder_decoder = False\n",
    "        self.encoder = T5Stack(encoder_config, self.shared)\n",
    "\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate) \n",
    "        self.classifier = T5EncoderClassificationHead(config, class_config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "    def parallelize(self, device_map=None):\n",
    "        self.device_map = (\n",
    "            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
    "            if device_map is None\n",
    "            else device_map\n",
    "        )\n",
    "        assert_device_map(self.device_map, len(self.encoder.block))\n",
    "        self.encoder.parallelize(self.device_map)\n",
    "        self.classifier = self.classifier.to(self.encoder.first_device)\n",
    "        self.model_parallel = True\n",
    "\n",
    "    def deparallelize(self):\n",
    "        self.encoder.deparallelize()\n",
    "        self.encoder = self.encoder.to(\"cpu\")\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.shared\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.shared = new_embeddings\n",
    "        self.encoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "        logits = self.classifier(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71394626-6f8b-4ca5-80f3-c697e4320bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.848217Z",
     "iopub.status.busy": "2024-04-05T12:53:29.847782Z",
     "iopub.status.idle": "2024-04-05T12:53:29.859841Z",
     "shell.execute_reply": "2024-04-05T12:53:29.858398Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.848182Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PT5_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "    # Load PT5 and tokenizer\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True)\n",
    "    \n",
    "    # model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")\n",
    "    # tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\") \n",
    "    \n",
    "    # Create new Classifier model with PT5 dimensions\n",
    "    class_config=ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "    class_model=T5EncoderForSimpleSequenceClassification(model.config,class_config)\n",
    "    \n",
    "    # Set encoder and embedding weights to checkpoint weights\n",
    "    class_model.shared=model.shared\n",
    "    class_model.encoder=model.encoder    \n",
    "    \n",
    "    # Delete the checkpoint model\n",
    "    model=class_model\n",
    "    del class_model\n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "    # Add model modification lora\n",
    "    config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "    # Add LoRA layers\n",
    "    model = modify_with_lora(model, config)\n",
    "    \n",
    "    # Freeze Embeddings and Encoder (except LoRA)\n",
    "    for (param_name, param) in model.shared.named_parameters():\n",
    "                param.requires_grad = False\n",
    "    for (param_name, param) in model.encoder.named_parameters():\n",
    "                param.requires_grad = False       \n",
    "\n",
    "    for (param_name, param) in model.named_parameters():\n",
    "            if re.fullmatch(config.trainable_param_names, param_name):\n",
    "                param.requires_grad = True\n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c4d56b2-c9ca-460d-b977-a1e4ae1e9568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.864172Z",
     "iopub.status.busy": "2024-04-05T12:53:29.863760Z",
     "iopub.status.idle": "2024-04-05T12:53:29.873119Z",
     "shell.execute_reply": "2024-04-05T12:53:29.871609Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.864135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4550fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    \"\"\"Custom early stopping callback that can monitor loss or accuracy.\"\"\"\n",
    "    \n",
    "    def __init__(self, metric_name='eval_loss', early_stopping_patience=3, minimize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric_name (str): Metric to monitor, default 'eval_loss'.\n",
    "            early_stopping_patience (int): Number of checks with no improvement after which training will be stopped.\n",
    "            minimize (bool): Set to True if the metric should be minimized, False if it should be maximized.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_counter = 0\n",
    "        self.minimize = minimize\n",
    "        self.best_metric = float('inf') if minimize else float('-inf')\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        current_metric = kwargs['metrics'][self.metric_name]\n",
    "        \n",
    "        if (self.minimize and current_metric < self.best_metric) or (not self.minimize and current_metric > self.best_metric):\n",
    "            self.best_metric = current_metric\n",
    "            self.early_stopping_counter = 0\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "        \n",
    "        if self.early_stopping_counter >= self.early_stopping_patience:\n",
    "            control.should_training_stop = True\n",
    "            print(f'Stopping early! No improvement in {self.metric_name} for {self.early_stopping_patience} evaluation steps.')\n",
    "\n",
    "\n",
    "class MultiObjectiveEarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        # Extract current validation loss and accuracy\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "\n",
    "        # Check if current loss and accuracy improved significantly\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            # Update best scores and reset wait time\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            # If no improvement, increment the wait counter\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                # If wait exceeds the patience, stop training\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "class MultiObjectiveEarlyStoppingAndSaveCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001, output_dir='./model_output', filename='finetuned_model'):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "        self.output_dir = output_dir\n",
    "        self.filename = filename\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "        model = kwargs['model']\n",
    "\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "            # Save the model as the best so far\n",
    "            self.save_finetuned_parameters(model, os.path.join(self.output_dir, self.filename))\n",
    "            print(f\"Saved improved model to {self.output_dir}/{self.filename}\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "    def save_finetuned_parameters(self, model, filepath):\n",
    "        # Create a dictionary to hold the non-frozen parameters\n",
    "        non_frozen_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "        # Save only the finetuned parameters \n",
    "        torch.save(non_frozen_params, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfb8bb11-79b0-4936-9099-f9f8ef97e105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.875565Z",
     "iopub.status.busy": "2024-04-05T12:53:29.875038Z",
     "iopub.status.idle": "2024-04-05T12:53:30.214710Z",
     "shell.execute_reply": "2024-04-05T12:53:30.213349Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.875495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "# Set random seeds for reproducibility of your trainings run\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "    \n",
    "# Main training fuction\n",
    "def train_per_protein(\n",
    "        train_dataset,         #training data\n",
    "        valid_dataset,         #validation data      \n",
    "        weight_decay,\n",
    "        warmup_pct,\n",
    "        num_labels= 2,    #1 for regression, >1 for classification\n",
    "    \n",
    "        # effective training batch size is batch * accum\n",
    "        # we recommend an effective batch size of 8 \n",
    "        batch= 4,         #for training\n",
    "        accum= 2,         #gradient accumulation\n",
    "    \n",
    "        val_batch = 16,   #batch size for evaluation\n",
    "        epochs=1,       #training epochs\n",
    "        lr= 3e-4,         #recommended learning rate\n",
    "        seed= 42,         #random seed\n",
    "        deepspeed=False,  #if gpu is large enough disable deepspeed for training speedup\n",
    "        gpu= 1,\n",
    "        dropout=0.5, #dropout rate\n",
    "         #L2 weight regularization\n",
    "        lora_rank=4,      #lora rank\n",
    "        lora_init_scale=0.01, #lora scaling rank\n",
    "        lora_scaling_rank=1,       #lora a\n",
    "        ):         #gpu selection (1 for first gpu)\n",
    "\n",
    "    # Set gpu device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # load model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=dropout, lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    total_steps = epochs * len(train_dataset) // batch\n",
    "    warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "    # Define TrainingArguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir='./results',              # where to save the model\n",
    "        evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "        logging_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        learning_rate=lr,                    # initial learning rate\n",
    "        per_device_train_batch_size=batch,   # batch size per device\n",
    "        gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "        num_train_epochs=epochs,             # number of epochs to train\n",
    "        weight_decay=weight_decay,           # L2 weight regularization\n",
    "        warmup_steps=warmup_steps,           # 10% of total steps\n",
    "        load_best_model_at_end=False,         # load the best model at the end of training\n",
    "        seed=seed,                           # random seed\n",
    "        push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "        logging_dir='./logs',\n",
    "    )\n",
    "    # metric_for_best_model='eval_loss|accuracy'\n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        # Check if predictions have the expected shape\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "        # Now, compute the metric (e.g., accuracy)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        # Return the metric(s) as a dictionary\n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    # For minimizing loss\n",
    "    early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "    # For maximizing accuracy\n",
    "    early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "            early_stopping_patience=3,\n",
    "            min_delta=0.001,\n",
    "            output_dir='./model_output',\n",
    "            filename='finetuned_model_D_and_P_balance_dataset.pth'\n",
    "        )],\n",
    "    )    \n",
    "        \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    # Get the best model\n",
    "    # model = trainer.model\n",
    "    # Ensure the best model is loaded\n",
    "    best_model_path = os.path.join('./model_output', 'finetuned_model_D_and_P_balance_dataset.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        state_dict = torch.load(best_model_path)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "    # Evaluate the best model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(eval_results)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b300952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Dataset creation\n",
    "def create_dataset(tokenizer,seqs,labels):\n",
    "    tokenized = tokenizer(seqs, max_length=64, padding=True, truncation=True)\n",
    "    dataset = Dataset.from_dict(tokenized)\n",
    "    dataset = dataset.add_column(\"labels\", labels)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Initialize the tokenizer\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\") \n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=\"/home/ubuntu/data/hai/huggingface_cache/\", force_download=True) \n",
    "\n",
    "\n",
    "train_df = my_train\n",
    "valid_df = my_valid\n",
    "\n",
    "# Preprocess inputs≈≈≈≈\n",
    "# Replace uncommon AAs with \"X\"\n",
    "train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "# Add spaces between each amino acid for PT5 to correctly use them\n",
    "train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "# Create Datasets\n",
    "train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']))\n",
    "valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ebf90f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 08:42:45,813] A new study created in RDB with name: finetuned_model_D_and_P_balance_dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 6508547.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 1:04:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.686417</td>\n",
       "      <td>0.573241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.658634</td>\n",
       "      <td>0.707036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.660600</td>\n",
       "      <td>0.626107</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.635100</td>\n",
       "      <td>0.593098</td>\n",
       "      <td>0.712803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.603600</td>\n",
       "      <td>0.564025</td>\n",
       "      <td>0.720877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.581500</td>\n",
       "      <td>0.545022</td>\n",
       "      <td>0.728950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.576500</td>\n",
       "      <td>0.529589</td>\n",
       "      <td>0.749712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.563600</td>\n",
       "      <td>0.518078</td>\n",
       "      <td>0.756632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.557200</td>\n",
       "      <td>0.516792</td>\n",
       "      <td>0.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.510511</td>\n",
       "      <td>0.769319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5105111002922058, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 13.1314, 'eval_samples_per_second': 66.025, 'eval_steps_per_second': 8.301, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 09:48:16,368] Trial 0 finished with values: [0.5105111002922058, 0.7693194925028836] and parameters: {'lr': 3.758762055180164e-05, 'batch': 1, 'accum': 4, 'dropout_rate': 0.7320932156900825, 'weight_decay': 0.0005031075722602088, 'warmup_pct': 0.2463007406840469, 'lora_rank': 4, 'lora_init_scale': 0.0008209558837694562, 'lora_scaling_rank': 7}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7054, 'learning_rate': 3.815532960825667e-06, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.6864169836044312, 'eval_accuracy': 0.5732410611303345, 'eval_runtime': 14.495, 'eval_samples_per_second': 59.814, 'eval_steps_per_second': 7.52, 'epoch': 1.0, 'step': 867}, {'loss': 0.6884, 'learning_rate': 7.631065921651334e-06, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.6586339473724365, 'eval_accuracy': 0.707035755478662, 'eval_runtime': 13.4709, 'eval_samples_per_second': 64.361, 'eval_steps_per_second': 8.092, 'epoch': 2.0, 'step': 1734}, {'loss': 0.6606, 'learning_rate': 1.1446598882477001e-05, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.6261072158813477, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 13.452, 'eval_samples_per_second': 64.451, 'eval_steps_per_second': 8.103, 'epoch': 3.0, 'step': 2601}, {'loss': 0.6351, 'learning_rate': 1.5262131843302667e-05, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.5930981040000916, 'eval_accuracy': 0.71280276816609, 'eval_runtime': 13.3781, 'eval_samples_per_second': 64.807, 'eval_steps_per_second': 8.148, 'epoch': 4.0, 'step': 3468}, {'loss': 0.6036, 'learning_rate': 1.9077664804128337e-05, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5640249848365784, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 13.3442, 'eval_samples_per_second': 64.972, 'eval_steps_per_second': 8.168, 'epoch': 5.0, 'step': 4335}, {'loss': 0.5815, 'learning_rate': 2.2893197764954003e-05, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.545022189617157, 'eval_accuracy': 0.7289504036908881, 'eval_runtime': 13.3251, 'eval_samples_per_second': 65.065, 'eval_steps_per_second': 8.18, 'epoch': 6.0, 'step': 5202}, {'loss': 0.5765, 'learning_rate': 2.670873072577967e-05, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.5295888185501099, 'eval_accuracy': 0.7497116493656286, 'eval_runtime': 13.312, 'eval_samples_per_second': 65.129, 'eval_steps_per_second': 8.188, 'epoch': 7.0, 'step': 6069}, {'loss': 0.5636, 'learning_rate': 3.0524263686605335e-05, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 0.5180782079696655, 'eval_accuracy': 0.7566320645905421, 'eval_runtime': 13.3107, 'eval_samples_per_second': 65.135, 'eval_steps_per_second': 8.189, 'epoch': 8.0, 'step': 6936}, {'loss': 0.5572, 'learning_rate': 3.4339796647431004e-05, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 0.5167917013168335, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 13.3102, 'eval_samples_per_second': 65.138, 'eval_steps_per_second': 8.189, 'epoch': 9.0, 'step': 7803}, {'loss': 0.5575, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5105111002922058, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 13.3025, 'eval_samples_per_second': 65.176, 'eval_steps_per_second': 8.194, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 3872.0185, 'train_samples_per_second': 8.957, 'train_steps_per_second': 2.239, 'total_flos': 8592021749357280.0, 'train_loss': 0.6129382246780836, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5105111002922058, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 13.1314, 'eval_samples_per_second': 66.025, 'eval_steps_per_second': 8.301, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 25:28, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.743200</td>\n",
       "      <td>0.673790</td>\n",
       "      <td>0.644752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.663900</td>\n",
       "      <td>0.588992</td>\n",
       "      <td>0.710496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.604500</td>\n",
       "      <td>0.532473</td>\n",
       "      <td>0.739331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.510869</td>\n",
       "      <td>0.752018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.559600</td>\n",
       "      <td>0.504713</td>\n",
       "      <td>0.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.559200</td>\n",
       "      <td>0.504481</td>\n",
       "      <td>0.758939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5047129392623901, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.4115, 'eval_samples_per_second': 69.855, 'eval_steps_per_second': 8.782, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 10:14:40,692] Trial 1 finished with values: [0.5047129392623901, 0.7612456747404844] and parameters: {'lr': 7.22642175796173e-05, 'batch': 4, 'accum': 2, 'dropout_rate': 0.8559550689440982, 'weight_decay': 0.00043227475326132285, 'warmup_pct': 0.15462277045804768, 'lora_rank': 28, 'lora_init_scale': 0.015547162542323927, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7432, 'learning_rate': 2.3351049411921112e-05, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6737896800041199, 'eval_accuracy': 0.6447520184544406, 'eval_runtime': 14.0524, 'eval_samples_per_second': 61.698, 'eval_steps_per_second': 7.757, 'epoch': 1.0, 'step': 433}, {'loss': 0.6921, 'learning_rate': 4.6756027344424025e-05, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.6294867396354675, 'eval_accuracy': 0.707035755478662, 'eval_runtime': 12.436, 'eval_samples_per_second': 69.717, 'eval_steps_per_second': 8.765, 'epoch': 2.0, 'step': 867}, {'loss': 0.6639, 'learning_rate': 7.010707675634515e-05, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.588991641998291, 'eval_accuracy': 0.7104959630911188, 'eval_runtime': 12.4859, 'eval_samples_per_second': 69.438, 'eval_steps_per_second': 8.73, 'epoch': 3.0, 'step': 1300}, {'loss': 0.6224, 'learning_rate': 6.274177553066439e-05, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.5548428893089294, 'eval_accuracy': 0.7277970011534025, 'eval_runtime': 12.4225, 'eval_samples_per_second': 69.793, 'eval_steps_per_second': 8.774, 'epoch': 4.0, 'step': 1734}, {'loss': 0.6045, 'learning_rate': 5.227675673067299e-05, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5324729681015015, 'eval_accuracy': 0.7393310265282583, 'eval_runtime': 12.4924, 'eval_samples_per_second': 69.402, 'eval_steps_per_second': 8.725, 'epoch': 5.0, 'step': 2167}, {'loss': 0.5979, 'learning_rate': 4.178756929603957e-05, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.5206310153007507, 'eval_accuracy': 0.7497116493656286, 'eval_runtime': 12.4464, 'eval_samples_per_second': 69.659, 'eval_steps_per_second': 8.758, 'epoch': 6.0, 'step': 2601}, {'loss': 0.5822, 'learning_rate': 3.132255049604817e-05, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.5108690857887268, 'eval_accuracy': 0.7520184544405998, 'eval_runtime': 12.4889, 'eval_samples_per_second': 69.422, 'eval_steps_per_second': 8.728, 'epoch': 7.0, 'step': 3034}, {'loss': 0.5779, 'learning_rate': 2.0833363061414752e-05, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.5071641206741333, 'eval_accuracy': 0.7566320645905421, 'eval_runtime': 12.4413, 'eval_samples_per_second': 69.688, 'eval_steps_per_second': 8.761, 'epoch': 8.0, 'step': 3468}, {'loss': 0.5596, 'learning_rate': 1.0368344261423352e-05, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.5047129392623901, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.4656, 'eval_samples_per_second': 69.552, 'eval_steps_per_second': 8.744, 'epoch': 9.0, 'step': 3901}, {'loss': 0.5592, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5044806003570557, 'eval_accuracy': 0.7589388696655133, 'eval_runtime': 12.4841, 'eval_samples_per_second': 69.448, 'eval_steps_per_second': 8.731, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 1528.6512, 'train_samples_per_second': 22.687, 'train_steps_per_second': 2.833, 'total_flos': 8648105445522240.0, 'train_loss': 0.6203284353912565, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5047129392623901, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.4115, 'eval_samples_per_second': 69.855, 'eval_steps_per_second': 8.782, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 6017027.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 24:29, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.699000</td>\n",
       "      <td>0.649077</td>\n",
       "      <td>0.695502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>0.584898</td>\n",
       "      <td>0.716263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.585200</td>\n",
       "      <td>0.538216</td>\n",
       "      <td>0.731257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.562800</td>\n",
       "      <td>0.501300</td>\n",
       "      <td>0.769319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.485238</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.506200</td>\n",
       "      <td>0.471656</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.487300</td>\n",
       "      <td>0.472879</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>0.495871</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>0.582072</td>\n",
       "      <td>0.769319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.965397923875432: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.48147228360176086, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.228, 'eval_samples_per_second': 70.903, 'eval_steps_per_second': 8.914, 'epoch': 9.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 10:40:06,034] Trial 2 finished with values: [0.48147228360176086, 0.7808535178777394] and parameters: {'lr': 0.0012503640810637153, 'batch': 4, 'accum': 8, 'dropout_rate': 0.7199713439988092, 'weight_decay': 0.00024332594426522476, 'warmup_pct': 0.2775446358093314, 'lora_rank': 4, 'lora_init_scale': 0.07579926522661985, 'lora_scaling_rank': 6}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.699, 'learning_rate': 5.61260684766755e-05, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6490774154663086, 'eval_accuracy': 0.6955017301038062, 'eval_runtime': 13.8488, 'eval_samples_per_second': 62.605, 'eval_steps_per_second': 7.871, 'epoch': 1.0, 'step': 108}, {'loss': 0.6386, 'learning_rate': 0.000112252136953351, 'epoch': 1.99, 'step': 216}, {'eval_loss': 0.584898054599762, 'eval_accuracy': 0.7162629757785467, 'eval_runtime': 12.1198, 'eval_samples_per_second': 71.536, 'eval_steps_per_second': 8.994, 'epoch': 1.99, 'step': 216}, {'loss': 0.5852, 'learning_rate': 0.000168897891249255, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.5382158160209656, 'eval_accuracy': 0.7312572087658593, 'eval_runtime': 12.1553, 'eval_samples_per_second': 71.327, 'eval_steps_per_second': 8.967, 'epoch': 3.0, 'step': 325}, {'loss': 0.5628, 'learning_rate': 0.00022502395972593049, 'epoch': 4.0, 'step': 433}, {'eval_loss': 0.5012996792793274, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 12.1157, 'eval_samples_per_second': 71.56, 'eval_steps_per_second': 8.997, 'epoch': 4.0, 'step': 433}, {'loss': 0.5381, 'learning_rate': 0.00028115002820260597, 'epoch': 4.99, 'step': 541}, {'eval_loss': 0.4852384924888611, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1409, 'eval_samples_per_second': 71.412, 'eval_steps_per_second': 8.978, 'epoch': 4.99, 'step': 541}, {'loss': 0.5062, 'learning_rate': 0.00033779578249851, 'epoch': 6.0, 'step': 650}, {'eval_loss': 0.4716556966304779, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.1229, 'eval_samples_per_second': 71.518, 'eval_steps_per_second': 8.991, 'epoch': 6.0, 'step': 650}, {'loss': 0.4873, 'learning_rate': 0.00039392185097518543, 'epoch': 6.99, 'step': 758}, {'eval_loss': 0.4728793203830719, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1275, 'eval_samples_per_second': 71.49, 'eval_steps_per_second': 8.988, 'epoch': 6.99, 'step': 758}, {'loss': 0.4462, 'learning_rate': 0.0004505676052710894, 'epoch': 8.0, 'step': 867}, {'eval_loss': 0.48147228360176086, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.1409, 'eval_samples_per_second': 71.412, 'eval_steps_per_second': 8.978, 'epoch': 8.0, 'step': 867}, {'loss': 0.4029, 'learning_rate': 0.0005066936737477649, 'epoch': 9.0, 'step': 975}, {'eval_loss': 0.4958708584308624, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.099, 'eval_samples_per_second': 71.659, 'eval_steps_per_second': 9.009, 'epoch': 9.0, 'step': 975}, {'loss': 0.3392, 'learning_rate': 0.0005612606847667551, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.5820724368095398, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 12.1419, 'eval_samples_per_second': 71.406, 'eval_steps_per_second': 8.977, 'epoch': 9.97, 'step': 1080}, {'train_runtime': 1471.2501, 'train_samples_per_second': 23.572, 'train_steps_per_second': 0.734, 'total_flos': 8558826236328960.0, 'train_loss': 0.5210253468266239, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.48147228360176086, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.228, 'eval_samples_per_second': 70.903, 'eval_steps_per_second': 8.914, 'epoch': 9.97, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 8966147.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2601' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2601/4330 15:10 < 10:05, 2.86 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.501384</td>\n",
       "      <td>0.768166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>0.506311</td>\n",
       "      <td>0.783160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.303300</td>\n",
       "      <td>0.907130</td>\n",
       "      <td>0.770473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.987812</td>\n",
       "      <td>0.782007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5063105821609497, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1014, 'eval_samples_per_second': 71.644, 'eval_steps_per_second': 9.007, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 10:56:09,884] Trial 3 finished with values: [0.5063105821609497, 0.7831603229527105] and parameters: {'lr': 0.0008810477725102257, 'batch': 4, 'accum': 2, 'dropout_rate': 0.7094520529165736, 'weight_decay': 2.8132302365672252e-05, 'warmup_pct': 0.025195812845497136, 'lora_rank': 12, 'lora_init_scale': 0.01750033378810108, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.638, 'learning_rate': 0.000834981315533159, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.5013837218284607, 'eval_accuracy': 0.7681660899653979, 'eval_runtime': 13.7977, 'eval_samples_per_second': 62.837, 'eval_steps_per_second': 7.9, 'epoch': 1.0, 'step': 433}, {'loss': 0.5428, 'learning_rate': 0.0007419913512166614, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5009746551513672, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.3529, 'eval_samples_per_second': 70.186, 'eval_steps_per_second': 8.824, 'epoch': 2.0, 'step': 867}, {'loss': 0.4834, 'learning_rate': 0.0006492156494907549, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.5063105821609497, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1207, 'eval_samples_per_second': 71.53, 'eval_steps_per_second': 8.993, 'epoch': 3.0, 'step': 1300}, {'loss': 0.3858, 'learning_rate': 0.0005562256851742573, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.6334637999534607, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1225, 'eval_samples_per_second': 71.52, 'eval_steps_per_second': 8.992, 'epoch': 4.0, 'step': 1734}, {'loss': 0.3033, 'learning_rate': 0.00046344998344835075, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.9071301221847534, 'eval_accuracy': 0.7704728950403691, 'eval_runtime': 12.1196, 'eval_samples_per_second': 71.537, 'eval_steps_per_second': 8.994, 'epoch': 5.0, 'step': 2167}, {'loss': 0.2119, 'learning_rate': 0.0003704600191318532, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.9878118634223938, 'eval_accuracy': 0.7820069204152249, 'eval_runtime': 12.1252, 'eval_samples_per_second': 71.504, 'eval_steps_per_second': 8.99, 'epoch': 6.0, 'step': 2601}, {'train_runtime': 910.6183, 'train_samples_per_second': 38.084, 'train_steps_per_second': 4.755, 'total_flos': 5165645148737568.0, 'train_loss': 0.42746640168350963, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.5063105821609497, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1014, 'eval_samples_per_second': 71.644, 'eval_steps_per_second': 9.007, 'epoch': 6.0, 'step': 2601}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2160' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2160/2160 37:54, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>0.690560</td>\n",
       "      <td>0.525952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.682100</td>\n",
       "      <td>0.672444</td>\n",
       "      <td>0.658593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.661300</td>\n",
       "      <td>0.648331</td>\n",
       "      <td>0.718570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.616800</td>\n",
       "      <td>0.599112</td>\n",
       "      <td>0.719723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.591100</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>0.718570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.569400</td>\n",
       "      <td>0.558757</td>\n",
       "      <td>0.726644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.541700</td>\n",
       "      <td>0.526394</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.520700</td>\n",
       "      <td>0.515346</td>\n",
       "      <td>0.761246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5153459906578064, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.5855, 'eval_samples_per_second': 68.889, 'eval_steps_per_second': 8.661, 'epoch': 9.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 11:34:58,024] Trial 4 finished with values: [0.5153459906578064, 0.7612456747404844] and parameters: {'lr': 2.7429739918683985e-05, 'batch': 2, 'accum': 8, 'dropout_rate': 0.11662725570417348, 'weight_decay': 1.3510283385379407e-05, 'warmup_pct': 0.22556147668738605, 'lora_rank': 28, 'lora_init_scale': 0.00017826421089376304, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6965, 'learning_rate': 1.5149127646217696e-06, 'epoch': 1.0, 'step': 216}, {'eval_loss': 0.6905604004859924, 'eval_accuracy': 0.5259515570934256, 'eval_runtime': 13.8313, 'eval_samples_per_second': 62.684, 'eval_steps_per_second': 7.881, 'epoch': 1.0, 'step': 216}, {'loss': 0.6821, 'learning_rate': 3.0368390142649364e-06, 'epoch': 2.0, 'step': 433}, {'eval_loss': 0.6724444031715393, 'eval_accuracy': 0.6585928489042676, 'eval_runtime': 12.1732, 'eval_samples_per_second': 71.222, 'eval_steps_per_second': 8.954, 'epoch': 2.0, 'step': 433}, {'loss': 0.6613, 'learning_rate': 4.5587652639081025e-06, 'epoch': 3.0, 'step': 650}, {'eval_loss': 0.6483312845230103, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.1933, 'eval_samples_per_second': 71.104, 'eval_steps_per_second': 8.939, 'epoch': 3.0, 'step': 650}, {'loss': 0.6374, 'learning_rate': 6.0806915135512695e-06, 'epoch': 4.0, 'step': 867}, {'eval_loss': 0.6228208541870117, 'eval_accuracy': 0.7162629757785467, 'eval_runtime': 12.2126, 'eval_samples_per_second': 70.992, 'eval_steps_per_second': 8.925, 'epoch': 4.0, 'step': 867}, {'loss': 0.6168, 'learning_rate': 7.595604278173039e-06, 'epoch': 5.0, 'step': 1083}, {'eval_loss': 0.599111795425415, 'eval_accuracy': 0.7197231833910035, 'eval_runtime': 12.2137, 'eval_samples_per_second': 70.986, 'eval_steps_per_second': 8.924, 'epoch': 5.0, 'step': 1083}, {'loss': 0.5911, 'learning_rate': 9.117530527816205e-06, 'epoch': 6.0, 'step': 1300}, {'eval_loss': 0.5779526233673096, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.181, 'eval_samples_per_second': 71.176, 'eval_steps_per_second': 8.948, 'epoch': 6.0, 'step': 1300}, {'loss': 0.5694, 'learning_rate': 1.0639456777459372e-05, 'epoch': 7.0, 'step': 1517}, {'eval_loss': 0.5587568879127502, 'eval_accuracy': 0.726643598615917, 'eval_runtime': 12.1988, 'eval_samples_per_second': 71.073, 'eval_steps_per_second': 8.935, 'epoch': 7.0, 'step': 1517}, {'loss': 0.5515, 'learning_rate': 1.2161383027102539e-05, 'epoch': 8.0, 'step': 1734}, {'eval_loss': 0.5423670411109924, 'eval_accuracy': 0.7393310265282583, 'eval_runtime': 12.2149, 'eval_samples_per_second': 70.979, 'eval_steps_per_second': 8.923, 'epoch': 8.0, 'step': 1734}, {'loss': 0.5417, 'learning_rate': 1.367629579172431e-05, 'epoch': 9.0, 'step': 1950}, {'eval_loss': 0.5263938307762146, 'eval_accuracy': 0.754325259515571, 'eval_runtime': 12.2073, 'eval_samples_per_second': 71.023, 'eval_steps_per_second': 8.929, 'epoch': 9.0, 'step': 1950}, {'loss': 0.5207, 'learning_rate': 1.5149127646217698e-05, 'epoch': 9.97, 'step': 2160}, {'eval_loss': 0.5153459906578064, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.182, 'eval_samples_per_second': 71.171, 'eval_steps_per_second': 8.948, 'epoch': 9.97, 'step': 2160}, {'train_runtime': 2275.2737, 'train_samples_per_second': 15.242, 'train_steps_per_second': 0.949, 'total_flos': 8624667581660160.0, 'train_loss': 0.607126956515842, 'epoch': 9.97, 'step': 2160}, {'eval_loss': 0.5153459906578064, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.5855, 'eval_samples_per_second': 68.889, 'eval_steps_per_second': 8.661, 'epoch': 9.97, 'step': 2160}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 12406787.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 18:12, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.714300</td>\n",
       "      <td>0.695676</td>\n",
       "      <td>0.477509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.709900</td>\n",
       "      <td>0.689695</td>\n",
       "      <td>0.534025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.707400</td>\n",
       "      <td>0.680298</td>\n",
       "      <td>0.621684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.685500</td>\n",
       "      <td>0.656084</td>\n",
       "      <td>0.709343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.643747</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.630438</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.631100</td>\n",
       "      <td>0.605129</td>\n",
       "      <td>0.713956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.621700</td>\n",
       "      <td>0.591674</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5916740894317627, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.2157, 'eval_samples_per_second': 70.974, 'eval_steps_per_second': 8.923, 'epoch': 9.95}\n",
      "History:  [{'loss': 0.7143, 'learning_rate': 3.0207259730167245e-06, 'epoch': 1.0, 'step': 54}, {'eval_loss': 0.6956760883331299, 'eval_accuracy': 0.47750865051903113, 'eval_runtime': 13.8055, 'eval_samples_per_second': 62.801, 'eval_steps_per_second': 7.895, 'epoch': 1.0, 'step': 54}, {'loss': 0.7099, 'learning_rate': 6.041451946033449e-06, 'epoch': 1.99, 'step': 108}, {'eval_loss': 0.6896949410438538, 'eval_accuracy': 0.5340253748558247, 'eval_runtime': 12.1777, 'eval_samples_per_second': 71.196, 'eval_steps_per_second': 8.951, 'epoch': 1.99, 'step': 108}, {'loss': 0.7074, 'learning_rate': 9.062177919050173e-06, 'epoch': 2.99, 'step': 162}, {'eval_loss': 0.6802976131439209, 'eval_accuracy': 0.621683967704729, 'eval_runtime': 12.1358, 'eval_samples_per_second': 71.441, 'eval_steps_per_second': 8.982, 'epoch': 2.99, 'step': 162}, {'loss': 0.685, 'learning_rate': 1.2138843261937579e-05, 'epoch': 4.0, 'step': 217}, {'eval_loss': 0.6684548258781433, 'eval_accuracy': 0.6735870818915801, 'eval_runtime': 12.171, 'eval_samples_per_second': 71.235, 'eval_steps_per_second': 8.956, 'epoch': 4.0, 'step': 217}, {'loss': 0.6855, 'learning_rate': 1.5159569234954302e-05, 'epoch': 5.0, 'step': 271}, {'eval_loss': 0.6560840606689453, 'eval_accuracy': 0.7093425605536332, 'eval_runtime': 12.1428, 'eval_samples_per_second': 71.4, 'eval_steps_per_second': 8.977, 'epoch': 5.0, 'step': 271}, {'loss': 0.677, 'learning_rate': 1.8180295207971026e-05, 'epoch': 5.99, 'step': 325}, {'eval_loss': 0.6437474489212036, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.1764, 'eval_samples_per_second': 71.203, 'eval_steps_per_second': 8.952, 'epoch': 5.99, 'step': 325}, {'loss': 0.6608, 'learning_rate': 2.1201021180987752e-05, 'epoch': 6.99, 'step': 379}, {'eval_loss': 0.6304383873939514, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.1542, 'eval_samples_per_second': 71.333, 'eval_steps_per_second': 8.968, 'epoch': 6.99, 'step': 379}, {'loss': 0.6347, 'learning_rate': 2.4277686523875158e-05, 'epoch': 8.0, 'step': 434}, {'eval_loss': 0.6174824833869934, 'eval_accuracy': 0.7104959630911188, 'eval_runtime': 12.1553, 'eval_samples_per_second': 71.327, 'eval_steps_per_second': 8.967, 'epoch': 8.0, 'step': 434}, {'loss': 0.6311, 'learning_rate': 2.729841249689188e-05, 'epoch': 9.0, 'step': 488}, {'eval_loss': 0.6051294207572937, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 12.1682, 'eval_samples_per_second': 71.251, 'eval_steps_per_second': 8.958, 'epoch': 9.0, 'step': 488}, {'loss': 0.6217, 'learning_rate': 3.0207259730167248e-05, 'epoch': 9.95, 'step': 540}, {'eval_loss': 0.5916740894317627, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.1444, 'eval_samples_per_second': 71.391, 'eval_steps_per_second': 8.975, 'epoch': 9.95, 'step': 540}, {'train_runtime': 1094.7198, 'train_samples_per_second': 31.679, 'train_steps_per_second': 0.493, 'total_flos': 8594913207477744.0, 'train_loss': 0.6728725857204861, 'epoch': 9.95, 'step': 540}, {'eval_loss': 0.5916740894317627, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.2157, 'eval_samples_per_second': 70.974, 'eval_steps_per_second': 8.923, 'epoch': 9.95, 'step': 540}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 11:54:05,690] Trial 5 finished with values: [0.5916740894317627, 0.7174163783160323] and parameters: {'lr': 6.080609504942925e-05, 'batch': 8, 'accum': 8, 'dropout_rate': 0.7463634565392911, 'weight_decay': 2.212635052362363e-05, 'warmup_pct': 0.25097989698030915, 'lora_rank': 20, 'lora_init_scale': 0.005454792883848043, 'lora_scaling_rank': 3}. \n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 13389827.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 18:20, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.658595</td>\n",
       "      <td>0.685121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.581600</td>\n",
       "      <td>0.544177</td>\n",
       "      <td>0.739331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.517800</td>\n",
       "      <td>0.484297</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.488600</td>\n",
       "      <td>0.470537</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.469961</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.457400</td>\n",
       "      <td>0.469624</td>\n",
       "      <td>0.777393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46962377429008484, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.1172, 'eval_samples_per_second': 71.551, 'eval_steps_per_second': 8.995, 'epoch': 9.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 12:13:20,168] Trial 6 finished with values: [0.46962377429008484, 0.7773933102652826] and parameters: {'lr': 9.741175165265519e-05, 'batch': 8, 'accum': 4, 'dropout_rate': 0.410982184611112, 'weight_decay': 8.22011375337804e-05, 'warmup_pct': 0.11539407364307791, 'lora_rank': 20, 'lora_init_scale': 0.00016314225042501977, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6899, 'learning_rate': 2.1040938356973522e-05, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6585950255393982, 'eval_accuracy': 0.6851211072664359, 'eval_runtime': 13.818, 'eval_samples_per_second': 62.744, 'eval_steps_per_second': 7.888, 'epoch': 1.0, 'step': 108}, {'loss': 0.6338, 'learning_rate': 4.227670021725235e-05, 'epoch': 2.0, 'step': 217}, {'eval_loss': 0.5963749289512634, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.1438, 'eval_samples_per_second': 71.394, 'eval_steps_per_second': 8.976, 'epoch': 2.0, 'step': 217}, {'loss': 0.5816, 'learning_rate': 6.331763857422588e-05, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.5441765785217285, 'eval_accuracy': 0.7393310265282583, 'eval_runtime': 12.1446, 'eval_samples_per_second': 71.39, 'eval_steps_per_second': 8.975, 'epoch': 3.0, 'step': 325}, {'loss': 0.5334, 'learning_rate': 8.45534004345047e-05, 'epoch': 4.0, 'step': 434}, {'eval_loss': 0.5052882432937622, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1327, 'eval_samples_per_second': 71.459, 'eval_steps_per_second': 8.984, 'epoch': 4.0, 'step': 434}, {'loss': 0.5178, 'learning_rate': 9.035779722263532e-05, 'epoch': 5.0, 'step': 542}, {'eval_loss': 0.48429661989212036, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.1427, 'eval_samples_per_second': 71.401, 'eval_steps_per_second': 8.977, 'epoch': 5.0, 'step': 542}, {'loss': 0.4951, 'learning_rate': 7.205110596377427e-05, 'epoch': 6.0, 'step': 651}, {'eval_loss': 0.47419473528862, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 12.123, 'eval_samples_per_second': 71.517, 'eval_steps_per_second': 8.991, 'epoch': 6.0, 'step': 651}, {'loss': 0.4886, 'learning_rate': 5.391236600086607e-05, 'epoch': 7.0, 'step': 759}, {'eval_loss': 0.4705365300178528, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1475, 'eval_samples_per_second': 71.373, 'eval_steps_per_second': 8.973, 'epoch': 7.0, 'step': 759}, {'loss': 0.4733, 'learning_rate': 3.5605674742005e-05, 'epoch': 8.0, 'step': 868}, {'eval_loss': 0.4685320258140564, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.1215, 'eval_samples_per_second': 71.526, 'eval_steps_per_second': 8.992, 'epoch': 8.0, 'step': 868}, {'loss': 0.4684, 'learning_rate': 1.7466934779096792e-05, 'epoch': 9.0, 'step': 976}, {'eval_loss': 0.46996110677719116, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.1376, 'eval_samples_per_second': 71.431, 'eval_steps_per_second': 8.98, 'epoch': 9.0, 'step': 976}, {'loss': 0.4574, 'learning_rate': 0.0, 'epoch': 9.95, 'step': 1080}, {'eval_loss': 0.46962377429008484, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.1203, 'eval_samples_per_second': 71.533, 'eval_steps_per_second': 8.993, 'epoch': 9.95, 'step': 1080}, {'train_runtime': 1101.6707, 'train_samples_per_second': 31.479, 'train_steps_per_second': 0.98, 'total_flos': 8601836655961584.0, 'train_loss': 0.5342216950875741, 'epoch': 9.95, 'step': 1080}, {'eval_loss': 0.46962377429008484, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.1172, 'eval_samples_per_second': 71.551, 'eval_steps_per_second': 8.995, 'epoch': 9.95, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 20762627.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6936' max='17340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6936/17340 26:50 < 40:16, 4.31 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.356700</td>\n",
       "      <td>0.697409</td>\n",
       "      <td>0.532872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.948600</td>\n",
       "      <td>0.838624</td>\n",
       "      <td>0.532872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.943200</td>\n",
       "      <td>1.661899</td>\n",
       "      <td>0.467128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.856700</td>\n",
       "      <td>0.725009</td>\n",
       "      <td>0.467128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6974089741706848, 'eval_accuracy': 0.532871972318339, 'eval_runtime': 12.1407, 'eval_samples_per_second': 71.413, 'eval_steps_per_second': 8.978, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 12:41:03,518] Trial 7 finished with values: [0.6974089741706848, 0.532871972318339] and parameters: {'lr': 0.003488902870105638, 'batch': 1, 'accum': 2, 'dropout_rate': 0.445921233032751, 'weight_decay': 0.0006951853072945229, 'warmup_pct': 0.0318342806955393, 'lora_rank': 32, 'lora_init_scale': 0.0022330993921392235, 'lora_scaling_rank': 8}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 1.3567, 'learning_rate': 0.0033535241556336896, 'epoch': 1.0, 'step': 1734}, {'eval_loss': 0.6974089741706848, 'eval_accuracy': 0.532871972318339, 'eval_runtime': 13.8416, 'eval_samples_per_second': 62.637, 'eval_steps_per_second': 7.875, 'epoch': 1.0, 'step': 1734}, {'loss': 0.9486, 'learning_rate': 0.0029809103605632796, 'epoch': 2.0, 'step': 3468}, {'eval_loss': 0.8386238217353821, 'eval_accuracy': 0.532871972318339, 'eval_runtime': 12.1763, 'eval_samples_per_second': 71.204, 'eval_steps_per_second': 8.952, 'epoch': 2.0, 'step': 3468}, {'loss': 0.9432, 'learning_rate': 0.0026082965654928695, 'epoch': 3.0, 'step': 5202}, {'eval_loss': 1.6618987321853638, 'eval_accuracy': 0.4671280276816609, 'eval_runtime': 12.171, 'eval_samples_per_second': 71.235, 'eval_steps_per_second': 8.956, 'epoch': 3.0, 'step': 5202}, {'loss': 0.8567, 'learning_rate': 0.00223568277042246, 'epoch': 4.0, 'step': 6936}, {'eval_loss': 0.7250089645385742, 'eval_accuracy': 0.4671280276816609, 'eval_runtime': 12.1699, 'eval_samples_per_second': 71.241, 'eval_steps_per_second': 8.957, 'epoch': 4.0, 'step': 6936}, {'train_runtime': 1610.6312, 'train_samples_per_second': 21.532, 'train_steps_per_second': 10.766, 'total_flos': 3477146149685952.0, 'train_loss': 1.026306997120999, 'epoch': 4.0, 'step': 6936}, {'eval_loss': 0.6974089741706848, 'eval_accuracy': 0.532871972318339, 'eval_runtime': 12.1407, 'eval_samples_per_second': 71.413, 'eval_steps_per_second': 8.978, 'epoch': 4.0, 'step': 6936}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 18796547.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2170' max='2170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2170/2170 18:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.662600</td>\n",
       "      <td>0.610622</td>\n",
       "      <td>0.716263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.596600</td>\n",
       "      <td>0.566639</td>\n",
       "      <td>0.730104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.562400</td>\n",
       "      <td>0.542956</td>\n",
       "      <td>0.745098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>0.528132</td>\n",
       "      <td>0.752018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.533600</td>\n",
       "      <td>0.518131</td>\n",
       "      <td>0.760092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.527400</td>\n",
       "      <td>0.512817</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.522400</td>\n",
       "      <td>0.506105</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.503390</td>\n",
       "      <td>0.769319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.512900</td>\n",
       "      <td>0.501940</td>\n",
       "      <td>0.770473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.501128</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5011276006698608, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.2766, 'eval_samples_per_second': 70.622, 'eval_steps_per_second': 8.879, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 13:00:41,296] Trial 8 finished with values: [0.5011276006698608, 0.7716262975778547] and parameters: {'lr': 2.7857512832582767e-05, 'batch': 8, 'accum': 2, 'dropout_rate': 0.39189323103060525, 'weight_decay': 0.00016125523015716014, 'warmup_pct': 0.019498689030115708, 'lora_rank': 32, 'lora_init_scale': 0.0012783874660457553, 'lora_scaling_rank': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6626, 'learning_rate': 2.60813626855389e-05, 'epoch': 1.0, 'step': 217}, {'eval_loss': 0.6106218695640564, 'eval_accuracy': 0.7162629757785467, 'eval_runtime': 13.9112, 'eval_samples_per_second': 62.324, 'eval_steps_per_second': 7.835, 'epoch': 1.0, 'step': 217}, {'loss': 0.5966, 'learning_rate': 2.31834334982568e-05, 'epoch': 2.0, 'step': 434}, {'eval_loss': 0.5666386485099792, 'eval_accuracy': 0.7301038062283737, 'eval_runtime': 12.1588, 'eval_samples_per_second': 71.306, 'eval_steps_per_second': 8.965, 'epoch': 2.0, 'step': 434}, {'loss': 0.5624, 'learning_rate': 2.02855043109747e-05, 'epoch': 3.0, 'step': 651}, {'eval_loss': 0.5429564714431763, 'eval_accuracy': 0.7450980392156863, 'eval_runtime': 12.1882, 'eval_samples_per_second': 71.134, 'eval_steps_per_second': 8.943, 'epoch': 3.0, 'step': 651}, {'loss': 0.5407, 'learning_rate': 1.73875751236926e-05, 'epoch': 4.0, 'step': 868}, {'eval_loss': 0.5281320810317993, 'eval_accuracy': 0.7520184544405998, 'eval_runtime': 12.1582, 'eval_samples_per_second': 71.31, 'eval_steps_per_second': 8.965, 'epoch': 4.0, 'step': 868}, {'loss': 0.5336, 'learning_rate': 1.44896459364105e-05, 'epoch': 5.0, 'step': 1085}, {'eval_loss': 0.518130898475647, 'eval_accuracy': 0.7600922722029988, 'eval_runtime': 12.1767, 'eval_samples_per_second': 71.201, 'eval_steps_per_second': 8.952, 'epoch': 5.0, 'step': 1085}, {'loss': 0.5274, 'learning_rate': 1.15917167491284e-05, 'epoch': 6.0, 'step': 1302}, {'eval_loss': 0.5128165483474731, 'eval_accuracy': 0.7577854671280276, 'eval_runtime': 12.1692, 'eval_samples_per_second': 71.245, 'eval_steps_per_second': 8.957, 'epoch': 6.0, 'step': 1302}, {'loss': 0.5224, 'learning_rate': 8.6937875618463e-06, 'epoch': 7.0, 'step': 1519}, {'eval_loss': 0.5061051249504089, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.1617, 'eval_samples_per_second': 71.289, 'eval_steps_per_second': 8.963, 'epoch': 7.0, 'step': 1519}, {'loss': 0.5168, 'learning_rate': 5.7958583745642e-06, 'epoch': 8.0, 'step': 1736}, {'eval_loss': 0.5033898949623108, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 12.1764, 'eval_samples_per_second': 71.203, 'eval_steps_per_second': 8.952, 'epoch': 8.0, 'step': 1736}, {'loss': 0.5129, 'learning_rate': 2.8979291872821e-06, 'epoch': 9.0, 'step': 1953}, {'eval_loss': 0.5019400119781494, 'eval_accuracy': 0.7704728950403691, 'eval_runtime': 12.1639, 'eval_samples_per_second': 71.277, 'eval_steps_per_second': 8.961, 'epoch': 9.0, 'step': 1953}, {'loss': 0.514, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 2170}, {'eval_loss': 0.5011276006698608, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1803, 'eval_samples_per_second': 71.18, 'eval_steps_per_second': 8.949, 'epoch': 10.0, 'step': 2170}, {'train_runtime': 1123.4069, 'train_samples_per_second': 30.87, 'train_steps_per_second': 1.932, 'total_flos': 8678955908717280.0, 'train_loss': 0.5489489049955447, 'epoch': 10.0, 'step': 2170}, {'eval_loss': 0.5011276006698608, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.2766, 'eval_samples_per_second': 70.622, 'eval_steps_per_second': 8.879, 'epoch': 10.0, 'step': 2170}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 9457667.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 38:14, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.690202</td>\n",
       "      <td>0.530565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.665400</td>\n",
       "      <td>0.646689</td>\n",
       "      <td>0.710496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.617300</td>\n",
       "      <td>0.596289</td>\n",
       "      <td>0.718570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.573400</td>\n",
       "      <td>0.560306</td>\n",
       "      <td>0.726644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.547031</td>\n",
       "      <td>0.731257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.555800</td>\n",
       "      <td>0.545329</td>\n",
       "      <td>0.735871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5453286170959473, 'eval_accuracy': 0.7358708189158016, 'eval_runtime': 12.2192, 'eval_samples_per_second': 70.954, 'eval_steps_per_second': 8.92, 'epoch': 9.99}\n",
      "History:  [{'loss': 0.6974, 'learning_rate': 1.7732797878062975e-06, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6902021765708923, 'eval_accuracy': 0.5305651672433679, 'eval_runtime': 13.8106, 'eval_samples_per_second': 62.778, 'eval_steps_per_second': 7.893, 'epoch': 1.0, 'step': 433}, {'loss': 0.6839, 'learning_rate': 3.55065490999552e-06, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.6714340448379517, 'eval_accuracy': 0.6632064590542099, 'eval_runtime': 12.2496, 'eval_samples_per_second': 70.778, 'eval_steps_per_second': 8.898, 'epoch': 2.0, 'step': 867}, {'loss': 0.6654, 'learning_rate': 5.323934697801817e-06, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.6466893553733826, 'eval_accuracy': 0.7104959630911188, 'eval_runtime': 12.1286, 'eval_samples_per_second': 71.484, 'eval_steps_per_second': 8.987, 'epoch': 3.0, 'step': 1300}, {'loss': 0.64, 'learning_rate': 7.10130981999104e-06, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.6207638382911682, 'eval_accuracy': 0.7116493656286044, 'eval_runtime': 12.1194, 'eval_samples_per_second': 71.538, 'eval_steps_per_second': 8.994, 'epoch': 4.0, 'step': 1734}, {'loss': 0.6173, 'learning_rate': 8.874589607797337e-06, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5962885022163391, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.1291, 'eval_samples_per_second': 71.481, 'eval_steps_per_second': 8.987, 'epoch': 5.0, 'step': 2167}, {'loss': 0.5965, 'learning_rate': 1.0105269728140448e-05, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.5751367807388306, 'eval_accuracy': 0.7197231833910035, 'eval_runtime': 12.1694, 'eval_samples_per_second': 71.244, 'eval_steps_per_second': 8.957, 'epoch': 6.0, 'step': 2601}, {'loss': 0.5734, 'learning_rate': 7.574568865049172e-06, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.5603064298629761, 'eval_accuracy': 0.726643598615917, 'eval_runtime': 12.124, 'eval_samples_per_second': 71.511, 'eval_steps_per_second': 8.99, 'epoch': 7.0, 'step': 3034}, {'loss': 0.5601, 'learning_rate': 5.038023427216348e-06, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.5518162846565247, 'eval_accuracy': 0.726643598615917, 'eval_runtime': 12.1218, 'eval_samples_per_second': 71.524, 'eval_steps_per_second': 8.992, 'epoch': 8.0, 'step': 3468}, {'loss': 0.561, 'learning_rate': 2.507322564125073e-06, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.5470306277275085, 'eval_accuracy': 0.7312572087658593, 'eval_runtime': 12.1167, 'eval_samples_per_second': 71.554, 'eval_steps_per_second': 8.996, 'epoch': 9.0, 'step': 3901}, {'loss': 0.5558, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5453286170959473, 'eval_accuracy': 0.7358708189158016, 'eval_runtime': 12.1052, 'eval_samples_per_second': 71.622, 'eval_steps_per_second': 9.004, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 2294.9162, 'train_samples_per_second': 15.112, 'train_steps_per_second': 1.887, 'total_flos': 8602951823096640.0, 'train_loss': 0.6151437455457022, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5453286170959473, 'eval_accuracy': 0.7358708189158016, 'eval_runtime': 12.2192, 'eval_samples_per_second': 70.954, 'eval_steps_per_second': 8.92, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 13:39:51,961] Trial 9 finished with values: [0.5453286170959473, 0.7358708189158016] and parameters: {'lr': 1.0426721338925713e-05, 'batch': 2, 'accum': 4, 'dropout_rate': 0.4748596845801991, 'weight_decay': 0.00015750528343988309, 'warmup_pct': 0.14682840320265267, 'lora_rank': 16, 'lora_init_scale': 0.00010609772427179262, 'lora_scaling_rank': 1}. \n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 7983107.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 24:31, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.671192</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.622122</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.601300</td>\n",
       "      <td>0.577509</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.570600</td>\n",
       "      <td>0.541891</td>\n",
       "      <td>0.741638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.539600</td>\n",
       "      <td>0.513356</td>\n",
       "      <td>0.760092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.511300</td>\n",
       "      <td>0.492808</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.503500</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>0.772780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>0.478434</td>\n",
       "      <td>0.762399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.453900</td>\n",
       "      <td>0.474064</td>\n",
       "      <td>0.772780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47406354546546936, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.0897, 'eval_samples_per_second': 71.714, 'eval_steps_per_second': 9.016, 'epoch': 9.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 14:05:16,910] Trial 10 finished with values: [0.47406354546546936, 0.7727797001153403] and parameters: {'lr': 0.00017217988685369333, 'batch': 4, 'accum': 8, 'dropout_rate': 0.2506796479437915, 'weight_decay': 4.1002548507731495e-05, 'warmup_pct': 0.19855362274271587, 'lora_rank': 8, 'lora_init_scale': 0.08991398196540609, 'lora_scaling_rank': 6}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6914, 'learning_rate': 1.0805013236605973e-05, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6711915135383606, 'eval_accuracy': 0.6470588235294118, 'eval_runtime': 13.7737, 'eval_samples_per_second': 62.946, 'eval_steps_per_second': 7.914, 'epoch': 1.0, 'step': 108}, {'loss': 0.653, 'learning_rate': 2.1610026473211947e-05, 'epoch': 1.99, 'step': 216}, {'eval_loss': 0.6221221685409546, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.1138, 'eval_samples_per_second': 71.571, 'eval_steps_per_second': 8.998, 'epoch': 1.99, 'step': 216}, {'loss': 0.6013, 'learning_rate': 3.251508612867538e-05, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.5775094628334045, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.1136, 'eval_samples_per_second': 71.572, 'eval_steps_per_second': 8.998, 'epoch': 3.0, 'step': 325}, {'loss': 0.5706, 'learning_rate': 4.3320099365281355e-05, 'epoch': 4.0, 'step': 433}, {'eval_loss': 0.5418911576271057, 'eval_accuracy': 0.7416378316032295, 'eval_runtime': 12.1162, 'eval_samples_per_second': 71.557, 'eval_steps_per_second': 8.996, 'epoch': 4.0, 'step': 433}, {'loss': 0.5396, 'learning_rate': 5.412511260188732e-05, 'epoch': 4.99, 'step': 541}, {'eval_loss': 0.5133557319641113, 'eval_accuracy': 0.7600922722029988, 'eval_runtime': 12.1137, 'eval_samples_per_second': 71.572, 'eval_steps_per_second': 8.998, 'epoch': 4.99, 'step': 541}, {'loss': 0.5113, 'learning_rate': 6.503017225735076e-05, 'epoch': 6.0, 'step': 650}, {'eval_loss': 0.4928078353404999, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.11, 'eval_samples_per_second': 71.594, 'eval_steps_per_second': 9.001, 'epoch': 6.0, 'step': 650}, {'loss': 0.5035, 'learning_rate': 7.583518549395674e-05, 'epoch': 6.99, 'step': 758}, {'eval_loss': 0.4836598336696625, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.1198, 'eval_samples_per_second': 71.536, 'eval_steps_per_second': 8.994, 'epoch': 6.99, 'step': 758}, {'loss': 0.4815, 'learning_rate': 8.674024514942017e-05, 'epoch': 8.0, 'step': 867}, {'eval_loss': 0.48582154512405396, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.113, 'eval_samples_per_second': 71.576, 'eval_steps_per_second': 8.999, 'epoch': 8.0, 'step': 867}, {'loss': 0.4726, 'learning_rate': 9.754525838602615e-05, 'epoch': 9.0, 'step': 975}, {'eval_loss': 0.4784338176250458, 'eval_accuracy': 0.76239907727797, 'eval_runtime': 12.1161, 'eval_samples_per_second': 71.558, 'eval_steps_per_second': 8.996, 'epoch': 9.0, 'step': 975}, {'loss': 0.4539, 'learning_rate': 0.00010805013236605973, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.47406354546546936, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.107, 'eval_samples_per_second': 71.611, 'eval_steps_per_second': 9.003, 'epoch': 9.97, 'step': 1080}, {'train_runtime': 1472.3775, 'train_samples_per_second': 23.554, 'train_steps_per_second': 0.734, 'total_flos': 8572687572188160.0, 'train_loss': 0.5480722250761809, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.47406354546546936, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.0897, 'eval_samples_per_second': 71.714, 'eval_steps_per_second': 9.016, 'epoch': 9.97, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 5525507.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 25:13, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.619700</td>\n",
       "      <td>0.513237</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.551200</td>\n",
       "      <td>0.471431</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.441800</td>\n",
       "      <td>0.520613</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.324900</td>\n",
       "      <td>0.789064</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.986994</td>\n",
       "      <td>0.786621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.144500</td>\n",
       "      <td>1.100539</td>\n",
       "      <td>0.790081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.9660893082618713, 'eval_accuracy': 0.7912341407151096, 'eval_runtime': 12.2798, 'eval_samples_per_second': 70.604, 'eval_steps_per_second': 8.876, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 14:31:23,536] Trial 11 finished with values: [0.9660893082618713, 0.7912341407151096] and parameters: {'lr': 0.0017007276558301762, 'batch': 4, 'accum': 2, 'dropout_rate': 0.5912121439542763, 'weight_decay': 1.7695724868609444e-05, 'warmup_pct': 0.08557794125611791, 'lora_rank': 4, 'lora_init_scale': 0.00012360041069115667, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6197, 'learning_rate': 0.0009938125168346373, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.5132373571395874, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 13.8524, 'eval_samples_per_second': 62.589, 'eval_steps_per_second': 7.869, 'epoch': 1.0, 'step': 433}, {'loss': 0.5877, 'learning_rate': 0.0016410197470437169, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.4990178346633911, 'eval_accuracy': 0.7566320645905421, 'eval_runtime': 12.2526, 'eval_samples_per_second': 70.761, 'eval_steps_per_second': 8.896, 'epoch': 2.0, 'step': 867}, {'loss': 0.5512, 'learning_rate': 0.0014358330446267579, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.47143104672431946, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.1192, 'eval_samples_per_second': 71.54, 'eval_steps_per_second': 8.994, 'epoch': 3.0, 'step': 1300}, {'loss': 0.4869, 'learning_rate': 0.0012301724699178426, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.49834349751472473, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.1318, 'eval_samples_per_second': 71.465, 'eval_steps_per_second': 8.985, 'epoch': 4.0, 'step': 1734}, {'loss': 0.4418, 'learning_rate': 0.0010249857675008836, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5206127762794495, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1212, 'eval_samples_per_second': 71.527, 'eval_steps_per_second': 8.992, 'epoch': 5.0, 'step': 2167}, {'loss': 0.359, 'learning_rate': 0.0008193251927919684, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.6332070231437683, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1342, 'eval_samples_per_second': 71.451, 'eval_steps_per_second': 8.983, 'epoch': 6.0, 'step': 2601}, {'loss': 0.3249, 'learning_rate': 0.0006141384903750092, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.7890641093254089, 'eval_accuracy': 0.7647058823529411, 'eval_runtime': 12.1265, 'eval_samples_per_second': 71.497, 'eval_steps_per_second': 8.989, 'epoch': 7.0, 'step': 3034}, {'loss': 0.2392, 'learning_rate': 0.00040847791566609414, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.9660893082618713, 'eval_accuracy': 0.7912341407151096, 'eval_runtime': 12.1243, 'eval_samples_per_second': 71.51, 'eval_steps_per_second': 8.99, 'epoch': 8.0, 'step': 3468}, {'loss': 0.1988, 'learning_rate': 0.00020329121324913501, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.9869940876960754, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.1438, 'eval_samples_per_second': 71.395, 'eval_steps_per_second': 8.976, 'epoch': 9.0, 'step': 3901}, {'loss': 0.1445, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 1.1005394458770752, 'eval_accuracy': 0.790080738177624, 'eval_runtime': 12.1149, 'eval_samples_per_second': 71.565, 'eval_steps_per_second': 8.997, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 1513.3606, 'train_samples_per_second': 22.916, 'train_steps_per_second': 2.861, 'total_flos': 8575164978527040.0, 'train_loss': 0.395638876864321, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.9660893082618713, 'eval_accuracy': 0.7912341407151096, 'eval_runtime': 12.2798, 'eval_samples_per_second': 70.604, 'eval_steps_per_second': 8.876, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 7491587.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 24:51, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.589100</td>\n",
       "      <td>0.495428</td>\n",
       "      <td>0.749712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.499200</td>\n",
       "      <td>0.550767</td>\n",
       "      <td>0.737024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.321600</td>\n",
       "      <td>0.647373</td>\n",
       "      <td>0.792388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>1.296712</td>\n",
       "      <td>0.795848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>1.699357</td>\n",
       "      <td>0.803922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>1.786019</td>\n",
       "      <td>0.806228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 1.6030584573745728, 'eval_accuracy': 0.8073817762399077, 'eval_runtime': 12.1122, 'eval_samples_per_second': 71.581, 'eval_steps_per_second': 8.999, 'epoch': 9.99}\n",
      "History:  [{'loss': 0.5891, 'learning_rate': 0.000600875883008678, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.49542805552482605, 'eval_accuracy': 0.7497116493656286, 'eval_runtime': 13.855, 'eval_samples_per_second': 62.577, 'eval_steps_per_second': 7.867, 'epoch': 1.0, 'step': 433}, {'loss': 0.5318, 'learning_rate': 0.0012031394701351587, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5047907829284668, 'eval_accuracy': 0.7681660899653979, 'eval_runtime': 12.417, 'eval_samples_per_second': 69.824, 'eval_steps_per_second': 8.778, 'epoch': 2.0, 'step': 867}, {'loss': 0.4992, 'learning_rate': 0.0012235628006846489, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.5507667660713196, 'eval_accuracy': 0.7370242214532872, 'eval_runtime': 12.1352, 'eval_samples_per_second': 71.445, 'eval_steps_per_second': 8.982, 'epoch': 3.0, 'step': 1300}, {'loss': 0.4193, 'learning_rate': 0.0010483066107516, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.6031402349472046, 'eval_accuracy': 0.7797001153402537, 'eval_runtime': 12.14, 'eval_samples_per_second': 71.417, 'eval_steps_per_second': 8.979, 'epoch': 4.0, 'step': 1734}, {'loss': 0.3216, 'learning_rate': 0.0008734542369243878, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.6473729610443115, 'eval_accuracy': 0.7923875432525952, 'eval_runtime': 12.1266, 'eval_samples_per_second': 71.496, 'eval_steps_per_second': 8.989, 'epoch': 5.0, 'step': 2167}, {'loss': 0.2183, 'learning_rate': 0.0006981980469913392, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 1.0801066160202026, 'eval_accuracy': 0.7912341407151096, 'eval_runtime': 12.1562, 'eval_samples_per_second': 71.322, 'eval_steps_per_second': 8.967, 'epoch': 6.0, 'step': 2601}, {'loss': 0.1659, 'learning_rate': 0.000523345673164127, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 1.2967115640640259, 'eval_accuracy': 0.7958477508650519, 'eval_runtime': 12.1394, 'eval_samples_per_second': 71.42, 'eval_steps_per_second': 8.979, 'epoch': 7.0, 'step': 3034}, {'loss': 0.0959, 'learning_rate': 0.0003480894832310783, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 1.6030584573745728, 'eval_accuracy': 0.8073817762399077, 'eval_runtime': 12.1497, 'eval_samples_per_second': 71.36, 'eval_steps_per_second': 8.971, 'epoch': 8.0, 'step': 3468}, {'loss': 0.0658, 'learning_rate': 0.00017323710940386612, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 1.6993566751480103, 'eval_accuracy': 0.803921568627451, 'eval_runtime': 12.145, 'eval_samples_per_second': 71.388, 'eval_steps_per_second': 8.975, 'epoch': 9.0, 'step': 3901}, {'loss': 0.0331, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 1.7860190868377686, 'eval_accuracy': 0.8062283737024222, 'eval_runtime': 12.146, 'eval_samples_per_second': 71.382, 'eval_steps_per_second': 8.974, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 1491.9477, 'train_samples_per_second': 23.245, 'train_steps_per_second': 2.902, 'total_flos': 8589058400811840.0, 'train_loss': 0.29425881145732785, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 1.6030584573745728, 'eval_accuracy': 0.8073817762399077, 'eval_runtime': 12.1122, 'eval_samples_per_second': 71.581, 'eval_steps_per_second': 8.999, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 14:57:09,284] Trial 12 finished with values: [1.6030584573745728, 0.8073817762399077] and parameters: {'lr': 0.0013543992189756805, 'batch': 4, 'accum': 2, 'dropout_rate': 0.13587545441638396, 'weight_decay': 5.237543549739713e-05, 'warmup_pct': 0.11257683544453856, 'lora_rank': 12, 'lora_init_scale': 0.0008342401720737065, 'lora_scaling_rank': 1}. \n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 10440707.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 39:04, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.612449</td>\n",
       "      <td>0.712803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>0.492470</td>\n",
       "      <td>0.758939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.512558</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.448700</td>\n",
       "      <td>0.509526</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>0.560017</td>\n",
       "      <td>0.790081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.764132</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5600172281265259, 'eval_accuracy': 0.790080738177624, 'eval_runtime': 12.241, 'eval_samples_per_second': 70.828, 'eval_steps_per_second': 8.905, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 15:37:09,749] Trial 13 finished with values: [0.5600172281265259, 0.790080738177624] and parameters: {'lr': 0.0002961775717294789, 'batch': 2, 'accum': 4, 'dropout_rate': 0.4302902527418263, 'weight_decay': 2.6661703110606258e-05, 'warmup_pct': 0.2310492292719728, 'lora_rank': 16, 'lora_init_scale': 0.022315586481149657, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.67, 'learning_rate': 3.201320233621178e-05, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6124491691589355, 'eval_accuracy': 0.71280276816609, 'eval_runtime': 13.8255, 'eval_samples_per_second': 62.71, 'eval_steps_per_second': 7.884, 'epoch': 1.0, 'step': 433}, {'loss': 0.5819, 'learning_rate': 6.410033816511688e-05, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5307042598724365, 'eval_accuracy': 0.748558246828143, 'eval_runtime': 12.1877, 'eval_samples_per_second': 71.137, 'eval_steps_per_second': 8.943, 'epoch': 2.0, 'step': 867}, {'loss': 0.5337, 'learning_rate': 9.611354050132866e-05, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.49247029423713684, 'eval_accuracy': 0.7589388696655133, 'eval_runtime': 12.1602, 'eval_samples_per_second': 71.298, 'eval_steps_per_second': 8.964, 'epoch': 3.0, 'step': 1300}, {'loss': 0.5048, 'learning_rate': 0.00012820067633023376, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.47576770186424255, 'eval_accuracy': 0.7635524798154556, 'eval_runtime': 12.1524, 'eval_samples_per_second': 71.344, 'eval_steps_per_second': 8.969, 'epoch': 4.0, 'step': 1734}, {'loss': 0.4986, 'learning_rate': 0.00016021387866644554, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5125581622123718, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.1463, 'eval_samples_per_second': 71.38, 'eval_steps_per_second': 8.974, 'epoch': 5.0, 'step': 2167}, {'loss': 0.4784, 'learning_rate': 0.00019230101449535064, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.49828872084617615, 'eval_accuracy': 0.7693194925028836, 'eval_runtime': 12.1454, 'eval_samples_per_second': 71.385, 'eval_steps_per_second': 8.975, 'epoch': 6.0, 'step': 2601}, {'loss': 0.4487, 'learning_rate': 0.00022431421683156242, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.5095263123512268, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1632, 'eval_samples_per_second': 71.281, 'eval_steps_per_second': 8.961, 'epoch': 7.0, 'step': 3034}, {'loss': 0.4096, 'learning_rate': 0.0002564013526604675, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.515697181224823, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.1655, 'eval_samples_per_second': 71.267, 'eval_steps_per_second': 8.96, 'epoch': 8.0, 'step': 3468}, {'loss': 0.363, 'learning_rate': 0.00028841455499667933, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.5600172281265259, 'eval_accuracy': 0.790080738177624, 'eval_runtime': 12.1532, 'eval_samples_per_second': 71.339, 'eval_steps_per_second': 8.969, 'epoch': 9.0, 'step': 3901}, {'loss': 0.3028, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.7641316652297974, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1544, 'eval_samples_per_second': 71.332, 'eval_steps_per_second': 8.968, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 2345.3239, 'train_samples_per_second': 14.787, 'train_steps_per_second': 1.846, 'total_flos': 8609898534239040.0, 'train_loss': 0.4793419148575076, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5600172281265259, 'eval_accuracy': 0.790080738177624, 'eval_runtime': 12.241, 'eval_samples_per_second': 70.828, 'eval_steps_per_second': 8.905, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 20762627.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3034' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3034/4330 17:49 < 07:37, 2.83 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.615800</td>\n",
       "      <td>0.510056</td>\n",
       "      <td>0.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.728950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.634300</td>\n",
       "      <td>0.554237</td>\n",
       "      <td>0.686275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.599600</td>\n",
       "      <td>0.626010</td>\n",
       "      <td>0.678201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 6.9988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.9988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5197371244430542, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.228, 'eval_samples_per_second': 70.903, 'eval_steps_per_second': 8.914, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 15:55:54,785] Trial 14 finished with values: [0.5197371244430542, 0.7716262975778547] and parameters: {'lr': 0.0029073895670711004, 'batch': 4, 'accum': 2, 'dropout_rate': 0.5950449403198204, 'weight_decay': 1.4692382946264017e-05, 'warmup_pct': 0.26774223987597806, 'lora_rank': 32, 'lora_init_scale': 0.010004801704867143, 'lora_scaling_rank': 8}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6158, 'learning_rate': 0.0005423953823962889, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.5100557804107666, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 13.8956, 'eval_samples_per_second': 62.394, 'eval_steps_per_second': 7.844, 'epoch': 1.0, 'step': 433}, {'loss': 0.5665, 'learning_rate': 0.0010860434100175113, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5227491855621338, 'eval_accuracy': 0.76239907727797, 'eval_runtime': 12.1795, 'eval_samples_per_second': 71.185, 'eval_steps_per_second': 8.949, 'epoch': 2.0, 'step': 867}, {'loss': 0.5515, 'learning_rate': 0.0016284387924138002, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.5340721607208252, 'eval_accuracy': 0.7289504036908881, 'eval_runtime': 12.1606, 'eval_samples_per_second': 71.296, 'eval_steps_per_second': 8.963, 'epoch': 3.0, 'step': 1300}, {'loss': 0.5251, 'learning_rate': 0.0021720868200350227, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.5197371244430542, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1529, 'eval_samples_per_second': 71.341, 'eval_steps_per_second': 8.969, 'epoch': 4.0, 'step': 1734}, {'loss': 0.6343, 'learning_rate': 0.0027144822024313116, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5542365908622742, 'eval_accuracy': 0.6862745098039216, 'eval_runtime': 12.1877, 'eval_samples_per_second': 71.137, 'eval_steps_per_second': 8.943, 'epoch': 5.0, 'step': 2167}, {'loss': 0.6258, 'learning_rate': 0.002502178477583839, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.6569838523864746, 'eval_accuracy': 0.6678200692041523, 'eval_runtime': 12.1712, 'eval_samples_per_second': 71.234, 'eval_steps_per_second': 8.956, 'epoch': 6.0, 'step': 2601}, {'loss': 0.5996, 'learning_rate': 0.0018755484713410381, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.6260102391242981, 'eval_accuracy': 0.6782006920415224, 'eval_runtime': 12.1757, 'eval_samples_per_second': 71.208, 'eval_steps_per_second': 8.952, 'epoch': 7.0, 'step': 3034}, {'train_runtime': 1070.0698, 'train_samples_per_second': 32.409, 'train_steps_per_second': 4.046, 'total_flos': 6085005761950416.0, 'train_loss': 0.588367263502248, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.5197371244430542, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.228, 'eval_samples_per_second': 70.903, 'eval_steps_per_second': 8.914, 'epoch': 7.0, 'step': 3034}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 40:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.639300</td>\n",
       "      <td>0.511262</td>\n",
       "      <td>0.756632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.594500</td>\n",
       "      <td>0.504704</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.570700</td>\n",
       "      <td>0.567855</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.572300</td>\n",
       "      <td>0.901183</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.574800</td>\n",
       "      <td>0.582358</td>\n",
       "      <td>0.782007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>0.877928</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.400600</td>\n",
       "      <td>0.986768</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>1.248542</td>\n",
       "      <td>0.787774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>1.169265</td>\n",
       "      <td>0.788927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>1.361581</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1692651510238647, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.101, 'eval_samples_per_second': 71.647, 'eval_steps_per_second': 9.008, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 16:36:50,567] Trial 15 finished with values: [1.1692651510238647, 0.7889273356401384] and parameters: {'lr': 0.000972482262056014, 'batch': 2, 'accum': 2, 'dropout_rate': 0.6478358562211909, 'weight_decay': 2.6745850083470124e-05, 'warmup_pct': 0.2285211298578528, 'lora_rank': 24, 'lora_init_scale': 0.00018857623865166026, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6393, 'learning_rate': 0.00021280719868817875, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.5112622976303101, 'eval_accuracy': 0.7566320645905421, 'eval_runtime': 13.8275, 'eval_samples_per_second': 62.701, 'eval_steps_per_second': 7.883, 'epoch': 1.0, 'step': 867}, {'loss': 0.5945, 'learning_rate': 0.0004256143973763575, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.5047042965888977, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.1709, 'eval_samples_per_second': 71.236, 'eval_steps_per_second': 8.956, 'epoch': 2.0, 'step': 1734}, {'loss': 0.5707, 'learning_rate': 0.0006384215960645362, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.5678554773330688, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.2031, 'eval_samples_per_second': 71.047, 'eval_steps_per_second': 8.932, 'epoch': 3.0, 'step': 2601}, {'loss': 0.5723, 'learning_rate': 0.000851228794752715, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.9011834263801575, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1658, 'eval_samples_per_second': 71.265, 'eval_steps_per_second': 8.96, 'epoch': 4.0, 'step': 3468}, {'loss': 0.5748, 'learning_rate': 0.0008954355577767249, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5823583006858826, 'eval_accuracy': 0.7820069204152249, 'eval_runtime': 12.1492, 'eval_samples_per_second': 71.363, 'eval_steps_per_second': 8.972, 'epoch': 5.0, 'step': 4335}, {'loss': 0.5093, 'learning_rate': 0.00071634844622138, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.8779280185699463, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.1434, 'eval_samples_per_second': 71.397, 'eval_steps_per_second': 8.976, 'epoch': 6.0, 'step': 5202}, {'loss': 0.4006, 'learning_rate': 0.0005372613346660349, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.9867682456970215, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.1779, 'eval_samples_per_second': 71.195, 'eval_steps_per_second': 8.951, 'epoch': 7.0, 'step': 6069}, {'loss': 0.3076, 'learning_rate': 0.00035817422311069, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 1.2485424280166626, 'eval_accuracy': 0.7877739331026529, 'eval_runtime': 12.1336, 'eval_samples_per_second': 71.455, 'eval_steps_per_second': 8.983, 'epoch': 8.0, 'step': 6936}, {'loss': 0.2192, 'learning_rate': 0.000179087111555345, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 1.1692651510238647, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.1438, 'eval_samples_per_second': 71.394, 'eval_steps_per_second': 8.976, 'epoch': 9.0, 'step': 7803}, {'loss': 0.1544, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 1.3615809679031372, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1432, 'eval_samples_per_second': 71.398, 'eval_steps_per_second': 8.976, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 2402.9752, 'train_samples_per_second': 14.432, 'train_steps_per_second': 3.608, 'total_flos': 8654614344096480.0, 'train_loss': 0.4542701026010128, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 1.1692651510238647, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.101, 'eval_samples_per_second': 71.647, 'eval_steps_per_second': 9.008, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 20762627.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 25:27, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.669400</td>\n",
       "      <td>0.615327</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.535200</td>\n",
       "      <td>0.514450</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.501300</td>\n",
       "      <td>0.490668</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.486900</td>\n",
       "      <td>0.483202</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.474100</td>\n",
       "      <td>0.481677</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.481871</td>\n",
       "      <td>0.772780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4816770553588867, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1896, 'eval_samples_per_second': 71.126, 'eval_steps_per_second': 8.942, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 17:03:10,645] Trial 16 finished with values: [0.4816770553588867, 0.7716262975778547] and parameters: {'lr': 2.7872807374972613e-05, 'batch': 4, 'accum': 2, 'dropout_rate': 0.1271500923890403, 'weight_decay': 0.00016140349133256677, 'warmup_pct': 0.07067302585418075, 'lora_rank': 32, 'lora_init_scale': 0.04528129489724986, 'lora_scaling_rank': 8}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6694, 'learning_rate': 1.9720466655822126e-05, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6153268218040466, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 13.9041, 'eval_samples_per_second': 62.356, 'eval_steps_per_second': 7.839, 'epoch': 1.0, 'step': 433}, {'loss': 0.5805, 'learning_rate': 2.5961143609341085e-05, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5390207171440125, 'eval_accuracy': 0.7439446366782007, 'eval_runtime': 12.2069, 'eval_samples_per_second': 71.026, 'eval_steps_per_second': 8.929, 'epoch': 2.0, 'step': 867}, {'loss': 0.5352, 'learning_rate': 2.271506356809226e-05, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.5144504308700562, 'eval_accuracy': 0.7577854671280276, 'eval_runtime': 12.1875, 'eval_samples_per_second': 71.138, 'eval_steps_per_second': 8.944, 'epoch': 3.0, 'step': 1300}, {'loss': 0.5158, 'learning_rate': 1.9461486806193896e-05, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.4968010187149048, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1669, 'eval_samples_per_second': 71.259, 'eval_steps_per_second': 8.959, 'epoch': 4.0, 'step': 1734}, {'loss': 0.5013, 'learning_rate': 1.6215406764945067e-05, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.4906676411628723, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.1653, 'eval_samples_per_second': 71.268, 'eval_steps_per_second': 8.96, 'epoch': 5.0, 'step': 2167}, {'loss': 0.4889, 'learning_rate': 1.2961830003046705e-05, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.4857884645462036, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.1719, 'eval_samples_per_second': 71.23, 'eval_steps_per_second': 8.955, 'epoch': 6.0, 'step': 2601}, {'loss': 0.4869, 'learning_rate': 9.715749961797877e-06, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.48320236802101135, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.1521, 'eval_samples_per_second': 71.346, 'eval_steps_per_second': 8.97, 'epoch': 7.0, 'step': 3034}, {'loss': 0.483, 'learning_rate': 6.462173199899514e-06, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.48230740427970886, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.1759, 'eval_samples_per_second': 71.206, 'eval_steps_per_second': 8.952, 'epoch': 8.0, 'step': 3468}, {'loss': 0.4741, 'learning_rate': 3.2160931586506864e-06, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.4816770553588867, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1649, 'eval_samples_per_second': 71.271, 'eval_steps_per_second': 8.96, 'epoch': 9.0, 'step': 3901}, {'loss': 0.4733, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.48187127709388733, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.1953, 'eval_samples_per_second': 71.093, 'eval_steps_per_second': 8.938, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 1527.4825, 'train_samples_per_second': 22.704, 'train_steps_per_second': 2.835, 'total_flos': 8682839001234240.0, 'train_loss': 0.5208771809144053, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.4816770553588867, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1896, 'eval_samples_per_second': 71.126, 'eval_steps_per_second': 8.942, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 1:05:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.673300</td>\n",
       "      <td>0.624790</td>\n",
       "      <td>0.722030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.590400</td>\n",
       "      <td>0.542267</td>\n",
       "      <td>0.734717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.535400</td>\n",
       "      <td>0.515584</td>\n",
       "      <td>0.760092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.518000</td>\n",
       "      <td>0.480431</td>\n",
       "      <td>0.772780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.508400</td>\n",
       "      <td>0.512112</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.494100</td>\n",
       "      <td>0.527156</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>0.540841</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>0.553183</td>\n",
       "      <td>0.780854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.568626</td>\n",
       "      <td>0.779700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.437300</td>\n",
       "      <td>0.607876</td>\n",
       "      <td>0.787774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6078755855560303, 'eval_accuracy': 0.7877739331026529, 'eval_runtime': 12.1316, 'eval_samples_per_second': 71.466, 'eval_steps_per_second': 8.985, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 18:09:08,283] Trial 17 finished with values: [0.6078755855560303, 0.7877739331026529] and parameters: {'lr': 0.00010228861175811826, 'batch': 1, 'accum': 4, 'dropout_rate': 0.15089605117222096, 'weight_decay': 0.0005848959498769158, 'warmup_pct': 0.22688248079209683, 'lora_rank': 24, 'lora_init_scale': 0.00016071693300725813, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6733, 'learning_rate': 1.127150818432747e-05, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.6247900128364563, 'eval_accuracy': 0.7220299884659747, 'eval_runtime': 13.8548, 'eval_samples_per_second': 62.578, 'eval_steps_per_second': 7.867, 'epoch': 1.0, 'step': 867}, {'loss': 0.5904, 'learning_rate': 2.254301636865494e-05, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.5422666668891907, 'eval_accuracy': 0.734717416378316, 'eval_runtime': 12.5055, 'eval_samples_per_second': 69.33, 'eval_steps_per_second': 8.716, 'epoch': 2.0, 'step': 1734}, {'loss': 0.5354, 'learning_rate': 3.3814524552982416e-05, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.5155836939811707, 'eval_accuracy': 0.7600922722029988, 'eval_runtime': 12.178, 'eval_samples_per_second': 71.194, 'eval_steps_per_second': 8.951, 'epoch': 3.0, 'step': 2601}, {'loss': 0.518, 'learning_rate': 4.508603273730988e-05, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.48043128848075867, 'eval_accuracy': 0.7727797001153403, 'eval_runtime': 12.1796, 'eval_samples_per_second': 71.184, 'eval_steps_per_second': 8.949, 'epoch': 4.0, 'step': 3468}, {'loss': 0.5084, 'learning_rate': 5.6357540921637346e-05, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5121115446090698, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.1651, 'eval_samples_per_second': 71.27, 'eval_steps_per_second': 8.96, 'epoch': 5.0, 'step': 4335}, {'loss': 0.4941, 'learning_rate': 6.762904910596483e-05, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.527155876159668, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.1798, 'eval_samples_per_second': 71.183, 'eval_steps_per_second': 8.949, 'epoch': 6.0, 'step': 5202}, {'loss': 0.5001, 'learning_rate': 7.890055729029229e-05, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.5408408045768738, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1812, 'eval_samples_per_second': 71.175, 'eval_steps_per_second': 8.948, 'epoch': 7.0, 'step': 6069}, {'loss': 0.484, 'learning_rate': 9.017206547461976e-05, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 0.5531830787658691, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.1815, 'eval_samples_per_second': 71.174, 'eval_steps_per_second': 8.948, 'epoch': 8.0, 'step': 6936}, {'loss': 0.4674, 'learning_rate': 0.00010144357365894723, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 0.5686255693435669, 'eval_accuracy': 0.7797001153402537, 'eval_runtime': 12.1818, 'eval_samples_per_second': 71.172, 'eval_steps_per_second': 8.948, 'epoch': 9.0, 'step': 7803}, {'loss': 0.4373, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.6078755855560303, 'eval_accuracy': 0.7877739331026529, 'eval_runtime': 12.1713, 'eval_samples_per_second': 71.233, 'eval_steps_per_second': 8.956, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 3903.1989, 'train_samples_per_second': 8.885, 'train_steps_per_second': 2.221, 'total_flos': 8654614344096480.0, 'train_loss': 0.520851862114331, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.6078755855560303, 'eval_accuracy': 0.7877739331026529, 'eval_runtime': 12.1316, 'eval_samples_per_second': 71.466, 'eval_steps_per_second': 8.985, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 8474627.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 24:37, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.780600</td>\n",
       "      <td>0.694232</td>\n",
       "      <td>0.493656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.757900</td>\n",
       "      <td>0.684389</td>\n",
       "      <td>0.597463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.740800</td>\n",
       "      <td>0.670192</td>\n",
       "      <td>0.658593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.739200</td>\n",
       "      <td>0.654492</td>\n",
       "      <td>0.704729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.638543</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.700900</td>\n",
       "      <td>0.623777</td>\n",
       "      <td>0.713956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.703300</td>\n",
       "      <td>0.610851</td>\n",
       "      <td>0.711649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.663600</td>\n",
       "      <td>0.584043</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.571783</td>\n",
       "      <td>0.720877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5717834234237671, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 12.1372, 'eval_samples_per_second': 71.433, 'eval_steps_per_second': 8.981, 'epoch': 9.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 18:34:40,868] Trial 18 finished with values: [0.5717834234237671, 0.720876585928489] and parameters: {'lr': 0.00011458998338605231, 'batch': 4, 'accum': 8, 'dropout_rate': 0.8889810712391235, 'weight_decay': 0.0002104362553864315, 'warmup_pct': 0.17551683751835567, 'lora_rank': 12, 'lora_init_scale': 0.00015938126565652648, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7806, 'learning_rate': 8.136566867648685e-06, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6942320466041565, 'eval_accuracy': 0.4936562860438293, 'eval_runtime': 13.8588, 'eval_samples_per_second': 62.56, 'eval_steps_per_second': 7.865, 'epoch': 1.0, 'step': 108}, {'loss': 0.7579, 'learning_rate': 1.627313373529737e-05, 'epoch': 1.99, 'step': 216}, {'eval_loss': 0.6843894124031067, 'eval_accuracy': 0.5974625144175317, 'eval_runtime': 12.4038, 'eval_samples_per_second': 69.898, 'eval_steps_per_second': 8.788, 'epoch': 1.99, 'step': 216}, {'loss': 0.7408, 'learning_rate': 2.448503918505391e-05, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.6701919436454773, 'eval_accuracy': 0.6585928489042676, 'eval_runtime': 12.167, 'eval_samples_per_second': 71.259, 'eval_steps_per_second': 8.959, 'epoch': 3.0, 'step': 325}, {'loss': 0.7392, 'learning_rate': 3.2621606052702596e-05, 'epoch': 4.0, 'step': 433}, {'eval_loss': 0.6544920206069946, 'eval_accuracy': 0.7047289504036909, 'eval_runtime': 12.1525, 'eval_samples_per_second': 71.343, 'eval_steps_per_second': 8.969, 'epoch': 4.0, 'step': 433}, {'loss': 0.7241, 'learning_rate': 4.075817292035129e-05, 'epoch': 4.99, 'step': 541}, {'eval_loss': 0.638542652130127, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.1735, 'eval_samples_per_second': 71.22, 'eval_steps_per_second': 8.954, 'epoch': 4.99, 'step': 541}, {'loss': 0.7009, 'learning_rate': 4.897007837010782e-05, 'epoch': 6.0, 'step': 650}, {'eval_loss': 0.6237766146659851, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 12.158, 'eval_samples_per_second': 71.311, 'eval_steps_per_second': 8.965, 'epoch': 6.0, 'step': 650}, {'loss': 0.7033, 'learning_rate': 5.710664523775651e-05, 'epoch': 6.99, 'step': 758}, {'eval_loss': 0.6108508110046387, 'eval_accuracy': 0.7116493656286044, 'eval_runtime': 12.1654, 'eval_samples_per_second': 71.268, 'eval_steps_per_second': 8.96, 'epoch': 6.99, 'step': 758}, {'loss': 0.6746, 'learning_rate': 6.531855068751306e-05, 'epoch': 8.0, 'step': 867}, {'eval_loss': 0.5987720489501953, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 12.1691, 'eval_samples_per_second': 71.246, 'eval_steps_per_second': 8.957, 'epoch': 8.0, 'step': 867}, {'loss': 0.6636, 'learning_rate': 7.345511755516175e-05, 'epoch': 9.0, 'step': 975}, {'eval_loss': 0.5840430855751038, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.1386, 'eval_samples_per_second': 71.425, 'eval_steps_per_second': 8.98, 'epoch': 9.0, 'step': 975}, {'loss': 0.645, 'learning_rate': 8.136566867648684e-05, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.5717834234237671, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 12.1538, 'eval_samples_per_second': 71.336, 'eval_steps_per_second': 8.968, 'epoch': 9.97, 'step': 1080}, {'train_runtime': 1478.3012, 'train_samples_per_second': 23.459, 'train_steps_per_second': 0.731, 'total_flos': 8576152906152960.0, 'train_loss': 0.7131701434100116, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.5717834234237671, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 12.1372, 'eval_samples_per_second': 71.433, 'eval_steps_per_second': 8.981, 'epoch': 9.97, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355907.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2170' max='2170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2170/2170 18:37, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.681800</td>\n",
       "      <td>0.640165</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.615700</td>\n",
       "      <td>0.565092</td>\n",
       "      <td>0.727797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.555700</td>\n",
       "      <td>0.515241</td>\n",
       "      <td>0.756632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.518800</td>\n",
       "      <td>0.483168</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.478990</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.484600</td>\n",
       "      <td>0.472042</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.478400</td>\n",
       "      <td>0.468585</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.469887</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.449800</td>\n",
       "      <td>0.472126</td>\n",
       "      <td>0.786621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.472196</td>\n",
       "      <td>0.782007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.472126305103302, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.3196, 'eval_samples_per_second': 70.376, 'eval_steps_per_second': 8.848, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 18:54:12,148] Trial 19 finished with values: [0.472126305103302, 0.7866205305651672] and parameters: {'lr': 0.00010175943017273118, 'batch': 8, 'accum': 2, 'dropout_rate': 0.4882243131202929, 'weight_decay': 0.00014993579804161342, 'warmup_pct': 0.18496515086758566, 'lora_rank': 24, 'lora_init_scale': 0.01370043600756871, 'lora_scaling_rank': 5}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6818, 'learning_rate': 2.756778570222555e-05, 'epoch': 1.0, 'step': 217}, {'eval_loss': 0.6401650905609131, 'eval_accuracy': 0.7058823529411765, 'eval_runtime': 13.8461, 'eval_samples_per_second': 62.617, 'eval_steps_per_second': 7.872, 'epoch': 1.0, 'step': 217}, {'loss': 0.6157, 'learning_rate': 5.51355714044511e-05, 'epoch': 2.0, 'step': 434}, {'eval_loss': 0.5650923252105713, 'eval_accuracy': 0.7277970011534025, 'eval_runtime': 12.3136, 'eval_samples_per_second': 70.41, 'eval_steps_per_second': 8.852, 'epoch': 2.0, 'step': 434}, {'loss': 0.5557, 'learning_rate': 8.270335710667665e-05, 'epoch': 3.0, 'step': 651}, {'eval_loss': 0.5152411460876465, 'eval_accuracy': 0.7566320645905421, 'eval_runtime': 12.1375, 'eval_samples_per_second': 71.432, 'eval_steps_per_second': 8.98, 'epoch': 3.0, 'step': 651}, {'loss': 0.5188, 'learning_rate': 9.677923892249525e-05, 'epoch': 4.0, 'step': 868}, {'eval_loss': 0.48316794633865356, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.1648, 'eval_samples_per_second': 71.271, 'eval_steps_per_second': 8.96, 'epoch': 4.0, 'step': 868}, {'loss': 0.508, 'learning_rate': 8.064936576874604e-05, 'epoch': 5.0, 'step': 1085}, {'eval_loss': 0.478990375995636, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.1325, 'eval_samples_per_second': 71.461, 'eval_steps_per_second': 8.984, 'epoch': 5.0, 'step': 1085}, {'loss': 0.4846, 'learning_rate': 6.451949261499683e-05, 'epoch': 6.0, 'step': 1302}, {'eval_loss': 0.4720420837402344, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.1694, 'eval_samples_per_second': 71.245, 'eval_steps_per_second': 8.957, 'epoch': 6.0, 'step': 1302}, {'loss': 0.4784, 'learning_rate': 4.8389619461247624e-05, 'epoch': 7.0, 'step': 1519}, {'eval_loss': 0.4685846269130707, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1325, 'eval_samples_per_second': 71.461, 'eval_steps_per_second': 8.984, 'epoch': 7.0, 'step': 1519}, {'loss': 0.4626, 'learning_rate': 3.2259746307498416e-05, 'epoch': 8.0, 'step': 1736}, {'eval_loss': 0.46988677978515625, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1633, 'eval_samples_per_second': 71.28, 'eval_steps_per_second': 8.961, 'epoch': 8.0, 'step': 1736}, {'loss': 0.4498, 'learning_rate': 1.6129873153749208e-05, 'epoch': 9.0, 'step': 1953}, {'eval_loss': 0.472126305103302, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.1435, 'eval_samples_per_second': 71.396, 'eval_steps_per_second': 8.976, 'epoch': 9.0, 'step': 1953}, {'loss': 0.444, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 2170}, {'eval_loss': 0.472196489572525, 'eval_accuracy': 0.7820069204152249, 'eval_runtime': 12.1796, 'eval_samples_per_second': 71.185, 'eval_steps_per_second': 8.949, 'epoch': 10.0, 'step': 2170}, {'train_runtime': 1118.0872, 'train_samples_per_second': 31.017, 'train_steps_per_second': 1.941, 'total_flos': 8654614344096480.0, 'train_loss': 0.5199425446822347, 'epoch': 10.0, 'step': 2170}, {'eval_loss': 0.472126305103302, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.3196, 'eval_samples_per_second': 70.376, 'eval_steps_per_second': 8.848, 'epoch': 10.0, 'step': 2170}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15847427.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 1:04:29, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.670400</td>\n",
       "      <td>0.616133</td>\n",
       "      <td>0.720877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.527700</td>\n",
       "      <td>0.498453</td>\n",
       "      <td>0.760092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.485900</td>\n",
       "      <td>0.498460</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.446200</td>\n",
       "      <td>0.491190</td>\n",
       "      <td>0.780854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.517331</td>\n",
       "      <td>0.780854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.512216</td>\n",
       "      <td>0.776240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5015458464622498, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.1567, 'eval_samples_per_second': 71.319, 'eval_steps_per_second': 8.966, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 19:59:35,577] Trial 20 finished with values: [0.5015458464622498, 0.7854671280276817] and parameters: {'lr': 9.81833165594484e-05, 'batch': 1, 'accum': 8, 'dropout_rate': 0.14904399426138495, 'weight_decay': 2.1520637807282497e-05, 'warmup_pct': 0.06255151975729772, 'lora_rank': 28, 'lora_init_scale': 0.009225575377661381, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6704, 'learning_rate': 1.9600450009332026e-05, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6161328554153442, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 13.8992, 'eval_samples_per_second': 62.378, 'eval_steps_per_second': 7.842, 'epoch': 1.0, 'step': 433}, {'loss': 0.5825, 'learning_rate': 3.924616664686112e-05, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.5331746339797974, 'eval_accuracy': 0.7508650519031141, 'eval_runtime': 12.2728, 'eval_samples_per_second': 70.644, 'eval_steps_per_second': 8.881, 'epoch': 2.0, 'step': 867}, {'loss': 0.5277, 'learning_rate': 5.884661665619314e-05, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.49845337867736816, 'eval_accuracy': 0.7600922722029988, 'eval_runtime': 12.2421, 'eval_samples_per_second': 70.821, 'eval_steps_per_second': 8.904, 'epoch': 3.0, 'step': 1300}, {'loss': 0.5005, 'learning_rate': 7.849233329372224e-05, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.4718185067176819, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.3108, 'eval_samples_per_second': 70.426, 'eval_steps_per_second': 8.854, 'epoch': 4.0, 'step': 1734}, {'loss': 0.4859, 'learning_rate': 9.809278330305426e-05, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.4984603822231293, 'eval_accuracy': 0.7647058823529411, 'eval_runtime': 12.2767, 'eval_samples_per_second': 70.622, 'eval_steps_per_second': 8.879, 'epoch': 5.0, 'step': 2167}, {'loss': 0.4602, 'learning_rate': 7.855574008851748e-05, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.49249815940856934, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.4597, 'eval_samples_per_second': 69.585, 'eval_steps_per_second': 8.748, 'epoch': 6.0, 'step': 2601}, {'loss': 0.4462, 'learning_rate': 5.888272941279275e-05, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.4911901652812958, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.3629, 'eval_samples_per_second': 70.129, 'eval_steps_per_second': 8.817, 'epoch': 7.0, 'step': 3034}, {'loss': 0.4304, 'learning_rate': 3.916428453227419e-05, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.5015458464622498, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.3605, 'eval_samples_per_second': 70.143, 'eval_steps_per_second': 8.818, 'epoch': 8.0, 'step': 3468}, {'loss': 0.4018, 'learning_rate': 1.9491273856549454e-05, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.517330527305603, 'eval_accuracy': 0.7808535178777394, 'eval_runtime': 12.3496, 'eval_samples_per_second': 70.205, 'eval_steps_per_second': 8.826, 'epoch': 9.0, 'step': 3901}, {'loss': 0.3968, 'learning_rate': 0.0, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5122155547142029, 'eval_accuracy': 0.776239907727797, 'eval_runtime': 12.3309, 'eval_samples_per_second': 70.311, 'eval_steps_per_second': 8.84, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 3870.546, 'train_samples_per_second': 8.96, 'train_steps_per_second': 1.119, 'total_flos': 8648105445522240.0, 'train_loss': 0.4903423952450653, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5015458464622498, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.1567, 'eval_samples_per_second': 71.319, 'eval_steps_per_second': 8.966, 'epoch': 9.99, 'step': 4330}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 12406787.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='17340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8670/17340 33:26 < 33:27, 4.32 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.718700</td>\n",
       "      <td>0.528246</td>\n",
       "      <td>0.749712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.678100</td>\n",
       "      <td>0.622431</td>\n",
       "      <td>0.786621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.578300</td>\n",
       "      <td>0.856225</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.465600</td>\n",
       "      <td>0.977599</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.333500</td>\n",
       "      <td>1.160793</td>\n",
       "      <td>0.786621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.6224311590194702, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.1147, 'eval_samples_per_second': 71.566, 'eval_steps_per_second': 8.997, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 20:34:00,503] Trial 21 finished with values: [0.6224311590194702, 0.7866205305651672] and parameters: {'lr': 0.0005968434843149745, 'batch': 1, 'accum': 2, 'dropout_rate': 0.24140355409911365, 'weight_decay': 2.4682778193751892e-05, 'warmup_pct': 0.02893006659693323, 'lora_rank': 20, 'lora_init_scale': 0.009333935071644909, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7187, 'learning_rate': 0.0005701376884507249, 'epoch': 1.0, 'step': 1734}, {'eval_loss': 0.5282460451126099, 'eval_accuracy': 0.7497116493656286, 'eval_runtime': 14.0258, 'eval_samples_per_second': 61.815, 'eval_steps_per_second': 7.771, 'epoch': 1.0, 'step': 1734}, {'loss': 0.6781, 'learning_rate': 0.0005067890564006444, 'epoch': 2.0, 'step': 3468}, {'eval_loss': 0.6224311590194702, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.354, 'eval_samples_per_second': 70.18, 'eval_steps_per_second': 8.823, 'epoch': 2.0, 'step': 3468}, {'loss': 0.5783, 'learning_rate': 0.0004434404243505638, 'epoch': 3.0, 'step': 5202}, {'eval_loss': 0.8562248349189758, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.3116, 'eval_samples_per_second': 70.422, 'eval_steps_per_second': 8.853, 'epoch': 3.0, 'step': 5202}, {'loss': 0.4656, 'learning_rate': 0.00038009179230048324, 'epoch': 4.0, 'step': 6936}, {'eval_loss': 0.9775992035865784, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.2603, 'eval_samples_per_second': 70.716, 'eval_steps_per_second': 8.89, 'epoch': 4.0, 'step': 6936}, {'loss': 0.3335, 'learning_rate': 0.0003167431602504027, 'epoch': 5.0, 'step': 8670}, {'eval_loss': 1.1607928276062012, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.202, 'eval_samples_per_second': 71.054, 'eval_steps_per_second': 8.933, 'epoch': 5.0, 'step': 8670}, {'train_runtime': 2007.2237, 'train_samples_per_second': 17.278, 'train_steps_per_second': 8.639, 'total_flos': 4316875072925040.0, 'train_loss': 0.5548425307048371, 'epoch': 5.0, 'step': 8670}, {'eval_loss': 0.6224311590194702, 'eval_accuracy': 0.7866205305651672, 'eval_runtime': 12.1147, 'eval_samples_per_second': 71.566, 'eval_steps_per_second': 8.997, 'epoch': 5.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 16338947.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 24:42, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>0.607423</td>\n",
       "      <td>0.713956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>0.533444</td>\n",
       "      <td>0.742791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.561800</td>\n",
       "      <td>0.495114</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.534100</td>\n",
       "      <td>0.478021</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.508200</td>\n",
       "      <td>0.468608</td>\n",
       "      <td>0.773933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.486900</td>\n",
       "      <td>0.464343</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.480800</td>\n",
       "      <td>0.471820</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.446400</td>\n",
       "      <td>0.479024</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.433100</td>\n",
       "      <td>0.478897</td>\n",
       "      <td>0.785467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 9.965397923875432: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.47510308027267456, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.1854, 'eval_samples_per_second': 71.151, 'eval_steps_per_second': 8.945, 'epoch': 9.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 20:59:40,018] Trial 22 finished with values: [0.47510308027267456, 0.7889273356401384] and parameters: {'lr': 0.00027931534083516736, 'batch': 4, 'accum': 8, 'dropout_rate': 0.7764293495201305, 'weight_decay': 0.0005674347244327496, 'warmup_pct': 0.01875664251543504, 'lora_rank': 24, 'lora_init_scale': 0.020967068638031418, 'lora_scaling_rank': 7}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6935, 'learning_rate': 0.0001862102272234449, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6074228882789612, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 13.9421, 'eval_samples_per_second': 62.186, 'eval_steps_per_second': 7.818, 'epoch': 1.0, 'step': 108}, {'loss': 0.6022, 'learning_rate': 0.0002628850266683928, 'epoch': 1.99, 'step': 216}, {'eval_loss': 0.5334439873695374, 'eval_accuracy': 0.7427912341407151, 'eval_runtime': 12.2126, 'eval_samples_per_second': 70.992, 'eval_steps_per_second': 8.925, 'epoch': 1.99, 'step': 216}, {'loss': 0.5618, 'learning_rate': 0.00022972013325768122, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.49511387944221497, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.449, 'eval_samples_per_second': 69.644, 'eval_steps_per_second': 8.756, 'epoch': 3.0, 'step': 325}, {'loss': 0.5341, 'learning_rate': 0.00019685950492413212, 'epoch': 4.0, 'step': 433}, {'eval_loss': 0.478020578622818, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1533, 'eval_samples_per_second': 71.339, 'eval_steps_per_second': 8.969, 'epoch': 4.0, 'step': 433}, {'loss': 0.5082, 'learning_rate': 0.000163998876590583, 'epoch': 4.99, 'step': 541}, {'eval_loss': 0.4686082899570465, 'eval_accuracy': 0.7739331026528259, 'eval_runtime': 12.2176, 'eval_samples_per_second': 70.963, 'eval_steps_per_second': 8.922, 'epoch': 4.99, 'step': 541}, {'loss': 0.4869, 'learning_rate': 0.00013083398317987143, 'epoch': 6.0, 'step': 650}, {'eval_loss': 0.46434250473976135, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1712, 'eval_samples_per_second': 71.234, 'eval_steps_per_second': 8.956, 'epoch': 6.0, 'step': 650}, {'loss': 0.4808, 'learning_rate': 9.797335484632232e-05, 'epoch': 6.99, 'step': 758}, {'eval_loss': 0.4718196988105774, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.2187, 'eval_samples_per_second': 70.957, 'eval_steps_per_second': 8.921, 'epoch': 6.99, 'step': 758}, {'loss': 0.4599, 'learning_rate': 6.480846143561073e-05, 'epoch': 8.0, 'step': 867}, {'eval_loss': 0.47510308027267456, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.1575, 'eval_samples_per_second': 71.314, 'eval_steps_per_second': 8.966, 'epoch': 8.0, 'step': 867}, {'loss': 0.4464, 'learning_rate': 3.1947833102061625e-05, 'epoch': 9.0, 'step': 975}, {'eval_loss': 0.4790240526199341, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.2088, 'eval_samples_per_second': 71.014, 'eval_steps_per_second': 8.928, 'epoch': 9.0, 'step': 975}, {'loss': 0.4331, 'learning_rate': 0.0, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.4788965582847595, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.167, 'eval_samples_per_second': 71.259, 'eval_steps_per_second': 8.959, 'epoch': 9.97, 'step': 1080}, {'train_runtime': 1483.3505, 'train_samples_per_second': 23.38, 'train_steps_per_second': 0.728, 'total_flos': 8631598249589760.0, 'train_loss': 0.5208851284450955, 'epoch': 9.97, 'step': 1080}, {'eval_loss': 0.47510308027267456, 'eval_accuracy': 0.7889273356401384, 'eval_runtime': 12.1854, 'eval_samples_per_second': 71.151, 'eval_steps_per_second': 8.945, 'epoch': 9.97, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 4050947.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3468' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3468/4330 20:11 < 05:01, 2.86 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.616200</td>\n",
       "      <td>0.513943</td>\n",
       "      <td>0.748558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500300</td>\n",
       "      <td>0.496461</td>\n",
       "      <td>0.770473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.552235</td>\n",
       "      <td>0.779700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>0.698879</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>0.803209</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5522353053092957, 'eval_accuracy': 0.7797001153402537, 'eval_runtime': 12.0795, 'eval_samples_per_second': 71.775, 'eval_steps_per_second': 9.024, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 21:20:45,352] Trial 23 finished with values: [0.5522353053092957, 0.7797001153402537] and parameters: {'lr': 0.0003198497851818602, 'batch': 4, 'accum': 2, 'dropout_rate': 0.311842510839078, 'weight_decay': 0.00044495852902112657, 'warmup_pct': 0.09157933131279024, 'lora_rank': 4, 'lora_init_scale': 0.0349471319445897, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6162, 'learning_rate': 0.000174646856221621, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.5139427185058594, 'eval_accuracy': 0.748558246828143, 'eval_runtime': 13.8051, 'eval_samples_per_second': 62.803, 'eval_steps_per_second': 7.896, 'epoch': 1.0, 'step': 433}, {'loss': 0.5341, 'learning_rate': 0.00031315798871495105, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.4877302050590515, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.2522, 'eval_samples_per_second': 70.763, 'eval_steps_per_second': 8.896, 'epoch': 2.0, 'step': 867}, {'loss': 0.5003, 'learning_rate': 0.000274001936415334, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.4964606761932373, 'eval_accuracy': 0.7704728950403691, 'eval_runtime': 12.1313, 'eval_samples_per_second': 71.468, 'eval_steps_per_second': 8.985, 'epoch': 3.0, 'step': 1300}, {'loss': 0.4499, 'learning_rate': 0.00023475545443373173, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.5118134617805481, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.3054, 'eval_samples_per_second': 70.457, 'eval_steps_per_second': 8.858, 'epoch': 4.0, 'step': 1734}, {'loss': 0.3954, 'learning_rate': 0.00019559940213411469, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5522353053092957, 'eval_accuracy': 0.7797001153402537, 'eval_runtime': 12.097, 'eval_samples_per_second': 71.671, 'eval_steps_per_second': 9.011, 'epoch': 5.0, 'step': 2167}, {'loss': 0.3338, 'learning_rate': 0.00015635292015251238, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.6400648951530457, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1082, 'eval_samples_per_second': 71.604, 'eval_steps_per_second': 9.002, 'epoch': 6.0, 'step': 2601}, {'loss': 0.3036, 'learning_rate': 0.00011719686785289535, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.698879063129425, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.13, 'eval_samples_per_second': 71.476, 'eval_steps_per_second': 8.986, 'epoch': 7.0, 'step': 3034}, {'loss': 0.2598, 'learning_rate': 7.795038587129305e-05, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.8032094836235046, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.1548, 'eval_samples_per_second': 71.33, 'eval_steps_per_second': 8.968, 'epoch': 8.0, 'step': 3468}, {'train_runtime': 1211.5033, 'train_samples_per_second': 28.626, 'train_steps_per_second': 3.574, 'total_flos': 6859707933988224.0, 'train_loss': 0.42410826765542214, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.5522353053092957, 'eval_accuracy': 0.7797001153402537, 'eval_runtime': 12.0795, 'eval_samples_per_second': 71.775, 'eval_steps_per_second': 9.024, 'epoch': 8.0, 'step': 3468}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 5525507.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 18:01, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.722500</td>\n",
       "      <td>0.676876</td>\n",
       "      <td>0.626298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.636341</td>\n",
       "      <td>0.712803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.615132</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.644400</td>\n",
       "      <td>0.603991</td>\n",
       "      <td>0.717416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.630300</td>\n",
       "      <td>0.599034</td>\n",
       "      <td>0.722030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.633300</td>\n",
       "      <td>0.598271</td>\n",
       "      <td>0.720877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5990336537361145, 'eval_accuracy': 0.7220299884659747, 'eval_runtime': 12.0664, 'eval_samples_per_second': 71.852, 'eval_steps_per_second': 9.033, 'epoch': 9.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 21:39:40,985] Trial 24 finished with values: [0.5990336537361145, 0.7220299884659747] and parameters: {'lr': 2.6341069367238703e-05, 'batch': 8, 'accum': 4, 'dropout_rate': 0.8076835748405067, 'weight_decay': 0.0002452720685722943, 'warmup_pct': 0.022835850984960264, 'lora_rank': 8, 'lora_init_scale': 0.0002155081781119327, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.7225, 'learning_rate': 2.607283037164564e-05, 'epoch': 1.0, 'step': 108}, {'eval_loss': 0.6768763065338135, 'eval_accuracy': 0.6262975778546713, 'eval_runtime': 13.7895, 'eval_samples_per_second': 62.874, 'eval_steps_per_second': 7.905, 'epoch': 1.0, 'step': 108}, {'loss': 0.6935, 'learning_rate': 2.3149025319681262e-05, 'epoch': 2.0, 'step': 217}, {'eval_loss': 0.6531267166137695, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 12.2851, 'eval_samples_per_second': 70.573, 'eval_steps_per_second': 8.873, 'epoch': 2.0, 'step': 217}, {'loss': 0.6875, 'learning_rate': 2.0252044167276192e-05, 'epoch': 3.0, 'step': 325}, {'eval_loss': 0.6363407373428345, 'eval_accuracy': 0.71280276816609, 'eval_runtime': 12.1157, 'eval_samples_per_second': 71.56, 'eval_steps_per_second': 8.997, 'epoch': 3.0, 'step': 325}, {'loss': 0.6605, 'learning_rate': 1.7328239115311814e-05, 'epoch': 4.0, 'step': 434}, {'eval_loss': 0.6236370801925659, 'eval_accuracy': 0.7162629757785467, 'eval_runtime': 12.0816, 'eval_samples_per_second': 71.762, 'eval_steps_per_second': 9.022, 'epoch': 4.0, 'step': 434}, {'loss': 0.6638, 'learning_rate': 1.4431257962906744e-05, 'epoch': 5.0, 'step': 542}, {'eval_loss': 0.6151316165924072, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.0803, 'eval_samples_per_second': 71.77, 'eval_steps_per_second': 9.023, 'epoch': 5.0, 'step': 542}, {'loss': 0.6474, 'learning_rate': 1.1507452910942366e-05, 'epoch': 6.0, 'step': 651}, {'eval_loss': 0.6092596650123596, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.0708, 'eval_samples_per_second': 71.826, 'eval_steps_per_second': 9.03, 'epoch': 6.0, 'step': 651}, {'loss': 0.6444, 'learning_rate': 8.610471758537295e-06, 'epoch': 7.0, 'step': 759}, {'eval_loss': 0.6039906740188599, 'eval_accuracy': 0.7174163783160323, 'eval_runtime': 12.0771, 'eval_samples_per_second': 71.789, 'eval_steps_per_second': 9.025, 'epoch': 7.0, 'step': 759}, {'loss': 0.6331, 'learning_rate': 5.686666706572918e-06, 'epoch': 8.0, 'step': 868}, {'eval_loss': 0.6007812023162842, 'eval_accuracy': 0.7197231833910035, 'eval_runtime': 12.1081, 'eval_samples_per_second': 71.605, 'eval_steps_per_second': 9.002, 'epoch': 8.0, 'step': 868}, {'loss': 0.6303, 'learning_rate': 2.7896855541678464e-06, 'epoch': 9.0, 'step': 976}, {'eval_loss': 0.5990336537361145, 'eval_accuracy': 0.7220299884659747, 'eval_runtime': 12.0895, 'eval_samples_per_second': 71.715, 'eval_steps_per_second': 9.016, 'epoch': 9.0, 'step': 976}, {'loss': 0.6333, 'learning_rate': 0.0, 'epoch': 9.95, 'step': 1080}, {'eval_loss': 0.5982711315155029, 'eval_accuracy': 0.720876585928489, 'eval_runtime': 12.0814, 'eval_samples_per_second': 71.763, 'eval_steps_per_second': 9.022, 'epoch': 9.95, 'step': 1080}, {'train_runtime': 1082.4376, 'train_samples_per_second': 32.039, 'train_steps_per_second': 0.998, 'total_flos': 8546449068090864.0, 'train_loss': 0.6617395330358434, 'epoch': 9.95, 'step': 1080}, {'eval_loss': 0.5990336537361145, 'eval_accuracy': 0.7220299884659747, 'eval_runtime': 12.0664, 'eval_samples_per_second': 71.852, 'eval_steps_per_second': 9.033, 'epoch': 9.95, 'step': 1080}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 17813507.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 40:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.651746</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.582316</td>\n",
       "      <td>0.711649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.539301</td>\n",
       "      <td>0.730104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.531300</td>\n",
       "      <td>0.511163</td>\n",
       "      <td>0.758939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.521700</td>\n",
       "      <td>0.505596</td>\n",
       "      <td>0.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.506600</td>\n",
       "      <td>0.501802</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.499873</td>\n",
       "      <td>0.768166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.502653</td>\n",
       "      <td>0.770473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.490700</td>\n",
       "      <td>0.503599</td>\n",
       "      <td>0.768166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.485200</td>\n",
       "      <td>0.504707</td>\n",
       "      <td>0.771626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5047073364257812, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1542, 'eval_samples_per_second': 71.333, 'eval_steps_per_second': 8.968, 'epoch': 10.0}\n",
      "History:  [{'loss': 0.6825, 'learning_rate': 6.412546116415441e-06, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.6517459154129028, 'eval_accuracy': 0.7058823529411765, 'eval_runtime': 13.9151, 'eval_samples_per_second': 62.307, 'eval_steps_per_second': 7.833, 'epoch': 1.0, 'step': 867}, {'loss': 0.6213, 'learning_rate': 1.2825092232830882e-05, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.5823163390159607, 'eval_accuracy': 0.7116493656286044, 'eval_runtime': 12.3779, 'eval_samples_per_second': 70.044, 'eval_steps_per_second': 8.806, 'epoch': 2.0, 'step': 1734}, {'loss': 0.564, 'learning_rate': 1.9237638349246322e-05, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.539301335811615, 'eval_accuracy': 0.7301038062283737, 'eval_runtime': 12.2118, 'eval_samples_per_second': 70.997, 'eval_steps_per_second': 8.926, 'epoch': 3.0, 'step': 2601}, {'loss': 0.5313, 'learning_rate': 2.5650184465661763e-05, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.5111632347106934, 'eval_accuracy': 0.7589388696655133, 'eval_runtime': 12.2821, 'eval_samples_per_second': 70.591, 'eval_steps_per_second': 8.875, 'epoch': 4.0, 'step': 3468}, {'loss': 0.5217, 'learning_rate': 2.7297481706329664e-05, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5055961608886719, 'eval_accuracy': 0.7612456747404844, 'eval_runtime': 12.2069, 'eval_samples_per_second': 71.025, 'eval_steps_per_second': 8.929, 'epoch': 5.0, 'step': 4335}, {'loss': 0.5066, 'learning_rate': 2.183798536506373e-05, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.5018021464347839, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.2112, 'eval_samples_per_second': 71.001, 'eval_steps_per_second': 8.926, 'epoch': 6.0, 'step': 5202}, {'loss': 0.4986, 'learning_rate': 1.63784890237978e-05, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.49987301230430603, 'eval_accuracy': 0.7681660899653979, 'eval_runtime': 12.1828, 'eval_samples_per_second': 71.166, 'eval_steps_per_second': 8.947, 'epoch': 7.0, 'step': 6069}, {'loss': 0.4905, 'learning_rate': 1.0918992682531864e-05, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 0.5026528239250183, 'eval_accuracy': 0.7704728950403691, 'eval_runtime': 12.2054, 'eval_samples_per_second': 71.034, 'eval_steps_per_second': 8.93, 'epoch': 8.0, 'step': 6936}, {'loss': 0.4907, 'learning_rate': 5.459496341265932e-06, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 0.5035994648933411, 'eval_accuracy': 0.7681660899653979, 'eval_runtime': 12.2109, 'eval_samples_per_second': 71.002, 'eval_steps_per_second': 8.926, 'epoch': 9.0, 'step': 7803}, {'loss': 0.4852, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5047073364257812, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1798, 'eval_samples_per_second': 71.183, 'eval_steps_per_second': 8.949, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 2416.4562, 'train_samples_per_second': 14.352, 'train_steps_per_second': 3.588, 'total_flos': 8672001175968480.0, 'train_loss': 0.5392434442469543, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5047073364257812, 'eval_accuracy': 0.7716262975778547, 'eval_runtime': 12.1542, 'eval_samples_per_second': 71.333, 'eval_steps_per_second': 8.968, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 22:20:51,531] Trial 25 finished with values: [0.5047073364257812, 0.7716262975778547] and parameters: {'lr': 2.9488836639156127e-05, 'batch': 2, 'accum': 2, 'dropout_rate': 0.2066959589161308, 'weight_decay': 3.152012130710034e-05, 'warmup_pct': 0.2299453124987169, 'lora_rank': 32, 'lora_init_scale': 0.057397598959444816, 'lora_scaling_rank': 2}. \n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 7491587.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 1:03:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.686429</td>\n",
       "      <td>0.566321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.676100</td>\n",
       "      <td>0.659804</td>\n",
       "      <td>0.702422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.648300</td>\n",
       "      <td>0.626751</td>\n",
       "      <td>0.713956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.618900</td>\n",
       "      <td>0.595146</td>\n",
       "      <td>0.718570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>0.567764</td>\n",
       "      <td>0.718570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.562100</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.732411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.546700</td>\n",
       "      <td>0.532136</td>\n",
       "      <td>0.748558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>0.520105</td>\n",
       "      <td>0.755479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.528200</td>\n",
       "      <td>0.512365</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.520800</td>\n",
       "      <td>0.510080</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5100799202919006, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.119, 'eval_samples_per_second': 71.541, 'eval_steps_per_second': 8.994, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 23:24:56,875] Trial 26 finished with values: [0.5100799202919006, 0.7658592848904268] and parameters: {'lr': 1.2950330583920711e-05, 'batch': 1, 'accum': 4, 'dropout_rate': 0.34356337977240714, 'weight_decay': 1.014633767671602e-05, 'warmup_pct': 0.21045539786396336, 'lora_rank': 12, 'lora_init_scale': 0.00021823609442865146, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6958, 'learning_rate': 1.5384950145600515e-06, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.686428964138031, 'eval_accuracy': 0.566320645905421, 'eval_runtime': 13.8646, 'eval_samples_per_second': 62.533, 'eval_steps_per_second': 7.862, 'epoch': 1.0, 'step': 867}, {'loss': 0.6761, 'learning_rate': 3.076990029120103e-06, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.6598038077354431, 'eval_accuracy': 0.7024221453287197, 'eval_runtime': 12.1982, 'eval_samples_per_second': 71.076, 'eval_steps_per_second': 8.936, 'epoch': 2.0, 'step': 1734}, {'loss': 0.6483, 'learning_rate': 4.615485043680155e-06, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.626750648021698, 'eval_accuracy': 0.7139561707035755, 'eval_runtime': 12.3187, 'eval_samples_per_second': 70.381, 'eval_steps_per_second': 8.848, 'epoch': 3.0, 'step': 2601}, {'loss': 0.6189, 'learning_rate': 6.153980058240206e-06, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.5951456427574158, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.1795, 'eval_samples_per_second': 71.185, 'eval_steps_per_second': 8.949, 'epoch': 4.0, 'step': 3468}, {'loss': 0.5864, 'learning_rate': 7.692475072800259e-06, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5677642226219177, 'eval_accuracy': 0.7185697808535179, 'eval_runtime': 12.2632, 'eval_samples_per_second': 70.7, 'eval_steps_per_second': 8.888, 'epoch': 5.0, 'step': 4335}, {'loss': 0.5621, 'learning_rate': 9.23097008736031e-06, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.5477780103683472, 'eval_accuracy': 0.7324106113033448, 'eval_runtime': 12.1948, 'eval_samples_per_second': 71.096, 'eval_steps_per_second': 8.938, 'epoch': 6.0, 'step': 5202}, {'loss': 0.5467, 'learning_rate': 1.0769465101920361e-05, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.5321357846260071, 'eval_accuracy': 0.748558246828143, 'eval_runtime': 12.1326, 'eval_samples_per_second': 71.46, 'eval_steps_per_second': 8.984, 'epoch': 7.0, 'step': 6069}, {'loss': 0.5407, 'learning_rate': 1.2307960116480412e-05, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 0.5201047658920288, 'eval_accuracy': 0.7554786620530565, 'eval_runtime': 12.1666, 'eval_samples_per_second': 71.261, 'eval_steps_per_second': 8.959, 'epoch': 8.0, 'step': 6936}, {'loss': 0.5282, 'learning_rate': 8.18362727132599e-06, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 0.5123647451400757, 'eval_accuracy': 0.7647058823529411, 'eval_runtime': 12.1304, 'eval_samples_per_second': 71.473, 'eval_steps_per_second': 8.986, 'epoch': 9.0, 'step': 7803}, {'loss': 0.5208, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5100799202919006, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.1937, 'eval_samples_per_second': 71.102, 'eval_steps_per_second': 8.939, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 3792.025, 'train_samples_per_second': 9.146, 'train_steps_per_second': 2.286, 'total_flos': 8598976482106080.0, 'train_loss': 0.5924025239691465, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 0.5100799202919006, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.119, 'eval_samples_per_second': 71.541, 'eval_steps_per_second': 8.994, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 11915267.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8670' max='8670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8670/8670 1:05:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.605400</td>\n",
       "      <td>0.505748</td>\n",
       "      <td>0.754325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.561600</td>\n",
       "      <td>0.537317</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.526400</td>\n",
       "      <td>0.565148</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.505900</td>\n",
       "      <td>0.585615</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.568846</td>\n",
       "      <td>0.777393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.428900</td>\n",
       "      <td>0.992668</td>\n",
       "      <td>0.777393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.434100</td>\n",
       "      <td>0.924367</td>\n",
       "      <td>0.778547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.330800</td>\n",
       "      <td>1.173546</td>\n",
       "      <td>0.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>1.277030</td>\n",
       "      <td>0.785467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>1.514849</td>\n",
       "      <td>0.783160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2770304679870605, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.2436, 'eval_samples_per_second': 70.812, 'eval_steps_per_second': 8.903, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-17 00:30:52,410] Trial 27 finished with values: [1.2770304679870605, 0.7854671280276817] and parameters: {'lr': 0.0010324348512860502, 'batch': 1, 'accum': 4, 'dropout_rate': 0.25975794671734587, 'weight_decay': 2.5566039657984235e-05, 'warmup_pct': 0.16846290950398396, 'lora_rank': 16, 'lora_init_scale': 0.00042970877502568024, 'lora_scaling_rank': 6}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6054, 'learning_rate': 0.00015322167341064798, 'epoch': 1.0, 'step': 867}, {'eval_loss': 0.5057482719421387, 'eval_accuracy': 0.754325259515571, 'eval_runtime': 13.8605, 'eval_samples_per_second': 62.552, 'eval_steps_per_second': 7.864, 'epoch': 1.0, 'step': 867}, {'loss': 0.5616, 'learning_rate': 0.00030644334682129596, 'epoch': 2.0, 'step': 1734}, {'eval_loss': 0.5373168587684631, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.2161, 'eval_samples_per_second': 70.972, 'eval_steps_per_second': 8.923, 'epoch': 2.0, 'step': 1734}, {'loss': 0.5264, 'learning_rate': 0.00045966502023194394, 'epoch': 3.0, 'step': 2601}, {'eval_loss': 0.5651479959487915, 'eval_accuracy': 0.7577854671280276, 'eval_runtime': 12.1883, 'eval_samples_per_second': 71.134, 'eval_steps_per_second': 8.943, 'epoch': 3.0, 'step': 2601}, {'loss': 0.5059, 'learning_rate': 0.0006128866936425919, 'epoch': 4.0, 'step': 3468}, {'eval_loss': 0.5856146216392517, 'eval_accuracy': 0.7750865051903114, 'eval_runtime': 12.1821, 'eval_samples_per_second': 71.17, 'eval_steps_per_second': 8.948, 'epoch': 4.0, 'step': 3468}, {'loss': 0.4766, 'learning_rate': 0.0007661083670532398, 'epoch': 5.0, 'step': 4335}, {'eval_loss': 0.5688461661338806, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.2101, 'eval_samples_per_second': 71.007, 'eval_steps_per_second': 8.927, 'epoch': 5.0, 'step': 4335}, {'loss': 0.4289, 'learning_rate': 0.0009193300404638879, 'epoch': 6.0, 'step': 5202}, {'eval_loss': 0.9926683306694031, 'eval_accuracy': 0.7773933102652826, 'eval_runtime': 12.1826, 'eval_samples_per_second': 71.167, 'eval_steps_per_second': 8.947, 'epoch': 6.0, 'step': 5202}, {'loss': 0.4341, 'learning_rate': 0.0009495626054437823, 'epoch': 7.0, 'step': 6069}, {'eval_loss': 0.9243665337562561, 'eval_accuracy': 0.7785467128027682, 'eval_runtime': 12.2321, 'eval_samples_per_second': 70.879, 'eval_steps_per_second': 8.911, 'epoch': 7.0, 'step': 6069}, {'loss': 0.3308, 'learning_rate': 0.0006330417369625216, 'epoch': 8.0, 'step': 6936}, {'eval_loss': 1.1735460758209229, 'eval_accuracy': 0.7670126874279123, 'eval_runtime': 12.1814, 'eval_samples_per_second': 71.174, 'eval_steps_per_second': 8.948, 'epoch': 8.0, 'step': 6936}, {'loss': 0.223, 'learning_rate': 0.0003165208684812608, 'epoch': 9.0, 'step': 7803}, {'eval_loss': 1.2770304679870605, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.2124, 'eval_samples_per_second': 70.993, 'eval_steps_per_second': 8.925, 'epoch': 9.0, 'step': 7803}, {'loss': 0.1199, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 1.514849066734314, 'eval_accuracy': 0.7831603229527105, 'eval_runtime': 12.1658, 'eval_samples_per_second': 71.265, 'eval_steps_per_second': 8.96, 'epoch': 10.0, 'step': 8670}, {'train_runtime': 3902.1759, 'train_samples_per_second': 8.887, 'train_steps_per_second': 2.222, 'total_flos': 8630272779475680.0, 'train_loss': 0.42127388994861503, 'epoch': 10.0, 'step': 8670}, {'eval_loss': 1.2770304679870605, 'eval_accuracy': 0.7854671280276817, 'eval_runtime': 12.2436, 'eval_samples_per_second': 70.812, 'eval_steps_per_second': 8.903, 'epoch': 10.0, 'step': 8670}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 3559427.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3034' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3034/4330 43:23 < 18:32, 1.16 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.664900</td>\n",
       "      <td>0.585309</td>\n",
       "      <td>0.709343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.536500</td>\n",
       "      <td>0.502088</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.522103</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.406900</td>\n",
       "      <td>0.603018</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Stopping early at epoch 6.9988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 6.9988465974625145: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.493902325630188, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1225, 'eval_samples_per_second': 71.52, 'eval_steps_per_second': 8.992, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-17 01:15:10,354] Trial 28 finished with values: [0.493902325630188, 0.7843137254901961] and parameters: {'lr': 0.0006536702577510741, 'batch': 1, 'accum': 8, 'dropout_rate': 0.6379424072856527, 'weight_decay': 0.00017102693572973834, 'warmup_pct': 0.10222157877969572, 'lora_rank': 4, 'lora_init_scale': 0.00029526840889784614, 'lora_scaling_rank': 1}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6649, 'learning_rate': 7.984181145450355e-05, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.5853091478347778, 'eval_accuracy': 0.7093425605536332, 'eval_runtime': 13.8422, 'eval_samples_per_second': 62.635, 'eval_steps_per_second': 7.874, 'epoch': 1.0, 'step': 433}, {'loss': 0.5711, 'learning_rate': 0.00015986801508326693, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.500209391117096, 'eval_accuracy': 0.76239907727797, 'eval_runtime': 12.359, 'eval_samples_per_second': 70.151, 'eval_steps_per_second': 8.819, 'epoch': 2.0, 'step': 867}, {'loss': 0.5365, 'learning_rate': 0.00023970982653777047, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.5020877718925476, 'eval_accuracy': 0.7658592848904268, 'eval_runtime': 12.2056, 'eval_samples_per_second': 71.033, 'eval_steps_per_second': 8.93, 'epoch': 3.0, 'step': 1300}, {'loss': 0.5074, 'learning_rate': 0.00031973603016653387, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.493902325630188, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1721, 'eval_samples_per_second': 71.229, 'eval_steps_per_second': 8.955, 'epoch': 4.0, 'step': 1734}, {'loss': 0.4947, 'learning_rate': 0.0003995778416210374, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.5221025347709656, 'eval_accuracy': 0.7647058823529411, 'eval_runtime': 12.151, 'eval_samples_per_second': 71.352, 'eval_steps_per_second': 8.97, 'epoch': 5.0, 'step': 2167}, {'loss': 0.4447, 'learning_rate': 0.0004796040452498008, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.6286039352416992, 'eval_accuracy': 0.7681660899653979, 'eval_runtime': 12.1579, 'eval_samples_per_second': 71.312, 'eval_steps_per_second': 8.965, 'epoch': 6.0, 'step': 2601}, {'loss': 0.4069, 'learning_rate': 0.0005594458567043044, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.6030178666114807, 'eval_accuracy': 0.7647058823529411, 'eval_runtime': 12.1913, 'eval_samples_per_second': 71.117, 'eval_steps_per_second': 8.941, 'epoch': 7.0, 'step': 3034}, {'train_runtime': 2604.4765, 'train_samples_per_second': 13.316, 'train_steps_per_second': 1.663, 'total_flos': 5999810285777616.0, 'train_loss': 0.518018447181938, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.493902325630188, 'eval_accuracy': 0.7843137254901961, 'eval_runtime': 12.1225, 'eval_samples_per_second': 71.52, 'eval_steps_per_second': 8.992, 'epoch': 7.0, 'step': 3034}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 17813507.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 1:04:31, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.692594</td>\n",
       "      <td>0.502884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.672600</td>\n",
       "      <td>0.659977</td>\n",
       "      <td>0.700115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.632400</td>\n",
       "      <td>0.617555</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.593200</td>\n",
       "      <td>0.579617</td>\n",
       "      <td>0.715110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.562100</td>\n",
       "      <td>0.548970</td>\n",
       "      <td>0.733564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>0.538559</td>\n",
       "      <td>0.741638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Saved improved model to ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n",
      "Loaded best model from ./model_output/finetuned_model_D_and_P_balance_dataset.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5385587215423584, 'eval_accuracy': 0.7416378316032295, 'eval_runtime': 12.1546, 'eval_samples_per_second': 71.331, 'eval_steps_per_second': 8.968, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-17 02:20:35,965] Trial 29 finished with values: [0.5385587215423584, 0.7416378316032295] and parameters: {'lr': 1.248794881486996e-05, 'batch': 1, 'accum': 8, 'dropout_rate': 0.24568882538347997, 'weight_decay': 0.00044108723597006456, 'warmup_pct': 0.1840727638819394, 'lora_rank': 32, 'lora_init_scale': 0.004927830932678862, 'lora_scaling_rank': 2}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6974, 'learning_rate': 8.47137997311404e-07, 'epoch': 1.0, 'step': 433}, {'eval_loss': 0.6925938725471497, 'eval_accuracy': 0.5028835063437139, 'eval_runtime': 13.8939, 'eval_samples_per_second': 62.402, 'eval_steps_per_second': 7.845, 'epoch': 1.0, 'step': 433}, {'loss': 0.6858, 'learning_rate': 1.6962324334156755e-06, 'epoch': 2.0, 'step': 867}, {'eval_loss': 0.6792370080947876, 'eval_accuracy': 0.6332179930795848, 'eval_runtime': 12.2925, 'eval_samples_per_second': 70.531, 'eval_steps_per_second': 8.867, 'epoch': 2.0, 'step': 867}, {'loss': 0.6726, 'learning_rate': 2.5433704307270797e-06, 'epoch': 3.0, 'step': 1300}, {'eval_loss': 0.6599773168563843, 'eval_accuracy': 0.7001153402537486, 'eval_runtime': 12.1872, 'eval_samples_per_second': 71.14, 'eval_steps_per_second': 8.944, 'epoch': 3.0, 'step': 1300}, {'loss': 0.6539, 'learning_rate': 3.392464866831351e-06, 'epoch': 4.0, 'step': 1734}, {'eval_loss': 0.6389437317848206, 'eval_accuracy': 0.7231833910034602, 'eval_runtime': 12.2264, 'eval_samples_per_second': 70.912, 'eval_steps_per_second': 8.915, 'epoch': 4.0, 'step': 1734}, {'loss': 0.6324, 'learning_rate': 4.239602864142755e-06, 'epoch': 5.0, 'step': 2167}, {'eval_loss': 0.6175552606582642, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.2165, 'eval_samples_per_second': 70.97, 'eval_steps_per_second': 8.922, 'epoch': 5.0, 'step': 2167}, {'loss': 0.6101, 'learning_rate': 5.088697300247026e-06, 'epoch': 6.0, 'step': 2601}, {'eval_loss': 0.5979918241500854, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.203, 'eval_samples_per_second': 71.048, 'eval_steps_per_second': 8.932, 'epoch': 6.0, 'step': 2601}, {'loss': 0.5932, 'learning_rate': 5.935835297558431e-06, 'epoch': 7.0, 'step': 3034}, {'eval_loss': 0.5796173810958862, 'eval_accuracy': 0.7151095732410612, 'eval_runtime': 12.2097, 'eval_samples_per_second': 71.009, 'eval_steps_per_second': 8.927, 'epoch': 7.0, 'step': 3034}, {'loss': 0.578, 'learning_rate': 6.784929733662702e-06, 'epoch': 8.0, 'step': 3468}, {'eval_loss': 0.5640504360198975, 'eval_accuracy': 0.7243367935409458, 'eval_runtime': 12.1916, 'eval_samples_per_second': 71.115, 'eval_steps_per_second': 8.941, 'epoch': 8.0, 'step': 3468}, {'loss': 0.5621, 'learning_rate': 7.632067730974105e-06, 'epoch': 9.0, 'step': 3901}, {'eval_loss': 0.548969566822052, 'eval_accuracy': 0.7335640138408305, 'eval_runtime': 12.2063, 'eval_samples_per_second': 71.029, 'eval_steps_per_second': 8.93, 'epoch': 9.0, 'step': 3901}, {'loss': 0.5515, 'learning_rate': 8.471379973114041e-06, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5385587215423584, 'eval_accuracy': 0.7416378316032295, 'eval_runtime': 12.1803, 'eval_samples_per_second': 71.18, 'eval_steps_per_second': 8.949, 'epoch': 9.99, 'step': 4330}, {'train_runtime': 3871.9168, 'train_samples_per_second': 8.957, 'train_steps_per_second': 1.118, 'total_flos': 8661998867807040.0, 'train_loss': 0.6237618743685046, 'epoch': 9.99, 'step': 4330}, {'eval_loss': 0.5385587215423584, 'eval_accuracy': 0.7416378316032295, 'eval_runtime': 12.1546, 'eval_samples_per_second': 71.331, 'eval_steps_per_second': 8.968, 'epoch': 9.99, 'step': 4330}]\n",
      "Loss: 0.46962377429008484, Accuracy: 0.7773933102652826\n",
      "Loss: 0.9660893082618713, Accuracy: 0.7912341407151096\n",
      "Loss: 1.6030584573745728, Accuracy: 0.8073817762399077\n",
      "Loss: 0.5600172281265259, Accuracy: 0.790080738177624\n",
      "Loss: 0.472126305103302, Accuracy: 0.7866205305651672\n",
      "Loss: 0.47510308027267456, Accuracy: 0.7889273356401384\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Set the seed for reproducibility in each trial\n",
    "    # seed = trial.suggest_int('seed', 0, 10000)\n",
    "    # set_seeds(seed)\n",
    "    \n",
    "    # Hyperparameters to be optimized\n",
    "    # Updated to use suggest_float with log=True for loguniform distribution\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    batch = trial.suggest_categorical('batch', [1, 2, 4, 8])\n",
    "    accum = trial.suggest_categorical('accum', [2, 4, 8])\n",
    "    # Updated to use suggest_float for uniform distribution\n",
    "    dropout = trial.suggest_float('dropout_rate', 0.1, 0.9)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    warmup_pct = trial.suggest_float(\"warmup_pct\", 0.01, 0.3)  # Warmup percentage between 1% and 30%\n",
    "    lora_rank = trial.suggest_int('lora_rank', 4, 32, step=4)\n",
    "    lora_init_scale = trial.suggest_float('lora_init_scale', 1e-4, 1e-1, log=True)\n",
    "    lora_scaling_rank = trial.suggest_int('lora_scaling_rank', 1, 8)\n",
    "\n",
    "\n",
    "    # Training and evaluation\n",
    "    tokenizer, model, history = train_per_protein(\n",
    "        train_dataset=train_set, \n",
    "        valid_dataset=valid_set, \n",
    "        num_labels=2, \n",
    "        batch=batch, \n",
    "        accum=accum, \n",
    "        epochs=10,  # Fewer epochs for the trial runs\n",
    "        lr=lr,\n",
    "        dropout=dropout,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_pct=warmup_pct,\n",
    "        lora_rank=lora_rank,\n",
    "        lora_init_scale=lora_init_scale,\n",
    "        lora_scaling_rank=lora_scaling_rank,\n",
    "        # seed=seed\n",
    "    )\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    # torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"History: \", history)\n",
    "    \n",
    "    # Extract the last validation accuracy from the history\n",
    "    val_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry][-1]\n",
    "    val_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry][-1]\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "directions=['minimize', 'maximize']  # Set the direction to maximize the validation accuracy, can also be 'minimize'\n",
    "study = optuna.create_study(directions=directions,\n",
    "                            storage=\"sqlite:///finetuned_model_D_and_P_balance_dataset.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"finetuned_model_D_and_P_balance_dataset\")\n",
    "study.optimize(objective, n_trials=30)  # Adjust the number of trials based on your computational resources\n",
    "\n",
    "# Analyzing results\n",
    "pareto_front = study.best_trials  # Get the Pareto front (best non-dominated solutions)\n",
    "for trial in pareto_front:\n",
    "    print(f\"Loss: {trial.values[0]}, Accuracy: {trial.values[1]}\")  # Note the negation of accuracy\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# print(\"  Value: \", study.best_trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in study.best_trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model, history = train_per_protein(train_set, valid_set, num_labels=2, batch=8, accum=2, epochs=20, seed=42, lr=0.00010175943017273118, dropout=0.4882243131202929, weight_decay=0.00014993579804161342, warmup_pct=0.18496515086758566, lora_rank=24, lora_init_scale=0.01370043600756871, lora_scaling_rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a28d3c1-8e24-4437-a1d9-dda9cefccfd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:37.168731Z",
     "iopub.status.busy": "2024-04-05T14:04:37.168220Z",
     "iopub.status.idle": "2024-04-05T14:04:38.081706Z",
     "shell.execute_reply": "2024-04-05T14:04:38.080275Z",
     "shell.execute_reply.started": "2024-04-05T14:04:37.168675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Truncate the longer list to the size of the shorter one\n",
    "min_length = min(len(loss), len(val_loss))\n",
    "loss = loss[:min_length]\n",
    "val_loss = val_loss[:min_length]\n",
    "\n",
    "# Get spearman (for regression) or accuracy value (for classification)\n",
    "if [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x] != []:\n",
    "    metric = [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x]\n",
    "else:\n",
    "    metric = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n",
    "\n",
    "epochs = [x['epoch'] for x in history if 'loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "line1 = ax1.plot(epochs, loss, label='train_loss')\n",
    "line2 = ax1.plot(epochs, val_loss, label='validation_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "#line3 = ax2.plot(epochs, metric, color='red', label='validation_metric')\n",
    "ax2.set_ylabel('Metric')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Add grid lines\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 \n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History for fine-tuning\")\n",
    "plt.savefig(f\"../Plots/Without_3rdline_Training_History_new.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccb1bbda-d70e-4b4c-a8d4-24600495171a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:38.083526Z",
     "iopub.status.busy": "2024-04-05T14:04:38.083162Z",
     "iopub.status.idle": "2024-04-05T14:04:38.092729Z",
     "shell.execute_reply": "2024-04-05T14:04:38.091278Z",
     "shell.execute_reply.started": "2024-04-05T14:04:38.083490Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "def load_model(filepath, num_labels=2):\n",
    "# Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "    # load a new model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=0.4882243131202929, lora_rank=24, lora_init_scale=0.01370043600756871, lora_scaling_rank=5)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c97fa52-3aea-42e8-b72f-c4bb84808576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:05:24.020589Z",
     "iopub.status.busy": "2024-04-05T14:05:24.019788Z",
     "iopub.status.idle": "2024-04-05T14:08:10.428922Z",
     "shell.execute_reply": "2024-04-05T14:08:10.426805Z",
     "shell.execute_reply.started": "2024-04-05T14:05:24.020524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193474\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 15355906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_D_and_P_balance_dataset.pth\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2c20e75-5f40-4ca1-9579-5df49b738fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:10.432313Z",
     "iopub.status.busy": "2024-04-05T14:08:10.431835Z",
     "iopub.status.idle": "2024-04-05T14:08:19.838631Z",
     "shell.execute_reply": "2024-04-05T14:08:19.836988Z",
     "shell.execute_reply.started": "2024-04-05T14:08:10.432274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have identical weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50b8a403-e7c5-4912-9c7a-f404c060c32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.841225Z",
     "iopub.status.busy": "2024-04-05T14:08:19.840752Z",
     "iopub.status.idle": "2024-04-05T14:08:19.864579Z",
     "shell.execute_reply": "2024-04-05T14:08:19.862993Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.841173Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|P20963|CD3Z_HUMAN%126%142</td>\n",
       "      <td>IGMKGERRRGKGHDGLYQGLSTATKDTYDALHM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|P00533|EGFR_HUMAN%1076%1092</td>\n",
       "      <td>ALTEDSIDDTFLPVPEYINQSVPKRPAGSVQNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|P08581|MET_HUMAN%1349%1365</td>\n",
       "      <td>YVHVNATYVNVKCVAPYPSLLSSEDNADDEVDT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P09619|PGFRB_HUMAN%841%857</td>\n",
       "      <td>KICDFGLARDIMRDSNYISKGSTFLPLKWMAPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q13480|GAB1_HUMAN%573%589</td>\n",
       "      <td>VHSTTSSSDSHDSEENYVPMNPNLSSEDPNLFG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0    sp|P20963|CD3Z_HUMAN%126%142  IGMKGERRRGKGHDGLYQGLSTATKDTYDALHM      1\n",
       "1  sp|P00533|EGFR_HUMAN%1076%1092  ALTEDSIDDTFLPVPEYINQSVPKRPAGSVQNP      1\n",
       "2   sp|P08581|MET_HUMAN%1349%1365  YVHVNATYVNVKCVAPYPSLLSSEDNADDEVDT      1\n",
       "3   sp|P09619|PGFRB_HUMAN%841%857  KICDFGLARDIMRDSNYISKGSTFLPLKWMAPE      1\n",
       "4    sp|Q13480|GAB1_HUMAN%573%589  VHSTTSSSDSHDSEENYVPMNPNLSSEDPNLFG      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../input_datasets/test_Pos_Neg_Y.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "    \n",
    "local_fasta_path = '../input_datasets/test_Pos_Neg_Y.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2d18716-fd26-49fe-9ba4-b84c936a364c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.867076Z",
     "iopub.status.busy": "2024-04-05T14:08:19.866598Z",
     "iopub.status.idle": "2024-04-05T14:08:19.887853Z",
     "shell.execute_reply": "2024-04-05T14:08:19.886215Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.867024Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sequence  label\n",
      "0  IGMKGERRRGKGHDGLYQGLSTATKDTYDALHM      1\n",
      "1  ALTEDSIDDTFLPVPEYINQSVPKRPAGSVQNP      1\n",
      "2  YVHVNATYVNVKCVAPYPSLLSSEDNADDEVDT      1\n",
      "3  KICDFGLARDIMRDSNYISKGSTFLPLKWMAPE      1\n",
      "4  VHSTTSSSDSHDSEENYVPMNPNLSSEDPNLFG      1\n"
     ]
    }
   ],
   "source": [
    "my_test=df[[\"sequence\", \"label\"]]\n",
    "\n",
    "print(my_test.head(5))\n",
    "\n",
    "'''\n",
    "my_test[\"sequence\"]=my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "my_test['sequence']=my_test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "'''\n",
    "\n",
    "#Using .loc ensures that you are modifying the original DataFrame rather than a view of it, which helps avoid the SettingWithCopyWarning.\n",
    "# Replace characters in the \"sequence\" column\n",
    "my_test.loc[:, \"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Convert each sequence to a space-separated string\n",
    "my_test.loc[:, 'sequence'] = my_test.apply(lambda row: \" \".join(row[\"sequence\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eee8fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = sequence.split()\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "my_test['middle_char'] = my_test['sequence'].apply(get_middle_char)\n",
    "\n",
    "# Split the DataFrame\n",
    "my_test_S = my_test[my_test['middle_char'] == 'S'].drop(columns=['middle_char'])\n",
    "my_test_T = my_test[my_test['middle_char'] == 'T'].drop(columns=['middle_char'])\n",
    "my_test_Y = my_test[my_test['middle_char'] == 'Y'].drop(columns=['middle_char'])\n",
    "my_test_ST = my_test[my_test['middle_char'].isin(['S', 'T'])].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcd9ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0dff151-a667-4717-af18-401818bc4c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.889951Z",
     "iopub.status.busy": "2024-04-05T14:08:19.889601Z",
     "iopub.status.idle": "2024-04-05T14:08:22.641629Z",
     "shell.execute_reply": "2024-04-05T14:08:22.639919Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.889916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.600012 |      0.846154 |          0.75 |        0.8 |  0.849359 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[22  4]\n",
      " [ 6 18]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ce2f51a-887c-4684-82b9-22ea5fffd334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:22.647264Z",
     "iopub.status.busy": "2024-04-05T14:08:22.646121Z",
     "iopub.status.idle": "2024-04-05T14:08:23.557189Z",
     "shell.execute_reply": "2024-04-05T14:08:23.555594Z",
     "shell.execute_reply.started": "2024-04-05T14:08:22.647207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['0', '1']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"../Plots/Confusion_matrix_for_dephos_new.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07603226",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5e0d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 28/28 [00:04<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------------+------------+-----------+\n",
      "|     MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+=========+===============+===============+============+===========+\n",
      "| 0.61005 |      0.794643 |      0.815315 |   0.804933 |  0.884512 |\n",
      "+---------+---------------+---------------+------------+-----------+\n",
      "[[178  46]\n",
      " [ 41 181]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

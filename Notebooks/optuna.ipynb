{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2319a5",
   "metadata": {},
   "source": [
    "This notebook will implement changing lora settings and separate dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a377270-2995-4da1-a673-5369769a6279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:52:49.264011Z",
     "iopub.status.busy": "2024-04-05T12:52:49.263502Z",
     "iopub.status.idle": "2024-04-05T12:53:29.491461Z",
     "shell.execute_reply": "2024-04-05T12:53:29.490156Z",
     "shell.execute_reply.started": "2024-04-05T12:52:49.263956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import transformers, datasets\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
    "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install umap-learn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0148ff8f-80eb-4bbd-aac7-fe1f371da27a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.508233Z",
     "iopub.status.busy": "2024-04-05T12:53:29.507801Z",
     "iopub.status.idle": "2024-04-05T12:53:29.536614Z",
     "shell.execute_reply": "2024-04-05T12:53:29.514877Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.508197Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.1.1+cu121\n",
      "Cuda version:  12.1\n",
      "Numpy version:  1.26.4\n",
      "Pandas version:  2.2.2\n",
      "Transformers version:  4.35.2\n",
      "Datasets version:  2.19.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \",torch.__version__)\n",
    "print(\"Cuda version: \",torch.version.cuda)\n",
    "print(\"Numpy version: \",np.__version__)\n",
    "print(\"Pandas version: \",pd.__version__)\n",
    "print(\"Transformers version: \",transformers.__version__)\n",
    "print(\"Datasets version: \",datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96bd9396-a81c-4d87-a722-0d2020627dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.538488Z",
     "iopub.status.busy": "2024-04-05T12:53:29.538089Z",
     "iopub.status.idle": "2024-04-05T12:53:29.768968Z",
     "shell.execute_reply": "2024-04-05T12:53:29.767620Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.538452Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|P24928|RPB1_HUMAN%1775%1791</td>\n",
       "      <td>NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%58%74</td>\n",
       "      <td>SGMGGITAVTVNQSLLSPLVLEVDPNIQAVRTQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q14832|GRM3_HUMAN%829%845</td>\n",
       "      <td>QPQKNVVTHRLHLNRFSVSGTGTTYSQSSASTY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P01106|MYC_HUMAN%46%62</td>\n",
       "      <td>SEDIWKKFELLPTPPLSPSRRSGLCSPSYVAVT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2792%2808</td>\n",
       "      <td>TREGDSMALYNRTRRISQTSQVSVDAAHGYSPR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0  sp|P24928|RPB1_HUMAN%1775%1791  NYTPTSPNYSPTSPSYSPTSPSYSPTSPSYSPS      1\n",
       "1      sp|P05787|K2C8_HUMAN%58%74  SGMGGITAVTVNQSLLSPLVLEVDPNIQAVRTQ      1\n",
       "2    sp|Q14832|GRM3_HUMAN%829%845  QPQKNVVTHRLHLNRFSVSGTGTTYSQSSASTY      1\n",
       "3       sp|P01106|MYC_HUMAN%46%62  SEDIWKKFELLPTPPLSPSRRSGLCSPSYVAVT      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2792%2808  TREGDSMALYNRTRRISQTSQVSVDAAHGYSPR      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/train_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/train_Pos_Neg_Y.fasta'\n",
    "\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76760f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "(1584, 2)\n",
      "\n",
      "Validation Set:\n",
      "(396, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "my_train, my_valid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "my_train=my_train[[\"sequence\", \"label\"]]\n",
    "my_valid=my_valid[[\"sequence\",\"label\"]]\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the training set\n",
    "print(\"Training Set:\")\n",
    "print(my_train.shape)\n",
    "\n",
    "# Print the first 5 rows of the validation set\n",
    "print(\"\\nValidation Set:\")\n",
    "print(my_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a424877b-787c-44fe-bf87-33346ffd3be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.789138Z",
     "iopub.status.busy": "2024-04-05T12:53:29.788675Z",
     "iopub.status.idle": "2024-04-05T12:53:29.816779Z",
     "shell.execute_reply": "2024-04-05T12:53:29.815341Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.789094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifies an existing transformer and introduce the LoRA layers\n",
    "\n",
    "class LoRAConfig:\n",
    "    def __init__(self, lora_rank=8, lora_init_scale=0.01, lora_scaling_rank=2):\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_init_scale = lora_init_scale\n",
    "        self.lora_modules = \".*SelfAttention|.*EncDecAttention\"\n",
    "        self.lora_layers = \"q|k|v|o\"\n",
    "        self.trainable_param_names = \".*layer_norm.*|.*lora_[ab].*\"\n",
    "        self.lora_scaling_rank = lora_scaling_rank\n",
    "        # lora_modules and lora_layers are specified with regular expressions\n",
    "        # see https://www.w3schools.com/python/python_regex.asp for reference\n",
    "        \n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, scaling_rank, init_scale):\n",
    "        super().__init__()\n",
    "        self.in_features = linear_layer.in_features\n",
    "        self.out_features = linear_layer.out_features\n",
    "        self.rank = rank\n",
    "        self.scaling_rank = scaling_rank\n",
    "        self.weight = linear_layer.weight\n",
    "        self.bias = linear_layer.bias\n",
    "        if self.rank > 0:\n",
    "            self.lora_a = nn.Parameter(torch.randn(rank, linear_layer.in_features) * init_scale)\n",
    "            if init_scale < 0:\n",
    "                self.lora_b = nn.Parameter(torch.randn(linear_layer.out_features, rank) * init_scale)\n",
    "            else:\n",
    "                self.lora_b = nn.Parameter(torch.zeros(linear_layer.out_features, rank))\n",
    "        if self.scaling_rank:\n",
    "            self.multi_lora_a = nn.Parameter(\n",
    "                torch.ones(self.scaling_rank, linear_layer.in_features)\n",
    "                + torch.randn(self.scaling_rank, linear_layer.in_features) * init_scale\n",
    "            )\n",
    "            if init_scale < 0:\n",
    "                self.multi_lora_b = nn.Parameter(\n",
    "                    torch.ones(linear_layer.out_features, self.scaling_rank)\n",
    "                    + torch.randn(linear_layer.out_features, self.scaling_rank) * init_scale\n",
    "                )\n",
    "            else:\n",
    "                self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, self.scaling_rank))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.scaling_rank == 1 and self.rank == 0:\n",
    "            # parsimonious implementation for ia3 and lora scaling\n",
    "            if self.multi_lora_a.requires_grad:\n",
    "                hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n",
    "            else:\n",
    "                hidden = F.linear(input, self.weight, self.bias)\n",
    "            if self.multi_lora_b.requires_grad:\n",
    "                hidden = hidden * self.multi_lora_b.flatten()\n",
    "            return hidden\n",
    "        else:\n",
    "            # general implementation for lora (adding and scaling)\n",
    "            weight = self.weight\n",
    "            if self.scaling_rank:\n",
    "                weight = weight * torch.matmul(self.multi_lora_b, self.multi_lora_a) / self.scaling_rank\n",
    "            if self.rank:\n",
    "                weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n",
    "            return F.linear(input, weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, rank={}, scaling_rank={}\".format(\n",
    "            self.in_features, self.out_features, self.bias is not None, self.rank, self.scaling_rank\n",
    "        )\n",
    "\n",
    "\n",
    "def modify_with_lora(transformer, config):\n",
    "    for m_name, module in dict(transformer.named_modules()).items():\n",
    "        if re.fullmatch(config.lora_modules, m_name):\n",
    "            for c_name, layer in dict(module.named_children()).items():\n",
    "                if re.fullmatch(config.lora_layers, c_name):\n",
    "                    assert isinstance(\n",
    "                        layer, nn.Linear\n",
    "                    ), f\"LoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        c_name,\n",
    "                        LoRALinear(layer, config.lora_rank, config.lora_scaling_rank, config.lora_init_scale),\n",
    "                    )\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e79b323-4677-4723-a5fd-a60dc13a3b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.819433Z",
     "iopub.status.busy": "2024-04-05T12:53:29.818965Z",
     "iopub.status.idle": "2024-04-05T12:53:29.845976Z",
     "shell.execute_reply": "2024-04-05T12:53:29.844438Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.819335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassConfig:\n",
    "    def __init__(self, dropout=0.7, num_labels=2):\n",
    "        self.dropout_rate = dropout\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "class T5EncoderClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, class_config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n",
    "        \n",
    "        # Trainable emphasis factor\n",
    "        self.emphasis_factor = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        seq_length = hidden_states.size(1)\n",
    "        middle_idx = seq_length // 2\n",
    "        middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "        # Apply trainable emphasis factor\n",
    "        emphasized_middle_embedding = middle_embedding * self.emphasis_factor\n",
    "\n",
    "        # Combine with the average embedding\n",
    "        average_embedding = torch.mean(hidden_states, dim=1)\n",
    "        combined_embedding = emphasized_middle_embedding + average_embedding\n",
    "\n",
    "        x = self.dropout(combined_embedding)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.out_proj(x)\n",
    "        return logits\n",
    "\n",
    "    # def forward(self, hidden_states):\n",
    "\n",
    "    #     hidden_states =  torch.mean(hidden_states,dim=1)  # avg embedding\n",
    "\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.dense(hidden_states)\n",
    "    #     hidden_states = torch.tanh(hidden_states)\n",
    "    #     hidden_states = self.dropout(hidden_states)\n",
    "    #     hidden_states = self.out_proj(hidden_states)\n",
    "    #     return hidden_states\n",
    "    \n",
    "    # def forward(self, hidden_states):\n",
    "    #     # Original sequence length and middle index\n",
    "    #     seq_length = hidden_states.size(1)\n",
    "    #     middle_idx = seq_length // 2\n",
    "\n",
    "    #     # Extract the middle embedding vector\n",
    "    #     middle_embedding = hidden_states[:, middle_idx, :]\n",
    "\n",
    "    #     # Amplify the influence of the middle embedding\n",
    "    #     amplified_middle_embedding = middle_embedding * 2\n",
    "\n",
    "    #     # Combine with average to retain context\n",
    "    #     average_embedding = torch.mean(hidden_states, dim=1)\n",
    "    #     combined_embedding = 0.5 * amplified_middle_embedding + 0.5 * average_embedding\n",
    "\n",
    "    #     # Classification layers\n",
    "    #     x = self.dropout(combined_embedding)\n",
    "    #     x = self.dense(x)\n",
    "    #     x = torch.tanh(x)\n",
    "    #     x = self.dropout(x)\n",
    "    #     logits = self.out_proj(x)\n",
    "    #     return logits\n",
    "\n",
    "\n",
    "class T5EncoderForSimpleSequenceClassification(T5PreTrainedModel):\n",
    "\n",
    "    def __init__(self, config: T5Config, class_config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = class_config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n",
    "\n",
    "        encoder_config = copy.deepcopy(config)\n",
    "        encoder_config.use_cache = False\n",
    "        encoder_config.is_encoder_decoder = False\n",
    "        self.encoder = T5Stack(encoder_config, self.shared)\n",
    "\n",
    "        self.dropout = nn.Dropout(class_config.dropout_rate) \n",
    "        self.classifier = T5EncoderClassificationHead(config, class_config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "\n",
    "    def parallelize(self, device_map=None):\n",
    "        self.device_map = (\n",
    "            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
    "            if device_map is None\n",
    "            else device_map\n",
    "        )\n",
    "        assert_device_map(self.device_map, len(self.encoder.block))\n",
    "        self.encoder.parallelize(self.device_map)\n",
    "        self.classifier = self.classifier.to(self.encoder.first_device)\n",
    "        self.model_parallel = True\n",
    "\n",
    "    def deparallelize(self):\n",
    "        self.encoder.deparallelize()\n",
    "        self.encoder = self.encoder.to(\"cpu\")\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.shared\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.shared = new_embeddings\n",
    "        self.encoder.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "        logits = self.classifier(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71394626-6f8b-4ca5-80f3-c697e4320bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.848217Z",
     "iopub.status.busy": "2024-04-05T12:53:29.847782Z",
     "iopub.status.idle": "2024-04-05T12:53:29.859841Z",
     "shell.execute_reply": "2024-04-05T12:53:29.858398Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.848182Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PT5_classification_model(num_labels, dropout, lora_rank, lora_init_scale, lora_scaling_rank):\n",
    "    # Load PT5 and tokenizer\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\") \n",
    "    \n",
    "    # Create new Classifier model with PT5 dimensions\n",
    "    class_config=ClassConfig(num_labels=num_labels, dropout=dropout)\n",
    "    class_model=T5EncoderForSimpleSequenceClassification(model.config,class_config)\n",
    "    \n",
    "    # Set encoder and embedding weights to checkpoint weights\n",
    "    class_model.shared=model.shared\n",
    "    class_model.encoder=model.encoder    \n",
    "    \n",
    "    # Delete the checkpoint model\n",
    "    model=class_model\n",
    "    del class_model\n",
    "    \n",
    "    # Print number of trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_Classfier\\nTrainable Parameter: \"+ str(params))    \n",
    " \n",
    "    # Add model modification lora\n",
    "    config = LoRAConfig(lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "    \n",
    "    # Add LoRA layers\n",
    "    model = modify_with_lora(model, config)\n",
    "    \n",
    "    # Freeze Embeddings and Encoder (except LoRA)\n",
    "    for (param_name, param) in model.shared.named_parameters():\n",
    "                param.requires_grad = False\n",
    "    for (param_name, param) in model.encoder.named_parameters():\n",
    "                param.requires_grad = False       \n",
    "\n",
    "    for (param_name, param) in model.named_parameters():\n",
    "            if re.fullmatch(config.trainable_param_names, param_name):\n",
    "                param.requires_grad = True\n",
    "\n",
    "    # Print trainable Parameter          \n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"ProtT5_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4d56b2-c9ca-460d-b977-a1e4ae1e9568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.864172Z",
     "iopub.status.busy": "2024-04-05T12:53:29.863760Z",
     "iopub.status.idle": "2024-04-05T12:53:29.873119Z",
     "shell.execute_reply": "2024-04-05T12:53:29.871609Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.864135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deepspeed config for optimizer CPU offload\n",
    "\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 2e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 2e8,\n",
    "        \"contiguous_gradients\": True\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4550fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    \"\"\"Custom early stopping callback that can monitor loss or accuracy.\"\"\"\n",
    "    \n",
    "    def __init__(self, metric_name='eval_loss', early_stopping_patience=3, minimize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric_name (str): Metric to monitor, default 'eval_loss'.\n",
    "            early_stopping_patience (int): Number of checks with no improvement after which training will be stopped.\n",
    "            minimize (bool): Set to True if the metric should be minimized, False if it should be maximized.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_counter = 0\n",
    "        self.minimize = minimize\n",
    "        self.best_metric = float('inf') if minimize else float('-inf')\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        current_metric = kwargs['metrics'][self.metric_name]\n",
    "        \n",
    "        if (self.minimize and current_metric < self.best_metric) or (not self.minimize and current_metric > self.best_metric):\n",
    "            self.best_metric = current_metric\n",
    "            self.early_stopping_counter = 0\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "        \n",
    "        if self.early_stopping_counter >= self.early_stopping_patience:\n",
    "            control.should_training_stop = True\n",
    "            print(f'Stopping early! No improvement in {self.metric_name} for {self.early_stopping_patience} evaluation steps.')\n",
    "\n",
    "\n",
    "class MultiObjectiveEarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        # Extract current validation loss and accuracy\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "\n",
    "        # Check if current loss and accuracy improved significantly\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            # Update best scores and reset wait time\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            # If no improvement, increment the wait counter\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                # If wait exceeds the patience, stop training\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "class MultiObjectiveEarlyStoppingAndSaveCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience, min_delta=0.001, output_dir='./model_output', filename='finetuned_model'):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = float('-inf')\n",
    "        self.wait = 0\n",
    "        self.output_dir = output_dir\n",
    "        self.filename = filename\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        val_loss = kwargs['metrics']['eval_loss']\n",
    "        val_accuracy = kwargs['metrics']['eval_accuracy']\n",
    "        model = kwargs['model']\n",
    "\n",
    "        loss_improved = (self.best_val_loss - val_loss) > self.min_delta\n",
    "        accuracy_improved = (val_accuracy - self.best_val_accuracy) > self.min_delta\n",
    "\n",
    "        if loss_improved or accuracy_improved:\n",
    "            self.best_val_loss = min(self.best_val_loss, val_loss)\n",
    "            self.best_val_accuracy = max(self.best_val_accuracy, val_accuracy)\n",
    "            self.wait = 0\n",
    "            # Save the model as the best so far\n",
    "            self.save_finetuned_parameters(model, os.path.join(self.output_dir, self.filename))\n",
    "            print(f\"Saved improved model to {self.output_dir}/{self.filename}\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.early_stopping_patience:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping early at epoch {state.epoch}: No improvement in loss or accuracy for {self.early_stopping_patience} evaluations.\")\n",
    "                \n",
    "    def save_finetuned_parameters(self, model, filepath):\n",
    "        # Create a dictionary to hold the non-frozen parameters\n",
    "        non_frozen_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "        # Save only the finetuned parameters \n",
    "        torch.save(non_frozen_params, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb8bb11-79b0-4936-9099-f9f8ef97e105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T12:53:29.875565Z",
     "iopub.status.busy": "2024-04-05T12:53:29.875038Z",
     "iopub.status.idle": "2024-04-05T12:53:30.214710Z",
     "shell.execute_reply": "2024-04-05T12:53:30.213349Z",
     "shell.execute_reply.started": "2024-04-05T12:53:29.875495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "# Set random seeds for reproducibility of your trainings run\n",
    "def set_seeds(s):\n",
    "    torch.manual_seed(s)\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    set_seed(s)\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, min_dist=0.01):\n",
    "    umap_model = umap.UMAP(n_components=n_components)\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    data = {\"UMAP1\": embeddings[:, 0], \"UMAP2\": embeddings[:, 1], \"Label\": labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9)\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_new.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "# Main training fuction\n",
    "def train_per_protein(\n",
    "        train_dataset,         #training data\n",
    "        valid_dataset,         #validation data      \n",
    "        weight_decay,\n",
    "        warmup_pct,\n",
    "        num_labels= 2,    #1 for regression, >1 for classification\n",
    "    \n",
    "        # effective training batch size is batch * accum\n",
    "        # we recommend an effective batch size of 8 \n",
    "        batch= 4,         #for training\n",
    "        accum= 2,         #gradient accumulation\n",
    "    \n",
    "        val_batch = 16,   #batch size for evaluation\n",
    "        epochs=1,       #training epochs\n",
    "        lr= 3e-4,         #recommended learning rate\n",
    "        seed= 42,         #random seed\n",
    "        deepspeed=False,  #if gpu is large enough disable deepspeed for training speedup\n",
    "        gpu= 1,\n",
    "        dropout=0.5, #dropout rate\n",
    "         #L2 weight regularization\n",
    "        lora_rank=4,      #lora rank\n",
    "        lora_init_scale=0.01, #lora scaling rank\n",
    "        lora_scaling_rank=1,       #lora a\n",
    "        ):         #gpu selection (1 for first gpu)\n",
    "\n",
    "    # Set gpu device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n",
    "    \n",
    "    # Set all random seeds\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # load model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=dropout, lora_rank=lora_rank, lora_init_scale=lora_init_scale, lora_scaling_rank=lora_scaling_rank)\n",
    "\n",
    "    # Huggingface Trainer arguments\n",
    "    total_steps = epochs * len(train_dataset) // batch\n",
    "    warmup_steps = int(warmup_pct * total_steps)\n",
    "     \n",
    "    # Define TrainingArguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir='./results',              # where to save the model\n",
    "        evaluation_strategy='epoch',         # evaluation is done at the end of each epoch\n",
    "        logging_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        learning_rate=lr,                    # initial learning rate\n",
    "        per_device_train_batch_size=batch,   # batch size per device\n",
    "        gradient_accumulation_steps=accum,   # gradient accumulation steps\n",
    "        num_train_epochs=epochs,             # number of epochs to train\n",
    "        weight_decay=weight_decay,           # L2 weight regularization\n",
    "        warmup_steps=warmup_steps,           # 10% of total steps\n",
    "        load_best_model_at_end=False,         # load the best model at the end of training\n",
    "        seed=seed,                           # random seed\n",
    "        push_to_hub=False,                   # if you want to push model to the hub (Hugging Face Model Hub)\n",
    "        logging_dir='./logs',\n",
    "    )\n",
    "    # metric_for_best_model='eval_loss|accuracy'\n",
    "\n",
    "    # Metric definition for validation data\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "        # Check if predictions have the expected shape\n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "        # Now, compute the metric (e.g., accuracy)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        # Return the metric(s) as a dictionary\n",
    "        return {\"accuracy\": accuracy}\n",
    "    \n",
    "    # For minimizing loss\n",
    "    early_stopping_loss = EarlyStoppingCallback(metric_name='eval_loss', early_stopping_patience=3, minimize=True)\n",
    "\n",
    "    # For maximizing accuracy\n",
    "    early_stopping_accuracy = EarlyStoppingCallback(metric_name='eval_accuracy', early_stopping_patience=3, minimize=False)\n",
    "    # Trainer          \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[MultiObjectiveEarlyStoppingAndSaveCallback(\n",
    "            early_stopping_patience=3,\n",
    "            min_delta=0.001,\n",
    "            output_dir='./model_output',\n",
    "            filename='finetuned_model_all.pth'\n",
    "        )],\n",
    "    )    \n",
    "\n",
    "    def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "        embeddings = []\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "    \n",
    "        # Iterate over the sequences in batches\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            # Extract a batch of sequences\n",
    "            batch = sequences[i:i + batch_size]\n",
    "    \n",
    "            # Tokenize the batch using the specified tokenizer and convert to PyTorch tensors\n",
    "            inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                # Forward pass through the model to obtain outputs\n",
    "                outputs = model(**inputs)\n",
    "    \n",
    "            # Extract hidden states from the second-to-last layer (penultimate layer)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "    \n",
    "            # Take the embeddings from the second-to-last layer\n",
    "            embeddings_from_layer = hidden_states[:, 0, :]\n",
    "    \n",
    "            # Extend the list with the generated embeddings\n",
    "            embeddings.extend(embeddings_from_layer)\n",
    "    \n",
    "            print(f\"Batch {i // batch_size + 1}, Second-to-Last Layer Embeddings Shape: {embeddings_from_layer.shape}\")\n",
    "    \n",
    "        return np.array(embeddings)\n",
    "\n",
    "        \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "\n",
    "    # Get the best model\n",
    "    # model = trainer.model\n",
    "    # Ensure the best model is loaded\n",
    "    best_model_path = os.path.join('./model_output', 'finetuned_model_all.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        state_dict = torch.load(best_model_path)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "        \n",
    "    # Evaluate the best model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(eval_results)\n",
    "    \n",
    "    # Print the current learning rate\n",
    "    # current_lr = trainer.optimizer.param_groups[0]['lr']\n",
    "    # print(f\"Current learning rate: {current_lr}\")\n",
    "    \n",
    "    # valid_sequences = list(valid_dataset['sequence'])\n",
    "    # valid_embeddings = get_embeddings(model, tokenizer, valid_sequences)\n",
    "\n",
    "    # # Apply UMAP for dimensionality reduction\n",
    "    # umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "    # # Plot UMAP embeddings\n",
    "    # labels = list(valid_dataset['label'])\n",
    "    # plot_umap(umap_embeddings, labels)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return tokenizer, model, trainer.state.log_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b300952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Dataset creation\n",
    "def create_dataset(tokenizer,seqs,labels):\n",
    "    tokenized = tokenizer(seqs, max_length=1024, padding=True, truncation=True)\n",
    "    dataset = Dataset.from_dict(tokenized)\n",
    "    dataset = dataset.add_column(\"labels\", labels)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\") \n",
    "\n",
    "train_df = my_train\n",
    "valid_df = my_valid\n",
    "\n",
    "# Preprocess inputs\n",
    "# Replace uncommon AAs with \"X\"\n",
    "train_df[\"sequence\"]=train_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "# Add spaces between each amino acid for PT5 to correctly use them\n",
    "train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "\n",
    "# Create Datasets\n",
    "train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']))\n",
    "valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f20a2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm all_dephos_withLORA_datasetloader.sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcbe5f",
   "metadata": {},
   "source": [
    "lr 0.00044666038459356726\n",
    "\n",
    "batch 1\n",
    "\n",
    "accum 2\n",
    "\n",
    "dropout_rate 0.6001375640608175\n",
    "\n",
    "weight_decay 9.882084078511897e-05\n",
    "\n",
    "warmup_pct 0.133784608876732\n",
    "\n",
    "lora_rank 16\n",
    "\n",
    "lora_init_scale 0.011516737020968842\n",
    "\n",
    "lora_scaling_rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a57f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddfce510-da2b-4b95-9491-49f9ae8efb06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T13:08:03.246094Z",
     "iopub.status.busy": "2024-04-05T13:08:03.244479Z",
     "iopub.status.idle": "2024-04-05T14:04:37.162324Z",
     "shell.execute_reply": "2024-04-05T14:04:37.160516Z",
     "shell.execute_reply.started": "2024-04-05T13:08:03.246029Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 10440707.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3960' max='15840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3960/15840 15:15 < 45:46, 4.33 it/s, Epoch 5/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>0.579028</td>\n",
       "      <td>0.707071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.625200</td>\n",
       "      <td>0.681396</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.701400</td>\n",
       "      <td>1.006878</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>0.927061</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.623300</td>\n",
       "      <td>1.303009</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all.pth\n",
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 5.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.681396484375, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 5.6057, 'eval_samples_per_second': 70.642, 'eval_steps_per_second': 8.919, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model, history = train_per_protein(train_set, valid_set, num_labels=2, batch=1, accum=2, epochs=20, seed=42, lr=0.00044666038459356726, dropout=0.6001375640608175, weight_decay=9.882084078511897e-05, warmup_pct=0.133784608876732, lora_rank=16, lora_init_scale=0.011516737020968842, lora_scaling_rank=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ebf90f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 09:56:23,235] A new study created in RDB with name: all_dephos_withLORA_datasetloader_10epochs\n",
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 14372867.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='792' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 792/1980 11:44 < 17:39, 1.12 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.614700</td>\n",
       "      <td>0.535447</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.581900</td>\n",
       "      <td>0.616467</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.809600</td>\n",
       "      <td>0.639161</td>\n",
       "      <td>0.633838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.793500</td>\n",
       "      <td>0.925453</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all.pth\n",
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 4.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.5354472398757935, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 6.5852, 'eval_samples_per_second': 60.135, 'eval_steps_per_second': 7.593, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 10:09:02,614] Trial 0 finished with values: [0.5354472398757935, 0.7525252525252525] and parameters: {'seed': 8170, 'lr': 0.006050639457743683, 'batch': 1, 'accum': 8, 'dropout_rate': 0.41825631626835424, 'weight_decay': 1.6698993944467325e-05, 'warmup_pct': 0.06331661691130211, 'lora_rank': 24, 'lora_init_scale': 0.0014788640432854632, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6147, 'learning_rate': 0.0011956353419493506, 'epoch': 1.0, 'step': 198}, {'eval_loss': 0.5354472398757935, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 6.2884, 'eval_samples_per_second': 62.973, 'eval_steps_per_second': 7.951, 'epoch': 1.0, 'step': 198}, {'loss': 0.5819, 'learning_rate': 0.002391270683898701, 'epoch': 2.0, 'step': 396}, {'eval_loss': 0.6164668798446655, 'eval_accuracy': 0.6818181818181818, 'eval_runtime': 6.1038, 'eval_samples_per_second': 64.878, 'eval_steps_per_second': 8.192, 'epoch': 2.0, 'step': 396}, {'loss': 0.8096, 'learning_rate': 0.003586906025848052, 'epoch': 3.0, 'step': 594}, {'eval_loss': 0.6391605138778687, 'eval_accuracy': 0.6338383838383839, 'eval_runtime': 6.1036, 'eval_samples_per_second': 64.88, 'eval_steps_per_second': 8.192, 'epoch': 3.0, 'step': 594}, {'loss': 0.7935, 'learning_rate': 0.004782541367797402, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.9254530072212219, 'eval_accuracy': 0.5025252525252525, 'eval_runtime': 6.6176, 'eval_samples_per_second': 59.841, 'eval_steps_per_second': 7.556, 'epoch': 4.0, 'step': 792}, {'train_runtime': 711.7821, 'train_samples_per_second': 22.254, 'train_steps_per_second': 2.782, 'total_flos': 1579918434183936.0, 'train_loss': 0.6999101349801728, 'epoch': 4.0, 'step': 792}, {'eval_loss': 0.5354472398757935, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 6.5852, 'eval_samples_per_second': 60.135, 'eval_steps_per_second': 7.593, 'epoch': 4.0, 'step': 792}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 14372867.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3168' max='3960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3168/3960 14:37 < 03:39, 3.61 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.640800</td>\n",
       "      <td>0.553667</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.554900</td>\n",
       "      <td>0.527418</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.524100</td>\n",
       "      <td>0.612049</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.459100</td>\n",
       "      <td>0.682857</td>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.397600</td>\n",
       "      <td>0.840289</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.994213</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>1.150294</td>\n",
       "      <td>0.760101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>1.399005</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all.pth\n",
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "Loaded best model from ./model_output/finetuned_model_all.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8.0: No improvement in loss or accuracy for 3 evaluations.\n",
      "{'eval_loss': 0.8402891755104065, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 5.4268, 'eval_samples_per_second': 72.971, 'eval_steps_per_second': 9.214, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-09 10:24:25,854] Trial 1 finished with values: [0.8402891755104065, 0.7676767676767676] and parameters: {'seed': 8747, 'lr': 0.0002607016729621089, 'batch': 2, 'accum': 2, 'dropout_rate': 0.3710917592904933, 'weight_decay': 2.8698275038042456e-05, 'warmup_pct': 0.12417012549126784, 'lora_rank': 24, 'lora_init_scale': 0.010350558503285328, 'lora_scaling_rank': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History:  [{'loss': 0.6408, 'learning_rate': 0.00010502325787690246, 'epoch': 1.0, 'step': 396}, {'eval_loss': 0.5536674857139587, 'eval_accuracy': 0.7474747474747475, 'eval_runtime': 5.9146, 'eval_samples_per_second': 66.952, 'eval_steps_per_second': 8.454, 'epoch': 1.0, 'step': 396}, {'loss': 0.5549, 'learning_rate': 0.00021004651575380493, 'epoch': 2.0, 'step': 792}, {'eval_loss': 0.5274180173873901, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 5.4399, 'eval_samples_per_second': 72.795, 'eval_steps_per_second': 9.191, 'epoch': 2.0, 'step': 792}, {'loss': 0.5241, 'learning_rate': 0.00024274942473999527, 'epoch': 3.0, 'step': 1188}, {'eval_loss': 0.6120488047599792, 'eval_accuracy': 0.7272727272727273, 'eval_runtime': 5.407, 'eval_samples_per_second': 73.238, 'eval_steps_per_second': 9.247, 'epoch': 3.0, 'step': 1188}, {'loss': 0.4591, 'learning_rate': 0.0002080709354914245, 'epoch': 4.0, 'step': 1584}, {'eval_loss': 0.6828574538230896, 'eval_accuracy': 0.7525252525252525, 'eval_runtime': 5.4102, 'eval_samples_per_second': 73.195, 'eval_steps_per_second': 9.242, 'epoch': 4.0, 'step': 1584}, {'loss': 0.3976, 'learning_rate': 0.00017339244624285375, 'epoch': 5.0, 'step': 1980}, {'eval_loss': 0.8402891755104065, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 5.4217, 'eval_samples_per_second': 73.04, 'eval_steps_per_second': 9.222, 'epoch': 5.0, 'step': 1980}, {'loss': 0.3504, 'learning_rate': 0.000138713956994283, 'epoch': 6.0, 'step': 2376}, {'eval_loss': 0.994212806224823, 'eval_accuracy': 0.7575757575757576, 'eval_runtime': 5.4301, 'eval_samples_per_second': 72.927, 'eval_steps_per_second': 9.208, 'epoch': 6.0, 'step': 2376}, {'loss': 0.2698, 'learning_rate': 0.00010403546774571226, 'epoch': 7.0, 'step': 2772}, {'eval_loss': 1.1502937078475952, 'eval_accuracy': 0.76010101010101, 'eval_runtime': 5.4178, 'eval_samples_per_second': 73.092, 'eval_steps_per_second': 9.229, 'epoch': 7.0, 'step': 2772}, {'loss': 0.235, 'learning_rate': 6.93569784971415e-05, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 1.3990050554275513, 'eval_accuracy': 0.75, 'eval_runtime': 5.4062, 'eval_samples_per_second': 73.249, 'eval_steps_per_second': 9.249, 'epoch': 8.0, 'step': 3168}, {'train_runtime': 877.5033, 'train_samples_per_second': 18.051, 'train_steps_per_second': 4.513, 'total_flos': 3159836868367872.0, 'train_loss': 0.428956865060209, 'epoch': 8.0, 'step': 3168}, {'eval_loss': 0.8402891755104065, 'eval_accuracy': 0.7676767676767676, 'eval_runtime': 5.4268, 'eval_samples_per_second': 72.971, 'eval_steps_per_second': 9.214, 'epoch': 8.0, 'step': 3168}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 7000067.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3181' max='7920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3181/7920 12:10 < 18:08, 4.35 it/s, Epoch 4.02/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.758800</td>\n",
       "      <td>0.897085</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.981200</td>\n",
       "      <td>1.070228</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.741900</td>\n",
       "      <td>1.768323</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.711600</td>\n",
       "      <td>0.930327</td>\n",
       "      <td>0.502525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved model to ./model_output/finetuned_model_all.pth\n",
      "Saved improved model to ./model_output/finetuned_model_all.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-06-09 10:37:10,450] Trial 2 failed with parameters: {'seed': 804, 'lr': 0.005391566088749226, 'batch': 1, 'accum': 2, 'dropout_rate': 0.6319613174795322, 'weight_decay': 0.00046303557019925385, 'warmup_pct': 0.28907568120702287, 'lora_rank': 8, 'lora_init_scale': 0.03002909540108965, 'lora_scaling_rank': 4} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_476311/1933266111.py\", line 23, in objective\n",
      "    tokenizer, model, history = train_per_protein(\n",
      "  File \"/tmp/ipykernel_476311/3706598427.py\", line 153, in train_per_protein\n",
      "    trainer.train()\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py\", line 1555, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py\", line 1860, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py\", line 2725, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py\", line 2748, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_476311/3569959170.py\", line 145, in forward\n",
      "    outputs = self.encoder(\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\", line 1113, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\", line 694, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\", line 601, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\", line 573, in forward\n",
      "    attn_output = self.o(attn_output)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_476311/4060211885.py\", line 58, in forward\n",
      "    weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-09 10:37:10,570] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 54\u001b[0m\n\u001b[1;32m     50\u001b[0m directions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Set the direction to maximize the validation accuracy, can also be 'minimize'\u001b[39;00m\n\u001b[1;32m     51\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(directions\u001b[38;5;241m=\u001b[39mdirections,\n\u001b[1;32m     52\u001b[0m                             storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///all_dephos_withLORA_datasetloader_10epochs.sqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Specify the storage URL here.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m                             study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_dephos_withLORA_datasetloader_10epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust the number of trials based on your computational resources\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Analyzing results\u001b[39;00m\n\u001b[1;32m     57\u001b[0m pareto_front \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trials  \u001b[38;5;66;03m# Get the Pareto front (best non-dominated solutions)\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     19\u001b[0m lora_scaling_rank \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlora_scaling_rank\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Training and evaluation\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m tokenizer, model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_per_protein\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Fewer epochs for the trial runs\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_pct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_init_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_init_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_scaling_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_scaling_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Clear GPU memory\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHistory: \u001b[39m\u001b[38;5;124m\"\u001b[39m, history)\n",
      "Cell \u001b[0;32mIn[10], line 153\u001b[0m, in \u001b[0;36mtrain_per_protein\u001b[0;34m(train_dataset, valid_dataset, weight_decay, warmup_pct, num_labels, batch, accum, val_batch, epochs, lr, seed, deepspeed, gpu, dropout, lora_rank, lora_init_scale, lora_scaling_rank)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(embeddings)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Get the best model\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# model = trainer.model\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Ensure the best model is loaded\u001b[39;00m\n\u001b[1;32m    158\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model_output\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetuned_model_all.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1860\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:2725\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2724\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2725\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2728\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/trainer.py:2748\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2747\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2748\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2749\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2750\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 145\u001b[0m, in \u001b[0;36mT5EncoderForSimpleSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    134\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ):\n\u001b[1;32m    143\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 145\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    156\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(hidden_states)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1113\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1099\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1100\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         output_attentions,\n\u001b[1;32m   1111\u001b[0m     )\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1113\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:694\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    704\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:601\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    592\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    599\u001b[0m ):\n\u001b[1;32m    600\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 601\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    611\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:573\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    570\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m*\u001b[39m layer_head_mask\n\u001b[1;32m    572\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m unshape(torch\u001b[38;5;241m.\u001b[39mmatmul(attn_weights, value_states))  \u001b[38;5;66;03m# (batch_size, seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> 573\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m present_key_value_state \u001b[38;5;241m=\u001b[39m (key_states, value_states) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m use_cache) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (attn_output,) \u001b[38;5;241m+\u001b[39m (present_key_value_state,) \u001b[38;5;241m+\u001b[39m (position_bias,)\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 58\u001b[0m, in \u001b[0;36mLoRALinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_lora_b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_lora_a) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_rank\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank:\n\u001b[0;32m---> 58\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[43mweight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_a\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Set the seed for reproducibility in each trial\n",
    "    seed = trial.suggest_int('seed', 0, 10000)\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    # Hyperparameters to be optimized\n",
    "    # Updated to use suggest_float with log=True for loguniform distribution\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    batch = trial.suggest_categorical('batch', [1, 2, 4, 8])\n",
    "    accum = trial.suggest_categorical('accum', [2, 4, 8])\n",
    "    # Updated to use suggest_float for uniform distribution\n",
    "    dropout = trial.suggest_float('dropout_rate', 0.1, 0.9)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    warmup_pct = trial.suggest_float(\"warmup_pct\", 0.01, 0.3)  # Warmup percentage between 1% and 30%\n",
    "    lora_rank = trial.suggest_int('lora_rank', 4, 32, step=4)\n",
    "    lora_init_scale = trial.suggest_float('lora_init_scale', 1e-4, 1e-1, log=True)\n",
    "    lora_scaling_rank = trial.suggest_int('lora_scaling_rank', 1, 4)\n",
    "\n",
    "\n",
    "    # Training and evaluation\n",
    "    tokenizer, model, history = train_per_protein(\n",
    "        train_dataset=train_set, \n",
    "        valid_dataset=valid_set, \n",
    "        num_labels=2, \n",
    "        batch=batch, \n",
    "        accum=accum, \n",
    "        epochs=10,  # Fewer epochs for the trial runs\n",
    "        lr=lr,\n",
    "        dropout=dropout,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_pct=warmup_pct,\n",
    "        lora_rank=lora_rank,\n",
    "        lora_init_scale=lora_init_scale,\n",
    "        lora_scaling_rank=lora_scaling_rank,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    # torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"History: \", history)\n",
    "    \n",
    "    # Extract the last validation accuracy from the history\n",
    "    val_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry][-1]\n",
    "    val_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry][-1]\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "directions=['minimize', 'maximize']  # Set the direction to maximize the validation accuracy, can also be 'minimize'\n",
    "study = optuna.create_study(directions=directions,\n",
    "                            storage=\"sqlite:///all_dephos_withLORA_datasetloader_10epochs.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"all_dephos_withLORA_datasetloader_10epochs\")\n",
    "study.optimize(objective, n_trials=50)  # Adjust the number of trials based on your computational resources\n",
    "\n",
    "# Analyzing results\n",
    "pareto_front = study.best_trials  # Get the Pareto front (best non-dominated solutions)\n",
    "for trial in pareto_front:\n",
    "    print(f\"Loss: {trial.values[0]}, Accuracy: {trial.values[1]}\")  # Note the negation of accuracy\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# print(\"  Value: \", study.best_trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in study.best_trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a28d3c1-8e24-4437-a1d9-dda9cefccfd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:37.168731Z",
     "iopub.status.busy": "2024-04-05T14:04:37.168220Z",
     "iopub.status.idle": "2024-04-05T14:04:38.081706Z",
     "shell.execute_reply": "2024-04-05T14:04:38.080275Z",
     "shell.execute_reply.started": "2024-04-05T14:04:37.168675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get loss, val_loss, and the computed metric from history\n",
    "loss = [x['loss'] for x in history if 'loss' in x]\n",
    "val_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "\n",
    "# Truncate the longer list to the size of the shorter one\n",
    "min_length = min(len(loss), len(val_loss))\n",
    "loss = loss[:min_length]\n",
    "val_loss = val_loss[:min_length]\n",
    "\n",
    "# Get spearman (for regression) or accuracy value (for classification)\n",
    "if [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x] != []:\n",
    "    metric = [x['eval_spearmanr'] for x in history if 'eval_spearmanr' in x]\n",
    "else:\n",
    "    metric = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n",
    "\n",
    "epochs = [x['epoch'] for x in history if 'loss' in x]\n",
    "\n",
    "# Create a figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot loss and val_loss on the first y-axis\n",
    "line1 = ax1.plot(epochs, loss, label='train_loss')\n",
    "line2 = ax1.plot(epochs, val_loss, label='validation_loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# Plot the computed metric on the second y-axis\n",
    "#line3 = ax2.plot(epochs, metric, color='red', label='validation_metric')\n",
    "ax2.set_ylabel('Metric')\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Add grid lines\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Combine the lines from both y-axes and create a single legend\n",
    "lines = line1 + line2 \n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='lower left')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Training History for fine-tuning\")\n",
    "plt.savefig(f\"../Plots/Without_3rdline_Training_History_new.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccb1bbda-d70e-4b4c-a8d4-24600495171a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:38.083526Z",
     "iopub.status.busy": "2024-04-05T14:04:38.083162Z",
     "iopub.status.idle": "2024-04-05T14:04:38.092729Z",
     "shell.execute_reply": "2024-04-05T14:04:38.091278Z",
     "shell.execute_reply.started": "2024-04-05T14:04:38.083490Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model,filepath):\n",
    "# Saves all parameters that were changed during finetuning\n",
    "\n",
    "    # Create a dictionary to hold the non-frozen parameters\n",
    "    non_frozen_params = {}\n",
    "\n",
    "    # Iterate through all the model parameters\n",
    "    for param_name, param in model.named_parameters():\n",
    "        # If the parameter has requires_grad=True, add it to the dictionary\n",
    "        if param.requires_grad:\n",
    "            non_frozen_params[param_name] = param\n",
    "\n",
    "    # Save only the finetuned parameters \n",
    "    torch.save(non_frozen_params, filepath)\n",
    "\n",
    "    \n",
    "def load_model(filepath, num_labels=2):\n",
    "# Creates a new PT5 model and loads the finetuned weights from a file\n",
    "\n",
    "    # load a new model\n",
    "    model, tokenizer = PT5_classification_model(num_labels=num_labels, dropout=0.6001375640608175, lora_rank=16, lora_init_scale=0.011516737020968842, lora_scaling_rank=3)\n",
    "    \n",
    "    # Load the non-frozen parameters from the saved file\n",
    "    non_frozen_params = torch.load(filepath)\n",
    "\n",
    "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
    "    for param_name, param in model.named_parameters():\n",
    "        if param_name in non_frozen_params:\n",
    "            param.data = non_frozen_params[param_name].data\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98e915-c8a8-433a-870a-c6dcaf191e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:04:38.095733Z",
     "iopub.status.busy": "2024-04-05T14:04:38.095313Z",
     "iopub.status.idle": "2024-04-05T14:05:24.016922Z",
     "shell.execute_reply": "2024-04-05T14:05:24.014560Z",
     "shell.execute_reply.started": "2024-04-05T14:04:38.095698Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def save_model(model, filepath):\n",
    "#     torch.save(model.state_dict(), filepath)\n",
    "\n",
    "# save_model(model, \"../finetuned_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa9b15",
   "metadata": {},
   "source": [
    "lr 0.00044666038459356726\n",
    "\n",
    "batch 1\n",
    "\n",
    "accum 2\n",
    "\n",
    "dropout_rate 0.6001375640608175\n",
    "\n",
    "weight_decay 9.882084078511897e-05\n",
    "\n",
    "warmup_pct 0.133784608876732\n",
    "\n",
    "lora_rank 16\n",
    "\n",
    "lora_init_scale 0.011516737020968842\n",
    "\n",
    "lora_scaling_rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c97fa52-3aea-42e8-b72f-c4bb84808576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:05:24.020589Z",
     "iopub.status.busy": "2024-04-05T14:05:24.019788Z",
     "iopub.status.idle": "2024-04-05T14:08:10.428922Z",
     "shell.execute_reply": "2024-04-05T14:08:10.426805Z",
     "shell.execute_reply.started": "2024-04-05T14:05:24.020524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 10440707.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_all.pth\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c20e75-5f40-4ca1-9579-5df49b738fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:10.432313Z",
     "iopub.status.busy": "2024-04-05T14:08:10.431835Z",
     "iopub.status.idle": "2024-04-05T14:08:19.838631Z",
     "shell.execute_reply": "2024-04-05T14:08:19.836988Z",
     "shell.execute_reply.started": "2024-04-05T14:08:10.432274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have identical weights\n"
     ]
    }
   ],
   "source": [
    "# Put both models to the same device\n",
    "model=model.to(\"cpu\")\n",
    "model_reload=model_reload.to(\"cpu\")\n",
    "\n",
    "# Iterate through the parameters of the two models and compare the data\n",
    "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
    "    if not torch.equal(param1.data, param2.data):\n",
    "        print(\"Models have different weights\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Models have identical weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a62aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = from_pretrained(\"model_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50b8a403-e7c5-4912-9c7a-f404c060c32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.841225Z",
     "iopub.status.busy": "2024-04-05T14:08:19.840752Z",
     "iopub.status.idle": "2024-04-05T14:08:19.864579Z",
     "shell.execute_reply": "2024-04-05T14:08:19.862993Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.841173Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|Q8WUI4|HDAC7_HUMAN%342%358</td>\n",
       "      <td>ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|Q13950|RUNX2_HUMAN%416%432</td>\n",
       "      <td>THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q15796|SMAD2_HUMAN%229%245</td>\n",
       "      <td>DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P05787|K2C8_HUMAN%416%432</td>\n",
       "      <td>TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q92736|RYR2_HUMAN%2798%2814</td>\n",
       "      <td>MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name                           sequence  label\n",
       "0   sp|Q8WUI4|HDAC7_HUMAN%342%358  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
       "1   sp|Q13950|RUNX2_HUMAN%416%432  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
       "2   sp|Q15796|SMAD2_HUMAN%229%245  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
       "3    sp|P05787|K2C8_HUMAN%416%432  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
       "4  sp|Q92736|RYR2_HUMAN%2798%2814  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "sequences = []\n",
    "\n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_ST.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "    \n",
    "local_fasta_path = '../src/input_datasets/test_Pos_Neg_Y.fasta'\n",
    "\n",
    "# Load FASTA file using Biopython\n",
    "for record in SeqIO.parse(local_fasta_path, \"fasta\"):\n",
    "    # Split the description to extract label\n",
    "    description_parts = record.description.split(\"%\")\n",
    "    label = int(description_parts[-1].split(\"LABEL=\")[1])  # Extracting the numeric part of the label\n",
    "    sequences.append([record.name, str(record.seq), label])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(sequences, columns=[\"name\", \"sequence\", \"label\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2d18716-fd26-49fe-9ba4-b84c936a364c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.867076Z",
     "iopub.status.busy": "2024-04-05T14:08:19.866598Z",
     "iopub.status.idle": "2024-04-05T14:08:19.887853Z",
     "shell.execute_reply": "2024-04-05T14:08:19.886215Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.867024Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sequence  label\n",
      "0  ERLSGSGLHWPLSRTRSEPLPPSATAPPPPGPM      1\n",
      "1  THYHTYLPPPYPGSSQSQSGPFQTSSTPYLYYG      1\n",
      "2  DGETSDQQLNQSMDTGSPAELSPTTLSPVNHSL      1\n",
      "3  TSGYAGGLSSAYGGLTSPGLSYSLGSSFGSGAG      1\n",
      "4  MALYNRTRRISQTSQVSVDAAHGYSPRAIDMSN      1\n"
     ]
    }
   ],
   "source": [
    "my_test=df[[\"sequence\", \"label\"]]\n",
    "\n",
    "print(my_test.head(5))\n",
    "\n",
    "'''\n",
    "my_test[\"sequence\"]=my_test[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n",
    "my_test['sequence']=my_test.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n",
    "'''\n",
    "\n",
    "#Using .loc ensures that you are modifying the original DataFrame rather than a view of it, which helps avoid the SettingWithCopyWarning.\n",
    "# Replace characters in the \"sequence\" column\n",
    "my_test.loc[:, \"sequence\"] = my_test[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "\n",
    "# Convert each sequence to a space-separated string\n",
    "my_test.loc[:, 'sequence'] = my_test.apply(lambda row: \" \".join(row[\"sequence\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eee8fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = sequence.split()\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "my_test['middle_char'] = my_test['sequence'].apply(get_middle_char)\n",
    "\n",
    "# Split the DataFrame\n",
    "my_test_S = my_test[my_test['middle_char'] == 'S'].drop(columns=['middle_char'])\n",
    "my_test_T = my_test[my_test['middle_char'] == 'T'].drop(columns=['middle_char'])\n",
    "my_test_Y = my_test[my_test['middle_char'] == 'Y'].drop(columns=['middle_char'])\n",
    "my_test_ST = my_test[my_test['middle_char'].isin(['S', 'T'])].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcd9ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0dff151-a667-4717-af18-401818bc4c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:19.889951Z",
     "iopub.status.busy": "2024-04-05T14:08:19.889601Z",
     "iopub.status.idle": "2024-04-05T14:08:22.641629Z",
     "shell.execute_reply": "2024-04-05T14:08:22.639919Z",
     "shell.execute_reply.started": "2024-04-05T14:08:19.889916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:00<00:00,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+-----------+\n",
      "|      MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+==========+===============+===============+============+===========+\n",
      "| 0.719681 |      0.884615 |      0.833333 |       0.86 |  0.955128 |\n",
      "+----------+---------------+---------------+------------+-----------+\n",
      "[[23  3]\n",
      " [ 4 20]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ce2f51a-887c-4684-82b9-22ea5fffd334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T14:08:22.647264Z",
     "iopub.status.busy": "2024-04-05T14:08:22.646121Z",
     "iopub.status.idle": "2024-04-05T14:08:23.557189Z",
     "shell.execute_reply": "2024-04-05T14:08:23.555594Z",
     "shell.execute_reply.started": "2024-04-05T14:08:22.647207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo0AAAIjCAYAAABmuyHTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABATElEQVR4nO3df3zN9f//8fvZcDbMRvaz/FYoNUJLfr8t412yVKLeb5sf/fCm0lDp/U6iWolIRL0rU1L0g5QiJqSQH63Uu7xtpuXD5keYDcfazvePvs670zbPndlxZq/b9XN5XS7t9eP5epzzudT7cbk/X6/nsTmdTqcAAACAs/DzdQEAAACo/GgaAQAAYETTCAAAACOaRgAAABjRNAIAAMCIphEAAABGNI0AAAAwomkEAACAEU0jAAAAjGgaAZzVrl271KtXLwUHB8tms2np0qUVOv6ePXtks9mUkpJSoeNeyLp3767u3bv7ugwAcEPTCFwAMjIydM8996hp06YKCAhQnTp11KlTJ73wwgs6efKkV++dkJCgHTt26KmnntKbb76p9u3be/V+51NiYqJsNpvq1KlT4ve4a9cu2Ww22Ww2TZ061ePx9+3bp4kTJyotLa0CqgUA36rm6wIAnN3y5ct12223yW63a/DgwWrdurVOnz6tDRs2aNy4cfrhhx/0yiuveOXeJ0+e1MaNG/XPf/5To0aN8so9GjVqpJMnT6p69epeGd+kWrVqOnHihD766CMNGDDA7dhbb72lgIAAnTp1qlxj79u3T0888YQaN26sNm3alPm6zz77rFz3AwBvomkEKrHMzEwNHDhQjRo10po1axQZGek6NnLkSKWnp2v58uVeu//BgwclSSEhIV67h81mU0BAgNfGN7Hb7erUqZPefvvtYk3jwoULdcMNN+j9998/L7WcOHFCNWvWVI0aNc7L/QDAE0xPA5XYlClTlJeXp9dee82tYTyjefPmeuCBB1x///bbb5o8ebKaNWsmu92uxo0b69FHH5XD4XC7rnHjxrrxxhu1YcMGXXPNNQoICFDTpk31xhtvuM6ZOHGiGjVqJEkaN26cbDabGjduLOn3ad0z//xHEydOlM1mc9u3atUqde7cWSEhIapdu7ZatGihRx991HW8tGca16xZoy5duqhWrVoKCQlRv3799OOPP5Z4v/T0dCUmJiokJETBwcEaMmSITpw4UfoX+yd33HGHPv30Ux09etS1b8uWLdq1a5fuuOOOYuf/+uuvGjt2rK688krVrl1bderUUZ8+ffTtt9+6zlm7dq06dOggSRoyZIhrmvvM5+zevbtat26tbdu2qWvXrqpZs6bre/nzM40JCQkKCAgo9vnj4uJUt25d7du3r8yfFQDKi6YRqMQ++ugjNW3aVNddd12Zzh8+fLgmTJigq6++WtOnT1e3bt2UnJysgQMHFjs3PT1dt956q66//npNmzZNdevWVWJion744QdJUv/+/TV9+nRJ0qBBg/Tmm29qxowZHtX/ww8/6MYbb5TD4dCkSZM0bdo03XTTTfryyy/Pet3q1asVFxenAwcOaOLEiUpKStJXX32lTp06ac+ePcXOHzBggI4fP67k5GQNGDBAKSkpeuKJJ8pcZ//+/WWz2fTBBx+49i1cuFAtW7bU1VdfXez83bt3a+nSpbrxxhv1/PPPa9y4cdqxY4e6devmauBatWqlSZMmSZLuvvtuvfnmm3rzzTfVtWtX1ziHDx9Wnz591KZNG82YMUM9evQosb4XXnhBoaGhSkhIUGFhoSTp5Zdf1meffaYXX3xRUVFRZf6sAFBuTgCV0rFjx5ySnP369SvT+WlpaU5JzuHDh7vtHzt2rFOSc82aNa59jRo1ckpyrl+/3rXvwIEDTrvd7hwzZoxrX2ZmplOS87nnnnMbMyEhwdmoUaNiNTz++OPOP/5nZfr06U5JzoMHD5Za95l7zJs3z7WvTZs2zrCwMOfhw4dd+7799lunn5+fc/DgwcXuN3ToULcxb775ZudFF11U6j3/+Dlq1arldDqdzltvvdXZs2dPp9PpdBYWFjojIiKcTzzxRInfwalTp5yFhYXFPofdbndOmjTJtW/Lli3FPtsZ3bp1c0pyzp07t8Rj3bp1c9u3cuVKpyTnk08+6dy9e7ezdu3azvj4eONnBICKQtIIVFK5ubmSpKCgoDKd/8knn0iSkpKS3PaPGTNGkoo9+3j55ZerS5curr9DQ0PVokUL7d69u9w1/9mZZyE//PBDFRUVlema/fv3Ky0tTYmJiapXr55r/1VXXaXrr7/e9Tn/6N5773X7u0uXLjp8+LDrOyyLO+64Q2vXrlV2drbWrFmj7OzsEqempd+fg/Tz+/0/n4WFhTp8+LBr6n379u1lvqfdbteQIUPKdG6vXr10zz33aNKkSerfv78CAgL08ssvl/leAHCuaBqBSqpOnTqSpOPHj5fp/J9//ll+fn5q3ry52/6IiAiFhITo559/dtvfsGHDYmPUrVtXR44cKWfFxd1+++3q1KmThg8frvDwcA0cOFCLFy8+awN5ps4WLVoUO9aqVSsdOnRI+fn5bvv//Fnq1q0rSR59lr/+9a8KCgrSokWL9NZbb6lDhw7FvsszioqKNH36dF166aWy2+2qX7++QkND9d133+nYsWNlvufFF1/s0UsvU6dOVb169ZSWlqaZM2cqLCyszNcCwLmiaQQqqTp16igqKkrff/+9R9f9+UWU0vj7+5e43+l0lvseZ563OyMwMFDr16/X6tWr9fe//13fffedbr/9dl1//fXFzj0X5/JZzrDb7erfv7/mz5+vJUuWlJoyStLTTz+tpKQkde3aVQsWLNDKlSu1atUqXXHFFWVOVKXfvx9PfPPNNzpw4IAkaceOHR5dCwDniqYRqMRuvPFGZWRkaOPGjcZzGzVqpKKiIu3atcttf05Ojo4ePep6E7oi1K1b1+1N4zP+nGZKkp+fn3r27Knnn39e//nPf/TUU09pzZo1+vzzz0sc+0ydO3fuLHbsp59+Uv369VWrVq1z+wCluOOOO/TNN9/o+PHjJb48dMZ7772nHj166LXXXtPAgQPVq1cvxcbGFvtOytrAl0V+fr6GDBmiyy+/XHfffbemTJmiLVu2VNj4AGBC0whUYg899JBq1aql4cOHKycnp9jxjIwMvfDCC5J+n16VVOwN5+eff16SdMMNN1RYXc2aNdOxY8f03Xffufbt379fS5YscTvv119/LXbtmUWu/7wM0BmRkZFq06aN5s+f79aEff/99/rss89cn9MbevToocmTJ2vWrFmKiIgo9Tx/f/9iKea7776r//u//3Pbd6a5LanB9tTDDz+srKwszZ8/X88//7waN26shISEUr9HAKhoLO4NVGLNmjXTwoULdfvtt6tVq1Zuvwjz1Vdf6d1331ViYqIkKTo6WgkJCXrllVd09OhRdevWTV9//bXmz5+v+Pj4UpdzKY+BAwfq4Ycf1s0336z7779fJ06c0Jw5c3TZZZe5vQgyadIkrV+/XjfccIMaNWqkAwcO6KWXXtIll1yizp07lzr+c889pz59+qhjx44aNmyYTp48qRdffFHBwcGaOHFihX2OP/Pz89O//vUv43k33nijJk2apCFDhui6667Tjh079NZbb6lp06Zu5zVr1kwhISGaO3eugoKCVKtWLcXExKhJkyYe1bVmzRq99NJLevzxx11LAM2bN0/du3fXY489pilTpng0HgCUB0kjUMnddNNN+u6773Trrbfqww8/1MiRI/XII49oz549mjZtmmbOnOk699VXX9UTTzyhLVu2aPTo0VqzZo3Gjx+vd955p0Jruuiii7RkyRLVrFlTDz30kObPn6/k5GT17du3WO0NGzbU66+/rpEjR2r27Nnq2rWr1qxZo+Dg4FLHj42N1YoVK3TRRRdpwoQJmjp1qq699lp9+eWXHjdc3vDoo49qzJgxWrlypR544AFt375dy5cvV4MGDdzOq169uubPny9/f3/de++9GjRokNatW+fRvY4fP66hQ4eqbdu2+uc//+na36VLFz3wwAOaNm2aNm3aVCGfCwDOxub05ElxAAAAWBJJIwAAAIxoGgEAAGBE0wgAAAAjmkYAAAAY0TQCAADAiKYRAAAARjSNAAAAMKqSvwgT2HaUr0sA4CVHtszydQkAvCTAh12JN3uHk99Ujf9ukTQCAADAqEomjQAAAB6xkaOZ0DQCAADYbL6uoNKjrQYAAIARSSMAAADT00Z8QwAAADCiaQQAALDZvLd5IDk5WR06dFBQUJDCwsIUHx+vnTt3uo7/+uuvuu+++9SiRQsFBgaqYcOGuv/++3Xs2LGzjpuYmCibzea29e7d26PaaBoBAAAqiXXr1mnkyJHatGmTVq1apYKCAvXq1Uv5+fmSpH379mnfvn2aOnWqvv/+e6WkpGjFihUaNmyYcezevXtr//79ru3tt9/2qDaeaQQAAKgkzzSuWLHC7e+UlBSFhYVp27Zt6tq1q1q3bq3333/fdbxZs2Z66qmn9Le//U2//fabqlUrvbWz2+2KiIgod22V4xsCAACoohwOh3Jzc902h8NRpmvPTDvXq1fvrOfUqVPnrA2jJK1du1ZhYWFq0aKFRowYocOHD5f9Q4imEQAAwKvPNCYnJys4ONhtS05ONpZUVFSk0aNHq1OnTmrdunWJ5xw6dEiTJ0/W3XfffdaxevfurTfeeEOpqal69tlntW7dOvXp00eFhYVl/4qcTqezzGdfIPjtaaDq4rengarLp789fe3DXhv76LpJxZJFu90uu91+1utGjBihTz/9VBs2bNAll1xS7Hhubq6uv/561atXT8uWLVP16tXLXNPu3bvVrFkzrV69Wj179izTNSSNAAAAXmS321WnTh23zdQwjho1Sh9//LE+//zzEhvG48ePq3fv3goKCtKSJUs8ahglqWnTpqpfv77S09PLfA0vwgAAAFSSnxF0Op267777tGTJEq1du1ZNmjQpdk5ubq7i4uJkt9u1bNkyBQQEeHyfvXv36vDhw4qMjCzzNSSNAAAAlcTIkSO1YMECLVy4UEFBQcrOzlZ2drZOnjwp6feG8cwSPK+99ppyc3Nd5/zx+cSWLVtqyZIlkqS8vDyNGzdOmzZt0p49e5Samqp+/fqpefPmiouLK3NtJI0AAACVZMmdOXPmSJK6d+/utn/evHlKTEzU9u3btXnzZklS8+bN3c7JzMxU48aNJUk7d+50vXnt7++v7777TvPnz9fRo0cVFRWlXr16afLkycZp8j+iaQQAAKgkTO8nd+/e3XjOn8cJDAzUypUrz7k2mkYAAIBK8kxjZVY5slgAAABUaiSNAAAAleSZxsqMphEAAIDpaSPaagAAABiRNAIAADA9bcQ3BAAAACOSRgAAAJJGI74hAAAAGJE0AgAA+PH2tAlJIwAAAIxIGgEAAHim0YimEQAAgMW9jWirAQAAYETSCAAAwPS0Ed8QAAAAjEgaAQAAeKbRiKQRAAAARiSNAAAAPNNoxDcEAAAAI5JGAAAAnmk0omkEAABgetqIbwgAAABGJI0AAABMTxuRNAIAAMCIpBEAAIBnGo34hgAAAGBE0ggAAMAzjUYkjQAAADAiaQQAAOCZRiOaRgAAAJpGI74hAAAAGJE0AgAA8CKMEUkjAAAAjEgaAQAAeKbRiG8IAAAARiSNAAAAPNNoRNIIAAAAI5JGAAAAnmk0omkEAABgetqIthoAAABGJI0AAMDybCSNRiSNAAAAMCJpBAAAlkfSaEbSCAAAACOSRgAAAIJGI5JGAAAAGNE0AgAAy7PZbF7bPJGcnKwOHTooKChIYWFhio+P186dO93OOXXqlEaOHKmLLrpItWvX1i233KKcnJyzjut0OjVhwgRFRkYqMDBQsbGx2rVrl0e10TQCAADLqyxN47p16zRy5Eht2rRJq1atUkFBgXr16qX8/HzXOQ8++KA++ugjvfvuu1q3bp327dun/v37n3XcKVOmaObMmZo7d642b96sWrVqKS4uTqdOnSr7d+R0Op0efZoLQGDbUb4uAYCXHNkyy9clAPCSAB++aRF0+3yvjX18UUK5rz148KDCwsK0bt06de3aVceOHVNoaKgWLlyoW2+9VZL0008/qVWrVtq4caOuvfbaYmM4nU5FRUVpzJgxGjt2rCTp2LFjCg8PV0pKigYOHFimWkgaAQCA5XkzaXQ4HMrNzXXbHA5Hmeo6duyYJKlevXqSpG3btqmgoECxsbGuc1q2bKmGDRtq48aNJY6RmZmp7Oxst2uCg4MVExNT6jUloWkEAADwouTkZAUHB7ttycnJxuuKioo0evRoderUSa1bt5YkZWdnq0aNGgoJCXE7Nzw8XNnZ2SWOc2Z/eHh4ma8pCUvuAAAAy/Pm4t7jx49XUlKS2z673W68buTIkfr++++1YcMGb5XmEZJGAAAAL7Lb7apTp47bZmoaR40apY8//liff/65LrnkEtf+iIgInT59WkePHnU7PycnRxERESWOdWb/n9+wPts1JaFpBAAAsHlx84DT6dSoUaO0ZMkSrVmzRk2aNHE73q5dO1WvXl2pqamufTt37lRWVpY6duxY4phNmjRRRESE2zW5ubnavHlzqdeUhKYRAACgkhg5cqQWLFighQsXKigoSNnZ2crOztbJkycl/f4Cy7Bhw5SUlKTPP/9c27Zt05AhQ9SxY0e3N6dbtmypJUuWSPp96n306NF68skntWzZMu3YsUODBw9WVFSU4uPjy1wbzzQCAADL8+YzjZ6YM2eOJKl79+5u++fNm6fExERJ0vTp0+Xn56dbbrlFDodDcXFxeumll9zO37lzp+vNa0l66KGHlJ+fr7vvvltHjx5V586dtWLFCgUEBJS5NtZpBHBBYZ1GoOry5TqNIXcu8NrYR9/6m9fGPp9IGgEAgOVVlqSxMqNpBAAAlkfTaMaLMAAAADAiaQQAAJZH0mhG0ggAAAAjkkYAAACCRiOSRgAAABiRNAIAAMvjmUYzkkYAAAAYkTQCAADLI2k0o2kEAACWR9NoxvQ0AAAAjEgaAQAACBqNSBoBAABgRNIIAAAsj2cazUgaAQAAYETSCAAALI+k0YykEQAAAEYkjQAAwPJIGs1oGgEAgOXRNJoxPQ0AAAAjkkYAAACCRiOSRgAAABiRNAIAAMvjmUYzkkYAAAAYkTQCAADLI2k0I2kEAACAEUkjAACwPJJGM5pGAAAAekYjpqcBAABgRNIIAAAsj+lpM5JGAAAAGJE0AgAAyyNpNCNpBAAAgBFJIy4IY4f2UvxfonVZ43CddBRo87e79c8XPtSunw+4znnxnwP1l5gWigwNVt5JhzZ9m6l/vfCh/rsnx4eVA/DU4ncWavGit7Xv//5PktSs+aW6Z8Q/1LlLNx9XhqqMpNGMpBEXhC5XN9fcRevVbfBU3ThilqpV89fHc0apZkAN1znf/PiL7p64QG36P6mb/jFbNptNH780Un5+/IcAuJCEhUfogQfH6u13P9DCxe/rmphr9cCokUpP3+Xr0gBLszmdTqevi6hogW1H+boEeFn9urX1y5pnFDtsur7cnlHiOa0vjdKWxY/q8r4Tlbn30HmuEN5yZMssX5cAH+jS8Ro9OHac+t9ym69LgRcF+HD+s8no5V4bO3PGDV4b+3zy6fT0oUOH9Prrr2vjxo3Kzs6WJEVEROi6665TYmKiQkNDfVkeKrE6tQMkSUeOnSjxeM2AGhp807XK3HtIe7OPnM/SAFSgwsJCfbZyhU6ePKHo6La+LgdVGZNSRj5rGrds2aK4uDjVrFlTsbGxuuyyyyRJOTk5mjlzpp555hmtXLlS7du3P+s4DodDDofDbZ+zqFA2P3+v1Q7fstlsem7srfrqmwz9J2O/27G7b+uip0bHq3ZNu3ZmZuuGEbNU8FuhjyoFUF67/rtTf79joE6fdqhmzZqaPnO2mjVv7uuyAEvz2fT0tddeq+joaM2dO7fYw6dOp1P33nuvvvvuO23cuPGs40ycOFFPPPGE2z7/8A6qHnlNhdeMyuGFR29XXKfL1XPIdP3fgaNux+rUDlBovSBF1K+j0YNjFRUarL8MeV6O07/5plhUOKanraHg9Gnt379feXnHteqzlVry/rt6LWUBjWMV58vp6aZJn3ht7N3P/9VrY59PPmsaAwMD9c0336hly5YlHv/pp5/Utm1bnTx58qzjlJQ0hnV5mKSxipr+8G26sftVih02Qz/vO3zWc6tX89f+9VP0j0kLtXjFtvNUIbyNptGa7h6WqEsaNNSEiZN8XQq8iKaxcvPZ/3siIiL09ddfl9o0fv311woPDzeOY7fbZbfb3fbRMFZN0x++TTf9JVq97nrB2DBKv09j22RTjeqsLAVc6IqKilRw+rSvy0AVxpI7Zj77X9OxY8fq7rvv1rZt29SzZ09Xg5iTk6PU1FT9+9//1tSpU31VHiqZGeMH6PY+7XXbg68oL/+Uwi8KkiQdyzulU44CNb74It0a106pG3/UoSN5ujg8RGOG9NJJR4FWbvjBx9UD8MQL06epc5euioiM1In8fH2y/GNt3fK15rzymq9LAyzNZ03jyJEjVb9+fU2fPl0vvfSSCgt/f1nB399f7dq1U0pKigYMGOCr8lDJ3DOgqyRp1auj3fbfNeFNLfhosxynf1Onts006o7uqlunpg4cPq4N29PVI3GaDh7J80HFAMrr118P61/jH9bBgwdUOyhIl13WQnNeeU0dr+vk69JQhRE0mlWKdRoLCgp06NDv6+jVr19f1atXP6fxWKcRqLp4phGounz5TGPzsZ96bez0qX28Nvb5VCke9qpevboiIyN9XQYAALAonmk0qxRNIwAAgC/RM5rx29MAAACVyPr169W3b19FRUXJZrNp6dKlbsdtNluJ23PPPVfqmBMnTix2fmkr2JSGpBEAAFheZZqezs/PV3R0tIYOHar+/fsXO75/v/uvoX366acaNmyYbrnllrOOe8UVV2j16tWuv6tV86wNpGkEAACoRPr06aM+fUp/eSYiIsLt7w8//FA9evRQ06ZNzzputWrVil3rCaanAQCA5dls3tscDodyc3Pdtj//ml155eTkaPny5Ro2bJjx3F27dikqKkpNmzbVnXfeqaysLI/uRdMIAADgRcnJyQoODnbbkpOTK2Ts+fPnKygoqMRp7D+KiYlRSkqKVqxYoTlz5igzM1NdunTR8ePHy3wvpqcBAIDl+fl575nG8ePHKykpyW3fn38Cubxef/113XnnnQoICDjreX+c7r7qqqsUExOjRo0aafHixWVKKSWaRgAAAK+y2+0V1iT+0RdffKGdO3dq0aJFHl8bEhKiyy67TOnp6WW+hulpAABged58ptFbXnvtNbVr107R0dEeX5uXl6eMjAyPflyFphEAAFheaWsfVsTmqby8PKWlpSktLU2SlJmZqbS0NLcXV3Jzc/Xuu+9q+PDhJY7Rs2dPzZr1v59dHTt2rNatW6c9e/boq6++0s033yx/f38NGjSozHUxPQ0AAFCJbN26VT169HD9feZ5yISEBKWkpEiS3nnnHTmdzlKbvoyMDB06dMj19969ezVo0CAdPnxYoaGh6ty5szZt2qTQ0NAy12VzOp3OcnyeSi2w7ShflwDAS45smWU+CcAFKcCHUdaVj63y2tg7Jl/vtbHPJ6anAQAAYMT0NAAAsLzK9DOClRVJIwAAAIxIGgEAgOWRNJqRNAIAAMCIpBEAAFgeQaMZTSMAALA8pqfNmJ4GAACAEUkjAACwPIJGM5JGAAAAGJE0AgAAy+OZRjOSRgAAABiRNAIAAMsjaDQjaQQAAIARSSMAALA8nmk0I2kEAACAEUkjAACwPIJGM5pGAABgeUxPmzE9DQAAACOSRgAAYHkEjWYkjQAAADAiaQQAAJbHM41mJI0AAAAwImkEAACWR9BoRtIIAAAAI5JGAABgeTzTaEbTCAAALI+e0YzpaQAAABiRNAIAAMtjetqMpBEAAABGJI0AAMDySBrNSBoBAABgRNIIAAAsj6DRjKQRAAAARiSNAADA8nim0YymEQAAWB49oxnT0wAAADAiaQQAAJbH9LQZSSMAAACMSBoBAIDlETSakTQCAADAiKQRAABYnh9RoxFJIwAAAIxIGgEAgOURNJrRNAIAAMtjyR0zpqcBAABgRNIIAAAsz4+g0YikEQAAoBJZv369+vbtq6ioKNlsNi1dutTteGJiomw2m9vWu3dv47izZ89W48aNFRAQoJiYGH399dce1UXTCAAALO/PTVhFbp7Kz89XdHS0Zs+eXeo5vXv31v79+13b22+/fdYxFy1apKSkJD3++OPavn27oqOjFRcXpwMHDpS5LqanAQAAKpE+ffqoT58+Zz3HbrcrIiKizGM+//zzuuuuuzRkyBBJ0ty5c7V8+XK9/vrreuSRR8o0BkkjAACwPJvNe5vD4VBubq7b5nA4zqnetWvXKiwsTC1atNCIESN0+PDhUs89ffq0tm3bptjYWNc+Pz8/xcbGauPGjWW+J00jAACAFyUnJys4ONhtS05OLvd4vXv31htvvKHU1FQ9++yzWrdunfr06aPCwsISzz906JAKCwsVHh7utj88PFzZ2dllvi/T0wAAwPJs8t7r0+PHj1dSUpLbPrvdXu7xBg4c6PrnK6+8UldddZWaNWumtWvXqmfPnuUe14SmEQAAWJ43l9yx2+3n1CSaNG3aVPXr11d6enqJTWP9+vXl7++vnJwct/05OTkePRfJ9DQAAMAFbO/evTp8+LAiIyNLPF6jRg21a9dOqamprn1FRUVKTU1Vx44dy3wfmkYAAGB5lWnJnby8PKWlpSktLU2SlJmZqbS0NGVlZSkvL0/jxo3Tpk2btGfPHqWmpqpfv35q3ry54uLiXGP07NlTs2bNcv2dlJSkf//735o/f75+/PFHjRgxQvn5+a63qcuC6WkAAIBKZOvWrerRo4fr7zPPQyYkJGjOnDn67rvvNH/+fB09elRRUVHq1auXJk+e7DYFnpGRoUOHDrn+vv3223Xw4EFNmDBB2dnZatOmjVasWFHs5ZizsTmdTmcFfL5KJbDtKF+XAMBLjmyZZT4JwAUpwIdRVvyrW7029tLh7b029vnE9DQAAACMmJ4GAACW51eOZw+thqQRAAAARiSNAADA8ggazWgaAQCA5ZVnaRyrYXoaAAAARiSNAADA8ggazUgaAQAAYETSCAAALI8ld8xIGgEAAGBE0ggAACyPnNGMpBEAAABGJI0AAMDyWKfRjKYRAABYnh89oxHT0wAAADAiaQQAAJbH9LQZSSMAAACMSBoBAIDlETSakTQCAADAiKQRAABYHs80mpWpaVy2bFmZB7zpppvKXQwAAAAqpzI1jfHx8WUazGazqbCw8FzqAQAAOO9Yp9GsTE1jUVGRt+sAAADwGaanzXgRBgAAAEblehEmPz9f69atU1ZWlk6fPu127P7776+QwgAAAM4XckYzj5vGb775Rn/961914sQJ5efnq169ejp06JBq1qypsLAwmkYAAIAqyOPp6QcffFB9+/bVkSNHFBgYqE2bNunnn39Wu3btNHXqVG/UCAAA4FV+NpvXtqrC46YxLS1NY8aMkZ+fn/z9/eVwONSgQQNNmTJFjz76qDdqBAAAgI953DRWr15dfn6/XxYWFqasrCxJUnBwsH755ZeKrQ4AAOA8sNm8t1UVHj/T2LZtW23ZskWXXnqpunXrpgkTJujQoUN688031bp1a2/UCAAAAB/zOGl8+umnFRkZKUl66qmnVLduXY0YMUIHDx7UK6+8UuEFAgAAeJvNZvPaVlV4nDS2b9/e9c9hYWFasWJFhRYEAACAyqdc6zQCAABUJVUoEPQaj5vGJk2anDVq3b179zkVBAAAcL5VpaVxvMXjpnH06NFufxcUFOibb77RihUrNG7cuIqqCwAAAJWIx03jAw88UOL+2bNna+vWredcEAAAwPlG0Gjm8dvTpenTp4/ef//9ihoOAAAAlUiFvQjz3nvvqV69ehU1HAAAwHlTlZbG8ZZyLe79xy/W6XQqOztbBw8e1EsvvVShxQEAAKBy8Lhp7Nevn1vT6Ofnp9DQUHXv3l0tW7as0OLKa9+XL/i6BABeEva3N3xdAgAvyX1nsM/uXWHP61VhHjeNEydO9EIZAAAAqMw8bqz9/f114MCBYvsPHz4sf3//CikKAADgfOJnBM08ThqdTmeJ+x0Oh2rUqHHOBQEAAJxvflWnt/OaMjeNM2fOlPR7J/7qq6+qdu3armOFhYVav359pXmmEQAAABWrzE3j9OnTJf2eNM6dO9dtKrpGjRpq3Lix5s6dW/EVAgAAeBlJo1mZm8bMzExJUo8ePfTBBx+obt26XisKAAAAlYvHL8J8/vnnNIwAAKBKqUwvwqxfv159+/ZVVFSUbDabli5d6jpWUFCghx9+WFdeeaVq1aqlqKgoDR48WPv27TvrmBMnTixWl6ePFXrcNN5yyy169tlni+2fMmWKbrvtNk+HAwAAwB/k5+crOjpas2fPLnbsxIkT2r59ux577DFt375dH3zwgXbu3KmbbrrJOO4VV1yh/fv3u7YNGzZ4VJfHb0+vX7++xLUa+/Tpo2nTpnk6HAAAgM9Vpmca+/Tpoz59+pR4LDg4WKtWrXLbN2vWLF1zzTXKyspSw4YNSx23WrVqioiIKHddHieNeXl5JS6tU716deXm5pa7EAAAgKrI4XAoNzfXbXM4HBU2/rFjx2Sz2RQSEnLW83bt2qWoqCg1bdpUd955p7Kysjy6j8dN45VXXqlFixYV2//OO+/o8ssv93Q4AAAAn7PZvLclJycrODjYbUtOTq6Quk+dOqWHH35YgwYNUp06dUo9LyYmRikpKVqxYoXmzJmjzMxMdenSRcePHy/zvTyenn7sscfUv39/ZWRk6C9/+YskKTU1VQsXLtR7773n6XAAAAA+5+fFX24ZP368kpKS3PbZ7fZzHregoEADBgyQ0+nUnDlzznruH6e7r7rqKsXExKhRo0ZavHixhg0bVqb7edw09u3bV0uXLtXTTz+t9957T4GBgYqOjtaaNWtUr149T4cDAACo0ux2e4U0iX90pmH8+eeftWbNmrOmjCUJCQnRZZddpvT09DJf4/H0tCTdcMMN+vLLL5Wfn6/du3drwIABGjt2rKKjo8szHAAAgE/5eXGraGcaxl27dmn16tW66KKLPB4jLy9PGRkZioyMLPM15f4s69evV0JCgqKiojRt2jT95S9/0aZNm8o7HAAAAPR7Q5eWlqa0tDRJv//ASlpamrKyslRQUKBbb71VW7du1VtvvaXCwkJlZ2crOztbp0+fdo3Rs2dPzZo1y/X32LFjtW7dOu3Zs0dfffWVbr75Zvn7+2vQoEFlrsuj6ens7GylpKTotddeU25urgYMGCCHw6GlS5fyEgwAALhgefGRRo9t3bpVPXr0cP195nnIhIQETZw4UcuWLZMktWnTxu26zz//XN27d5ckZWRk6NChQ65je/fu1aBBg3T48GGFhoaqc+fO2rRpk0JDQ8tcV5mbxr59+2r9+vW64YYbNGPGDPXu3Vv+/v783jQAAEAF6t69u5xOZ6nHz3bsjD179rj9/c4775xrWWVvGj/99FPdf//9GjFihC699NJzvjEAAEBl4c23p6uKMj/TuGHDBh0/flzt2rVTTEyMZs2a5RZ7AgAAoOoqc9N47bXX6t///rf279+ve+65R++8846ioqJUVFSkVatWebQ4JAAAQGXizcW9qwqP356uVauWhg4dqg0bNmjHjh0aM2aMnnnmGYWFhZXpx7IBAAAqGz+b97aq4pyWD2rRooWmTJmivXv36u23366omgAAAFDJePyLMCXx9/dXfHy84uPjK2I4AACA84oXYcy8sVA5AAAAqpgKSRoBAAAuZASNZiSNAAAAMCJpBAAAlleV3nL2FpJGAAAAGJE0AgAAy7OJqNGEphEAAFge09NmTE8DAADAiKQRAABYHkmjGUkjAAAAjEgaAQCA5dlY3duIpBEAAABGJI0AAMDyeKbRjKQRAAAARiSNAADA8nik0YymEQAAWJ4fXaMR09MAAAAwImkEAACWx4swZiSNAAAAMCJpBAAAlscjjWYkjQAAADAiaQQAAJbnJ6JGE5JGAAAAGJE0AgAAy+OZRjOaRgAAYHksuWPG9DQAAACMSBoBAIDl8TOCZiSNAAAAMCJpBAAAlkfQaEbSCAAAACOSRgAAYHk802hG0ggAAAAjkkYAAGB5BI1mNI0AAMDymHo14zsCAACAEUkjAACwPBvz00YkjQAAADAiaQQAAJZHzmhG0ggAAAAjkkYAAGB5LO5tRtIIAAAAI5pGAABgeTYvbp5av369+vbtq6ioKNlsNi1dutTtuNPp1IQJExQZGanAwEDFxsZq165dxnFnz56txo0bKyAgQDExMfr66689qoumEQAAWJ7N5r3NU/n5+YqOjtbs2bNLPD5lyhTNnDlTc+fO1ebNm1WrVi3FxcXp1KlTpY65aNEiJSUl6fHHH9f27dsVHR2tuLg4HThwoMx12ZxOp9PjT1PJHTlR6OsSAHhJo6Fv+boEAF6S+85gn9174fa9Xhv7jqsvKfe1NptNS5YsUXx8vKTfU8aoqCiNGTNGY8eOlSQdO3ZM4eHhSklJ0cCBA0scJyYmRh06dNCsWbMkSUVFRWrQoIHuu+8+PfLII2WqhaQRAABYns1m89rmcDiUm5vrtjkcjnLVmZmZqezsbMXGxrr2BQcHKyYmRhs3bizxmtOnT2vbtm1u1/j5+Sk2NrbUa0pC0wgAAOBFycnJCg4OdtuSk5PLNVZ2drYkKTw83G1/eHi469ifHTp0SIWFhR5dUxKW3AEAAJbnzRRt/PjxSkpKcttnt9u9eEfvoGkEAADwIrvdXmFNYkREhCQpJydHkZGRrv05OTlq06ZNidfUr19f/v7+ysnJcdufk5PjGq8smJ4GAACW581nGitSkyZNFBERodTUVNe+3Nxcbd68WR07dizxmho1aqhdu3Zu1xQVFSk1NbXUa0pC0ggAAFCJ5OXlKT093fV3Zmam0tLSVK9ePTVs2FCjR4/Wk08+qUsvvVRNmjTRY489pqioKNcb1pLUs2dP3XzzzRo1apQkKSkpSQkJCWrfvr2uueYazZgxQ/n5+RoyZEiZ66JpBAAAlleZfkRw69at6tGjh+vvM89DJiQkKCUlRQ899JDy8/N199136+jRo+rcubNWrFihgIAA1zUZGRk6dOiQ6+/bb79dBw8e1IQJE5Sdna02bdpoxYoVxV6OORvWaQRwQWGdRqDq8uU6je+m7fPa2Le1ifLa2OcTSSMAALC8in72sCqiaQQAAJbHm8FmfEcAAAAwImkEAACWx/S0GUkjAAAAjEgaAQCA5ZEzmpE0AgAAwIikEQAAWB6PNJqRNAIAAMCIpBEAAFieH081GtE0AgAAy2N62ozpaQAAABiRNAIAAMuzMT1tRNIIAAAAI5JGAABgeTzTaEbSCAAAACOSRgAAYHksuWNG0ggAAAAjkkYAAGB5PNNoRtMIAAAsj6bRjOlpAAAAGJE0AgAAy2NxbzOSRgAAABiRNAIAAMvzI2g0ImkEAACAEUkjAACwPJ5pNCNpBAAAgBFJIwAAsDzWaTSjaQQAAJbH9LQZ09MAAAAwImkEAACWx5I7ZiSNAAAAMCJpBAAAlsczjWYkjQAAADAiaUSV8Mbr/9ZLL07X7Xf8XQ+OG+/rcgB4IKlfa910TUNdGhWsU6d/0+b/HtSEhduVvj/XdY69up+e/lt73XJdE9Wo7qfUb/cp6fXNOnjslA8rR1XCkjtmJI244P3nhx1a8v5iNb+0ha9LAVAOnVuF65XPdqrnY5+o31OrVd3fT0sfjVVN+/9yjeTBHdS7XQMNnrFOf31ipSLr1tRbSd19VzRgQTSNuKCdOJGvxx99SOMfe0JBder4uhwA5dD/mVQtXJehn/Ye0/dZR3TvnC/VMLS22jSpJ0mqE1hdg3s016NvbtH6H7KVlvmrRsz9Ute2CFOH5vV9XD2qCpsXt6qCphEXtKnJT6pTl2665trrfF0KgAoSXLOGJOlI3mlJUpumF6lGNX+t3bHfdc6ufbnKOpinay4L9UmNqHr8bDavbVVFpW4af/nlFw0dOvSs5zgcDuXm5rptDofjPFUIX1q14hPt/Ok/GnHfg74uBUAFsdmkZxI6aONPB/Tj3qOSpPCQQDkKCnXsRIHbuQePnVJYSKAPqgSsqVI3jb/++qvmz59/1nOSk5MVHBzstk2f+sx5qhC+kpO9X88/l6yJT02R3W73dTkAKsi0oTFq1SBEQ2au93UpsBimp818+vb0smXLznp89+7dxjHGjx+vpKQkt30nCnkpvKr76ccfdOTXw0q841bXvsLCQqVt36r3Fi3U+s1p8vf392GFADw1dcg16n31JeozcaX2/XrCtT/n6EnZq/sruGZ1t7QxNDhAB46e9EWpgCX5tLuKj4+XzWaT0+ks9Ryb4VkAu91eLGkqPFFYIfWh8mp/TUe99e6HbvuefPyfatSkif6eOJyGEbjATB1yjW7s0FA3TFqpnw/muR1L231Yp38rVLfWkVr2dZYkqXlkHTUMra2v/3vQF+WiKqpKkaCX+LRpjIyM1EsvvaR+/fqVeDwtLU3t2rU7z1XhQlCrVi01a36p276AwEAFB4cU2w+gcnt+aIxu7dREg6Z+ruMnCxQWHCBJyj1RoFMFhco9WaA3Pk/X039vryN5Dh0/WaDnhlyjzf89oC3ph3xcPWAdPm0a27Vrp23btpXaNJpSSADAhW94r9/XWP308Ti3/ffO+VIL12VIksa/sUXOIqcWJHVXjWp+Sv1un5Je23zea0XVxc8ImtmcPuzKvvjiC+Xn56t3794lHs/Pz9fWrVvVrVs3j8Y9wvQ0UGU1GvqWr0sA4CW57wz22b03Zxzz2tgxzYK9Nvb55NOksUuXLmc9XqtWLY8bRgAAAE9VoeUUvYbXjAEAgOXRM5pV6nUaAQAArKRx48ay2WzFtpEjR5Z4fkpKSrFzAwICvFIbSSMAAEAliRq3bNmiwsL/vZvx/fff6/rrr9dtt91W6jV16tTRzp07XX+blissL5pGAACASiI01P331J955hk1a9bsrO942Gw2RUREeLs0pqcBAABsXvw/h8Oh3Nxct83hcBhrOn36tBYsWKChQ4eeNT3My8tTo0aN1KBBA/Xr108//PBDRX41LjSNAAAAXpScnKzg4GC3LTk52Xjd0qVLdfToUSUmJpZ6TosWLfT666/rww8/1IIFC1RUVKTrrrtOe/furcBP8DufrtPoLazTCFRdrNMIVF2+XKdx255cr43dOtJeLFks6WeQ/ywuLk41atTQRx99VOZ7FRQUqFWrVho0aJAmT55crnpLwzONAAAAXlSWBvHPfv75Z61evVoffPCBR9dVr15dbdu2VXp6ukfXlQXT0wAAwPJsXtzKY968eQoLC9MNN9zg0XWFhYXasWOHIiMjy3nn0pE0AgAAVJIldySpqKhI8+bNU0JCgqpVc2/VBg8erIsvvtj1TOSkSZN07bXXqnnz5jp69Kiee+45/fzzzxo+fHiF10XTCAAAUImsXr1aWVlZGjp0aLFjWVlZ8vP730TxkSNHdNdddyk7O1t169ZVu3bt9NVXX+nyyy+v8Lp4EQbABYUXYYCqy5cvwnzz83Gvjd22UZDXxj6feKYRAAAARkxPAwAAy/PSL+9VKSSNAAAAMCJpBAAAlkfQaEbSCAAAACOSRgAAAKJGI5pGAABgeTa6RiOmpwEAAGBE0ggAACyPJXfMSBoBAABgRNIIAAAsj6DRjKQRAAAARiSNAAAARI1GJI0AAAAwImkEAACWxzqNZiSNAAAAMCJpBAAAlsc6jWY0jQAAwPLoGc2YngYAAIARSSMAAABRoxFJIwAAAIxIGgEAgOWx5I4ZSSMAAACMSBoBAIDlseSOGUkjAAAAjEgaAQCA5RE0mtE0AgAA0DUaMT0NAAAAI5JGAABgeSy5Y0bSCAAAACOSRgAAYHksuWNG0ggAAAAjkkYAAGB5BI1mJI0AAAAwImkEAAAgajSiaQQAAJbHkjtmTE8DAADAiKQRAABYHkvumJE0AgAAwIikEQAAWB5BoxlJIwAAAIxIGgEAAIgajUgaAQAAYETSCAAALI91Gs1oGgEAgOWx5I4Z09MAAAAwImkEAACWR9BoRtIIAABQSUycOFE2m81ta9my5Vmveffdd9WyZUsFBAToyiuv1CeffOKV2mgaAQCA5dls3ts8dcUVV2j//v2ubcOGDaWe+9VXX2nQoEEaNmyYvvnmG8XHxys+Pl7ff//9OXwbJaNpBAAAqESqVaumiIgI11a/fv1Sz33hhRfUu3dvjRs3Tq1atdLkyZN19dVXa9asWRVeF00jAACAbF7bHA6HcnNz3TaHw1FqJbt27VJUVJSaNm2qO++8U1lZWaWeu3HjRsXGxrrti4uL08aNG8vxHZwdTSMAAIAXJScnKzg42G1LTk4u8dyYmBilpKRoxYoVmjNnjjIzM9WlSxcdP368xPOzs7MVHh7uti88PFzZ2dkV/jl4exoAAFieN9dpHD9+vJKSktz22e32Es/t06eP65+vuuoqxcTEqFGjRlq8eLGGDRvmvSLLgKYRAABYnjeX3LHb7aU2iSYhISG67LLLlJ6eXuLxiIgI5eTkuO3LyclRREREue53NkxPAwAAVFJ5eXnKyMhQZGRkicc7duyo1NRUt32rVq1Sx44dK7wWmkYAAGB5lWXJnbFjx2rdunXas2ePvvrqK918883y9/fXoEGDJEmDBw/W+PHjXec/8MADWrFihaZNm6affvpJEydO1NatWzVq1KiK/HokMT0NAABQaezdu1eDBg3S4cOHFRoaqs6dO2vTpk0KDQ2VJGVlZcnP73+Z33XXXaeFCxfqX//6lx599FFdeumlWrp0qVq3bl3htdmcTqezwkf1sSMnCn1dAgAvaTT0LV+XAMBLct8Z7LN7Zx8r8NrYEcHVvTb2+cT0NAAAAIyYngYAAPDm69NVBEkjAAAAjEgaAQCA5RE0mtE0AgAAy/PmL8JUFUxPAwAAwIikEQAAWJ6NCWojkkYAAAAYkTQCAAAQNBqRNAIAAMCIpBEAAFgeQaMZSSMAAACMSBoBAIDlsU6jGU0jAACwPJbcMWN6GgAAAEYkjQAAwPKYnjYjaQQAAIARTSMAAACMaBoBAABgxDONAADA8nim0YykEQAAAEYkjQAAwPJYp9GMphEAAFge09NmTE8DAADAiKQRAABYHkGjGUkjAAAAjEgaAQAAiBqNSBoBAABgRNIIAAAsjyV3zEgaAQAAYETSCAAALI91Gs1IGgEAAGBE0ggAACyPoNGMphEAAICu0YjpaQAAABiRNAIAAMtjyR0zkkYAAAAYkTQCAADLY8kdM5JGAAAAGNmcTqfT10UA5eVwOJScnKzx48fLbrf7uhwAFYh/v4HKhaYRF7Tc3FwFBwfr2LFjqlOnjq/LAVCB+PcbqFyYngYAAIARTSMAAACMaBoBAABgRNOIC5rdbtfjjz/OQ/JAFcS/30DlwoswAAAAMCJpBAAAgBFNIwAAAIxoGgEAAGBE0wgAAAAjmkZc0GbPnq3GjRsrICBAMTEx+vrrr31dEoBztH79evXt21dRUVGy2WxaunSpr0sCIJpGXMAWLVqkpKQkPf7449q+fbuio6MVFxenAwcO+Lo0AOcgPz9f0dHRmj17tq9LAfAHLLmDC1ZMTIw6dOigWbNmSZKKiorUoEED3XfffXrkkUd8XB2AimCz2bRkyRLFx8f7uhTA8kgacUE6ffq0tm3bptjYWNc+Pz8/xcbGauPGjT6sDACAqommERekQ4cOqbCwUOHh4W77w8PDlZ2d7aOqAACoumgaAQAAYETTiAtS/fr15e/vr5ycHLf9OTk5ioiI8FFVAABUXTSNuCDVqFFD7dq1U2pqqmtfUVGRUlNT1bFjRx9WBgBA1VTN1wUA5ZWUlKSEhAS1b99e11xzjWbMmKH8/HwNGTLE16UBOAd5eXlKT093/Z2Zmam0tDTVq1dPDRs29GFlgLWx5A4uaLNmzdJzzz2n7OxstWnTRjNnzlRMTIyvywJwDtauXasePXoU25+QkKCUlJTzXxAASTSNAAAAKAOeaQQAAIARTSMAAACMaBoBAABgRNMIAAAAI5pGAAAAGNE0AgAAwIimEQAAAEY0jQAAADCiaQRQaSUmJio+Pt71d/fu3TV69OjzXsfatWtls9l09OjR835vAKgsaBoBeCwxMVE2m002m001atRQ8+bNNWnSJP32229eve8HH3ygyZMnl+lcGj0AqFjVfF0AgAtT7969NW/ePDkcDn3yyScaOXKkqlevrvHjx7udd/r0adWoUaNC7lmvXr0KGQcA4DmSRgDlYrfbFRERoUaNGmnEiBGKjY3VsmXLXFPKTz31lKKiotSiRQtJ0i+//KIBAwYoJCRE9erVU79+/bRnzx7XeIWFhUpKSlJISIguuugiPfTQQ3I6nW73/PP0tMPh0MMPP6wGDRrIbrerefPmeu2117Rnzx716NFDklS3bl3ZbDYlJiZKkoqKipScnKwmTZooMDBQ0dHReu+999zu88knn+iyyy5TYGCgevTo4VYnAFgVTSOAChEYGKjTp09LklJTU7Vz506tWrVKH3/8sQoKChQXF6egoCB98cUX+vLLL1W7dm317t3bdc20adOUkpKi119/XRs2bNCvv/6qJUuWnPWegwcP1ttvv62ZM2fqxx9/1Msvv6zatWurQYMGev/99yVJO3fu1P79+/XCCy9IkpKTk/XGG29o7ty5+uGHH/Tggw/qb3/7m9atWyfp9+a2f//+6tu3r9LS0jR8+HA98sgj3vraAOCCwfQ0gHPidDqVmpqqlStX6r777tPBgwdVq1Ytvfrqq65p6QULFqioqEivvvqqbDabJGnevHkKCQnR2rVr1atXL82YMUPjx49X//79JUlz587VypUrS73vf//7Xy1evFirVq1SbGysJKlp06au42emssPCwhQSEiLp92Ty6aef1urVq9WxY0fXNRs2bNDLL7+sbt26ac6cOWrWrJmmTZsmSWrRooV27NihZ599tgK/NQC48NA0AiiXjz/+WLVr11ZBQYGKiop0xx13aOLEiRo5cqSuvPJKt+cYv/32W6WnpysoKMhtjFOnTikjI0PHjh3T/v37FRMT4zpWrVo1tW/fvtgU9RlpaWny9/dXt27dylxzenq6Tpw4oeuvv95t/+nTp9W2bVtJ0o8//uhWhyRXgwkAVkbTCKBcevTooTlz5qhGjRqKiopStWr/+89JrVq13M7Ny8tTu3bt9NZbbxUbJzQ0tFz3DwwM9PiavLw8SdLy5ct18cUXux2z2+3lqgMArIKmEUC51KpVS82bNy/TuVdffbUWLVqksLAw1alTp8RzIiMjtXnzZnXt2lWS9Ntvv2nbtm26+uqrSzz/yiuvVFFRkdatW+eanv6jM0lnYWGha9/ll18uu92urKysUhPKVq1aadmyZW77Nm3aZP6QAFDF8SIMAK+78847Vb9+ffXr109ffPGFMjMztXbtWt1///3au3evJOmBBx7QM888o6VLl+qnn37SP/7xj7Ousdi4cWMlJCRo6NChWrp0qWvMxYsXS5IaNWokm82mjz/+WAcPHlReXp6CgoI0duxYPfjgg5o/f74yMjK0fft2vfjii5o/f74k6d5779WuXbs0btw47dy5UwsXLlRKSoq3vyIAqPRoGgF4Xc2aNbV+/Xo1bNhQ/fv3V6tWrTRs2DCdOnXKlTyOGTNGf//735WQkKCOHTsqKChIN99881nHnTNnjm699Vb94x//UMuWLXXXXXcpPz9fknTxxRfriSee0COPPKLw8HCNGjVKkjR58mQ99thjSk5OVqtWrdS7d28tX75cTZo0kSQ1bNhQ77//vpYuXaro6GjNnTtXTz/9tBe/HQC4MNicpT1lDgAAAPx/JI0AAAAwomkEAACAEU0jAAAAjGgaAQAAYETTCAAAACOaRgAAABjRNAIAAMCIphEAAABGNI0AAAAwomkEAACAEU0jAAAAjP4fT5li/oVkvlwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['0', '1']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"../Plots/Confusion_matrix_for_dephos_new.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07603226",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = my_test_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5e0d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 28/28 [00:04<00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------------+------------+-----------+\n",
      "|     MCC |   Specificity |   Sensitivity |   Accuracy |   ROC-AUC |\n",
      "+=========+===============+===============+============+===========+\n",
      "| 0.64577 |      0.830357 |      0.815315 |    0.82287 |  0.869591 |\n",
      "+---------+---------------+---------------+------------+-----------+\n",
      "[[186  38]\n",
      " [ 41 181]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_reload.to(device)\n",
    "\n",
    "# create Dataset\n",
    "test_set=create_dataset(tokenizer,list(my_test['sequence']),list(my_test['label']))\n",
    "# make compatible with torch DataLoader\n",
    "test_set = test_set.with_format(\"torch\", device=device)\n",
    "\n",
    "# Create a dataloader for the test dataset\n",
    "test_dataloader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_reload.eval()\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "raw_logits = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # add batch results (logits) to predictions\n",
    "        raw_logits += model_reload(input_ids, attention_mask=attention_mask).logits.tolist()\n",
    "        labels += batch[\"labels\"].tolist()\n",
    "\n",
    "# Convert logits to predictions\n",
    "raw_logits = np.array(raw_logits)\n",
    "predictions = np.argmax(raw_logits, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "mcc = matthews_corrcoef(labels, predictions)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "roc_auc = roc_auc_score(labels, raw_logits[:, 1])  # Assuming binary classification, adjust accordingly\n",
    "\n",
    "\n",
    "metrics_table = [\n",
    "    [\"MCC\", \"Specificity\", \"Sensitivity\", \"Accuracy\", \"ROC-AUC\"],\n",
    "    [mcc, specificity, sensitivity, accuracy, roc_auc]\n",
    "]\n",
    "\n",
    "print(tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5528dc-6e06-456d-920f-8f05055d0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "def apply_umap(embeddings, n_components=2, n_neighbors=5, min_dist=0.01, metric='euclidean'):\n",
    "    umap_model = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric\n",
    "    )\n",
    "    umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "    return umap_embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_umap(embeddings, labels):\n",
    "    df = pd.DataFrame({\n",
    "        \"UMAP1\": embeddings[:, 0],\n",
    "        \"UMAP2\": embeddings[:, 1],\n",
    "        \"Label\": labels\n",
    "    })\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = sns.scatterplot(\n",
    "        x=\"UMAP1\", y=\"UMAP2\", hue=\"Label\", data=df, palette={0: \"blue\", 1: \"magenta\"}, s=50, alpha=0.9\n",
    "    )\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.legend(title='Label', bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    plt.savefig(\"../Plots/UMAP_Visualization_of_Embeddings_ST.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_embeddings(model, tokenizer, sequences, batch_size=32, device=\"cuda\"):\n",
    "    embeddings = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch = sequences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.hidden_states[-2].detach().cpu().numpy()\n",
    "            embeddings.extend(hidden_states[:, 0, :])\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(sequences) // batch_size + 1}\")\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7718f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the middle character\n",
    "def get_middle_char(sequence):\n",
    "    chars = list(sequence)\n",
    "    middle_index = len(chars) // 2\n",
    "    return chars[middle_index]\n",
    "\n",
    "valid_df = df\n",
    "\n",
    "# Apply the function to get the middle characters\n",
    "valid_df['middle_char'] = valid_df['sequence'].apply(get_middle_char)\n",
    "\n",
    "valid_df = valid_df[valid_df['middle_char'] == 'T'].drop(columns=['middle_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a162964f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sp|Q9GZM8|NDEL1_HUMAN%203%219</td>\n",
       "      <td>CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>sp|Q8N163|CCAR2_HUMAN%438%454</td>\n",
       "      <td>EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>sp|P10636-8|TAU_HUMAN%196%212</td>\n",
       "      <td>GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>sp|Q02241|KIF23_HUMAN%434%450</td>\n",
       "      <td>QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sp|Q04206|TF65_HUMAN%419%435</td>\n",
       "      <td>QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>sp|Q76N33|STALP_MOUSE%326%342</td>\n",
       "      <td>ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>sp|P49790|NU153_HUMAN%1098%1114</td>\n",
       "      <td>FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>sp|Q8NFC6|BD1L1_HUMAN%2789%2805</td>\n",
       "      <td>DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>sp|Q5T6F2|UBAP2_HUMAN%514%530</td>\n",
       "      <td>SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>sp|Q9H040|SPRTN_HUMAN%265%281</td>\n",
       "      <td>NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name                           sequence  label\n",
       "180    sp|Q9GZM8|NDEL1_HUMAN%203%219  CEKMDSAVQASLSLPATPVGKGTENTFPSPKAI      1\n",
       "181    sp|Q8N163|CCAR2_HUMAN%438%454  EWEALCQQKAAEAAPPTQEAQGETEPTEQAPDA      1\n",
       "182    sp|P10636-8|TAU_HUMAN%196%212  GYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAV      1\n",
       "183    sp|Q02241|KIF23_HUMAN%434%450  QEVEVARPVDKAICGLTPGRRYRNQPRGPVGNE      1\n",
       "184     sp|Q04206|TF65_HUMAN%419%435  QAVAPPAPKPTQAGEGTLSEALLQLQFDDEDLG      1\n",
       "..                               ...                                ...    ...\n",
       "441    sp|Q76N33|STALP_MOUSE%326%342  ENVEELFNVQDQHGLLTLGWIHTHPTQTAFLSS      0\n",
       "442  sp|P49790|NU153_HUMAN%1098%1114  FVLGRTEEKQQEPVTSTSLVFGKKADNEEPKCQ      0\n",
       "443  sp|Q8NFC6|BD1L1_HUMAN%2789%2805  DVLDSRIETAQRQCPETEPHDTKEENSRDLEEL      0\n",
       "444    sp|Q5T6F2|UBAP2_HUMAN%514%530  SKIPASAVEMPGSADVTGLNVQFGALEFGSEPS      0\n",
       "445    sp|Q9H040|SPRTN_HUMAN%265%281  NLPSPGKLITSHAINKTQDLLNQNHSANAVRPN      0\n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a44d9187-1ac5-4e36-89a0-8f827a7f0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/finetune-dephos/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtT5_Classfier\n",
      "Trainable Parameter: 1209193475.0\n",
      "ProtT5_LoRA_Classfier\n",
      "Trainable Parameter: 3559427.0\n",
      "\n",
      "Processed batch 1/3\n",
      "Processed batch 2/3\n",
      "Processed batch 3/3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_df = my_valid\n",
    "\n",
    "# tokenizer, model_reload = load_model(\"../finetuned_model.pth\", num_labels=2)\n",
    "tokenizer, model_reload = load_model(\"model_output/finetuned_model_ST.pth\",num_labels=2)\n",
    "\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].str.replace('|'.join([\"O\", \"B\", \"U\", \"Z\"]), \"X\", regex=True)\n",
    "valid_df[\"sequence\"] = valid_df[\"sequence\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "valid_sequences = list(valid_df['sequence'])\n",
    "valid_embeddings = get_embeddings(model_reload, tokenizer, valid_sequences)\n",
    "\n",
    "umap_embeddings = apply_umap(valid_embeddings)\n",
    "\n",
    "\n",
    "labels = list(valid_df['label'])\n",
    "\n",
    "plot_umap(umap_embeddings, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f029bcf-42ef-4476-b575-3c14adb71b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da0e6c-e921-493b-9304-8ba9aad07d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
